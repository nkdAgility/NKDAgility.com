- FrontMatter:
    title: 'The Evidence-Based Management Guide: Improving Value Delivery under Conditions of Uncertainty'
    description: Evidence-Based Management (EBM) is an empirical approach that helps organizations to continuously improve customer outcomes, organizational capabilities, and business results under conditions of uncertainty.
    ResourceId: Rv0ZjvwYVy5
    ResourceImport: false
    ResourceType: guides
    ResourceContentOrigin: Human
    resourceTypes: guide
    layout: guide
    aliesses:
    - /learn/agile-delivery-kit/guides/evidence-based-management-guide-2020
    - practices/evidence-based-management-guide-2020
    - practices/evidence-based-management-guide-2020.html
    - guides/evidence-based-management-guide-2020
    - guides/evidence-based-management-guide-2020.html
    references:
    - title: The Evidence-Based Management Guide | Scrum.org
      url: https://scrum.org/resources/evidence-based-management-guide
    - title: 'Evidence-based Management: Gathering the metrics'
      url: https://nkdagility.com/blog/evidence-based-management-gathering-metrics/
    - title: Metrics that matter with evidence-based management
      url: https://nkdagility.com/blog/metrics-that-matter-with-evidence-based-management/
    - title: 'Evidence-based Management: Gathering the metrics'
      url: https://nkdagility.com/blog/evidence-based-management-gathering-metrics/
    - title: Professional Agile Leadership with Evidence-Based Management (PAL-EBM)
      url: https://nkdagility.com/training/courses/professional-agile-leadership-with-evidence-based-management-pal-ebm-training-experience-with-certification-measuring-value-to-enable-improvement-and-agility/
    recommendedContent: 
    videos: 
    date: 2024-09-17
    weight: 360
    creator: Martin Hinshelwood
    card:
      button:
        content: Learn More
      content: Discover more about "The Evidence-Based Management Guide and how it can help you in your Agile journey!
      title: 'The Evidence-Based Management Guide: Improving Value Delivery under Conditions of Uncertainty'
    aliases:
    - /resources/Rv0ZjvwYVy5
    categories:
    - Product Development
    - Product Management
    - Engineering Excellence
    tags:
    - Evidence Based Management
    - Continuous Improvement
    - Current Value
    - Decision Making
    - Evidence Based Leadership
    - Experimentation
    - Metrics and Learning
    - Value Delivery
    - Empirical Process Control
    - Hypothesis Driven Development
    - Software Development
    - Operational Practices
    - Business Agility
    - Organisational Agility
    - Agile Philosophy
  BodyContent: |
    Evidence-Based Management (EBM) is an empirical approach that helps organizations to continuously improve customer outcomes, organizational capabilities, and business results under conditions of uncertainty. It provides a framework for organizations to improve their ability to deliver value in an uncertain world, seeking a path toward [strategic goals]({{< ref "/tags/strategic-goals" >}}). Using intentional [experimentation]({{< ref "/tags/experimentation" >}}) and evidence (measures), EBM enables organizations to systematically improve their performance over time and refine their goals based on better information
    By measuring current conditions, setting performance goals, forming small experiments for improvement that can be run quickly, measuring the effect of the experiment, and inspecting and adapting goals and next steps, EBM helps organizations to take into account the best available evidence to help them make decisions on ways to improve.

    This Guide defines EBM, its concepts, and its application.

    ## Seek Goals using Empiricism

    Complex problems defy easy solutions, but instead require organizations seek toward their goals in a series of small steps, inspecting the results of each step, and adapting their next actions based on feedback.

    This model has several key elements:

    - A **Strategic Goal**, which is something important that the organization would like to achieve. This goal is so big and far away, with many uncertainties along the journey that the organization must use empiricism. Because the Strategic Goal is aspirational and the path to it is uncertain, the organization needs a series of practical targets, like
    - **Intermediate Goals**, achievements of which will indicate that the organization is on the path to its Strategic Goal. The path to the Intermediate Goal is often still somewhat uncertain, but not completely unknown.
    - **Immediate Tactical Goals**, critical near-term objectives toward which a team or group of teams will work help toward Intermediate Goals.
    - A **Starting State**, which is where the organization is relative to the Strategic Goal when it starts its journey.
    - A **Current State**, which is where the organization is relative to the Strategic Goal at the
      present time.

    In order to progress toward the Strategic Goal, organizations run experiments which involve forming hypotheses that are intended to advance the organization toward their current Intermediate Goal. As they run these experiments and gather results, they use the evidence they obtain to evaluate their goals and determine their next steps to advance toward these goals.

    ![Reaching strategic goals requires experimenting, inspecting, and adapting](https://nkdagility.com/wp-content/uploads/2020/11/naked-agility-hypothesis-driven-480x450.jpg)

    ## Setting Goals

    When setting goals, organizations must define specific measures that will indicate that the goal is achieved. Goals, measures, and experiments should be made transparent in order to encourage organizational alignment.
    Consider the case of the response to an infectious disease:

    - The Strategic Goal is to eradicate the effects of the disease, as measured by the number of people who fall ill and suffer significant illness. Measurement is important; in this example, the goal is focused on the effects of the disease, and not on the means for achieving the desired impact. For example, the goal is not to vaccinate a certain percentage of the population against the disease; that may be an activity necessary to achieving the Strategic Goal, but it is not the Strategic Goal.
    - An example of an Intermediate Goal is the successful completion of a trial of a vaccine against the disease. This is still ambitious and measurable, and achieving it may require the completion of many different activities, but it is seen as a necessary step on the path to achieving the Strategic Goal.
      Examples of immediate tactical goals may include activities like isolating symptoms, evaluating a therapy, sequencing the DNA of a virus or bacterium, and so forth.
    - The Strategic Goal is usually focused on achieving a highly desirable but unrealized outcome for a specific group of people that results in improved happiness, safety, security, or well-being of the recipients of some product or service. In EBM, we refer to this as Unrealized Value, which is the satisfaction gap between a beneficiary’s desired outcome and their current experience. Unrealized Value is described in greater detail below, in the Key-Value Areas section.

    ## Understanding What Is Valuable

    Organizations measure many different kinds of things. Broadly speaking, measures fall into three categories:

    - **Activities**. These are things that people in the organization do, such as perform work, go to meetings, have discussions, write code, create reports, attend conferences, and so forth.
    - **Outputs**. These are things that the organization produces, such as product releases (including features), reports, defect reports, product reviews, and so on.
    - **Outcomes**. These are desirable things that a customer or user of a product experiences. They represent some new or improved capability that the customer or user was not able to achieve before. Examples include being able to travel to a destination faster than before or being able to earn or save more money than before. Outcomes can also be negative, as in the case where the value a customer or user experiences declines from previous experiences, for example when a service they previously relied upon is no longer available.

    The problem most organizations face, which is often reflected in the things they measure, is that measuring activities and outputs is easy while measuring outcomes is difficult. Organizations may gather a lot of data with insufficient information about their ability to deliver value. However, delivering valuable outcomes to customers is essential if organizations are to reach their goals. For example, working more hours (activities) and delivering more features (outputs) does not necessarily lead to improved customer experiences (outcomes).

    ## Four Key Value Areas

    In addition to using hypotheses and experiments to move toward goals, EBM provides a set of perspectives on value and the organization’s ability to deliver value. These perspectives are called Key Value Areas (KVAs). These areas examine the goals of the organization (Unrealized Value), the current state of the organization relative to those goals ([Current Value]({{< ref "/tags/current-value" >}})), the responsiveness of the organization in delivering value (Time-to-Market), and the effectiveness of the organization in delivering value (Ability-to-Innovate). Focusing on these four dimensions enables organizations to better understand where they are and where they need to go (see
    Figure 2).

    ![EBM focuses on four Key Value Areas (KVAs)](https://nkdagility.com/wp-content/uploads/2020/11/naked-agility-evidence-based-management-768x394.jpg)

    Each KVA focuses on a different aspect of either value or the ability of the organization to deliver value. Delivering business value (Current Value) is important, but organizations must also show that they can respond to change (Time-to-Market) while being able to sustain innovation over time (Ability-to-Innovate). And they must be able to continually make progress toward their long-term goals (Unrealized Value) or they risk succumbing to stagnation and complacency. Example Key Value Measures (KVMs) for each KVA are described in the Appendix.

    ### Current Value (CV)

    The value that the product delivers today.

    The purpose of looking at CV is to understand the value that an organization delivers to
    customers and stakeholders at the present time; it considers only what exists right now, not the
    value that might exist in the future. Questions that organizations need to continually re-evaluate
    for current value are:

    - How happy are users and customers today? Is their happiness improving or declining?
    - How happy are your employees today? Is their happiness improving or declining?
    - How happy are your investors and other stakeholders today? Is their happiness improving or declining?

    Considering CV helps an organization understand the value that their customers or users experience today

    > Example: While profit, one way to measure investor happiness, will tell you the economic impact of the value that you deliver, knowing whether customers are happy with their purchase will tell you more about where you may need to improve to keep those customers. If your customers have few alternatives to your product, you may have high profit even though [customer satisfaction]({{< ref "/tags/customer-satisfaction" >}}) is low. Considering CV from several perspectives will give you a better understanding of your challenges and opportunities. Customer happiness and investor happiness also do not tell the whole story about your ability to deliver value. Considering employee attitudes recognizes that employees are ultimately the producers of value. Engaged employees that know how to maintain, sustain and enhance the product are one of the most significant assets of an organization, and happy employees are more engaged and productive.

    ### Unrealized Value (UV)

    The potential future value that could be realized if the organization met the needs of all potential customers or users

    Looking at Unrealized Value helps an organization to maximize the value that it realizes from a product or service over time. When customers, users, or clients experience a gap between their current experience and the experience that they would like to have, the difference between the two represents an opportunity; this opportunity is measured by Unrealized Value.

    Questions that organizations need to continually re-evaluate for UV are:

    - Can any additional value be created by our organization in this market or other markets?
    - Is it worth the effort and risk to pursue these untapped opportunities?
    - Should further investments be made to capture additional Unrealized Value?

    The consideration of both CV and UV provides organizations with a way to balance present and possible future benefits. Strategic Goals are formed from some satisfaction gap and an opportunity for an organization to decrease UV by increasing CV.

    > Example: A product may have low CV, because it is an early version being used to test the market, but very high UV, indicating that there is great market potential. Investing in the product to try to boost CV is probably warranted, given the potential returns, even though the product is not currently producing high CV. Conversely, a product with very high CV, large [market share]({{< ref "/tags/market-share" >}}), no near competitors, and very satisfied customers may not warrant much new investment; this is the classic cash cow product that is very profitable but nearing the end of its product investment cycle with low UV.

    ### Time-to-Market (T2M)

    The organization’s ability to quickly deliver new capabilities, services, or products

    The reason for looking at T2M is to minimize the amount of time it takes for the organization to deliver value. Without actively managing T2M, the ability to sustainably deliver value in the future is unknown. Questions that organizations need to continually re-evaluate for T2M are:

    - How fast can the organization learn from new experiments and information?
    - How fast can you adapt based on the information?
    - How fast can you test new ideas with customers?

    Improving T2M helps improve the frequency at which an organization can potentially change
    CV.

    > Example: Reducing the number of features in a product release can dramatically improve T2M; the smallest release possible is one that delivers at least some
    > incremental improvement in value to some subset of the customers/users of the product. Many organizations also focus on removing non value-added activities from the [product development]({{< ref "/categories/product-development" >}}) and delivery process to improve their T2M.

    ### [Ability to Innovate]({{< ref "/tags/ability-to-innovate" >}}) (A2I)

    The effectiveness of an organization to deliver new capabilities that might better meet customer needs

    The goal of looking at the A2I is to maximize the organization’s ability to deliver new capabilities
    and innovative solutions. Organizations should continually re-evaluate their A2I by asking:

    - What prevents the organization from delivering new value?
    - What prevents customers or users from benefiting from that innovation?
    - Improving A2I helps an organization become more effective in ensuring that the work that it does improves the value that its products or services deliver to customers or users.

    > Example: A variety of things can impede an organization from being able to deliver new capabilities and value: spending too much time remedying poor product quality, needing to maintain multiple variations of a product due to lack of operational excellence, lack of decentralized decision-making, inability to hire and inspire talented, passionate team members, and so on.
    > As low-value features and systemic impediments accumulate, more budget and time is consumed maintaining the product or overcoming impediments, reducing its available capacity to innovate. In addition, anything that prevents users or customers from benefiting from innovation, such as hard to assemble/install products or new versions of products, will also reduce A2I.

    ## Progress toward Goals

    The first step in the journey toward a Strategic Goal is understanding your Current State. If your focus is to achieve a Strategic Goal related to Unrealized Value (UV), as is typically the case, then measuring the Current Value (CV) your product or service delivers is where you should start (of course, if your product or service is new then its CV will be zero). To understand where you need to improve, you may also need to understand your effectiveness (A2I), and your responsiveness (T2M).

    The Experiment Loop (shown in Figure 1) helps organizations move from their Current State toward their Next Target Goal, and ultimately their Strategic Goal, by taking small, measured steps, called experiments, using explicit hypotheses.3 This loop consists of:

    - **Forming a hypothesis for improvement.** Based on experience, form an idea of something you think will help you move toward your Next Target Goal, and decide how you will know whether this experiment succeeded based on measurement.
    - **Running your experiments.** Make the change you think will help you to improve and gather data to support or refute your hypothesis.
    - **Inspecting your results. **Did the change you made improve your results based on the measurements you have made? Not all changes do; some changes actually make things worse.
    - **Adapting your goals or your approach based on what you learned.** Both your goals and your improvement experiments will likely evolve as you learn more about customers, competitors, and your organization’s capabilities. Goals can change because of outside events, and your tactics to reach your goals may need to be reconsidered and revised. Was the Intermediate Goal the right goal? Is the Strategic Goal still relevant? If you achieved the Intermediate Goal, you will need to choose a new Intermediate Goal. If you did not achieve it, you will need to decide whether you need to persevere, stop, or pivot toward something new. If your Strategic Goal is no longer relevant, you will need to either adapt it, or replace it.

    ## Hypotheses, Experiments, Features, and Requirements

    Features are “distinguishing characteristics of a product” , while a requirement is, practically speaking, something that someone thinks would be desirable in a product. A feature description is one kind of requirement.

    Organizations can spend a lot of money implementing features and other requirements in products, only to find that customers don’t share the company’s opinion on their value; beliefs in what is valuable are merely assumptions until they are validated by customers. This is where hypotheses and experiments are useful.

    In simplified terms, a hypothesis is a proposed explanation for some observation that has not yet been proven (or disproven). In the context of requirements, it is a belief that doing something will lead to something else, such as delivering feature X will lead to outcome Y. An experiment is a test that is designed to prove or reject some hypothesis.

    Every feature and every requirement really represent a hypothesis about value. One of the goals of an empirical approach is to make these hypotheses explicit and to consciously design experiments that explicitly test the value of the features and requirements. The entire feature or requirement need not actually be built to determine whether it is valuable; it may be sufficient for a team to simply build enough of it to validate critical assumptions that would prove or disprove its value.

    Explicitly forming hypotheses, measuring results, and inspecting and adapting goals based on those results are implicit parts of an agile approach. Making this work explicit and transparent is what EBM adds to the organizational improvement process.

    ## End Note

    Evidence-Based Management is free and offered in this Guide. Although implementing only parts of EBM is possible, the result is not Evidence-Based Management

    ## Acknowledgements

    Evidence-Based Management was collaboratively developed by [Scrum]({{< ref "/categories/scrum" >}}).org, the [Professional Scrum]({{< ref "/tags/professional-scrum" >}}) Trainer community, Ken Schwaber and Christina Schwaber.

    ## Appendix: Example Key Value Measures

    To encourage adaptability, EBM defines no specific Key Value Measures (KVMs). KVMs listed below are presented to show the kinds of measures that might help an organization to understand its current state, desired future state, and factors that influence its ability to improve.

    ### Current Value (CV)

    | KVM                   | Measuring                                                                                                                                                                                            |
    | --------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | [Revenue per Employee]({{< ref "/tags/revenue-per-employee" >}})  | The ratio (gross revenue / # of employees) is a key competitive indicator within an industry. This varies significantly by industry.                                                                 |
    | Product Cost Ratio    | Total expenses and costs for the product(s)/system(s) being measured, including operational costs compared to revenue.                                                                               |
    | Employee Satisfaction | Some form of sentiment analysis to help gauge [employee engagement]({{< ref "/tags/employee-engagement" >}}), energy, and enthusiasm.                                                                                                           |
    | Customer Satisfaction | Some form of sentiment analysis to help gauge customer engagement and happiness with the product.                                                                                                    |
    | Customer Usage Index  | Measurement of usage, by feature, to help infer the degree to which customers find the product useful and whether actual usage meets expectations on how long users should be taking with a feature. |

    {: .table .table-striped .table-bordered .d-none .d-md-block}

    ### Unrealized Value (UV)

    | KVM                                         | Measuring                                                                                                                                                       |
    | ------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | Market Share                                | The relative percentage of the market not controlled by the product; the potential market share that the product might achieve if it better met customer needs. |
    | Customer or User Satisfaction Gap           | The difference between a customer or user’s desired experience and their current experience.                                                                    |
    | Desired Customer Experience or satisfaction | A measure that indicates the experience that the customer would like to have.                                                                                   |

    {: .table .table-striped .table-bordered .d-none .d-md-block}

    ### Time-to-Market (T2M)

    | KVM                             | Measuring                                                                                                                                                                                                                                                                                                                                                                                                          |
    | ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
    | Build and Integration Frequency | The number of integrated and tested builds per time period. For a team that is releasing frequently or continuously, this measure is superseded by actual release measures.                                                                                                                                                                                                                                        |
    | Release Frequency               | The number of releases per time period, e.g. continuously, daily, weekly, monthly, quarterly, etc. This helps reflect the time needed to satisfy the customer with new and competitive products.                                                                                                                                                                                                                   |
    | Release Stabilization Period    | The time spent correcting product problems between the point the developers say it is ready to release and the point where it is actually released to customers. This helps represent the impact of poor development practices and underlying design and codebase.                                                                                                                                                 |
    | Mean Time to Repair             | The average amount of time it takes from when an error is detected and when it is fixed. This helps reveal the efficiency of an organization to fix an error.                                                                                                                                                                                                                                                      |
    | Customer [Cycle Time]({{< ref "/tags/cycle-time" >}})             | The amount of time from when work starts on a release until the point where it is actually released. This measure helps reflect an organization’s ability to reach its customer.                                                                                                                                                                                                                                   |
    | [Lead Time]({{< ref "/tags/lead-time" >}})                       | The amount of time from when an idea is proposed or a hypothesis is formed until a customer can benefit from that idea. This measure may vary based on customer and product. It is a contributing factor in customer satisfaction.                                                                                                                                                                                 |
    | Lead Time for Changes           | The amount of time to go from code-committed to code successfully running in production. For more information, see the DORA 2019 report.                                                                                                                                                                                                                                                                           |
    | [Deployment Frequency]({{< ref "/tags/deployment-frequency" >}})            | The number of times that the organization deployed (released) a new version of the product to customers/users. For more information, see the DORA 2019 report.                                                                                                                                                                                                                                                     |
    | Time to Restore Service         | The amount of time between the start of a service outage and the restoration of full availability of the service. For more information, see the DORA 2019 report.                                                                                                                                                                                                                                                  |
    | Time-to-Learn                   | The total time needed to sketch an idea or improvement, build it, deliver it to users, and learn from their usage.                                                                                                                                                                                                                                                                                                 |
    | Time to remove Impediment       | The average amount of time from when an impediment is raised until when it is resolved. It is a contributing factor to lead time and employee satisfaction                                                                                                                                                                                                                                                         |
    | Time to Pivot                   | A measure of true [business agility]({{< ref "/tags/business-agility" >}}) that presents the elapsed time between when an organization receives feedback or new information and when it responds to that feedback; for example, the time between when it finds out that a competitor has delivered a new market-winning feature to when the organization responds with matching or exceeding new capabilities that measurably improve customer experience. |

    {: .table .table-striped .table-bordered .d-none .d-md-block}

    ### Ability to Innovate (A2I)

    | KVM                                      | Measuring                                                                                                                                                                                                                                                      |
    | ---------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | Innovation Rate                          | The percentage of effort or cost spent on new product capabilities, divided by total product effort or cost. This provides insight into the capacity of the organization to deliver new product capabilities.                                                  |
    | Defect Trends                            | Measurement of change in defects since the last measurement. A defect is anything that reduces the value of the product to a customer, user, or to the organization itself. Defects are generally things that don’t work as intended.                          |
    | On-Product Index                         | The percentage of time teams spend working on product and value.                                                                                                                                                                                               |
    | Installed Version Index                  | The number of versions of a product that are currently being supported. This reflects the effort the organization spends supporting and maintaining older versions of the software.                                                                            |
    | [Technical Debt]({{< ref "/tags/technical-debt" >}})                           | A concept in programming that reflects the extra development and testing work that arises when “quick and dirty” solutions result in later remediation. It creates an undesirable impact on the delivery of value and an avoidable increase in waste and risk. |
    | Production Incident Count                | The number of times in a given period that the Development Team was interrupted to fix a problem in an installed product. The number and frequency of Production Incidents can help indicate the stability of the product.                                     |
    | Active Product (Code) Branches           | The number of different versions (or variants) of a product or service. Provides insight into the potential impact of change and the resulting complexity of work.                                                                                             |
    | Time Spent Merging Code Between Branches | The amount of time spent applying changes across different versions of a product or service. Provides insight into the potential impact of change and the resulting complexity of work.                                                                        |
    | Time Spent Context-Switching             | Examples include time lost to interruptions caused by meetings or calls, time spent switching between tasks, and time lost when team members are interrupted to help people outside the team can give simple insight into the magnitude of the problem.        |
    | Change Failure Rate                      | The percentage of released product changes that result in degraded service and require remediation (e.g. hotfix, rollback, patch). For more information, see the DORA 2019 report.                                                                             |

    {: .table .table-striped .table-bordered .d-none .d-md-block}

    © 2020 Scrum.org
    This publication is offered for license under the Attribution Share-Alike license of Creative Commons,
    accessible at http://creativecommons.org/licenses/by-sa/4.0/legalcode and also described in
    summary form at http://creativecommons.org/licenses/by-sa/4.0/. By utilizing this EBM Guide, you
    acknowledge and agree that you have read and agree to be bound by the terms of the Attribution
    Share-Alike license of Creative Commons.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\evidence-based-management-guide-2020\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\evidence-based-management-guide-2020
- FrontMatter:
    title: Detecting Agile BS
    description: The purpose of this document is to provide guidance to DoD program executives and acquisition professionals on how to detect software projects that are really using agile development versus those that are simply waterfall or spiral development in agile clothing.
    ResourceId: Tt8SPr3xJER
    ResourceImport: false
    ResourceType: guides
    ResourceContentOrigin: Human
    resourceTypes: guide
    layout: guide
    image: https://nkdagility.com/wp-content/uploads/2020/12/image-2.png
    references:
    - title: DIB Guide - Detecting Agile BS
      url: https://media.defense.gov/2019/May/02/2002127286/-1/-1/0/DIBGUIDEDETECTINGAGILEBS.PDF
    - title: Defense Innovation Board Ten Commandments of Software
      url: https://media.defense.gov/2018/Apr/22/2001906836/-1/-1/0/DEFENSEINNOVATIONBOARD_TEN_COMMANDMENTS_OF_SOFTWARE_2018.04.20.PDF
    - title: Defense Innovation Board Metrics for Software Development
      url: https://media.defense.gov/2018/Jul/10/2001940937/-1/-1/0/DIB_METRICS_FOR_SOFTWARE_DEVELOPMENT_V0.9_2018.07.10.PDF
    - title: Defense Innovation Board Do’s and Don’ts for Software
      url: https://media.defense.gov/2018/Oct/09/2002049593/-1/-1/0/DIB_DOS_DONTS_SOFTWARE_2018.10.05.PDF
    videos:
    - title: stackconf 2021 | The Tyranny of Taylorism and how to spot Agile BS
      embed: https://www.youtube.com/embed/OJ-7YVekG2s
    - title: 'stackconf online 2020 | Agile Evolution: An Enterprise transformation that shows that you can too'
      embed: https://www.youtube.com/embed/6D7ZC5Yq8rU
    - title: 'Agile Evolution: Live Site Culture & Site Reliability at Azure DevOps'
      embed: https://www.youtube.com/embed/5bgcpPqcGlw
    date: 2024-09-17
    weight: 360
    creator: Martin Hinshelwood
    card:
      button:
        content: Learn More
      content: Discover more about Detecting Agile BS and how it can help you in your Agile journey!
      title: Detecting Agile BS
    aliases:
    - /Guides/Detecting-Agile-BS.html
    - /learn/agile-delivery-kit/guides/detecting-agile-bs
    - /resources/Tt8SPr3xJER
    aliasesArchive:
    - /Guides/Detecting-Agile-BS.html
    - /learn/agile-delivery-kit/guides/detecting-agile-bs
    categories:
    - Product Development
    - Engineering Excellence
    tags:
    - Software Development
    - Operational Practices
    - Product Delivery
  BodyContent: |
    Agile is a buzzword of [software development]({{< ref "/tags/software-development" >}}), and so all DoD software development projects are, almost by default, now declared to be “agile.” The purpose of this document is to provide guidance to DoD program executives and acquisition professionals on how to detect software projects that are really using agile development versus those that are simply waterfall or spiral development in agile clothing (“agile-[scrum]({{< ref "/categories/scrum" >}})-fall”).

    ![Detecting Agile BS](https://nkdagility.com/wp-content/uploads/2020/12/image-2.png){: .responsiveImage}

    ## Principles, Values, and Tools

    Experts and devotees profess certain key “values” to characterize the culture and approach of
    agile development. In its work, the DIB has developed its own guiding maxims that roughly map
    to these true agile values:

    | Agile value                                           | DIB maxim                                                                                             |
    | ----------------------------------------------------- | ----------------------------------------------------------------------------------------------------- |
    | Individuals and interactions over processes and tools | “[Competence]({{< ref "/tags/competence" >}}) trumps process”                                                                           |
    | [Working software]({{< ref "/tags/working-software" >}}) over comprehensive documentation     | “Minimize time from program launch to deployment of simplest useful functionality”                    |
    | Customer collaboration over contract negotiation      | “Adopt a DevSecOps culture for software systems”                                                      |
    | Responding to change over following a plan            | “Software programs should start small, be iterative, and build on success ‒ or be terminated quickly” |

    {: .table .table-striped .table-bordered .d-none .d-md-block}

    Key flags that a project is not really agile:

    - Nobody on the software development team is talking with and observing the users of the software in action; we mean the actual users of the actual code.1 (The Program Executive Office (PEO) does not count as an actual user, nor does the commanding officer, unless she uses the code.)
    - Continuous feedback from users to the development team (bug reports, users assessments) is not available. Talking once at the beginning of a program to verify requirements doesn’t count!
    - Meeting requirements is treated as more important than getting something useful into the field as quickly as possible.
    - Stakeholders (development, test, ops, security, contracting, contractors, end-users, etc.)2 are acting more-or-less autonomously (e.g. ‘it’s not my job.’)
    - End users of the software are missing-in-action throughout development; at a minimum, they should be present during Release Planning and User Acceptance Testing.
    - DevSecOps culture is lacking if manual processes are tolerated when such processes can and should be automated (e.g. [automated testing]({{< ref "/tags/automated-testing" >}}), [continuous integration]({{< ref "/tags/continuous-integration" >}}), [continuous delivery]({{< ref "/tags/continuous-delivery" >}})).

    Some current, common tools in use by teams using agile development (these will change as better tools become available):

    - Git, ClearCase, or Subversion – version control system for tracking changes to source code. Git is the de-facto open-source standard for modern software development.
    - [Azure Repos]({{< ref "/tags/azure-repos" >}}), BitBucket, [GitHub]({{< ref "/tags/github" >}}) – repository hosting sites. Also provide issues tracking, continuous integration “apps” and other productivity tools. Widely used by the open-source community.
    - [Azure Pipelines]({{< ref "/tags/azure-pipelines" >}}), Jenkins, Circle CI, Travis CI – continuous integration service used to build and test BitBucket and GitHub software projects
    - Chef, Ansible, or Puppet – software for writing [system configuration]({{< ref "/tags/system-configuration" >}}) “recipes” and streamlining the task of configuring and maintaining a collection of servers
    - Docker – a computer program that performs operating-system-level virtualization, also known as “containerization”
    - Kubernetes or Docker Swarm – for container orchestration
    - [Azure Boards]({{< ref "/tags/azure-boards" >}}), GitHub, Jira, Pivotal Tracker – issues reporting, tracking, and management

    Graphical version:

    ![DIB DevSecOps Technology Stack](https://nkdagility.com/wp-content/uploads/2020/12/image-1-768x428.png){: .responsiveImage}

    ## Questions to Ask

    - How do you test your code? (Wrong answers: “we have a testing organization”, “OT&E is responsible for testing”)
      Advanced version: what tool suite are you using for unit tests, regression testing, functional tests, security scans, and deployment certification?
    - How automated are your development, testing, security, and deployment pipelines?
      Advanced version: what tool suite are you using for continuous integration (CI), continuous deployment (CD), regression testing, program documentation; is your infrastructure defined by code?
    - Who are your users and how are you interacting with them?
      Advanced version: what mechanisms are you using to get direct feedback from your users? What tool suite are you using for issue reporting and tracking? How do you allocate issues to programming teams? How to you inform users that their issues are being addressed and/or have been resolved?
    - What is your (current and future) [cycle time]({{< ref "/tags/cycle-time" >}}) for releases to your users?
      Advanced version: what software platforms to you support? Are you using containers? What configuration management tools do you use?

    ## Questions for Program Management

    - How many programmers are part of the organizations that own the budget and milestones for the program? (Wrong answers: “we don’t know,” “zero,” “it depends on how you define a programmer”)
    - What are your management metrics for development and operations; how are they used to inform priorities, detect problems; how often are they accessed and used by [leadership]({{< ref "/categories/leadership" >}})?
    - What have you learned in your past three sprint cycles and what did you do about it? (Wrong answers: “what’s a sprint cycle?,” “we are waiting to get approval from management”)
    - Who are the users that you deliver value to each sprint cycle? Can we talk to them? (Wrong answers: “we don’t directly deploy our code to users”)

    ## Questions for Customers and Users

    - How do you communicate with the developers? Did they observe your relevant teams working and ask questions that indicated a deep understanding of your needs? When is the last time they sat with you and talked about features you would like to see implemented?
    - How do you send in suggestions for new features or report issues or bugs in the code? What type of feedback do you get to your requests/reports? Are you ever asked to try prototypes of new software features and observed using them?
    - What is the time it takes for a requested feature to show up in the application?

    ## Questions for Program Leadership

    - Are teams delivering working software to at least some subset of real users every iteration (including the first) and gathering feedback? (alt: every two weeks)
    - Is there a product charter that lays out the mission and [strategic goals]({{< ref "/tags/strategic-goals" >}})? Do all members of the team understand both, and are they able to see how their work contributes to both?
    - Is feedback from users turned into concrete work items for sprint teams on timelines shorter than one month?
    - Are teams empowered to change the requirements based on user feedback?
    - Are teams empowered to change their process based on what they learn?
    - Is the full ecosystem of your project agile? (Agile programming teams followed by linear, bureaucratic deployment is a failure.)

    More information on some of the features of DoD software programs are included in Appendix A [DIB Ten Commandments on Software](https://media.defense.gov/2018/Apr/22/2001906836/-1/-1/0/DEFENSEINNOVATIONBOARD_TEN_COMMANDMENTS_OF_SOFTWARE_2018.04.20.PDF), Appendix B [DIB Metrics for Software Development](https://media.defense.gov/2018/Jul/10/2001940937/-1/-1/0/DIB_METRICS_FOR_SOFTWARE_DEVELOPMENT_V0.9_2018.07.10.PDF),
    and Appendix C [DIB Do’s and Don’ts of Software](https://media.defense.gov/2018/Oct/09/2002049593/-1/-1/0/DIB_DOS_DONTS_SOFTWARE_2018.10.05.PDF).
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\detecting-agile-bs\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\detecting-agile-bs
- FrontMatter:
    title: Nexus Guide
    description: Discover the Nexus framework for scaling Scrum, enabling multiple teams to collaborate effectively and deliver integrated products with enhanced value.
    ResourceId: iC8MlA3TE7S
    ResourceImport: false
    ResourceType: guides
    ResourceContentOrigin: Human
    resourceTypes: guide
    layout: guide
    aliases:
    - guides/Nexus-Framework/
    - guides/Nexus-Framework.html
    - /learn/agile-delivery-kit/guides/nexus-framework
    - /resources/iC8MlA3TE7S
    aliasesArchive:
    - guides/Nexus-Framework/
    - guides/Nexus-Framework.html
    - /learn/agile-delivery-kit/guides/nexus-framework
    references:
    - title: The 2020 Scrum Guide
      url: https://scrumguides.org/scrum-guide.html
    - title: The Nexus Guide
      url: https://www.scrum.org/resources/online-nexus-guide
    recommendedContent:
    - collection: practices
      path: _practices/definition-of-done-dod.md
    - collection: practices
      path: _practices/definition-of-ready-dor.md
    videos:
    - title: Overview of The Scrum Framework with Martin Hinshelwood
      embed: https://www.youtube.com/embed/Q2Fo3sM6BVo
    date: 2024-09-17
    weight: 750
    creator: Martin Hinshelwood
    card:
      button:
        content: Learn More
      content: Discover more about Nexus Guide and how it can help you in your Agile journey!
      title: Nexus Guide
    categories:
    - Scrum
    - Product Development
    tags:
    - Professional Scrum
    - Agile Frameworks
    - Scaling
    - Software Development
    - Increment
    - Product Delivery
    - Empirical Process Control
    - Social Technologies
    - Transparency
    - Value Delivery
    - Large Scale Agility
    - Working Software
    - Product Backlog
    - Scrum Team
    - Agile Transformation
  BodyContent: |
    The Definitive Guide to [Scaling]({{< ref "/tags/scaling" >}}) [Scrum]({{< ref "/categories/scrum" >}}) with Nexus

    January 2021

    # Purpose of the Nexus Guide

    [Product delivery]({{< ref "/tags/product-delivery" >}}) is complex, and the integration of [product development]({{< ref "/categories/product-development" >}}) work into a valuable product requires coordinating many diverse activities. Nexus is a framework for developing and sustaining scaled product delivery initiatives. It builds upon Scrum, extending it only where absolutely necessary to minimize and manage dependencies between multiple Scrum Teams while promoting empiricism and the [Scrum Values]({{< ref "/tags/scrum-values" >}}).

    The Nexus framework inherits the purpose and intent of the Scrum framework as documented in the [Scrum Guide](../_guides/scrum-guide.md) Scaled Scrum is still Scrum. Nexus does not change the core design or ideas of Scrum, or leave out elements, or negate the rules of Scrum. Doing so covers up problems and limits the benefits of Scrum, potentially even rendering it useless.

    This Guide contains the definition of Nexus. Each element of the framework serves a specific purpose that is essential to help teams and organizations scale the benefits of Scrum with multiple teams working together.

    As organizations use Nexus, they typically discover complementary patterns, processes, and practices that help them in their application of the Nexus framework. As with Scrum, such tactics vary widely and are described elsewhere.

    ![The Nexus Framework](../../assets/images/nexus-framework.png)

    # Nexus Definition

    A Nexus is a group of approximately three to nine Scrum Teams that work together to deliver a single product; it is a connection between people and things. A Nexus has a single [Product Owner]({{< ref "/tags/product-owner" >}}) who manages a single [Product Backlog]({{< ref "/tags/product-backlog" >}}) from which the Scrum Teams work.

    The Nexus framework defines the accountabilities, events, and artifacts that bind and weave together the work of the Scrum Teams in a Nexus. Nexus builds upon Scrum's foundation, and its parts will be familiar to those who have used Scrum. It minimally extends the Scrum framework only where absolutely necessary to enable multiple teams to work from a single Product Backlog to build an Integrated [Increment]({{< ref "/tags/increment" >}}) that meets a goal.

    # Nexus Theory

    At its heart, Nexus seeks to preserve and enhance Scrum's foundational bottom-up intelligence and empiricism while enabling a group of Scrum Teams to deliver more value than can be achieved by a single team. The goal of Nexus is to scale the value that a group of Scrum Teams, working on a single product, is able to deliver. It does this by reducing the complexity that those teams encounter as they collaborate to deliver an integrated, valuable, useful product Increment at least once every Sprint.

    The Nexus Framework helps teams solve common scaling challenges like reducing cross-team dependencies, preserving team self-management and [transparency]({{< ref "/tags/transparency" >}}), and ensuring accountability. Nexus helps to make transparent dependencies. These dependencies are often caused by mismatches related to:

    1.  **Product structure:** The degree to which different concerns are independently separated in the product will greatly affect the complexity of creating an integrated product release.
    2.  **Communication structure:** The way that people communicate within and between teams affects their ability to get work done; delays in communication and feedback reduce the flow of work.

    Nexus provides opportunities to change the process, product structure, and communication structure to reduce or remove these dependencies.

    While often counterintuitive, scaling the value that is delivered does not always require adding more people. Increasing the number of people and the size of a product increases complexity and dependencies, the need for collaboration, and the number of communication pathways involved in making decisions. Scaling-down, reducing the number of people who work on something, can be an important practice in delivering more value.

    # The Nexus Framework

    Nexus builds upon Scrum by enhancing the foundational elements of Scrum in ways that help solve the dependency and collaboration challenges of cross-team work. Nexus (see Figure 1) reveals an empirical process that closely mirrors Scrum.

    Nexus extends Scrum in the following ways:

    - **Accountabilities**: The Nexus Integration Team ensures that the Nexus delivers a valuable, useful Integrated Increment at least once every Sprint. The Nexus Integration Team consists of the Product Owner, a [Scrum Master]({{< ref "/tags/scrum-master" >}}), and Nexus Integration Team Members.
    - **Events**: Events are appended to, placed around, or replace regular Scrum events to augment them. As modified, they serve both the overall effort of all Scrum Teams in the Nexus, and each individual team. A Nexus Sprint Goal is the objective for the Sprint.
    - **Artifacts**: All Scrum Teams use the same, single Product Backlog. As the Product Backlog items are refined and made ready, indicators of which team will most likely do the work inside a Sprint are made transparent. A Nexus Sprint Backlog exists to assist with transparency during the Sprint. The Integrated Increment represents the current sum of all integrated work completed by a Nexus.

    Figure 1: The Nexus Framework

    # Accountabilities in Nexus

    A Nexus consists of Scrum Teams that work together toward a Product Goal. The Scrum framework defines three specific sets of accountabilities within a [Scrum Team]({{< ref "/tags/scrum-team" >}}): the Developers, the Product Owner, and the Scrum Master. These accountabilities are prescribed in the Scrum Guide. In Nexus, an additional accountability is introduced, the Nexus Integration Team.

    ## Nexus Integration Team 

    The Nexus Integration Team is accountable for ensuring that a done Integrated Increment (the combined work completed by a Nexus) is produced at least once a Sprint. It provides the focus that makes possible the accountability of multiple Scrum Teams to come together to create valuable, useful Increments, as prescribed in Scrum.

    While Scrum Teams address integration issues within the Nexus, the Nexus Integration Team provides a focal point of integration for the Nexus. Integration includes addressing technical and non-technical cross-functional team constraints that may impede a Nexus' ability to deliver a constantly Integrated Increment. It should use bottom-up intelligence from within the Nexus to achieve resolution.

    The Product Owner, a Scrum Master, and the appropriate members from the Scrum Teams belong to the Nexus Integration Team. Appropriate members are the people with the necessary skills and knowledge to help resolve the issues the Nexus faces at any point in time. Composition of the Nexus Integration Team may change over time to reflect the current needs of a Nexus. Common activities the Nexus Integration Team might perform include [coaching]({{< ref "/tags/coaching" >}}), consulting, and highlighting awareness of dependencies and cross-team issues.

    The Nexus Integration Team consists of:

    - **The Product Owner:** A Nexus works off a single Product Backlog, and as described in Scrum, a Product Backlog has a single Product Owner who has the final say on its contents. The Product Owner is accountable for maximizing the value of the product and the work performed and integrated by the Scrum Teams in a Nexus. The Product Owner is also accountable for effective Product Backlog management. How this is done may vary widely across organizations, Nexuses, Scrum Teams, and individuals.
    - **A Scrum Master:** The Scrum Master in the Nexus Integration Team is accountable for ensuring the Nexus framework is understood and enacted as described in the Nexus Guide. This Scrum Master may also be a Scrum Master in one or more of the Scrum Teams in the Nexus.
    - **One or more\*\***Nexus Integration Team Members:\*\* The Nexus Integration Team often consists of Scrum Team members who help the Scrum Teams to adopt tools and practices that contribute to the Scrum Teams' ability to deliver a valuable and useful Integrated Increment that frequently meets the [Definition of Done]({{< ref "/tags/definition-of-done" >}}).

    The Nexus Integration Team is responsible for coaching and guiding the Scrum Teams to acquire, implement, and learn practices and tools that improve their ability to produce a valuable, useful Increment.

    Membership in the Nexus Integration Team takes precedence over individual Scrum Team membership. As long as their Nexus Integration Team responsibility is satisfied, they can work as team members of their respective Scrum Teams. This preference helps ensure that the work to resolve issues affecting multiple teams has priority.

    ## Nexus Events  

    Nexus adds to or extends the events defined by Scrum. The duration of Nexus events is guided by the length of the corresponding events in the Scrum Guide. They are timeboxed in addition to their corresponding Scrum events.

    At scale, it may not be practical for all members of the Nexus to participate to share information or to come to an agreement. Except where noted, Nexus events are attended by whichever members of the Nexus are needed to achieve the intended outcome of the event most effectively.

    Nexus events consist of:

    ## The Sprint

    A Sprint in Nexus is the same as in Scrum. The Scrum Teams in a Nexus produce a single Integrated Increment.

    ## Cross-Team Refinement

    Cross-Team Refinement of the Product Backlog reduces or eliminates cross-team dependencies within a Nexus. The Product Backlog must be decomposed so that dependencies are transparent, identified across teams, and removed or minimized. Product Backlog items pass through different levels of decomposition from very large and vague requests to actionable work that a single Scrum Team could deliver inside a Sprint.

    Cross-Team Refinement of the Product Backlog at scale serves a dual purpose:

    - It helps the Scrum Teams forecast which team will deliver which Product Backlog items.
    - It identifies dependencies across those teams.

    Cross-Team Refinement is ongoing. The frequency, duration, and attendance of Cross-Team Refinement varies to optimize these two purposes.

    Where needed, each Scrum Team will continue their own refinement in order for the Product Backlog items to be ready for selection in a Nexus Sprint Planning event. An adequately refined Product Backlog will minimize the emergence of new dependencies during Nexus Sprint Planning.

    ## Nexus Sprint Planning

    The purpose of Nexus Sprint Planning is to coordinate the activities of all Scrum Teams within a Nexus for a single Sprint. Appropriate representatives from each Scrum Team and the Product Owner meet to plan the Sprint.

    The result of Nexus Sprint Planning is:

    - a Nexus Sprint Goal that aligns with the Product Goal and describes the purpose that will be achieved by the Nexus during the Sprint
    - a Sprint Goal for each Scrum Team that aligns with the Nexus Sprint Goal
    - a single Nexus Sprint Backlog that represents the work of the Nexus toward the Nexus Sprint Goal and makes cross-team dependencies transparent
    - A Sprint Backlog for each Scrum Team, which makes transparent the work they will do in support of the Nexus Sprint Goal

    ## Nexus [Daily Scrum]({{< ref "/tags/daily-scrum" >}})

    The purpose of the Nexus Daily Scrum is to identify any integration issues and inspect progress toward the Nexus Sprint Goal. Appropriate representatives from the Scrum Teams attend the Nexus Daily Scrum, inspect the current state of the integrated Increment, and identify integration issues and newly discovered cross-team dependencies or impacts. Each Scrum Team's Daily Scrum complements the Nexus Daily Scrum by creating plans for the day, focused primarily on addressing the integration issues raised during the Nexus Daily Scrum.

    The Nexus Daily Scrum is not the only time Scrum Teams in the Nexus are allowed to adjust their plan. Cross-team communication can occur throughout the day for more detailed discussions about adapting or re-planning the rest of the Sprint's work.

    ## Nexus [Sprint Review]({{< ref "/tags/sprint-review" >}})

    The Nexus Sprint Review is held at the end of the Sprint to provide feedback on the done Integrated Increment that the Nexus has built over the Sprint and determine future adaptations.

    Since the entire Integrated Increment is the focus for capturing feedback from stakeholders, a Nexus Sprint Review replaces individual Scrum Team Sprint Reviews. During the event, the Nexus presents the results of their work to key stakeholders and progress toward the Product Goal is discussed, although it may not be possible to show all completed work in detail. Based on this information, attendees collaborate on what the Nexus should do to address the feedback. The Product Backlog may be adjusted to reflect these discussions.

    ## Nexus Sprint Retrospective

    The purpose of the Nexus Sprint Retrospective is to plan ways to increase quality and effectiveness across the whole Nexus. The Nexus inspects how the last Sprint went with regards to individuals, teams, interactions, processes, tools, and its Definition of Done. In addition to individual team improvements, the Scrum Teams' Sprint Retrospectives complement the Nexus Sprint Retrospective by using bottom-up intelligence to focus on issues that affect the Nexus as a whole.

    The Nexus Sprint Retrospective concludes the Sprint.

    # Nexus Artifacts and Commitments

    Artifacts represent work or value, and are designed to maximize transparency, as described in the Scrum Guide. The Nexus Integration Team works with the Scrum Teams within a Nexus to ensure that transparency is achieved across all artifacts and that the state of the Integrated Increment is widely understood.

    Nexus extends Scrum with the following artifacts, and each artifact contains a commitment, as indicated below. These commitments exist to reinforce empiricism and the Scrum value for the Nexus and its stakeholders.

    ## Product Backlog

    There is a single Product Backlog that contains a list of what is needed to improve the product for the entire Nexus and all of its Scrum Teams. At scale, the Product Backlog must be understood at a level where dependencies can be detected and minimized. The Product Owner is accountable for the Product Backlog, including its content, availability, and ordering.

    ### Commitment: Product Goal

    The _commitment_ for the Product Backlog is the **Product Goal**. The Product Goal, which describes the future state of the product and serves as a long-term goal of the Nexus.

    ## Nexus Sprint Backlog

    A Nexus Sprint Backlog is the composite of the Nexus Sprint Goal and Product Backlog items from the Sprint Backlogs of the individual Scrum Teams. It is used to highlight dependencies and the flow of work during the Sprint. The Nexus Sprint Backlog is updated throughout the Sprint as more is learned. It should have enough detail that the Nexus can inspect their progress in the Nexus Daily Scrum.

    ### Commitment: Nexus Sprint Goal

    The _commitment_ for the Nexus Sprint Backlog is the **Nexus Sprint Goal**. The Nexus Sprint Goal is a single objective for the Nexus. It is the sum of all the work and Sprint Goals of the Scrum Teams within the Nexus. It creates coherence and focus for the Nexus for the Sprint by encouraging the Scrum Teams to work together rather than on separate initiatives. The Nexus Sprint Goal is created at the Nexus Sprint Planning event and added to the Nexus Sprint Backlog. As Scrum Teams work during the Sprint, they keep the Nexus Sprint Goal in mind. The Nexus should demonstrate the valuable and useful functionality that is done to achieve the Nexus Sprint Goal at the Nexus Sprint Review in order to receive stakeholder feedback.

    ## Integrated Increment

    The Integrated Increment represents the current sum of all integrated work completed by a Nexus toward the Product Goal. The Integrated Increment is inspected at the Nexus Sprint Review, but may be delivered to stakeholders before the end of the Sprint. The Integrated Increment must meet the Definition of Done.

    ### Commitment: Definition of Done

    The _commitment_ for the Integrated Increment is the **Definition of Done,** which defines the state of the integrated work when it meets the quality and measures required for the product. The Increment is done only when integrated, valuable, and usable. The Nexus Integration Team is responsible for a Definition of Done that can be applied to the Integrated Increment developed each Sprint. All Scrum Teams within the Nexus must define and adhere to this Definition of Done. Individual Scrum Teams self-manage to achieve this state. They may choose to apply a more stringent Definition of Done within their own teams, but cannot apply less rigorous criteria than agreed for the Integrated Increment.

    Decisions made based on the state of artifacts are only as effective as the level of artifact transparency. Incomplete or partial information will lead to incorrect or flawed decisions. The impact of those decisions can be magnified at the scale of Nexus.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\nexus-framework\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\nexus-framework
- FrontMatter:
    title: Manifesto for Agile Software Development
    description: We are uncovering better ways of developing software by doing it and helping others do it. These are our values and principles.
    ResourceId: poyC7fUGitC
    ResourceImport: false
    ResourceType: guides
    ResourceContentOrigin: Human
    resourceTypes: guide
    layout: guide
    aliases:
    - guides/manifesto-for-agile-software-developmen/
    - /learn/agile-delivery-kit/guides/manifesto-for-agile-software-development
    - /resources/poyC7fUGitC
    aliasesArchive:
    - guides/manifesto-for-agile-software-developmen/
    - /learn/agile-delivery-kit/guides/manifesto-for-agile-software-development
    references:
    - title: Manifesto for Agile Software Development
      url: https://agilemanifesto.org/
    recommendedContent: 
    date: 2024-09-17
    weight: 505
    creator: Martin Hinshelwood
    card:
      button:
        content: Learn More
      content: Discover more about Manifesto for Agile Software Development and how it can help you in your Agile journey!
      title: Manifesto for Agile Software Development
    categories:
    - Product Development
    tags:
    - Agile Values and Principles
    - Agile Philosophy
    - Agile Transformation
    - Software Development
    - Value Delivery
    - Working Software
    - Agile Frameworks
    - Agile Planning
    - Organisational Agility
    - Product Delivery
  BodyContent: |
    We are uncovering better ways of developing software by doing it and helping others do it. Through this work we have come to value:

    - **Individuals and interactions** over _processes and tools_
    - **[Working software]({{< ref "/tags/working-software" >}})** over _comprehensive documentation_
    - **Customer collaboration** over _contract negotiation_
    - **Responding to change** over _following a plan_

    That is, while there is value in the items on the right, we value the items on the left more.

    ## Principles behind the Agile Manifesto

    We follow these principles:

    - Our highest priority is to satisfy the customer through early and [continuous delivery]({{< ref "/tags/continuous-delivery" >}}) of valuable software.
    - Welcome changing requirements, even late in development. Agile processes harness change for the customer's competitive advantage.
    - Deliver working software frequently, from a couple of weeks to a couple of months, with a preference to the shorter timescale.
    - Business people and developers must work together daily throughout the project.
    - Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done.
    - The most efficient and effective method of conveying information to and within a development team is face-to-face conversation.
    - Working software is the primary measure of progress.
    - Agile processes promote sustainable development. The sponsors, developers, and users should be able to maintain a constant pace indefinitely.
    - Continuous attention to [technical excellence]({{< ref "/tags/technical-excellence" >}}) and good design enhances agility.
    - Simplicity--the art of maximizing the amount of work not done--is essential.
    - The best architectures, requirements, and designs emerge from self-organizing teams.
    - At regular intervals, the team reflects on how to become more effective, then tunes and adjusts its behavior accordingly.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\manifesto-for-agile-software-development\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\manifesto-for-agile-software-development
- FrontMatter:
    title: Kanban Guide
    description: Kanban is a strategy for optimizing the flow of value through a process that uses a visual, pull-based system.
    ResourceId: uD_5MdHKu1Q
    ResourceImport: false
    ResourceType: guides
    ResourceContentOrigin: Human
    resourceTypes: guide
    layout: guide
    aliases:
    - /learn/agile-delivery-kit/guides/kanban-guide
    - /resources/uD_5MdHKu1Q
    aliasesArchive:
    - /learn/agile-delivery-kit/guides/kanban-guide
    references:
    - title: The Kanban Guide
      url: https://kanbanguides.org/english/
    recommendedContent:
    - collection: practices
      path: _practices/service-level-expectation-sle.md
    date: 2024-09-17
    weight: 840
    creator: Martin Hinshelwood
    card:
      button:
        content: Learn More
      content: Discover more about Kanban Guide and how it can help you in your Agile journey!
      title: Kanban Guide
    categories:
    - Kanban
    - Lean
    tags:
    - Agile Frameworks
    - Flow Efficiency
    - Operational Practices
    - Software Development
    - Value Delivery
    - Throughput
    - Lean Principles
    - Lean Thinking
  BodyContent: |
    December 2020

    By reducing [Kanban]({{< ref "/categories/kanban" >}}) to its essential components, the hope is that this guide will be a unifying reference for the community. By building upon Kanban fundamentals, the strategy presented here can accommodate the full spectrum of [value delivery]({{< ref "/tags/value-delivery" >}}) and organizational challenges.
    {: .lead}

    Any use of the word Kanban in this document specifically means the holistic set of concepts in this guide.

    ## Definition of Kanban

    Kanban is a strategy for optimizing the flow of value through a process that uses a visual, pull-based system. There may be various ways to define value, including consideration of the needs of the customer, the end-user, the organization, and the environment, for example.

    Kanban comprises the following three practices working in tandem:

    - Defining and visualizing a workflow
    - Actively managing items in a workflow
    - Improving a workflow

    In their implementation, these Kanban practices are collectively called a Kanban system. Those who participate in the value delivery of a Kanban system are called Kanban system members.

    ## Why Use Kanban?

    Central to the definition of Kanban is the concept of flow. Flow is the movement of potential value through a system. As most workflows exist to optimize value, the strategy of Kanban is to optimize value by optimizing flow. Optimization does not necessarily imply maximization. Rather, value optimization means striving to find the right balance of effectiveness, efficiency, and predictability in how work gets done:

    - An effective workflow is one that delivers what customers want when they want it.
    - An efficient workflow allocates available economic resources as optimally as possible to deliver value.
    - A predictable workflow means being able to accurately forecast value delivery within an acceptable degree of uncertainty.
    - The strategy of Kanban is to get members to ask the right questions sooner as part of a [continuous improvement]({{< ref "/tags/continuous-improvement" >}}) effort in pursuit of these goals. Only by finding a sustainable balance among these three elements can value optimization be achieved.

    Because Kanban can work with virtually any workflow, its application is not limited to any one industry or context. Professional knowledge workers, such as those in finance, marketing, healthcare, and software (to name a few), have benefited from Kanban practices.

    ## Kanban Theory

    Kanban draws on established flow theory, including but not limited to: [systems thinking]({{< ref "/tags/systems-thinking" >}}), [lean]({{< ref "/categories/lean" >}}) principles, queuing theory (batch size and queue size), variability, and quality control. Continually improving a Kanban system over time based on these theories is one way that organizations can attempt to optimize the delivery of value.

    The theory upon which Kanban is based is also shared by many existing value-oriented methodologies and frameworks. Because of these similarities, Kanban can and should be used to augment those delivery techniques.

    ## Kanban Practices

    ### Defining and Visualizing the Workflow

    Optimizing flow requires defining what flow means in a given context. The explicit shared understanding of flow among Kanban system members within their context is called a Definition of Workflow (DoW). DoW is a fundamental concept of Kanban. All other elements of this guide depend heavily on how workflow is defined.

    **At minimum**, members must create their DoW using all of the following elements:

    - A definition of the individual units of value that are moving through the workflow. These units of value are referred to as work items (or items).
    - A definition for when work items are started and finished within the workflow. Your workflow may have more than one started or finished points depending on the work item.
      One or more defined states that the work items flow through from started to finished. Any work items between a started point and a finished point are considered work in progress (WIP).
    - A definition of how WIP will be controlled from started to finished.
    - Explicit policies about how work items can flow through each state from started to finished.
    - A service level expectation (SLE), which is a forecast of how long it should take a work item to flow from started to finished.

    Kanban system members often require additional DoW elements such as values, principles, and [working agreements]({{< ref "/tags/working-agreements" >}}) depending on the team’s circumstances. The options vary, and there are resources beyond this guide that can help with deciding which ones to incorporate.

    The visualization of the DoW is called a Kanban board. Making at least the minimum elements of DoW transparent on the Kanban board is essential to processing knowledge that informs optimal workflow operation and facilitates continuous process improvement.

    There are no specific guidelines for how a visualization should look as long as it encompasses the shared understanding of how value gets delivered. Consideration should be given to all aspects of the DoW (e.g., work items, policies) along with any other context-specific factors that may affect how the process operates. Kanban system members are limited only by their imagination regarding how they make flow transparent.

    ### Actively Managing Items in a Workflow

    Active management of items in a workflow can take several forms, including but not limited to the following:

    - Controlling WIP.
    - Avoiding work items piling up in any part of the workflow.
    - Ensuring work items do not age unnecessarily, using the SLE as a reference.
    - Unblocking blocked work.

    A common practice is for Kanban system members to review the active management of items regularly. Although some may choose a daily meeting, there is no requirement to formalize the review or meet at a regular cadence so long as active management takes place.

    ### Controlling Work In Progress

    Kanban system members must explicitly control the number of work items in a workflow from start to finish. That control is usually represented as numbers or slots/tokens on a Kanban board that are called WIP limits. A WIP limit can include (but is not limited to) work items in a single column, several grouped columns/lanes/areas, or a whole board.

    A side effect of controlling WIP is that it creates a pull system. It is called a pull system because Kanban system members start work on an item (pulls or selects) only when there is a clear signal that there is capacity to do so. When WIP drops below the limit in the DoW, that is a signal to select new work. Members should refrain from pulling/selecting more than the number of work items into a given part of the workflow as defined by the WIP Limit. In rare cases, system members may agree to pull additional work items beyond the WIP Limit, but it should not be routine.

    Controlling WIP not only helps workflow but often also improves the Kanban system members’ collective focus, commitment, and collaboration. Any acceptable exceptions to controlling WIP should be made explicit as part of the DoW.

    ### Service Level Expectation

    The SLE is a forecast of how long it should take a single work item to flow from started to finished. The SLE itself has two parts: a period of elapsed time and a probability associated with that period (e.g., “85% of work items will be finished in eight days or less”). The SLE should be based on historical [cycle time]({{< ref "/tags/cycle-time" >}}), and once calculated, should be visualized on the Kanban board. If historical cycle time data does not exist, a best guess will do until there is enough historical data for a proper SLE calculation.

    ## Improving the Workflow

    Having made the DoW explicit, the Kanban system members’ responsibility is to continuously improve their workflow to achieve a better balance of effectiveness, efficiency, and predictability. The information they gain from visualization and other Kanban measures guide what tweaks to the DoW may be most beneficial.

    It is common practice to review the DoW from time to time to discuss and implement any changes needed. There is no requirement, however, to wait for a formal meeting at a regular cadence to make these changes. Kanban system members can and should make just-in-time alterations as the context dictates. There is also nothing that prescribes improvements to workflow to be small and incremental. If visualization and the Kanban measures indicate that a big change is needed, that is what the members should implement.

    ## Kanban Measures

    The application of Kanban requires the collection and analysis of a minimum set of flow measures (or metrics). They are a reflection of the Kanban system’s current health and performance and will help inform decisions about how value gets delivered.

    The four mandatory flow measures to track are:

    - **WIP**: The number of work items started but not finished.
    - **[Throughput]({{< ref "/tags/throughput" >}})**: The number of work items finished per unit of time. Note the measurement of throughput is the exact count of work items.
    - **Work Item Age**: The amount of elapsed time between when a work item started and the current time.
    - **Cycle Time**: The amount of elapsed time between when a work item started and when a work item finished.
    - For these mandatory four flow measures, started and finished refer to how the Kanban system members have defined those terms in the DoW.

    Provided that the members use these metrics as described in this guide, members can refer to any of these measures using any other names as they choose.

    In and of themselves, these metrics are meaningless unless they can inform one or more of the three Kanban practices. Therefore, visualizing these metrics using charts is recommended. It does not matter what kind of charts are used as long as they enable a shared understanding of the Kanban system’s current health and performance.

    The flow measures listed in this guide represent only the minimum required for the operation of a Kanban system. Kanban system members may and often should use additional context-specific measures that assist data-informed decisions.

    ## Endnote

    Kanban’s practices and measures are immutable. Although implementing only parts of Kanban is possible, the result is not Kanban. One can and likely should add other principles, methodologies, and techniques to the Kanban system, but the minimum set of practices, measures, and the spirit of optimizing value must be preserved.

    ## History of Kanban

    The present state of Kanban can trace its roots to the Toyota Production System (and its antecedents) and the work of people like Taiichi Ohno and W. Edwards Deming. The collective set of practices for knowledge work that is now commonly referred to as Kanban mostly originated on a team at Corbis in 2006. Those practices quickly spread to encompass a large and diverse international community that has continued to enhance and evolve the approach.

    Extracted from [Kanban Guide](https://kanbanguides.org/){:target="\_blank"}

    This publication is offered for license under the Attribution ShareAlike license of Creative Commons, accessible at http://creativecommons.org/licenses/by-sa/4.0/legalcode and also described in summary form at http://creativecommons.org/licenses/by-sa/4.0/, By using this Kanban Guide, you acknowledge that you have read and agree to be bound by the terms of the Attribution ShareAlike license of Creative Commons. This work is licensed by Orderly Disruption Limited and Daniel S. Vacanti, Inc. under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\kanban-guide\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\kanban-guide
- FrontMatter:
    title: 'The Evidence-Based Management Guide: Improving Value Delivery under Conditions of Uncertainty'
    description: Evidence-Based Management (EBM) is an empirical approach that helps organizations to continuously improve customer outcomes, organizational capabilities, and business results under conditions of uncertainty.
    ResourceId: ltc7lzhy14U
    ResourceImport: false
    ResourceType: guides
    ResourceContentOrigin: Human
    resourceTypes: guide
    layout: guide
    aliases:
    - /learn/agile-delivery-kit/guides/evidence-based-management-guide
    - /resources/ltc7lzhy14U
    aliasesArchive:
    - /learn/agile-delivery-kit/guides/evidence-based-management-guide
    references:
    - title: The Evidence-Based Management Guide | Scrum.org
      url: https://scrum.org/resources/evidence-based-management-guide
    - title: 'Evidence-based Management: Gathering the metrics'
      url: https://nkdagility.com/blog/evidence-based-management-gathering-metrics/
    - title: Metrics that matter with evidence-based management
      url: https://nkdagility.com/blog/metrics-that-matter-with-evidence-based-management/
    - title: 'Evidence-based Management: Gathering the metrics'
      url: https://nkdagility.com/blog/evidence-based-management-gathering-metrics/
    - title: Professional Agile Leadership with Evidence-Based Management (PAL-EBM)
      url: https://nkdagility.com/training/courses/professional-agile-leadership-with-evidence-based-management-pal-ebm-training-experience-with-certification-measuring-value-to-enable-improvement-and-agility/
    recommendedContent: 
    videos: 
    date: 2024-09-17
    weight: 390
    creator: Martin Hinshelwood
    card:
      button:
        content: Learn More
      content: Discover more about The Evidence-Based Management Guide
      title: The Evidence-Based Management Guide Improving Value Delivery under Conditions of Uncertainty
    categories:
    - Product Development
    - Product Management
    tags:
    - Strategic Goals
    - Decision Making
    - Evidence Based Leadership
    - Evidence Based Management
    - Metrics and Learning
    - Value Delivery
    - Agile Product Management
    - Agile Strategy
    - Business Agility
    - Organisational Agility
    - Product Strategy
    - Software Development
    - Enterprise Agility
    - Common Goals
    - Continuous Improvement
  BodyContent: |
    # The Evidence-Based Management Guide: Improving [Value Delivery]({{< ref "/tags/value-delivery" >}}) under Conditions of Uncertainty

    ### May 2024

    Organizations exist for a reason: to achieve something that they think they, uniquely, can achieve. They often express this purpose in different ways, at different levels, to create purpose
    and alignment about what they do:

    - A Vision Statement , an expression of the change that the organization wants to make in the world.
    - A Mission Statement , an expression of why the organization is uniquely capable of achieving the Vision Statement.
    - Goals , on several different levels and timescales, that help the organization achieve its Mission and Vision.

    Organizations form goals to make concrete progress toward achieving their _Mission_ and _Vision_. Without goals, the _Mission_ and _Vision_ are simply lofty aspirations. Furthermore, without effective _Mission_ and _Vision_ statements goals lack a compelling purpose, especially for those working under conditions of uncertainty.

    This Guide defines EBM and its concepts.

    ## Definition of Evidence-Based Management

    Evidence-Based Management (EBM) is a framework that helps people, teams, and organizations make better-informed decisions to help them achieve their goals by using intentional [experimentation]({{< ref "/tags/experimentation" >}}) and feedback.

    ## EBM Helps Organizations Achieve Their Goals in a Complex World

    Complex problems don't have easy solutions. In order to solve them, organizations must experiment by defining, working toward, and achieving larger goals in small steps. Each step
    involves comparing the actual result of the experiment with its desired outcome, and adapting the next step based accordingly (see Figure 1).^1

    EBM focuses on three levels of goals:

    - [Strategic Goals]({{< ref "/tags/strategic-goals" >}}), important things that the organization feels it needs to achieve to realize its Mission and Vision. These goals are so big and far away, with many uncertainties along the journey that the organization must use empiricism to achieve them. Because a Strategic Goal is aspirational and the path to achieving it is uncertain, the organization needs a series of practical targets, like Intermediate Goals.
    - Intermediate Goals , achievements of which will indicate that the organization is on the path to a Strategic Goal. The path to the Intermediate Goal is often still somewhat uncertain, but not completely unknown.
    - Immediate Tactical Goals , which are the current focus of the organization’s improvement efforts.

    To progress towards Strategic and Intermediate goals, organizations form hypotheses about improvements they can make to move toward their Immediate Tactical Goals. These
    hypotheses form the basis of experiments that they run to try to improve. They measure the results of these experiments (evidence) to evaluate their progress toward their goals, and to
    determine their next steps (new hypotheses), which may include adjusting their goals based on what they have learned. This is empiricism in action with EBM.

    (^1) 1 For more on complexity, see the [Scrum]({{< ref "/categories/scrum" >}}) Theory section of the Scrum Guide at
    https://www.scrumguides.org/scrum-guide.html

    **Figure 1: Reaching strategic goals requires experimenting, inspecting, and adapting**^2

    ### Setting Goals

    Organizations must define measurable goals that will indicate whether that goal is achieved. These measurable goals, measures, and experiments should be made transparent in order to
    encourage organizational alignment.

    (^2) 2 Figure adapted from Mike Rother’s Improvement Kata
    (http://wwwpersonal.umich.edu/~mrother/The_Improvement_Kata.html)

    Consider the case of the response to an infectious disease:

    - The Strategic Goal is to eradicate the effects of the disease as measured by the number of people who fall ill and suffer significant illness. Measurement is important to understand if progress is being made and if the strategic goal is relevant across time. In this example, the goal is focused on the effects of the disease, and not on the means for
      achieving the desired impact. For example, the goal is not to vaccinate a certain percentage of the population against the disease. While that may be an activity
      necessary to achieving the Strategic Goal, it is not the Strategic Goal.
    - An example of an Intermediate Goal is the successful completion of a trial of a vaccine against the disease. This is still ambitious and measurable, and achieving it may require the completion of many different activities. It is a necessary step on the path to achieving the Strategic Goal.
    - Examples of immediate tactical goals may include activities like isolating symptoms, evaluating a therapy, sequencing the DNA of a virus or bacterium, and so forth. These are critical near-term objectives toward which a team or group of teams will work.

    The Strategic Goal is usually focused on achieving a highly desirable but unrealized outcome for a specific group of people. Achieving the goal results in improved happiness, safety,
    security, or well-being of the recipients of some product or service. In EBM, we refer to this as Unrealized Value, which is the satisfaction gap between a beneficiary’s desired outcome and
    their current experience. Unrealized Value is described in greater detail below, in the Key Value Areas section.

    ## Understanding What is Valuable

    Organizations measure many different kinds of things. Broadly speaking, measures fall into five categories:

    - _Inputs_. These are things that the organization spends money on. While necessary to produce value, there is no correlation between the amount of input and the value that customers experience. Inputs establish constraints on experiments, e.g. an organization may establish limits on how much a team may spend (the input) to test an improvement idea.
    - _Activities_. These are things that people in the organization do, such as perform work, go to meetings, have discussions, write code, create reports, attend conferences, and so
      forth.
    - _Outputs_. These are things that the organization produces, such as product releases (including features), reports, defect reports, product reviews, and so on.
    - _Outcomes_. These are desirable things that a customer or user of a product experiences. They represent some new or improved capability that the customer or user was not able to achieve before. Examples include being able to travel to a destination faster than before, or being able to earn or save more money than before. Outcomes can also be negative, as in the case where the value a customer or user experiences declines from previous experiences, for example when a service they previously relied upon is no longer available.
    - _Impacts_. Results that the organization or its non-customer stakeholders (such as investors) achieve when customers or users of a product achieve their desired outcomes. Examples include things like increased revenue or profit, improved [market share]({{< ref "/tags/market-share" >}}), and increased share price. Positive Impacts are only sustainably achievable when customers experience improved outcomes.

    The problem most organizations face, which is often reflected in the things they measure, is that measuring activities and outputs is easy, while measuring outcomes is difficult. Organizations may gather a lot of data with insufficient information about their ability to deliver value. However, delivering valuable outcomes to customers is essential if organizations are to reach their goals. For example, working more hours (activities) and delivering more features (outputs) does not necessarily lead to improved customer experiences (outcomes).

    While it is possible for organizations to improve _impacts_ without improving customer outcomes, doing so usually harms the organization, such as when it reduces product quality to improve
    profitability, or when it sells products below cost to increase revenue and market share but harms profitability. Achieving impacts is important, but they have to be achieved in a sustainable way that does not harm the organization’s long-term viability.

    #### Making Progress Toward Goals in a Series of Small Steps

    The first step in the journey toward a Strategic Goal is understanding your Current State to frame your thinking about where and how you need to improve. For example, if your goal is to
    improve the satisfaction of your customers you will need to know what your customers experience today and what they would like to experience in the future. You will probably also
    need to understand your own capability for delivering value, i.e. how fast you are able to makeimprovements in the value that your customers will experience, so that you can set realistic
    short and medium term goals.

    The Experiment Loop (shown in Figure 1) helps organizations move from their Current State toward their Immediate Tactical Goal, their Intermediate Goal, and ultimately their Strategic
    Goal, by taking small, measured steps, called experiments, using explicit hypotheses.^3 This loop consists of:

    - _Forming a hypothesis for improvement._ Based on experience, form an idea of
      something you think will help you move toward your Immediate Tactical Goal, and
      decide how you will know whether this experiment succeeded based on measurement.
    - _Running your experiments._ Make the change you think will help you to improve, and
      gather data to support or refute your hypothesis.

    (^3) The Experiment Loop is a variation on the Shewhart Cycle, popularized by W. Edwards Deming, also
    sometimes called the PDCA (Plan-Do-Check-Act) cycle; see https://en.wikipedia.org/wiki/PDCA.

    - Inspecting your results. Did the change you made improve your results based on the measurements you have made? Not all changes do; some changes actually make things worse.
    - Adapting your goals or your approach based on what you learned. Both your goals and your improvement experiments will likely evolve as you learn more about customers, competitors, and your organization's capabilities. Goals can change because of outside events, and your tactics to reach your goals may need to be reconsidered and revised, for example:
    - Was the Immediate Tactical Goal the right goal?
    - Are the Intermediate and Strategic Goals still relevant or do they need to be adapted?
    - If you failed to achieve the Immediate Tactical Goal but you think it is still important to achieve, how might you do better next time?
    - If you achieved your Intermediate or Strategic Goals you will need to formulate new goals.

    ### Hypotheses, Experiments, Features, and Requirements

    Organizations can spend a lot of money implementing features (distinguishing characteristics) and other requirements in products,^4 only to find that customers don’t share the company’s
    opinion on their value; beliefs in what is valuable are merely assumptions until they are validated by customers. This is where hypotheses and experiments are useful.

    A hypothesis is a belief that doing something will lead to something else, such as delivering feature X will lead to outcome Y. An experiment is a test that is designed to prove or reject
    some hypothesis.

    Every feature and every requirement really represents a hypothesis about value. One of the goals of an empirical approach is to make these hypotheses explicit and to consciously design
    experiments that explicitly test the value of the features and requirements. The entire feature or requirement need not actually be built to determine whether it is valuable; it may be sufficient for a team to simply build enough of it to validate critical assumptions that would prove or disprove its value.

    Explicitly forming hypotheses, measuring results, and inspecting and adapting goals based on those results are implicit parts of an agile approach. Making this work explicit and transparent is what EBM adds to the organizational improvement process.

    (^4) Adapted from the IEEE 829 specification

    ## EBM Uses Key Value Areas to Examine Improvement

    ## Opportunities

    In addition to using hypotheses and experiments to move toward goals, EBM provides a set of perspectives on value and the organization’s ability to deliver value. These perspectives are
    called Key Value Areas (KVAs). These areas examine the goals of the organization (Unrealized Value), the current state of the organization relative to those goals ([Current Value]({{< ref "/tags/current-value" >}})), the
    responsiveness of the organization in delivering value (Time-to-Market), and the effectiveness of the organization in delivering value (Ability-to-Innovate).

    Market value KVAs (UV, CV) reflect customer outcomes. Whereas, organizational capability KVAs (A2I, T2M) reflect the organization’s ability to deliver valuable customer outcomes, and
    so may be measured in terms of either outcomes or outputs. Input, activity, output, and impact measures do not tell an organization anything about organizational capability to deliver valuable outcomes.

    Focusing on these four dimensions enables organizations to better understand where they are and where they need to go (see Figure 2).

    **Figure 2: Key Value Areas provide lenses to examine improvement opportunities.**

    Each KVA focuses on a different aspect of either value, or the ability of the organization to deliver value. Delivering business value (Current Value) is important, but organizations must
    also show that they can respond to change (Time-to-Market) while being able to sustain innovation over time (Ability-to-Innovate). And they must be able to continually make progress
    toward their long-term goals (Unrealized Value) or they risk succumbing to stagnation and complacency.

    ### Current Value (CV)

    ##### Measures that quantify the value that the product delivers today

    The purpose of looking at CV measures is to understand the value that an organization delivers to customers and stakeholders at the present time; it considers only what exists right now, not
    the value that might exist in the future. Questions that organizations need to continually re-evaluate for current value are:

    1. How happy are users and customers today? Is their happiness improving or declining?
    2. How happy are your employees today? Is their happiness improving or declining?
    3. How happy are your investors and other stakeholders today? Is their happiness improving or declining?

    Considering CV helps an organization understand the value that their customers or users experience today.

    Example: While profit, one way to measure investor happiness, will tell you the economic impact of the value that you deliver, knowing whether customers are happy with their purchase will tell you more about where you may need to improve to keep those customers. If your customers have few alternatives to your product, you may have high profit even though customer atisfaction is low. Considering CV from several perspectives will give you a better understanding of your challenges and opportunities.

    Customer happiness and investor happiness also do not tell the whole story about your ability to deliver value. Considering employee attitudes recognizes that employees are ultimately the producers of value. Engaged employees that know how to maintain, sustain and enhance the product are one of the most significant assets of an organization, and happy employees are more engaged and productive.

    ### Unrealized Value (UV)

    ##### Measures that quantify the potential future value that could be realized if the organization met the needs of all potential customers or users

    Looking at Unrealized Value measures helps an organization to maximize the value that it realizes from a product or service over time. When customers, users, or clients experience a
    gap between their current experience and the experience that they would like to have, the difference between the two represents an opportunity; this opportunity is measured by Unrealized Value.

    Questions that organizations need to continually re-evaluate for UV are:

    1. Can any additional value be created by our organization in this market or other markets?
    2. Is it worth the effort and risk to pursue these untapped opportunities?
    3. Should further investments be made to capture additional Unrealized Value?

    The consideration of both CV and UV provides organizations with a way to balance present and possible future benefits. Strategic Goals are formed from some satisfaction gap and an
    opportunity for an organization to decrease UV by increasing CV.

    Example : A product may have low CV, because it is an early version being used to test the market, but very high UV, indicating that there is great market potential. Investing in
    the product to try to boost CV is probably warranted, given the potential returns, even though the product is not currently producing high CV.

    Conversely, a product with very high CV, large market share, no near competitors, and very satisfied customers may not warrant much new investment; this is the classic cash cow product that is very profitable but nearing the end of its product investment cycle with low UV.

    ### [Ability to Innovate]({{< ref "/tags/ability-to-innovate" >}}) (A2I)

    ##### Measures that quantify the effectiveness of an organization in delivering new capabilities

    The goal of looking at A2I measures is to maximize the organization’s ability to deliver new capabilities and innovative solutions. Organizations should continually re-evaluate their A2I by
    asking:

    1. What prevents the organization from delivering new value?
    2. What prevents customers or users from benefiting from that innovation?

    Improving A2I helps an organization become more effective in ensuring that the work that it does improves the value that its products or services deliver to customers or users.

    Example : A variety of things can impede an organization from being able to deliver new capabilities and value: spending too much time remedying poor product quality, needing to maintain multiple variations of a product due to lack of operational excellence, lack of decentralized decision-making, inability to hire and inspire talented, passionate team-members, and so on.

    As low-value features and systemic impediments accumulate, more budget and time are consumed maintaining the product or overcoming impediments, reducing its available capacity to innovate. In addition, anything that prevents users or customers from benefiting from innovation, such as hard to assemble/install products or new versions of products, will also reduce A2I.

    ### Time-to-Market (T2M)

    ##### Measures that quantify how quickly the organization can deliver and learn from feedback they gather from experiments

    The reason for looking at T2M measures is to minimize the amount of time it takes for the organization to deliver something that is potentially valuable. To know this they must measure
    the result so that they know whether they actually improved the value their customers experienced. Questions that organizations need to ask to evaluate their T2M are:

    1. How fast can the organization learn from new experiments and information?
    2. How fast can you adapt based on the information?
    3. How fast can you test new ideas with customers?

    Improving T2M helps improve the frequency at which an organization can potentially change CV.

    Example : Reducing the number of features in a product release can dramatically improve T2M; the smallest release possible is one that delivers at least some incremental improvement in value to some subset of the customers/users of the product. Many organizations also focus on removing non value-added activities from the [product development]({{< ref "/categories/product-development" >}}) and delivery process to improve their T2M.

    Example Key Value Measures (KVMs) for each KVA are described in the Appendix.

    ## Inspecting and Adapting Based on Experiment Results

    Once you have gathered measures from your experiments to improve value, you will need to inspect or evaluate your results against your goals to see if your improvement ideas worked.
    Examining measures in each of the Key Value Areas will help you to maintain a balanced perspective.

    Immediate Tactical Goals should improve Current Value and reduce Unrealized Value. Even when Immediate Tactical Goals are focused on organizational effectiveness or speed of obtaining feedback, considering CV and UV helps the organization keep [customer satisfaction]({{< ref "/tags/customer-satisfaction" >}}) in sight. Each KVAs is a different lens that helps you focus on different aspects of your performance towards the goals you are trying to achieve.

    Similarly, when your Immediate Tactical Goals are focused on improving effectiveness (A2I) or the speed at which you can obtain feedback (T2M), you never want to ignore or take for granted
    your customers’ experiences. When an organization targets improvements only in A2I and T2M without monitoring CV and UV, they are focused only on internal processes that may not help
    them further satisfy customers or achieve value. This can lead to, or be an indication of, a lack of outcome-based goals.

    If you succeed in achieving your Immediate Tactical Goal, congratulations! Your next step will be to form a new Immediate Tactical Goal that, when achieved, will take you closer to your
    Intermediate Goal. Continue devising experiments, or things you can try, to achieve that goal.

    If you’ve actually achieved your Intermediate Goal, even better! Now you’ll need to form a new Intermediate Goal that, when you achieve it, will move you closer to your Strategic Goal. You’ll also need to form a new Immediate Tactical Goal to provide you with a nearer target to work toward.

    Sometimes you’ll find that your goals need adjusting. You might discover that a goal is no longer relevant, or that it needs to be refined. This can happen to your goals at any level. And
    sometimes you’ll fail to reach your Immediate Tactical Goal because your experiment did not produce the results you had expected. This is not a bad thing, and what you learned helps you
    to devise new experiments that may yield better results.

    ## End Note

    Evidence-Based Management is free and offered in this Guide. Although implementing only
    parts of EBM is possible, the result is not Evidence-Based Management.

    ## Acknowledgements

    Evidence-Based Management was collaboratively developed by Scrum.org, the Professional
    Scrum Trainer Community, Ken Schwaber and Christina Schwaber.

    ## Appendix: Example Key Value Measures

    To encourage adaptability, EBM defines no specific Key Value Measures (KVMs). KVMs listed below are presented to show the kinds of measures that might help an organization to understand its current state, desired future state, and factors that influence its ability to improve.

    ### Current Value (CV)

    | KVM                   | Measuring                                                                                                                                                                                            |
    | --------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | [Revenue per Employee]({{< ref "/tags/revenue-per-employee" >}})  | The ratio (gross revenue / # of employees) is a key competitive indicator within an industry. This varies significantly by industry.                                                                 |
    | Product Cost Ratio    | Total expenses and costs for the product(s)/system(s) being measured, including operational costs compared to revenue.                                                                               |
    | Employee Satisfaction | Some form of sentiment analysis to help gauge [employee engagement]({{< ref "/tags/employee-engagement" >}}), energy, and enthusiasm.                                                                                                           |
    | Customer Satisfaction | Some form of sentiment analysis to help gauge customer engagement and happiness with the product.                                                                                                    |
    | Customer Usage Index  | Measurement of usage, by feature, to help infer the degree to which customers find the product useful and whether actual usage meets expectations on how long users should be taking with a feature. |

    {: .table .table-striped .table-bordered .d-none .d-md-block}

    ### Unrealized Value (UV)

    | KVM                                         | Measuring                                                                                                                                                       |
    | ------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | Market Share                                | The relative percentage of the market not controlled by the product; the potential market share that the product might achieve if it better met customer needs. |
    | Customer or User Satisfaction Gap           | The difference between a customer or user’s desired experience and their current experience.                                                                    |
    | Desired Customer Experience or satisfaction | A measure that indicates the experience that the customer would like to have.                                                                                   |

    {: .table .table-striped .table-bordered .d-none .d-md-block}

    ### Time-to-Market (T2M)

    | KVM                             | Measuring                                                                                                                                                                                                                                                                                                                                                                                                          |
    | ------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
    | Build and Integration Frequency | The number of integrated and tested builds per time period. For a team that is releasing frequently or continuously, this measure is superseded by actual release measures.                                                                                                                                                                                                                                        |
    | Release Frequency               | The number of releases per time period, e.g. continuously, daily, weekly, monthly, quarterly, etc. This helps reflect the time needed to satisfy the customer with new and competitive products.                                                                                                                                                                                                                   |
    | Release Stabilization Period    | The time spent correcting product problems between the point the developers say it is ready to release and the point where it is actually released to customers. This helps represent the impact of poor development practices and underlying design and codebase.                                                                                                                                                 |
    | Mean Time to Repair             | The average amount of time it takes from when an error is detected and when it is fixed. This helps reveal the efficiency of an organization to fix an error.                                                                                                                                                                                                                                                      |
    | Customer [Cycle Time]({{< ref "/tags/cycle-time" >}})             | The amount of time from when work starts on a release until the point where it is actually released. This measure helps reflect an organization’s ability to reach its customer.                                                                                                                                                                                                                                   |
    | [Lead Time]({{< ref "/tags/lead-time" >}})                       | The amount of time from when an idea is proposed or a hypothesis is formed until a customer can benefit from that idea. This measure may vary based on customer and product. It is a contributing factor in customer satisfaction.                                                                                                                                                                                 |
    | Lead Time for Changes           | The amount of time to go from code-committed to code successfully running in production. For more information, see the DORA 2019 report.                                                                                                                                                                                                                                                                           |
    | [Deployment Frequency]({{< ref "/tags/deployment-frequency" >}})            | The number of times that the organization deployed (released) a new version of the product to customers/users. For more information, see the DORA 2019 report.                                                                                                                                                                                                                                                     |
    | Time to Restore Service         | The amount of time between the start of a service outage and the restoration of full availability of the service. For more information, see the DORA 2019 report.                                                                                                                                                                                                                                                  |
    | Time-to-Learn                   | The total time needed to sketch an idea or improvement, build it, deliver it to users, and learn from their usage.                                                                                                                                                                                                                                                                                                 |
    | Time to remove Impediment       | The average amount of time from when an impediment is raised until when it is resolved. It is a contributing factor to lead time and employee satisfaction                                                                                                                                                                                                                                                         |
    | Time to Pivot                   | A measure of true [business agility]({{< ref "/tags/business-agility" >}}) that presents the elapsed time between when an organization receives feedback or new information and when it responds to that feedback; for example, the time between when it finds out that a competitor has delivered a new market-winning feature to when the organization responds with matching or exceeding new capabilities that measurably improve customer experience. |

    {: .table .table-striped .table-bordered .d-none .d-md-block}

    ### Ability to Innovate (A2I)

    | KVM                                      | Measuring                                                                                                                                                                                                                                                      |
    | ---------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | Innovation Rate                          | The percentage of effort or cost spent on new product capabilities, divided by total product effort or cost. This provides insight into the capacity of the organization to deliver new product capabilities.                                                  |
    | Defect Trends                            | Measurement of change in defects since the last measurement. A defect is anything that reduces the value of the product to a customer, user, or to the organization itself. Defects are generally things that don’t work as intended.                          |
    | On-Product Index                         | The percentage of time teams spend working on product and value.                                                                                                                                                                                               |
    | Installed Version Index                  | The number of versions of a product that are currently being supported. This reflects the effort the organization spends supporting and maintaining older versions of the software.                                                                            |
    | [Technical Debt]({{< ref "/tags/technical-debt" >}})                           | A concept in programming that reflects the extra development and testing work that arises when “quick and dirty” solutions result in later remediation. It creates an undesirable impact on the delivery of value and an avoidable increase in waste and risk. |
    | Production Incident Count                | The number of times in a given period that the Development Team was interrupted to fix a problem in an installed product. The number and frequency of Production Incidents can help indicate the stability of the product.                                     |
    | Active Product (Code) Branches           | The number of different versions (or variants) of a product or service. Provides insight into the potential impact of change and the resulting complexity of work.                                                                                             |
    | Time Spent Merging Code Between Branches | The amount of time spent applying changes across different versions of a product or service. Provides insight into the potential impact of change and the resulting complexity of work.                                                                        |
    | Time Spent Context-Switching             | Examples include time lost to interruptions caused by meetings or calls, time spent switching between tasks, and time lost when team members are interrupted to help people outside the team can give simple insight into the magnitude of the problem.        |
    | Change Failure Rate                      | The percentage of released product changes that result in degraded service and require remediation (e.g. hotfix, rollback, patch). For more information, see the DORA 2019 report.                                                                             |

    {: .table .table-striped .table-bordered .d-none .d-md-block}

    The percentage of released product changes that result in degraded service
    and require remediation (e.g. hotfix, rollback, patch). For more information,
    see the DORA 2019 report.

    © 2024 Scrum.org
    This publication is offered for license under the Attribution Share-Alike license of Creative
    Commons, accessible at http://creativecommons.org/licenses/by-sa/4.0/legalcode and also
    described in summary form at http://creativecommons.org/licenses/by-sa/4.0/. By utilizing this
    EBM Guide, you acknowledge and agree that you have read and agree to be bound by the
    terms of the Attribution Share-Alike license of Creative Commons.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\evidence-based-management-guide\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\evidence-based-management-guide
- FrontMatter:
    title: Kanban Guide for Scrum Teams
    description: The flow-based perspective of Kanban can enhance and complement the Scrum framework and its implementation.
    ResourceId: Z3HzXH_nmmz
    ResourceImport: false
    ResourceType: guides
    ResourceContentOrigin: Human
    resourceTypes: guide
    layout: guide
    aliases:
    - /guides/Kanban-Guide-for-Scrum-Teams.html
    - /learn/agile-delivery-kit/guides/kanban-guide-for-scrum-teams
    - /resources/Z3HzXH_nmmz
    aliasesArchive:
    - /guides/Kanban-Guide-for-Scrum-Teams.html
    - /learn/agile-delivery-kit/guides/kanban-guide-for-scrum-teams
    references:
    - title: The Kanban Guide for Scrum Teams on Scrum.org
      url: https://scrum.org/resources/kanban-guide-scrum-teams
    - title: Work can flow across the Sprint boundary
      url: https://nkdagility.com/blog/work-can-flow-across-sprint-boundary/
    - title: No Estimates and is it advisable for a Scrum Team to adopt it?
      url: https://nkdagility.com/blog/no-estimates-and-is-it-advisable-for-a-scrum-team-to-adopt-it/
    recommendedContent:
    - collection: practices
      path: _practices/service-level-expectation-sle.md
    date: 2024-09-17
    weight: 840
    creator: Martin Hinshelwood
    card:
      button:
        content: Learn More
      content: Discover more about Kanban Guide for Scrum Teams and how it can help you in your Agile journey!
      title: Kanban Guide for Scrum Teams
    categories:
    - Product Development
    tags:
    - Software Development
    - Flow Efficiency
    - Operational Practices
    - Metrics and Learning
    - Transparency
    - Value Delivery
    - Agile Frameworks
    - Empirical Process Control
    - Throughput
    - Cycle Time
    - Scrum Team
    - Pragmatic Thinking
    - Team Performance
    - Agile Product Management
  BodyContent: |
    The flow-based perspective of [Kanban]({{< ref "/categories/kanban" >}}) can enhance and complement the [Scrum]({{< ref "/categories/scrum" >}}) framework and its implementation. Teams can add complementary Kanban practices whether they are just starting to use Scrum or have been using it all along. The Kanban Guide for Scrum Teams is the result of a collaboration between members of the Scrum.org community and leaders of the Kanban community. Together, they stand behind The Kanban Guide for Scrum Teams. It is their shared belief that professional [product development]({{< ref "/categories/product-development" >}}) practitioners can benefit from the application of Kanban together with Scrum.
    {: .lead}

    ### Relation to the Scrum Guide

    This guide does not replace or discount any part of The Scrum Guide. It is designed to enhance and expand the practices of Scrum. This guide assumes the reader is operating a process using the Scrum framework. Therefore, The Scrum Guide applies in its entirety.

    ## Definition of Kanban

    Kanban (n): a strategy for optimizing the flow of value through a process that uses a visual, work-in-progress limited pull system.

    ## Kanban with Scrum Theory

    ### Flow and Empiricism

    Central to the definition of Kanban is the concept of flow. Flow is the movement of value throughout the product development system. Kanban optimizes flow by improving the overall efficiency, effectiveness, and predictability of a process. Optimizing flow in a Scrum context requires defining what flow means in Scrum. Scrum is founded on [empirical process control]({{< ref "/tags/empirical-process-control" >}}) theory, or empiricism. Key to empirical process control is the frequency of the [transparency]({{< ref "/tags/transparency" >}}), inspection, and adaptation cycle – which we can also describe as the [cycle time]({{< ref "/tags/cycle-time" >}}) through the feedback loop. When Kanban practices are applied to Scrum, they provide a focus on improving the flow through the feedback loop; optimizing transparency and the frequency of inspection and adaptation for both the product and the process.

    ### The Basic Metrics of Flow

    The four basic metrics of flow that Scrum Teams using Kanban need to track are as follows:

    - **Work in Progress (WIP)**: The number of work items started but not finished. Note the difference between the WIP metric and the policies a [Scrum Team]({{< ref "/tags/scrum-team" >}}) uses to limit WIP. The team can use the WIP metric to provide transparency about their progress towards reducing their WIP and improving their flow.
    - **Cycle Time**: The amount of elapsed time between when a work item starts and when a work item finishes.
    - **Work Item Age**: The amount of time between when a work item started and the current time. This applies only to items that are still in progress.
    - **[Throughput]({{< ref "/tags/throughput" >}})**: The number of work items finished per unit of time.

    ### Little’s Law – The Key to Governing Flow

    A key tenet governing flow theory is Little’s Law, which is a guideline that establishes the following relationship:

    ![Littles Law](https://nkdagility.com/wp-content/uploads/2020/11/naked-agility-littles-law.jpg)

    Little’s Law reveals that in general, for a given process with a given throughput, the more things that you work on at any given time (on average), the longer it is going to take to finish those things (on average). If cycle times are too long, the first action Scrum Teams should consider is lowering WIP. Most of the other elements of Kanban are built upon the relationship between WIP and cycle time. Little’s Law also shows us how flow theory relies on empiricism by using flow metrics and data to gain transparency into the historical flow and then using that data to inform flow inspection and adaptation experiments.

    ## Kanban Practices

    Scrum Teams can achieve flow optimization by using the following four practices:

    - Visualization of the workflow
    - Limiting Work in Progress (WIP)
    - Active management of work items in progress
    - Inspecting and adapting the team’s definition of “Workflow”

    ### Definition of “Workflow”

    The four Kanban practices are enabled by the Scrum Team’s Definition of Workflow. This definition represents the Scrum Team members’ explicit understanding of what their policies are for following the Kanban practices. This shared understanding improves transparency and enables self-management. Note that the scope of the Definition of Workflow may span beyond the Sprint and the Sprint Backlog. For instance, a Scrum Team‘s Definition of Workflow may encompass flow inside and/or outside of the Sprint. Creating and adapting the Definition of Workflow is the accountability of the relevant roles on the Scrum Team as described in the Scrum Guide. No one outside of the Scrum Team should tell the Scrum Team how to define their Workflow.

    ### Visualization of the Workflow – the Kanban Board

    Visualization using the Kanban board is the way the Scrum Team makes its Workflow transparent. The board’s configuration should prompt the right conversations at the right time and proactively suggest opportunities for improvement. Visualization should include the following:

    - Defined points at which the Scrum Team considers work to have started and to have finished.
    - A definition of the work items – the individual units of value (stakeholder value, knowledge value, process improvement value) that are flowing through the Scrum Team’s system (most likely [Product Backlog]({{< ref "/tags/product-backlog" >}}) items (PBIs)).
    - A definition of the workflow states that the work items flow through from start to finish (of which there must be at least one active state).
    - Explicit policies about how work flows through each state (which may include items from a Scrum Team’s [Definition of Done]({{< ref "/tags/definition-of-done" >}}) and pull policies between stages).
    - Policies for limiting Work in Progress (WIP).

    ### Limiting Work in Progress (WIP)

    Work in Progress (WIP) refers to the work items the Scrum Team has started but has not yet finished. Scrum Teams using Kanban must explicitly limit the number of these work items in progress. A Scrum Team can explicitly limit WIP however they see fit but should stick to that limit once established. The primary effect of limiting WIP is that it creates a pull system. It is called a pull system because the team starts work (i.e. pulls) on an item only when it is clear that it has the capacity to do so. When the WIP drops below the defined limit, that is the signal to start new work. Note this is different from a push system, which demands that work starts on an item whenever it is requested. Limiting WIP helps flow and improves the Scrum Team’s self-management, focus, commitment, and collaboration.

    ### Active Management of Work Items in Progress

    Limiting WIP is necessary to achieve flow, but it alone is not sufficient. The third practice to establish flow is the active management of work items in progress. Within the Sprint, this management by the Scrum Team can take several forms, including but not limited to the following:

    - Making sure that work items are only pulled into the Workflow at about the same rate that they leave the Workflow.
    - Ensuring work items aren’t left to age unnecessarily.
    - Responding quickly to blocked or queued work items as well those that are exceeding the team’s expected Cycle Time levels (See Service Level Expectation – SLE).

    ### Service Level Expectation (SLE)

    A service level expectation (SLE) forecasts how long it should take a given item to flow from start to finish within the Scrum Team’s Workflow. The Scrum Team uses its SLE to find active flow issues and to inspect and adapt in cases of falling below those expectations. The SLE itself has two parts: a range of elapsed days and a probability associated with that period (e.g., 85% of work items should be finished in eight days or less). The SLE should be based on the Scrum Team’s historical Cycle Time, and once calculated, the Scrum Team should make it transparent. If no historical Cycle Time data exists, the Scrum Team should make its best guess and then inspect and adapt once there is enough historical data to do a proper SLE calculation.

    ### Inspect and Adapt the Definition of “Workflow”

    The Scrum Team uses the existing Scrum events to inspect and adapt its Definition of Workflow, thereby helping to improve empiricism and optimizing the value the Scrum Team delivers. The following are aspects of the Definition of Workflow the Scrum Team might adopt:

    - **Visualization policies** – for example, Workflow states – either changing the actual Workflow or bringing more transparency to an area in which the team wants to inspect and adapt.
    - **How-we-work policies** – these can directly address an impediment. For example, adjusting WIP limits and SLEs or changing the batch size (how often items are pulled between states) can have a dramatic impact.

    ## Flow-Based Events

    Kanban in a Scrum context does not require any additional events to those outlined in The Scrum Guide. However, using a flow-based perspective and metrics in Scrum’s events strengthens Scrum’s empirical approach.

    ### The Sprint

    The Kanban complementary practices don’t invalidate the need for Scrum’s Sprint. The Sprint and its events provide opportunities for inspection and adaptation of both product and process. It’s a common misconception that teams can only deliver value once per Sprint. In fact, they must deliver value at least once per Sprint. Teams using Scrum with Kanban use the Sprint and its events as a feedback improvement loop by collaboratively inspecting and adapting their Definition of Workflow and flow metrics. Kanban practices can help Scrum Teams improve flow and create an environment where decisions are made just-in-time throughout the Sprint based on inspection and adaptation. In this environment, Scrum Teams rely on the Sprint Goal and close collaboration within the Scrum Team to optimize the value delivered in the Sprint

    ### Sprint Planning

    A flow-based Sprint Planning meeting uses flow metrics as an aid for developing the Sprint Backlog. Reviewing historical throughput can help a Scrum Team understand their capacity for the next Sprint.

    ### [Daily Scrum]({{< ref "/tags/daily-scrum" >}})

    A flow-based Daily Scrum focuses the Developers on doing everything they can to maintain consistent flow. While the goal of the Daily Scrum remains the same as outlined in The Scrum Guide, the meeting itself takes place around the Kanban board and focuses on where flow is lacking and on what actions the Developers can take to get it back. Additional things to consider during a flow-based Daily Scrum include the following:
    What work items are blocked and what can be done to get them unblocked?
    What work is flowing slower than expected? What is the Work Item Age of each item in progress? What work items have violated or are about to violate their SLE and what can the Scrum Team do to get that work completed?
    Are there any factors not represented on the board that may impact our ability to complete work today?
    Have we learned anything new that might change what the Scrum Team has planned to work on next?
    Have we broken our WIP limit? And what can we do to ensure we can complete the work in progress?

    ### [Sprint Review]({{< ref "/tags/sprint-review" >}})

    The Scrum Guide provides an outline of the Sprint Review. Inspecting Kanban flow metrics as part of the review can create opportunities for new conversations about monitoring progress towards the Product Goal. Reviewing Throughput can provide additional information when the [Product Owner]({{< ref "/tags/product-owner" >}}) discusses likely delivery dates.

    ### Sprint Retrospective

    A flow-based Sprint Retrospective adds the inspection of flow metrics and analytics to help determine what improvements the Scrum Team can make to its processes. The Scrum Team using Kanban also inspects and adapts the Definition of Workflow to optimize the flow in the next Sprint. Using a cumulative flow diagram to visualize a Scrum Team’s WIP, approximate average Cycle Time and average Throughput can be valuable. In addition to the Sprint Retrospective, the Scrum Team should consider taking advantage of process inspection and adaptation opportunities as they emerge throughout the Sprint. Similarly, changes to a Scrum Team’s Definition of Workflow may happen at any time. Because these changes will have a material impact on how the Scrum Team performs, changes made during the regular cadence provided by the Sprint Retrospective event will reduce complexity and improve focus, commitment and transparency.

    ### [Increment]({{< ref "/tags/increment" >}})

    Scrum requires the team to create (at minimum) a valuable, useful Increment every Sprint. Scrum’s empiricism encourages the creation of multiple valuable increments during the Sprint to enable fast inspect and adapt feedback loops. Kanban helps manage the flow of these feedback loops more explicitly and allows the Scrum Team to identify bottlenecks, constraints, and impediments to enable this faster, more [continuous delivery]({{< ref "/tags/continuous-delivery" >}}) of value
    Check our blog for more details
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\kanban-guide-for-scrum-teams\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\kanban-guide-for-scrum-teams
- FrontMatter:
    title: Investing for Business Agility - Using evidence-based portfolio management to achieve better business outcomes
    description: Discover how to enhance business agility beyond teams with evidence-based portfolio management for improved competitiveness and responsiveness.
    ResourceId: KD08D48Weks
    ResourceImport: false
    ResourceType: guides
    ResourceContentOrigin: Human
    resourceTypes: guide
    layout: guide
    date: 2024-09-17
    weight: 1000
    creator: Martin Hinshelwood
    aliases:
    - /learn/agile-delivery-kit/guides/evidence-based-portfolio-management
    - /resources/KD08D48Weks
    aliasesArchive:
    - /learn/agile-delivery-kit/guides/evidence-based-portfolio-management
    card:
      button:
        content: Learn More
      content: Discover more about Investing for Business Agility - Using evidence-based portfolio management to achieve better business outcomes and how it can help you in your Agile journey!
      title: Investing for Business Agility - Using evidence-based portfolio management to achieve better business outcomes
    categories:
    - Uncategorized
    tags:
    - Business Agility
  BodyContent: |
    Organizations who seek to improve their competitiveness by being more responsive to change often turn to agile approaches to improve their responsiveness. While many organizations have reaped the rewards of agility at the team level, their traditional management practices impede deeper change that would enable true [business agility]({{< ref "/tags/business-agility" >}}). Agile principles and practices must spread beyond the [Scrum]({{< ref "/categories/scrum" >}}) Team in order for organizations to achieve the dramatic improvement that they seek in their business results.

    Read: [Investing for Business Agility: Using evidence-based portfolio management to achieve better business outcomes](https://scrum.org/resources/investing-business-agility)
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\evidence-based-portfolio-management\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\evidence-based-portfolio-management
- FrontMatter:
    title: The Scrum Guide
    description: The Scrum Guide contains the definition of Scrum.
    ResourceId: 59gcHh1fYtC
    ResourceImport: false
    ResourceType: guides
    ResourceContentOrigin: Human
    resourceTypes: guide
    layout: guide
    aliases:
    - /guides/Scrum-Guide/
    - /guides/Scrum-Guide.html
    - /learn/agile-delivery-kit/guides/scrum-guide
    - /resources/guides/_guides/scrum-guide.md
    - /resources/59gcHh1fYtC
    aliasesArchive:
    - /guides/Scrum-Guide/
    - /guides/Scrum-Guide.html
    - /learn/agile-delivery-kit/guides/scrum-guide
    - /resources/guides/_guides/scrum-guide.md
    downloads:
    - title: Scrum Guide 2020
      type: pdf
      url: /assets/attachments/Scrum-Guide-2020.pdf
    - title: Scrum Guide 2017
      type: pdf
      url: /assets/attachments/Scrum-Guide-2017.pdf
    - title: Scrum Guide 2016
      type: pdf
      url: /assets/attachments/Scrum-Guide-2016.pdf
    - title: Scrum Guide 2013
      type: pdf
      url: /assets/attachments/Scrum-Guide-2013-07.pdf
    - title: Scrum Guide 2011 v2
      type: pdf
      url: /assets/attachments/2011-07-Scrum_Guide.pdf
    - title: Scrum Guide 2011
      type: pdf
      url: /assets/attachments/Scrum-Guide-2011-07.pdf
    - title: Scrum Guide 2010
      type: pdf
      url: /assets/attachments/Scrum-Guide-2010-v1-Scrum-Alliance.pdf
    references:
    - title: The 2020 Scrum Guide
      url: https://scrumguides.org/scrum-guide.html
    recommendedContent:
    - collection: practices
      path: _practices/definition-of-done-dod.md
    - collection: practices
      path: _practices/definition-of-ready-dor.md
    videos:
    - title: Overview of The Scrum Framework with Martin Hinshelwood
      embed: https://www.youtube.com/embed/Q2Fo3sM6BVo
    date: 2024-09-17
    weight: 690
    creator: Martin Hinshelwood
    card:
      button:
        content: Learn More
      content: Discover more about The Scrum Guide and how it can help you in your Agile journey!
      title: The Scrum Guide
    categories:
    - Scrum
    - Product Development
    tags:
    - Professional Scrum
    - Transparency
    - Agile Frameworks
    - Scrum Team
    - Empirical Process Control
    - Agile Product Management
    - Software Development
    - Value Delivery
    - Product Backlog
    - Scrum Master
    - Scrum Values
    - Agile Planning
    - Product Delivery
    - Team Performance
    - Sprint Review
  BodyContent: |
    The [Scrum]({{< ref "/categories/scrum" >}}) Guide is the rule book, or timber frame, of Scrum and is immutable of definition but not of implementation. If you have already read the Scrum Guide and are looking more for a Strategy Guide then head over to the Scrum Strategy Guide.
    {: .lead}

    NOTE: Extracted from the [Scrum Guide 2020](https://scrumguides.org/){:target="\_blank"}

    ## Purpose of the Scrum Guide

    We developed Scrum in the early 1990s. We wrote the first version of the Scrum Guide in 2010 to help people worldwide understand Scrum. We have evolved the Guide since then through small, functional updates. Together, we stand behind it.

    The Scrum Guide contains the definition of Scrum. Each element of the framework serves a specific purpose that is essential to the overall value and results realized with Scrum. Changing the core design or ideas of Scrum, leaving out elements, or not following the rules of Scrum, covers up problems and limits the benefits of Scrum, potentially even rendering it useless.

    We follow the growing use of Scrum within an ever-growing complex world. We are humbled to see Scrum being adopted in many domains holding essentially complex work, beyond software [product development]({{< ref "/categories/product-development" >}}) where Scrum has its roots. As Scrum's use spreads, developers, researchers, analysts, scientists, and other specialists do the work. We use the word “developers” in Scrum not to exclude, but to simplify. If you get value from Scrum, consider yourself included.

    As Scrum is being used, patterns, processes, and insights that fit the Scrum framework as described in this document, may be found, applied and devised. Their description is beyond the purpose of the Scrum Guide because they are context-sensitive and differ widely between Scrum uses. Such tactics for using within the Scrum framework vary widely and are described elsewhere.

    ![The Scrum Framework](https://nkdagility.com/wp-content/uploads/2020/11/naked-Agility-Scrum-Framework-575x450.jpg)

    ## Scrum Definition

    Scrum is a lightweight framework that helps people, teams and organizations generate value through adaptive solutions for complex problems.

    In a nutshell, Scrum requires a [Scrum Master]({{< ref "/tags/scrum-master" >}}) to foster an environment where:

    1. A [Product Owner]({{< ref "/tags/product-owner" >}}) orders the work for a complex problem into a [Product Backlog]({{< ref "/tags/product-backlog" >}}).
    1. The [Scrum Team]({{< ref "/tags/scrum-team" >}}) turns a selection of the work into an [Increment]({{< ref "/tags/increment" >}}) of value during a Sprint.
    1. The Scrum Team and its stakeholders inspect the results and adjust for the next Sprint.
       Repeat

    Scrum is simple. Try it as is and determine if its philosophy, theory, and structure help to achieve goals and create value. The Scrum framework is purposefully incomplete, only defining the parts required to implement Scrum theory. Scrum is built upon by the collective intelligence of the people using it. Rather than provide people with detailed instructions, the rules of Scrum guide their relationships and interactions.

    Various processes, techniques and methods can be employed within the framework. Scrum wraps around existing practices or renders them unnecessary. Scrum makes visible the relative efficacy of current management, environment, and work techniques so that improvements can be made.

    ## Scrum Theory

    Scrum is founded on empiricism and [lean]({{< ref "/categories/lean" >}}) thinking. Empiricism asserts that knowledge comes from experience and making decisions based on what is observed. [Lean thinking]({{< ref "/tags/lean-thinking" >}}) reduces waste and focuses on the essentials.

    Scrum employs an iterative, incremental approach to optimize predictability and to control risk. Scrum engages groups of people who collectively have all the skills and expertise to do the work and share or acquire such skills as needed.

    Scrum combines four formal events for inspection and adaptation within a containing event, the Sprint. These events work because they implement the empirical Scrum pillars of [transparency]({{< ref "/tags/transparency" >}}), inspection, and adaptation.

    ### Transparency

    The emergent process and work must be visible to those performing the work as well as those receiving the work. With Scrum, important decisions are based on the perceived state of its three formal artefacts. Artefacts that have low transparency can lead to decisions that diminish value and increase risk.

    Transparency enables inspection. Inspection without transparency is misleading and wasteful.

    ### Inspection

    The Scrum artefacts and the progress toward agreed goals must be inspected frequently and diligently to detect potentially undesirable variances or problems. To help with inspection, Scrum provides cadence in the form of its five events.

    Inspection enables adaptation. Inspection without adaptation is considered pointless. Scrum events are designed to provoke change.

    ### Adaptation

    If any aspects of a process deviate outside acceptable limits or if the resulting product is unacceptable, the process being applied or the materials being produced must be adjusted. The adjustment must be made as soon as possible to minimize further deviation.

    Adaptation becomes more difficult when the people involved are not empowered or self-managing. A Scrum Team is expected to adapt the moment it learns anything new through inspection.

    ## [Scrum Values]({{< ref "/tags/scrum-values" >}})

    Successful use of Scrum depends on people becoming more proficient in living five values:

    _Commitment, Focus, Openness, Respect, and Courage_

    The Scrum Team commits to achieving its goals and to supporting each other. Their primary focus is on the work of the Sprint to make the best possible progress toward these goals. The Scrum Team and its stakeholders are open about the work and the challenges. Scrum Team members respect each other to be capable, independent people, and are respected as such by the people with whom they work. The Scrum Team members have the courage to do the right thing, to work on tough problems.

    These values give direction to the Scrum Team with regard to their work, actions, and behaviour. The decisions that are made, the steps taken, and the way Scrum is used should reinforce these values, not diminish or undermine them. The Scrum Team members learn and explore the values as they work with the Scrum events and artifacts. When these values are embodied by the Scrum Team and the people they work with, the empirical Scrum pillars of transparency, inspection, and adaptation come to life building trust.

    ## Scrum Team

    The fundamental unit of Scrum is a small team of people, a Scrum Team. The Scrum Team consists of one Scrum Master, one Product Owner, and Developers. Within a Scrum Team, there are no sub-teams or hierarchies. It is a cohesive unit of professionals focused on one objective at a time, the Product Goal.

    Scrum Teams are cross-functional, meaning the members have all the skills necessary to create value each Sprint. They are also self-managing, meaning they internally decide who does what, when, and how.

    The Scrum Team is small enough to remain nimble and large enough to complete significant work within a Sprint, typically 10 or fewer people. In general, we have found that smaller teams communicate better and are more productive. If Scrum Teams become too large, they should consider reorganizing into multiple cohesive Scrum Teams, each focused on the same product. Therefore, they should share the same Product Goal, Product Backlog, and Product Owner.

    The Scrum Team is responsible for all product-related activities from stakeholder collaboration, verification, maintenance, operation, [experimentation]({{< ref "/tags/experimentation" >}}), research and development, and anything else that might be required. They are structured and empowered by the organization to manage their own work. Working in Sprints at a sustainable pace improves the Scrum Team's focus and consistency.

    The entire Scrum Team is accountable for creating a valuable, useful Increment every Sprint. Scrum defines three specific accountabilities within the Scrum Team: the Developers, the Product Owner, and the Scrum Master.

    ### Developers

    Developers are the people in the Scrum Team that are committed to creating any aspect of a usable Increment each Sprint.

    The specific skills needed by the Developers are often broad and will vary with the domain of work. However, the Developers are always accountable for:

    - Creating a plan for the Sprint, the Sprint Backlog;
    - Instilling quality by adhering to a [Definition of Done]({{< ref "/tags/definition-of-done" >}});
    - Adapting their plan each day toward the Sprint Goal; and,
    - Holding each other accountable as professionals.

    ### Product Owner

    The Product Owner is accountable for maximizing the value of the product resulting from the work of the Scrum Team. How this is done may vary widely across organizations, Scrum Teams, and individuals.

    The Product Owner is also accountable for effective Product Backlog management, which includes:

    - Developing and explicitly communicating the Product Goal;
    - Creating and clearly communicating Product Backlog items;
    - Ordering Product Backlog items; and,
    - Ensuring that the Product Backlog is transparent, visible and understood.

    The Product Owner may do the above work or may delegate the responsibility to others. Regardless, the Product Owner remains accountable.

    For Product Owners to succeed, the entire organization must respect their decisions. These decisions are visible in the content and ordering of the Product Backlog, and through the inspectable Increment at the [Sprint Review]({{< ref "/tags/sprint-review" >}}).

    The Product Owner is one person, not a committee. The Product Owner may represent the needs of many stakeholders in the Product Backlog. Those wanting to change the Product Backlog can do so by trying to convince the Product Owner.

    ### Scrum Master

    The Scrum Master is accountable for establishing Scrum as defined in the Scrum Guide. They do this by helping everyone understand Scrum theory and practice, both within the Scrum Team and the organization.

    The Scrum Master is accountable for the Scrum Team's effectiveness. They do this by enabling the Scrum Team to improve its practices, within the Scrum framework.

    Scrum Masters are true leaders who serve the Scrum Team and the larger organization.

    The Scrum Master serves the Scrum Team in several ways, including:

    - [Coaching]({{< ref "/tags/coaching" >}}) the team members in self-management and cross-functionality;
    - Helping the Scrum Team focus on creating high-value Increments that meet the Definition of Done;
    - Causing the removal of impediments to the Scrum Team's progress; and,
    - Ensuring that all Scrum events take place and are positive, productive, and kept within the timebox.

    The Scrum Master serves the Product Owner in several ways, including:

    - Helping find techniques for effective Product Goal definition and Product Backlog management;
    - Helping the Scrum Team understand the need for clear and concise Product Backlog items;
    - Helping establish empirical product planning for a complex environment; and,
    - Facilitating stakeholder collaboration as requested or needed.

    The Scrum Master serves the organization in several ways, including:

    - Leading, training, and coaching the organization in its Scrum adoption;
    - Planning and advising Scrum implementations within the organization;
    - Helping employees and stakeholders understand and enact an empirical approach for complex work; and,
    - Removing barriers between stakeholders and Scrum Teams.

    ## Scrum Events

    The Sprint is a container for all other events. Each event in Scrum is a formal opportunity to inspect and adapt Scrum artefacts. These events are specifically designed to enable the transparency required. Failure to operate any events as prescribed results in lost opportunities to inspect and adapt. Events are used in Scrum to create regularity and to minimize the need for meetings not defined in Scrum.

    Optimally, all events are held at the same time and place to reduce complexity.

    ### The Sprint

    Sprints are the heartbeat of Scrum, where ideas are turned into value.

    They are fixed length events of one month or less to create consistency. A new Sprint starts immediately after the conclusion of the previous Sprint.

    All the work necessary to achieve the Product Goal, including Sprint Planning, Daily Scrums, Sprint Review, and Sprint Retrospective, happen within Sprints.

    During the Sprint:

    - No changes are made that would endanger the Sprint Goal;
    - Quality does not decrease;
    - The Product Backlog is refined as needed; and,
    - Scope may be clarified and renegotiated with the Product Owner as more is learned.

    Sprints enable predictability by ensuring inspection and adaptation of progress toward a Product Goal at least every calendar month. When a Sprint's horizon is too long the Sprint Goal may become invalid, complexity may rise, and risk may increase. Shorter Sprints can be employed to generate more learning cycles and limit risk of cost and effort to a smaller time frame. Each Sprint may be considered a short project.

    Various practices exist to forecast progress, like burn-downs, burn-ups, or cumulative flows. While proven useful, these do not replace the importance of empiricism. In complex environments, what will happen is unknown. Only what has already happened may be used for forward-looking [decision making]({{< ref "/tags/decision-making" >}}).

    A Sprint could be cancelled if the Sprint Goal becomes obsolete. Only the Product Owner has the authority to cancel the Sprint.

    ### Sprint Planning

    Sprint Planning initiates the Sprint by laying out the work to be performed for the Sprint. This resulting plan is created by the collaborative work of the entire Scrum Team.

    The Product Owner ensures that attendees are prepared to discuss the most important Product Backlog items and how they map to the Product Goal. The Scrum Team may also invite other people to attend Sprint Planning to provide advice.

    Sprint Planning addresses the following topics:

    #### Topic One: Why is this Sprint valuable?

    The Product Owner proposes how the product could increase its value and utility in the current Sprint. The whole Scrum Team then collaborates to define a Sprint Goal that communicates why the Sprint is valuable to stakeholders. The Sprint Goal must be finalized prior to the end of Sprint Planning.

    #### Topic Two: What can be Done this Sprint?

    Through discussion with the Product Owner, the Developers select items from the Product Backlog to include in the current Sprint. The Scrum Team may refine these items during this process, which increases understanding and confidence.

    Selecting how much can be completed within a Sprint may be challenging. However, the more the Developers know about their past performance, their upcoming capacity, and their Definition of Done, the more confident they will be in their Sprint forecasts.

    #### Topic Three: How will the chosen work get done?

    For each selected Product Backlog item, the Developers plan the work necessary to create an Increment that meets the Definition of Done. This is often done by decomposing Product Backlog items into smaller work items of one day or less. How this is done is at the sole discretion of the Developers. No one else tells them how to turn Product Backlog items into Increments of value.

    The Sprint Goal, the Product Backlog items selected for the Sprint, plus the plan for delivering them are together referred to as the Sprint Backlog.

    Sprint Planning is timeboxed to a maximum of eight hours for a one-month Sprint. For shorter Sprints, the event is usually shorter.

    ### [Daily Scrum]({{< ref "/tags/daily-scrum" >}})

    The purpose of the Daily Scrum is to inspect progress toward the Sprint Goal and adapt the Sprint Backlog as necessary, adjusting the upcoming planned work.

    The Daily Scrum is a 15-minute event for the Developers of the Scrum Team. To reduce complexity, it is held at the same time and place every working day of the Sprint. If the Product Owner or Scrum Master are actively working on items in the Sprint Backlog, they participate as Developers.

    The Developers can select whatever structure and techniques they want, as long as their Daily Scrum focuses on progress toward the Sprint Goal and produces an actionable plan for the next day of work. This creates focus and improves self-management.

    Daily Scrums improve communications, identify impediments, promote quick decision-making, and consequently eliminate the need for other meetings.

    The Daily Scrum is not the only time Developers are allowed to adjust their plan. They often meet throughout the day for more detailed discussions about adapting or re-planning the rest of the Sprint's work.

    ### Sprint Review

    The purpose of the Sprint Review is to inspect the outcome of the Sprint and determine future adaptations. The Scrum Team presents the results of their work to key stakeholders and progress toward the Product Goal is discussed.

    During the event, the Scrum Team and stakeholders review what was accomplished in the Sprint and what has changed in their environment. Based on this information, attendees collaborate on what to do next. The Product Backlog may also be adjusted to meet new opportunities. The Sprint Review is a working session and the Scrum Team should avoid limiting it to a presentation.

    The Sprint Review is the second to last event of the Sprint and is timeboxed to a maximum of four hours for a one-month Sprint. For shorter Sprints, the event is usually shorter.

    ### Sprint Retrospective

    The purpose of the Sprint Retrospective is to plan ways to increase quality and effectiveness.

    The Scrum Team inspects how the last Sprint went with regards to individuals, interactions, processes, tools, and their Definition of Done. Inspected elements often vary with the domain of work. Assumptions that led them astray are identified and their origins explored. The Scrum Team discusses what went well during the Sprint, what problems it encountered, and how those problems were (or were not) solved.

    The Scrum Team identifies the most helpful changes to improve its effectiveness. The most impactful improvements are addressed as soon as possible. They may even be added to the Sprint Backlog for the next Sprint.

    The Sprint Retrospective concludes the Sprint. It is timeboxed to a maximum of three hours for a one-month Sprint. For shorter Sprints, the event is usually shorter.

    ## Scrum Artefacts

    Scrum's artefacts represent work or value. They are designed to maximize transparency of key information. Thus, everyone inspecting them has the same basis for adaptation.

    Each artefact contains a commitment to ensure it provides information that enhances transparency and focus against which progress can be measured:

    - For the Product Backlog, it is the Product Goal.
    - For the Sprint Backlog it is the Sprint Goal.
    - For the Increment, it is the Definition of Done.

    These commitments exist to reinforce empiricism and the Scrum values for the Scrum Team and their stakeholders.

    ### Product Backlog

    The Product Backlog is an emergent, ordered list of what is needed to improve the product. It is the single source of work undertaken by the Scrum Team.

    Product Backlog items that can be Done by the Scrum Team within one Sprint are deemed ready for selection in a Sprint Planning event. They usually acquire this degree of transparency after refining activities. Product [Backlog refinement]({{< ref "/tags/backlog-refinement" >}}) is the act of breaking down and further defining Product Backlog items into smaller more precise items. This is an ongoing activity to add details, such as a description, order, and size. Attributes often vary with the domain of work.

    The Developers who will be doing the work are responsible for the sizing. The Product Owner may influence the Developers by helping them understand and select trade-offs.

    ### Commitment: Product Goal

    The Product Goal describes a future state of the product which can serve as a target for the Scrum Team to plan against. The Product Goal is in the Product Backlog. The rest of the Product Backlog emerges to define “what” will fulfil the Product Goal.

    A product is a vehicle to deliver value. It has a clear boundary, known stakeholders, well-defined users or customers. A product could be a service, a physical product, or something more abstract.

    The Product Goal is the long-term objective of the Scrum Team. They must fulfil (or abandon) one objective before taking on the next.

    Some additional content on Product Goal:

    ### Sprint Backlog

    The Sprint Backlog is composed of the Sprint Goal (why), the set of Product Backlog items selected for the Sprint (what), as well as an actionable plan for delivering the Increment (how).

    The Sprint Backlog is a plan by and for the Developers. It is a highly visible, real-time picture of the work that the Developers plan to accomplish during the Sprint in order to achieve the Sprint Goal. Consequently, the Sprint Backlog is updated throughout the Sprint as more is learned. It should have enough detail that they can inspect their progress in the Daily Scrum.

    #### Commitment: Sprint Goal

    The Sprint Goal is the single objective for the Sprint. Although the Sprint Goal is a commitment by the Developers, it provides flexibility in terms of the exact work needed to achieve it. The Sprint Goal also creates coherence and focus, encouraging the Scrum Team to work together rather than on separate initiatives.

    The Sprint Goal is created during the Sprint Planning event and then added to the Sprint Backlog. As the Developers work during the Sprint, they keep the Sprint Goal in mind. If the work turns out to be different than they expected, they collaborate with the Product Owner to negotiate the scope of the Sprint Backlog within the Sprint without affecting the Sprint Goal.

    ### Increment

    An Increment is a concrete stepping stone toward the Product Goal. Each Increment is additive to all prior Increments and thoroughly verified, ensuring that all Increments work together. In order to provide value, the Increment must be usable.

    Multiple Increments may be created within a Sprint. The sum of the Increments is presented at the Sprint Review thus supporting empiricism. However, an Increment may be delivered to stakeholders prior to the end of the Sprint. The Sprint Review should never be considered a gate to releasing value.

    Work cannot be considered part of an Increment unless it meets the Definition of Done.

    #### Commitment: Definition of Done

    The Definition of Done is a formal description of the state of the Increment when it meets the quality measures required for the product.

    The moment a Product Backlog item meets the Definition of Done, an Increment is born.

    The Definition of Done creates transparency by providing everyone with a shared understanding of what work was completed as part of the Increment. If a Product Backlog item does not meet the Definition of Done, it cannot be released or even presented at the Sprint Review. Instead, it returns to the Product Backlog for future consideration.

    If the Definition of Done for an increment is part of the standards of the organization, all Scrum Teams must follow it as a minimum. If it is not an organizational standard, the Scrum Team must create a Definition of Done appropriately for the product.

    Developers are required to conform to the Definition of Done. If there are multiple Scrum Teams working together on a product, they must mutually define and comply with the same Definition of Done.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\scrum-guide\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\guides\scrum-guide

