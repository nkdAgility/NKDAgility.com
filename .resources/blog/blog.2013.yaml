- FrontMatter:
    title: Professional Scrum in Immingham, UK
    description: Join the Professional Scrum course in Immingham, UK, and enhance your team's collaboration and efficiency. Discover the value of co-located training today!
    ResourceId: b-WImy6z9no
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10301
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-12-11
    weight: 540
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: professional-scrum-immingham-uk
    aliases:
    - /resources/b-WImy6z9no
    aliasesArchive:
    - /blog/professional-scrum-immingham-uk
    - /professional-scrum-immingham-uk
    - /professional-scrum-in-immingham,-uk
    - /blog/professional-scrum-in-immingham,-uk
    - /professional-scrum-in-immingham--uk
    - /blog/professional-scrum-in-immingham--uk
    - /resources/blog/professional-scrum-immingham-uk
    tags:
    - Software Development
    - Team Collaboration
    - Agile Frameworks
    - Team Performance
    categories:
    - Scrum
    preview: nakedalm-experts-professional-scrum-6-6.png
  BodyContent: |
    As my first engagement as naked ALM Consulting in the UK I got to work with the fantastic team at DFDS Seaways and teach the Professional Scrum course from Scrum.org.

    DFDS Seaways is an organisation that runs ports across Europe and for the PSF training we had folks traveling in from Norway, Sweden and Denmark. We had about 4 physical teams represented, some of which were distributed, and having them all in the one place was unusual.

    ![WP_20131112_09_23_11_Pro_thumb1](images/WP_20131112_09_23_11_Pro_thumb1-800x450-7-8.jpg)  
    { .post-img }
    Figure: DFDS Seaways teams getting organised

    If you work in American you will notice that there are no cubes in the office. In Europe cubes are fairly rare, to the point I have not encountered them, and most organisation have desks organised in little pods of four or so people. As you can imagine this is a little more cognisant of collocated teams, but I did mention that these guys were distributed.

    ![](images/121113_0930_Professiona1-1-1.jpg)  
    { .post-img }
    Figure: Tasmanian devil

    If you plan of having your teams participate in team based Scrum training like the Professional Scrum course from Scrum.org then you should consider getting everyone together for one large course (30 max.) This allows all of your teams, or as many as you can get into a room to get value from interacting with each other and cross skilling.

    ![](images/121113_0930_Professiona2-2-2.jpg)  
    { .post-img }
    Figure: Aardvark team working together

    With so many usually distributed folks from so many teams I asked them to 'self-organise' into teams of 5-6 with instructions to try and find folks that they did not know and had not worked with before. Here we have Brits and Sweed's working together to understand the backlog…

    ![](images/121113_0930_Professiona3-3-3.jpg)  
    { .post-img }
    Figure: Team Badger figuring out the requirements

    One of the huge advantages to co-located teams is that they can work together, and in high-performing teams 'swarm' to solve problems. The Badger team was a good example of that with representatives of two teams from Norway, Netherlands and Britain. Even better, they had representatives from the business who were not in any way technical. Effectively folks that were product owners and stakeholders. There is a lot of value for these types of folks to attend as both sides of the fence learn something.

    The Development Team learns how to work with the business and starts to understand, thorough conversation and questions from the business, what is actually important to them.

    The Stakeholders and Product Owners learn how valuable their interactions with the Development Team are and start to get an idea of the amount of information that they need to provide to be successful.

    ![](images/121113_0930_Professiona4-4-4.jpg)  
    { .post-img }
    Figure: Team Squirrel looking for direction

    The guys at DFDS have been doing Scrum for over 9 months, however this was their first formal training. It was interesting to see which teams picked up the practices more quickly. Indeed the fact that we had 5 teams all working independently on the same work helped those that thought some of the practices, like daily Scrum's, visual boards, and retrospectives provided value. By the end of the first day there was significant improvement in the teams understanding of the framework, and more importantly their ability to orchestrate the delivery of value in a short period of time.

    ![](images/121113_0930_Professiona5-5-5.jpg)  
    { .post-img }
    Figure: Greek dinner with the multi-national group

    After a long two days training and interacting the entire group got together for a well-earned meal and interaction. The software teams at DFDS were some of the most capable that I have worked with and their camaraderie was intense. I got a lot of value in training them and it was very refreshing to teach Europeans rather than Americans. There are many cultural differences with language being just one…

    I really enjoyed my time with DFDS and hopefully they enjoyed the course as well.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-12-11-professional-scrum-immingham-uk\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-12-11-professional-scrum-immingham-uk
- FrontMatter:
    title: ALM Consulting in Scotland, UK, Scandinavia &amp; Europe
    description: Discover expert ALM consulting across Scotland, the UK, and Europe. Enhance your software development processes with tailored training and coaching.
    ResourceId: ETl5K8OQ9kV
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10226
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-11-11
    weight: 390
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: alm-consulting-scotland-uk-scandinavia-europe
    aliases:
    - /resources/ETl5K8OQ9kV
    - /resources/blog/alm-consulting-in-scotland-uk-scandinavia-amp-europe
    aliasesArchive:
    - /blog/alm-consulting-scotland-uk-scandinavia-europe
    - /alm-consulting-scotland-uk-scandinavia-europe
    - /alm-consulting-in-scotland,-uk,-scandinavia-&amp;-europe
    - /blog/alm-consulting-in-scotland,-uk,-scandinavia-&amp;-europe
    - /alm-consulting-in-scotland--uk--scandinavia-&amp;-europe
    - /blog/alm-consulting-in-scotland--uk--scandinavia-&amp;-europe
    - /resources/blog/alm-consulting-scotland-uk-scandinavia-europe
    - /resources/blog/alm-consulting-in-scotland-uk-scandinavia-amp-europe
    tags:
    - Software Development
    - Application Lifecycle Management
    categories:
    - Uncategorized
    preview: nakedalm-logo-128-link-1-1.png
  BodyContent: |
    Well, that's me started ALM Consulting in Scotland, UK & Europe as naked ALM Consulting – Martin Hinshelwood. As I write this I am on a train on my way to my first engagement in the north of England is what looks to be and awesome group of folks to talk a little Scrum and Team Foundation Build.

    As of the first of November I am back in Scotland and will be basing naked ALM Consulting out of my home town of Glasgow. However I will be traveling around Europe doing consulting and training for lean-agile, TFS, Visual Studio and Scrum and working with a bunch of ALM Gold partners in various countries. As I have been talking to my contacts many folks have been asking what it is that I have been doing for the last 3 years and what it is that naked ALM Consulting does… and even what ALM means anyway. I especially get these questions from my family…

    > **Application lifecycle management** (**ALM**) is the product lifecycle management (governance, development, and maintenance) of application software. It encompasses requirements management, software architecture, computer programming, software testing, software maintenance, change management, project management, and release management [Wikipedia](http://en.wikipedia.org/wiki/Application_lifecycle_management)

    If you are still asking, “But what can you do Martin?” then by all means read on as this post was created specifically for you. However there really is no short answer that does not open even more questions and I think that all of the ALM MVP’s are in the same boat with this.  I sometimes use “I help companies that build software build it better” for laymen, or “I help companies improve their software development processes” for the more initiated. Unfortunately that statement is neither eloquent nor expletive enough so I have tried many times to come up with something a little live a list of ‘things that I have done’:

    - **Lean-Agile Training\\Coaching** – Delivering PSD, PSF and PSM for customers across the USA including two major defence contractors, US government departments, and many other companies across the spectrum of industries. In some cases I have also provided additional Agile Engineering and Agile Requirements days to help jump start the process.
      - [Professional Scrum Foundations in Salt Lake City, Utah](http://nkdagility.com/professional-scrum-foundations-in-salt-lake-city-utah/)
      - [Professional Scrum Foundations in Alameda, California](http://nkdagility.com/professional-scrum-foundations-in-alameda-california/)
        While training is easy to quantify, coaching is a little more difficult. Suffice to say I have worked with many companies and teams in that capacity, and not just .NET teams, and hope to work with many more.
    - **ALM Assessment** – Delivering ALM Assessments are fun and require a lot of focus. The goal is to understand, in a short space of time, the current state of a companies software lifecycle and where they can improve. Sometimes they are very tools focused, but we all know that tools don’t solve problems. Tools only support the process that solves problems. Having conducted ALM Assessments for financial and medial institutions as well as commercial, land management, port management and even retail I feel that I can get a handle on any companies situation and goals.
    - **TFS Training** – I have created and delivered targeted TFS training for major biopharmaceutical, airline manufacturing, defence and government as well as investment capital, and auction organisations. Training is a fine art and one needs to balance learning with comedy (thanks Rennie) to create something that is more like a Enter-trainer rather than a monotonous drone.  Having lots of real world experience in both delivering and using the tools helps a lot with making sure that students really understand how to get the most out of the tools for their situation. Most training I have done was delivered privately where it is easier to target the companies needs, but public courses in ALM and TFS also benefit from that knowledge.
    - **DPS Tools & Test** – Deployment Planning Services (DPS) is a funny old beast. If you have DPS vouchers from Microsoft you can trade them in to have a consultant come onsite and assess your organisation for deployment of, or increased usage of, the features of Visual Studio ALM. There are currently two flavours of DPS. You can have a DPS Tools where one would look at implementing Team Foundation Server (TFS) in general, and there is a DPS Test where I would look at a companies adoption and usage of Microsoft Test Manager and other Testing capabilities of Visual Studio ALM. Think of DPS as a very targeted mini ALM Assessment that Microsoft pays for. Loads of companies have leveraged DPS from me and they have been fortune 500, government and small local shops. If you have the vouchers then you should use them.
    - **Upgrade and Migration** – In the past this has been the meat and potatoes of ALM Consulting in the Microsoft space. Now however with the investment that Microsoft has made in the installer since 2008 and their cloud solution I expect that business to drop off. It did however breed a special appreciation for simplicity and  I could not count the number of upgrades and migrations I have done with more than 8 customers already on TFS 2013 RTM. Of those 8 customers I have upgraded to the RTM only 4 were small, less than 100 developers, and the others were over 500 developers. I would always recommend that teams have a go at a trial upgrade to TFS 2013 from 2012 or even 2010 before you call a consultant as the process is much easier now. If however you are still on 2005 \\ 2008 then please give me a call!
    - **Process Template Upgrade & Customisation –** As I always recommend customers keep this ass a separate thing so I also want to call it out separately here. Upgrading, migrating and customising your process within TFS is an art and not a science. There are many ways to implement things and one does not only need to know the options available but also be deeply integrated in to the future directions of the product to make the best choices.
    - **Build Automation** – Moving folks to TF Build from Cruse Control, Maven, Team City or whatever to TFS and making sure that their applications can build can be a trial. Worse if they have no build process or a manual one. Automating them can be a real pain and this included potentially re-architecting parts of their application to support automated deployment. Large software that has been around for many years can take many months to automate and while I have done full time onsite to help folks out I try to get your teams to do as much of the work as possible. If they don’t do it then they will not know how nor be able to take it forward. This should be your knowledge in your team but they probably need training and coaching to make it work.
    - **Automated Deployment** – I have worked with Release management for Visual Studio (InRelease, LabDeploy) and Octopus Deploy to create end to end release management and deployment strategies for customers large and small, banks and point of sale. This is going to be the hot ticket over the next few years as more and more companies push towards continuous delivery.

    I only tried to hit the highlights as I have had almost 80 customer engagements in the last 3 years with Northwest Cadence and every customer has unique problems and situations that are representative of their size or complexity. Its sometimes just about rolling up your sleeves and getting stuck in.

    Wither you are looking for an ALM Consultant or you are a consulting company looking for an ALM Partner or even just an overflow valve (lol) for those busy periods then  I can help you out. If you need to understand what your organisation needs to do to improve their process then give me a call, and remember: Every company deserves working software on a regular cadence.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-11-11-alm-consulting-scotland-uk-scandinavia-europe\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-11-11-alm-consulting-scotland-uk-scandinavia-europe
- FrontMatter:
    title: 'Issue [ TFS 2013 ] Value cannot be null. Parameter name: key'
    description: Discover how to resolve the 'Value cannot be null' error in TFS 2013 when customizing work item tracking. Learn essential fixes and best practices!
    ResourceId: XGBjZzEb6D0
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10221
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-10-23
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: issue-tfs-2013-work-item-tracking-gives-you-value-cannot-be-null-parameter-name-key
    aliases:
    - /resources/XGBjZzEb6D0
    - /resources/blog/issue-tfs-2013-value-cannot-be-null.-parameter-name-key
    aliasesArchive:
    - /blog/issue-tfs-2013-work-item-tracking-gives-you-value-cannot-be-null-parameter-name-key
    - /issue-tfs-2013-work-item-tracking-gives-you-value-cannot-be-null-parameter-name-key
    - /issue-[-tfs-2013-]-value-cannot-be-null--parameter-name--key
    - /blog/issue-[-tfs-2013-]-value-cannot-be-null--parameter-name--key
    - /resources/blog/issue-tfs-2013-work-item-tracking-gives-you-value-cannot-be-null-parameter-name-key
    - /resources/blog/issue-tfs-2013-value-cannot-be-null.-parameter-name-key
    tags:
    - Troubleshooting
    - Software Development
    categories:
    - Uncategorized
  BodyContent: |
    When customising your process template work item tracking gives you an “ArgumentNullException: Value cannot be null. Parameter name: key” exception with no more details.

    I have been onsite at a customer creating a custom processes template and migrating their current data into the new format. Because they make extensive use of Area Path for documentation purposes we could not use it for Team. So I dutifully configured their [TFS for ‘team field’](http://nkdagility.com/team-foundation-server-2012-teams-without-areas/) as their client field so that they could create ‘teams’ that represent the work that is done for each client. All looked good for a few hours until the tester tried to edit one of their old work item; 2663.

    ![image](images/image_thumb9-1-1.png "image")   
    { .post-img }
    Figure: Team Foundation Error: the server operation failed.

    At first I though that it was just an isolated issue, so I popped an email off to the product team with this odd error and wen back to my other deliverables. Then this error occurred under other circumstances.

    [![image](images/image3_thumb-3-3.png "image")](http://nkdagility.com/wp-content/uploads/2013/10/image32-4-4.png)  
    { .post-img }
    Figure: Value cannot be null. Parameter name: key

    When one of the team was creating sub tasks of an existing work item using the “Tasks” tab on the PBI or Bug then this is what happened. I was then again able to replicate the issue, but only when creating sub work item’s from an existing one. If I used the Agile Planning Tools and clicked the green plus then it would work, wired. I let the product team know and they decided a remote debugging session would be required…

    The first thing that they did, which I did not know was even there, was to do a fiddler like session in Internet Explorer.

    ![image](images/image11-2-2.png "image")  
    { .post-img }
    Figure: Network diagnostics with Internet Explorer

    If you hit F12 to open the developer tools and look for the little router icon on the left. This then has the play/stop that you would expect from a traffic monitor and we can then enable it and try to save the work item. This resulted in a 500 server error and that, if you did not know already, is not a good thing. This immediately made it some sort of bug as that should never be able to happen. However it did and they needed to investigate more…

    I gave up control so that could enable some ninja trace capabilities of TFS no I will not be telling you how, and they checked a log of every method enter and every method leave that was recorded as a result. Listening over Lync I overheard a bunch of folks poking at the the event log on my customers server and matching it up to source code I could not see. There was lost of “now we are in this method” and “but there is nothing that can bang there”. At one point the awesome Dennis Habib asked me…

    “um… is this team project using Team Field?”

    At that point Dennis, Zhenyuan Zhao and Ahmet Akkas, who were scouring the source code, knew exactly what the problem was. As it turns out there is a bugs on the server that effectively assume that you have a value for Team on the work item. Now if you are using the out-of-the-box Area Path for Team then it can never be null and it looks like the code assumed that. But when you use Team Field it can be blank.

    There is however an easy fix that can be applied client side to make sure that the field is never null, you can make the field required in the work item definitions. I made the change and the problem was solved.

    Obviously there is a server side coding assumption, which is bad, but there is also a UI issue. If you use the Agile Planning tools to create Work Items or child items then it populated the Team that you are currently running as. However if you just open a work item and add a child link, or use the “task” tab it does not. This can be replicated in both the Web and Visual Studio UI and I hope it gets updated to understand the context.

    ## Conclusion

    If you are using Team Field then you need to make sure that you make the field that you use for it a required field in the work item definition. Don’t make my mistake and end up scratching your and the product teams head trying to figure it out.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-10-23-issue-tfs-2013-work-item-tracking-gives-you-value-cannot-be-null-parameter-name-key\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-10-23-issue-tfs-2013-work-item-tracking-gives-you-value-cannot-be-null-parameter-name-key
- FrontMatter:
    title: Visual Studio 2013 and TFS 2013 are released, get yours now! Oh and Windows 8.1&hellip;
    description: Discover the powerful features of Visual Studio 2013 and TFS 2013, now available for download! Upgrade your development experience with the latest tools.
    ResourceId: 6g2Cp_ZpsHo
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10214
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-10-17
    weight: 875
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: visual-studio-2013-and-tfs-2013-are-released-get-yours-now-oh-and-windows-8-1
    aliases:
    - /resources/6g2Cp_ZpsHo
    - /resources/blog/visual-studio-2013-and-tfs-2013-are-released-get-yours-now-oh-and-windows-8.1-hellip
    aliasesArchive:
    - /blog/visual-studio-2013-and-tfs-2013-are-released-get-yours-now-oh-and-windows-8-1
    - /visual-studio-2013-and-tfs-2013-are-released-get-yours-now-oh-and-windows-8-1
    - /visual-studio-2013-and-tfs-2013-are-released,-get-yours-now--oh-and-windows-8-1&hellip;
    - /blog/visual-studio-2013-and-tfs-2013-are-released,-get-yours-now--oh-and-windows-8-1&hellip;
    - /visual-studio-2013-and-tfs-2013-are-released--get-yours-now--oh-and-windows-8-1&hellip;
    - /blog/visual-studio-2013-and-tfs-2013-are-released--get-yours-now--oh-and-windows-8-1&hellip;
    - /resources/blog/visual-studio-2013-and-tfs-2013-are-released-get-yours-now-oh-and-windows-8-1
    - /resources/blog/visual-studio-2013-and-tfs-2013-are-released-get-yours-now-oh-and-windows-8.1-hellip
    tags: []
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-3-3.png
  BodyContent: |
    Microsoft just made both Visual Studio 2013 and Windows 8.1 available for download on MSDN and on [http://visualstudio.com](http://visualstudio.com). This release includes [Visual Studio 2013, .NET 4.5.1, and Team Foundation Server 2013](http://go.microsoft.com/fwlink/p/?LinkId=306566) as well as making [Windows 8.1 available on Windows Update](http://blogs.windows.com/windows/b/bloggingwindows/archive/2013/10/17/windows-8-1-now-available.aspx).

    Although the launch event will not be until November 13th in New York this is certainly plenty to be getting on with. I have been using Visual Studio for many years and Visual Studio 2013 exclusively for more than 6 months in one pre-release flavoured or another. It is by far the most powerful IDE platform available and Team Foundation Server is the most integrated and best ALM platform available today.

    - Update If you have an MSDN Subscription then you already have a licence for VS 2013. If you just have Visual Studio Pro you can [upgrade for $99](http://www.microsoft.com/visualstudio/eng/buy), for a limited time.

    ![image](images/image_thumb8-1-1.png "image")  
    { .post-img }
    Figure: Gartner Magic Quadrant

    With what Visual Studio & TFS 2013 bring to Visual Studio ALM I don’t see this changing any time soon.

    ### What's new in the Visual Studio 2013 & TFS 2013 RTM

    I have extensive posts on [What’s new in Visual Studio 2013 RC with Team Foundation Server](http://nkdagility.com/whats-new-in-visual-studio-2013-rc-with-team-foundation-server/) and [What’s new in Visual Studio 2013 Team Foundation Server Preview](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/) that cover these topics very well. Indeed I even did a video on [manage portfolio backlogs to understand the scope of work](http://nkdagility.com/video-new-with-visual-studio-2013-manage-portfolio-backlogs-to-understand-the-scope-of-work/). There are not any additional features in the RTM on-premises so these posts are still good illustrations of what is available.

    Ever since the Preview [Team Foundation Server 2013 has been production ready](http://nkdagility.com/team-foundation-server-2013-is-production-ready/) with the TFS product team providing a go-live licence (providing production support and upgrades) but now with the general availability there is no excuse for being on anything less than 2013 RTM. Well, there is one excuse: As the web access no longer supports IE8 you need a minimum of IE9…

    So far I have done 8 upgrades for customers in production with TFS 2013 and already have 2 customers running on the RTM. As I have been spending so much time on the sharp end of the stick I have not had as much time as I would like to write posts on my experiences, but here are the few I have managed to crank our on TFS 2013:

    ### New and Improved

    - [What’s new in Visual Studio 2013 RC with Team Foundation Server](http://nkdagility.com/whats-new-in-visual-studio-2013-rc-with-team-foundation-server/)
    - [What’s new in Visual Studio 2013 Team Foundation Server Preview](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/)
    - [Team Foundation Server 2013 has been production ready](http://nkdagility.com/team-foundation-server-2013-is-production-ready/)

    ### Tools and Techniques

    - [Create a Portfolio Backlog hierarchy in Team Foundation Server 2013](http://nkdagility.com/create-a-portfolio-backlog-hierarchy-in-team-foundation-server-2013/)
    - [Modelling Teams in Team Foundation Server 2013](http://nkdagility.com/modelling-teams-in-team-foundation-server-2013/)
    - [Quality enablement with Visual Studio 2012](http://nkdagility.com/quality-enablement-with-visual-studio-2012/)

    ### Code and Complexity

    - [PowerShell TFS 2013 API #1 – Get TfsCollection and TFS Services](http://nkdagility.com/powershell-tfs-2013-api-1-get-tfscollection-and-tfs-services/)
    - [Customise the colours in Team Foundation Server 2013 Agile Planning Tools](http://nkdagility.com/customise-the-colours-in-team-foundation-server-2013-agile-planning-tools/)

    ### Install and Configuration

    - [Engaging with complexity – Team Foundation Server Edition](http://nkdagility.com/engaging-with-complexity-team-foundation-server-edition/)
    - [Issue \[ TFS 2013 \] TF50309 when configuring features in Team Foundation Server 2013](http://nkdagility.com/issue-tfs-2013-tf50309-when-configuring-features-in-team-foundation-server-2013/)
    - [Configure features in Team Foundation Server 2013](http://nkdagility.com/configure-features-in-team-foundation-server-2013/)
    - [Installing Visual Studio 2013 on Server 2012](http://nkdagility.com/installing-visual-studio-2013-on-server-2012/)
    - [Upgrading to Visual Studio Scrum 3.0 process template in TFS 2013](http://nkdagility.com/upgrading-to-visual-studio-scrum-3-0-process-template-in-tfs-2013/)
    - [Unable to install Visual Studio 2013 RC on Windows 8.1 Preview](http://nkdagility.com/unable-to-install-visual-studio-2013-rc-on-windows-8-1-preview/)
    - [Integrate SharePoint 2013 with Team Foundation Server 2013](http://nkdagility.com/integrate-sharepoint-2013-with-team-foundation-server-2013/)
    - [Upgrading to Team Foundation Server 2013](http://nkdagility.com/upgrading-to-team-foundation-server-2013/)
    - [Upgrading from the TFS 2013 Preview to TFS 2013 RC](http://nkdagility.com/upgrading-from-the-tfs-2013-preview-to-tfs-2013-rc/)

    I have literally had two issues in ~8 installations, neither of which were of any real import and are described in the posts above. I have had no problems recommending  the upgrade, even to the preview, for even the most conservative of customers. That does not mean that they always listened, but now that the RTM is released I have upgrades to do and I expect many more to come over the next year…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-10-17-visual-studio-2013-and-tfs-2013-are-released-get-yours-now-oh-and-windows-8-1\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-10-17-visual-studio-2013-and-tfs-2013-are-released-get-yours-now-oh-and-windows-8-1
- FrontMatter:
    title: 'PowerShell TFS 2013 API #2 - Adding to a GlobalList'
    description: Learn how to enhance your TFS 2013 Global List using PowerShell. Automate team field additions effortlessly with our step-by-step guide and reusable functions.
    ResourceId: Y2XTGIaY_Os
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10151
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-10-16
    weight: 790
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: powershell-tfs-2013-api-2-adding-to-a-globallist
    aliases:
    - /resources/Y2XTGIaY_Os
    aliasesArchive:
    - /blog/powershell-tfs-2013-api-2-adding-to-a-globallist
    - /powershell-tfs-2013-api-2-adding-to-a-globallist
    - /powershell-tfs-2013-api--2
    - /powershell-tfs-2013-api--2---adding-to-a-globallist
    - /blog/powershell-tfs-2013-api--2---adding-to-a-globallist
    - /resources/blog/powershell-tfs-2013-api-2-adding-to-a-globallist
    tags:
    - Software Development
    categories:
    - Uncategorized
    preview: metro-powershell-logo-1-1.png
  BodyContent: |
    Using the TFS 2013 API along with a little PowerShell we can add a ‘team field’ to our global list.

    I have been working a lot with PowerShell recently and I have been stuck by its flexibility even when calling standard .NET API’s.  You should start with g[eting the TFS Collection](http://nkdagility.com/powershell-tfs-2013-api-0-get-tfscollection-and-tfs-services/ "Get TFS Collection") which will give you basic connectivity and imports required to get started. If we want to use 'team field' we may want to automate some of the activities that we need to make it happen slickly. You will have created a Global List for your 'team field' and you will want to add new entries. You can add them manually, or you can hit the TFS API to give you a leg up...

    In order to add an entry to a global list we unfortunately need to export all of the global lists locally as XML, edit it and then upload it back in. I have been trying to create as many reusable functions as possible in my PowerShell exploits and I am building up a rather hearty set of components. I have not yet figured out how to create reusable components that can be easily imported but I have figured out functions:

    ```
    function Add-TfsGlobalListItem {
        Param(
            [parameter(Mandatory=$true)][Microsoft.TeamFoundation.Client.TfsTeamProjectCollection] $TfsCollection,
            [parameter(Mandatory=$true)][String] $GlobalListName,
            [parameter(Mandatory=$true)][String] $GlobalEntryValue
            )
        # Get Global List
        $store = Get-TfsWorkItemStore $TfsCollection
        [xml]$export = $store.ExportGlobalLists();

        $globalLists = $export.ChildNodes[0];
        $globalList = $globalLists.SelectSingleNode("//GLOBALLIST[@name='$GlobalListName']")

        # if no GL then add it
        If ($globalList -eq $null)
        {
            $globalList = $export.CreateElement("GLOBALLIST");
            $globalListNameAttribute = $export.CreateAttribute("name");
            $globalListNameAttribute.Value = $GlobalListName
            $globalList.Attributes.Append($globalListNameAttribute);
            $globalLists.AppendChild($globalList);
        }

        #Create a new node.
        $GlobalEntry = $export.CreateElement("LISTITEM");
        $GlobalEntryAttribute = $export.CreateAttribute("value");
        $GlobalEntryAttribute.Value = $GlobalEntryValue
        $GlobalEntry.Attributes.Append($GlobalEntryAttribute);

        #Add new entry to list
        $globalList.AppendChild($GlobalEntry)
        # Import list to server
        $store.ImportGlobalLists($globalLists)
    }

    ```

    Figure: Adding to a GlobalList with PowerShell

    Here you can see that we are first getting the Work Item Store service, which is where all of the magic around Work Item Tracking occurs. Once we have that we need to export the XML using the “ExportGlobalLists” (#9) method which effectively just pucks up the entire XML tree for the global lists. We can then parse and edit it like any other piece of XML. We can find the list that we want, as all of the lists are exported, using a little XPath (#11)  and determine wither the required global list even exists. If it does not then my script goes ahead and adds one (#14-21) so that we don’t get an error. If this is the first time that you are added and element to a list it only makes sense that you would want the list to exist so creating it is not a stretch.

    Once we have the list, wither it is a new or existing one, we can go ahead and create and add the new element (#24-27.) Once we have everything in place we can import the entire set of global lists back into the server using the Import method.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-10-16-powershell-tfs-2013-api-2-adding-to-a-globallist\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-10-16-powershell-tfs-2013-api-2-adding-to-a-globallist
- FrontMatter:
    title: 'Review Part 3: Two Months with Intel Haswell Harris Beach SDS Ultrabook'
    description: Explore my two-month journey with the Intel Haswell Harris Beach SDS Ultrabook, highlighting performance, battery life, and Windows 8.1 updates. Read more!
    ResourceId: LSTyPpa3cnS
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10209
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-10-15
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: review-two-months-intel-haswell-harris-beach-sds-ultrabook
    aliases:
    - /resources/LSTyPpa3cnS
    aliasesArchive:
    - /blog/review-two-months-intel-haswell-harris-beach-sds-ultrabook
    - /review-two-months-intel-haswell-harris-beach-sds-ultrabook
    - /review-part-3--two-months-with-intel-haswell-harris-beach-sds-ultrabook
    - /blog/review-part-3--two-months-with-intel-haswell-harris-beach-sds-ultrabook
    - /resources/blog/review-two-months-intel-haswell-harris-beach-sds-ultrabook
    tags:
    - Windows
    categories:
    - Uncategorized
    preview: Web-Intel-Metro-icon-3-3.png
  BodyContent: |
    Now that I have had two months with the Intel Haswell Harris Beach SDS Ultrabook I thought that it would be a good idea to give you an update. You can check out Part #1 & #2 below however in this post I want to concentrate on Windows 8.1 with the SDS.

    - [Review Part 1: Harris Beach SDS Ultrabook from Intel with Haswell](http://nkdagility.com/review-harris-beach-sds-ultrabook-from-intel-unboxing/)
    - [Review Part 2: Developing with Intel Haswell Harris Beach SDS Ultrabook](http://nkdagility.com/review-developing-intel-haswell-harris-beach-sds-ultrabook/)
    - Review Part 3: Two Months with Intel Haswell Harris Beach SDS Ultrabook

    As you might have noticed from Part #1 I had a whole bunch of issues with Windows 8.1 and the drivers for this model. This is not surprising due to the prototype nature of this laptop but the team at Intel have been hard at work making it work and a few days ago they release a new set of drivers. I was really… hesitant… to again try 8.1 on this laptop but I am a glutton for punishment so…

    ![image](images/image8-1-1.png "image")  
    { .post-img }
    Figure: Windows 8.1 System

    … it looks like they have solved all of my main issues. They were mainly power and screen based which is detrimental for this sort of laptop. With the old 8.1 drivers I could close the lid and have the the system boot, overheat and the battery drain in my bag. Not good… The only thing that is still a little wired is that on Chrome my gestures end up not where my finger is. Meh… it will get fixed eventually and Internet Explorer with touch is way better than Chrome anyway (If you install the Canary version of Chrome the touch works.)

    I have been running Visual Studio 2013 and TFS 2013 on this laptop with no performance issues what so ever. Its slick… I especially like the battery life. When the driver gods are smiling I get a good 6-7 hours of use and as I spend a lot of time traveling without power this is just awesome. I have a Dell M6600 but the battery only lasts for 45 minutes and to be honest its too big to open the lid on a plane anywhere but first class.

    ![image](images/image9-2-2.png "image")  
    { .post-img }
    Figure: Visual Studio 2013 on Windows 8.1

    Although I have been working with this laptop for a few months I have done very little development and have instead be working extensively on it in Windows Live Writer, Word, Outlook and a little bit of Visual Studio. Almost all of my blog posts in the last few months have been written on this laptop. I also walk a lot and, instead of wondering, I like to have a goal. So I take this laptop and head out for the day to Redmond City Centre or to the Family Pancake House down the road to write blog posts and work on my Book. And you know what… I have never had to worry about the battery, or cut my blogging sessions short. The Haswell chipset provides the power and longevity that I need.

    I have also used it on a few engagements where I don’t need virtual machines to get the job done. Oh… don’t get me wrong, this Haswell laptop could handle the VM’s its just that I only have 4GB or RAM and my TFS VM’s need at least 5GB to run effectively… hence why I have the M6600 with 24GB RAM.

    If I was looking for a laptop to really work on I would likely go with the top spec Lenovo Helix with a Haswell processor. This would give me i7, 8GB RAM and the hybrid capability to transform it into a tablet. That would replace my actual tablet  (Acer Ionia W520) and this computer in one. However as money does not yet grow on trees this awesome Haswell developer platform will serve the same purpose admirably.

    Disclosure of Material Connection: I received one or more of the products or services mentioned above for free in the hope that I would mention it on my blog. Regardless, I only recommend products or services I use personally and believe my readers will enjoy. I am disclosing this in accordance with the Federal Trade Commission’s 16 CFR, Part 255: “[Guides Concerning the Use of Endorsements and Testimonials in Advertising](http://www.access.gpo.gov/nara/cfr/waisidx_03/16cfr255_03.html).”
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-10-15-review-two-months-intel-haswell-harris-beach-sds-ultrabook\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-10-15-review-two-months-intel-haswell-harris-beach-sds-ultrabook
- FrontMatter:
    title: 'PowerShell TFS 2013 API #1 - Get TfsCollection and TFS Services'
    description: Learn to harness PowerShell with the TFS 2013 API in this comprehensive guide. Discover essential functions to manage TFS collections and services effectively!
    ResourceId: kaEC07NAXT7
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10149
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-10-02
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: powershell-tfs-2013-api-1-get-tfscollection-and-tfs-services
    aliases:
    - /resources/kaEC07NAXT7
    aliasesArchive:
    - /blog/powershell-tfs-2013-api-1-get-tfscollection-and-tfs-services
    - /powershell-tfs-2013-api-1-get-tfscollection-and-tfs-services
    - /powershell-tfs-2013-api--1
    - /powershell-tfs-2013-api--1---get-tfscollection-and-tfs-services
    - /blog/powershell-tfs-2013-api--1---get-tfscollection-and-tfs-services
    - /resources/blog/powershell-tfs-2013-api-1-get-tfscollection-and-tfs-services
    tags:
    - Software Development
    - Install and Configuration
    categories:
    - Uncategorized
    preview: metro-powershell-logo-1-1.png
  BodyContent: |
    Have you ever wanted to use PowerShell to interact with the TFS 2013 API? Well I have been working through a few scenarios and wanted to get them to you so that I can get some feedback.

    This will likely be a series of PowerShell posts as I build up my library of PowerShell statements. In order to interact with the TFS API with PowerShell, the first things we need to do is import the types that we are going to use. As there are no real PowerShell comandlets for TFS out of the box we need to import the actual assemblies and then wrap a bunch of functions that we want to use.

    ```
    $pathToAss2 = "C:\Program Files (x86)\Microsoft Visual Studio 12.0\Common7\IDE\ReferenceAssemblies\v2.0"
    $pathToAss4 = "C:\Program Files (x86)\Microsoft Visual Studio 12.0\Common7\IDE\ReferenceAssemblies\v4.5"
    Add-Type -Path "$pathToAss2\Microsoft.TeamFoundation.Client.dll"
    Add-Type -Path "$pathToAss2\Microsoft.TeamFoundation.Common.dll"
    #Add-Type -Path "$pathToAss2\Microsoft.TeamFoundation.dll"
    Add-Type -Path "$pathToAss2\Microsoft.TeamFoundation.WorkItemTracking.Client.dll"
    Add-Type -Path "$pathToAss2\Microsoft.TeamFoundation.VersionControl.Client.dll"
    Add-Type -Path "$pathToAss4\Microsoft.TeamFoundation.ProjectManagement.dll"

    ```

    Figure: Referencing Assemblies

    Above I have a set of Assembly imports that reflect the breadth of the functions that I am adding. I am continuously adding to this list but there are a few parts of interest. The first 3 assemblies loaded are the core TFS API’s that you will need for almost every interaction. They represent things like the Server and Collection as well as TeamProject and other core concepts that traverse any particular component. It is worth noting that everything here is the same as you would do in .NET.

    The last three assemblies provide Work Item Tracking, Version Control and Project Management respectively. The Project Management assemblies are in the v4.5 folder instead of v2.0 as they were only recently added. With more new features coming down the line it is likely that more things will end up in the v4.5 folder.

    The very first thing that you will always do when working with the TFS is connect to your TFS server. Really that means that you will be connecting to the Collection that you want to work with. There are some things that you may want to do against the server but not many.

    ```
    function Get-TfsCollection {
     Param(
           [string] $CollectionUrl
           )
        if ($CollectionUrl -ne "")
        {
            #if collection is passed then use it and select all projects
            $tfs = [Microsoft.TeamFoundation.Client.TfsTeamProjectCollectionFactory]::GetTeamProjectCollection($CollectionUrl)
        }
        else
        {
            #if no collection specified, open project picker to select it via gui
            $picker = New-Object Microsoft.TeamFoundation.Client.TeamProjectPicker([Microsoft.TeamFoundation.Client.TeamProjectPickerMode]::NoProject, $false)
            $dialogResult = $picker.ShowDialog()
            if ($dialogResult -ne "OK")
            {
                #exit
            }
            $tfs = $picker.SelectedTeamProjectCollection
        }
        Return $tfs
    }

    ```

    Figure: Connecting to the TFS Collection in PowerShell

    Here I am doing a couple of things. If you pass a URL to a TFS Collection as a string into the function it will create a TFS Collection object based on that URL by calling the static GetTeamProjectCollection method on the built in factory class. That is the easy way. If you don’t specify the URL the PowerShell script above hooks into the built in API’s to show the same Collection Picker dialog that you get in Visual Studio when you try to connect. This actually has three modes, but here i am only using the “NoProject” mode to select a Collection only.

    ```
    function Get-TfsCommonStructureService {
     Param(
           [Microsoft.TeamFoundation.Client.TfsTeamProjectCollection] $TfsCollection
           )
        Return $TfsCollection.GetService("Microsoft.TeamFoundation.Server.ICommonStructureService3")
    }

    ```

    Figure: Connecting to the TFS Common Structure Service with PowerShell

    Now that we have our TFS server object we can start exercising it. However everything in TFS is pretty much done through a collection of servers that you get from that Collection object. Here we are doing a get on the [Common Structure Service](http://msdn.microsoft.com/en-us/library/microsoft.teamfoundation.server.icommonstructureservice3.aspx) which is responsible for some of the underlying structures like Team Projects, Area Paths and Iteration Paths.

    ```
    $global:TfsWorkItemStoreCache
    function Get-TfsWorkItemStore {
     Param(
           [Microsoft.TeamFoundation.Client.TfsTeamProjectCollection] $TfsCollection,
           [switch] $refresh
           )
           If ($global:TfsWorkItemStoreCache -eq $null -or $refresh -eq $true)
           {
           $global:TfsWorkItemStoreCache= $TfsCollection.GetService([Microsoft.TeamFoundation.WorkItemTracking.Client.WorkItemStore])
           }
        Return $global:TfsWorkItemStoreCache
    }

    ```

    Figure: Connecting to the TFS Work Item Store with PowerShell

    Another component that you will get a lot of use out of is the [Work Item Store](http://msdn.microsoft.com/en-us/library/microsoft.teamfoundation.workitemtracking.client.workitemstore.aspx). This is where all of the magic happens with Work Items. We can use it to access queries, create our own queries as well as create and edit Work Items. If you are just a little crazy you can also edit the work item types…

    ```
    function Get-TfsVersionControlServer {
        Param(
            [Microsoft.TeamFoundation.Client.TfsTeamProjectCollection] $TfsCollection
            )
        Return $TfsCollection.GetService("Microsoft.TeamFoundation.VersionControl.Client.VersionControlServer")
    }

    ```

    Figure: Connecting to TFS Version Control with PowerShell

    If you are seeking to work with the Source Code then [Version Control Server](http://msdn.microsoft.com/en-us/library/microsoft.teamfoundation.versioncontrol.client.versioncontrolserver.aspx) is the service you are looking for. It allows you to work with all of the files in source control and to add more. Simple to work with once you accept that you need a Local Workspace to do anything.

    ```
    function Get-TfsProjectProcessConfigurationService {
        Param(
            [Microsoft.TeamFoundation.Client.TfsTeamProjectCollection] $TfsCollection
            )
        return $TfsCollection.GetService([Microsoft.TeamFoundation.ProcessConfiguration.Client.ProjectProcessConfigurationService]);
    }

    ```

    Figure: Connecting to TFS Project Process Configuration with PowerShell

    There are many new features in 2012 and 2013 that required new API’s to edit and configure. The [Project Process Configuration](http://msdn.microsoft.com/en-us/library/microsoft.teamfoundation.processconfiguration.client.projectprocessconfigurationservice.aspx) is one such entity that comes from the new “Microsoft.TeamFoundation.ProjectManagement.dll”. This allows you to configure and work with the Process Configuration for your Team Project. This is the configuration and layout of your Backlogs and Boards. You can just read the settings or you can set them as well.

    ```
    function Get-TfsTeamSettingsConfigurationService {
        Param(
            [Microsoft.TeamFoundation.Client.TfsTeamProjectCollection] $TfsCollection
            )
        return $TfsCollection.GetService([ Microsoft.TeamFoundation.ProcessConfiguration.Client.TeamSettingsConfigurationService]);
    }

    ```

    Figure: Connecting to TFS Team Settings Configuration with PowerShell

    While you can use the Process configuration above to change the process template there are also settings that are specific to the Teams that are created with TFS. Not only can you create new teams but there are a plethora of configuration options. Use the [Team Settings Configuration services](http://msdn.microsoft.com/en-us/library/microsoft.teamfoundation.processconfiguration.client.teamsettingsconfigurationservice.aspx) to access and edit these new features. It a little more convoluted an API than I would have liked, but it does have some awesome capabilities.

    ## Conclusion

    Have you been playing with the TFS API in PowerShell? The advantage of a scripting language is obvious in the versatility of both edit-ability and runtime execution of commands to figure out what you need to do. I would have loved for TFS to have built in commands, but with access to the API’s there really is no need. You can do whatever you want.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-10-02-powershell-tfs-2013-api-1-get-tfscollection-and-tfs-services\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-10-02-powershell-tfs-2013-api-1-get-tfscollection-and-tfs-services
- FrontMatter:
    title: Granting access to Team Foundation Server 2012 for diagnostic troubleshooting
    description: Learn how to grant access to TFS 2012 for diagnostic troubleshooting without full admin rights. Enhance your efficiency with simple command line solutions!
    ResourceId: 8N31NtGZFyB
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10002
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-09-24
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: granting-access-team-foundation-server-2012-diagnostic-troubleshooting
    aliases:
    - /resources/8N31NtGZFyB
    aliasesArchive:
    - /blog/granting-access-team-foundation-server-2012-diagnostic-troubleshooting
    - /granting-access-team-foundation-server-2012-diagnostic-troubleshooting
    - /granting-access-to-team-foundation-server-2012-for-diagnostic-troubleshooting
    - /blog/granting-access-to-team-foundation-server-2012-for-diagnostic-troubleshooting
    - /resources/blog/granting-access-team-foundation-server-2012-diagnostic-troubleshooting
    tags:
    - Troubleshooting
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-3-3.png
  BodyContent: |
    In TFS 2012 the product team added a way to get to the tbl_Command information without needing to connect directly to the SQL Server and having access to the tables. This was an awesome add as being able to diagnose server issues and troubleshoot user reported problems makes us a little more efficient.

    ![image](images/image11-1-1.png "image")  
    { .post-img }
    Figure: Viewing the diagnostic activity logs for troubleshooting

    However I had always had to give access by adding the user to the “Team Foundation Administrators” group which is a little too much power just to do a little diagnostic spelunking… so my question is:

    How do I give permission to the Activity Log without giving TFS Administrator?

    Well, it looks like the command line has the answer. Although there is no representative entry in the GUI to give permission for a user only to the diagnostic troubleshooting page you can grant it explicitly:

    ```
    tfssecurity /a+ Diagnostic Diagnostic Troubleshoot n:domain\username ALLOW /server:http://tfsserver:8080

    ```

    This gives that group explicit access.

    ![image](images/image12-2-2.png "image")  
    { .post-img }
    Figure: Use the command line to grant diagnostic troubleshooting permission

    What might be a better and more manageable solution would be to create a group called “Team Foundation Troubleshooters” and instead grant that group permission to that access control. This is done in exactly the same way, you just need to replace the domain account with the TFS Group.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-24-granting-access-team-foundation-server-2012-diagnostic-troubleshooting\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-24-granting-access-team-foundation-server-2012-diagnostic-troubleshooting
- FrontMatter:
    title: Issue [ TFS 2013 ] TF255466 A previous update or installation requires a restart
    description: Resolve the TF255466 error in TFS 2013 after SQL Server 2012 SP1 installation. Discover solutions to clear pending reboots and ensure smooth setup.
    ResourceId: Crf5MJ60PGe
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10006
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-09-17
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: issue-tfs-2013-tf255466-previous-update-installation-requires-restart
    aliases:
    - /resources/Crf5MJ60PGe
    - /resources/blog/issue-tfs-2013-tf255466-a-previous-update-or-installation-requires-a-restart
    aliasesArchive:
    - /blog/issue-tfs-2013-tf255466-previous-update-installation-requires-restart
    - /issue-tfs-2013-tf255466-previous-update-installation-requires-restart
    - /issue-[-tfs-2013-]-tf255466-a-previous-update-or-installation-requires-a-restart
    - /blog/issue-[-tfs-2013-]-tf255466-a-previous-update-or-installation-requires-a-restart
    - /resources/blog/issue-tfs-2013-tf255466-previous-update-installation-requires-restart
    - /resources/blog/issue-tfs-2013-tf255466-a-previous-update-or-installation-requires-a-restart
    tags:
    - Windows
    - Troubleshooting
    - Install and Configuration
    categories:
    - Uncategorized
    preview: metro-problem-icon-4-4.png
  BodyContent: |
    After you have installed SQL Server 2012 Service Pack 1 you may encounter the error “TF255466 A previous update or installation requires a restart” when trying to install TFS 2013.

    Even if you install all Windows Updates and reboot you continue to get this message.

    MANDATORY SP1 Hotfix _SP1 installations are currently experiencing an issue in certain configurations as described in Knowledge Base article [KB2793634](http://support.microsoft.com/kb/2793634). The article provides a fix for this issue that is currently available for download, and is MANDATORY for application immediately following a Service Pack 1 installation. The fix is also being made available on Microsoft Update._

    ![image](images/image13-1-1.png "image")  
    { .post-img }
    Figure: TF255466 A previous update or installation requires a restart

    Even if you reboot untill you are pounding on the keyboard....

    ## Applies to

    - Visual Studio 2013 Team Foundation Server Preview
    - Visual Studio 2013 Team Foundation Server RC

    ## Findings

    No matter what you do this error continues to occur whenever you try an install TFS 2013. If you have a look at the log you should see that a “PendingFileRenameOperations” flag has been set and does not want to clear.

    ```
    [Info   @18:53:14.576] +-+-+-+-+-| Verifying that the system restart is not required |+-+-+-+-+-
    [Info   @18:53:14.576] Starting Node: VPENDINGREBOOT
    [Info   @18:53:14.576] NodePath : VINPUTS/Conditional/Progress/VPENDINGREBOOT
    [Info   @18:53:14.577] IsPendingSxsRebootRequired() returned False
    [Info   @18:53:14.577] The value 'PendingFileRenameOperations' under 'HKEY_LOCALMACHINE\SYSTEM\CurrentControlSet\Control\Session Manager' registry key is not empty
    [Info   @18:53:14.577] IsSessionManagerRebootRequired(True, True) returned True
    [Error  @18:53:14.577] Found a pending file operation - configuration blocked until reboot
    [Info   @18:53:14.577] Node returned: Error
    [Error  @18:53:14.577] TF255466: The configuration process for Team Foundation Server cannot continue.  A previous update or installation requires a restart of the operating system.  Restart the computer, and then open the administration console for Team Foundation to restart the configuration wizard.
    [Info   @18:53:14.577] Completed NoPendingReboots: Error
    [Info   @18:53:14.577] -----------------------------------------------------
    ```

    This is normally cleared when you do a reboot as whatever actions can be taken then. This can continue to happen with a newly installed copy of Windows Server 2012 due to the volume of updates that are available. Effectively every time you reboot it can start installing updates immediately. If this is the case then you can wait until all of the Updates are finished or you can stop the Windows Update service temporarily to get things done.

    ## Solution: Non Security Update for SQL Server 2012 SP1

    However there was a bug with SQL Server 2012 where the [Windows Installer starts repeatedly after you install SQL Server 2012 SP1](http://support.microsoft.com/kb/2793634). Basically there is a mismatch of the version of a file that is installed and the SQL Server installer keep trying to fix it. Thus resulting in a permanent loop of pending reboots…

    ![image](images/image14-2-2.png "image")  
    { .post-img }
    Figure: Windows Installer starts repeatedly after you install SQL Server 2012 SP1

    If think this is the issue you can head on over here and download the [Non Security Update for SQL Server 2012 SP1 (KB2793634)](http://www.microsoft.com/en-us/download/details.aspx?id=36215) to fix it.

    ![image](images/image15-3-3.png "image")  
    { .post-img }
    Figure: All readiness checks complete

    For me this fixed my issue…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-17-issue-tfs-2013-tf255466-previous-update-installation-requires-restart\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-17-issue-tfs-2013-tf255466-previous-update-installation-requires-restart
- FrontMatter:
    title: Unable to install Visual Studio 2013 RC on Windows 8.1 Preview
    description: Struggling to install Visual Studio 2013 RC on Windows 8.1 Preview? Discover the compatibility issues and find solutions to move forward with your setup.
    ResourceId: RXXbeQU6tAH
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9998
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-09-09
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: unable-to-install-visual-studio-2013-rc-on-windows-8-1-preview
    aliases:
    - /resources/RXXbeQU6tAH
    - /resources/blog/unable-to-install-visual-studio-2013-rc-on-windows-8.1-preview
    aliasesArchive:
    - /blog/unable-to-install-visual-studio-2013-rc-on-windows-8-1-preview
    - /unable-to-install-visual-studio-2013-rc-on-windows-8-1-preview
    - /resources/blog/unable-to-install-visual-studio-2013-rc-on-windows-8-1-preview
    - /resources/blog/unable-to-install-visual-studio-2013-rc-on-windows-8.1-preview
    tags:
    - Windows
    - Install and Configuration
    - Troubleshooting
    categories:
    - Uncategorized
  BodyContent: |
    When you try to install Visual Studio 2013 RC (or Visual Studio 2013 RC Team Foundation Server) you get the message “Error: This version of Team Foundation Server is not compatible with Windows 8.1 Preview”

    ![image](images/image10-1-1.png "image")  
    { .post-img }
    Figure: This version of Team Foundation Server is not compatible with Windows 8.1 Preview

    ## Applies to

    - Team Foundation Server 2013 Preview on Windows Server 2012 R2 Preview
    - Visual Studio on Windows Server 2012 R2 Preview
    - Team Foundation Server 2013 Preview on Windows 8.1 Preview
    - Visual Studio on Windows 8.1 Preview

    ## Findings

    Unfortunately in order to install the Release Candidate there is a requirement to update the version of .NET that is on the server. As the Preview copies of Windows 8.1 and Windows Server 2012 R2 has .net 4.5.1 Preview baked in you will not be able to install the new version on there.

    You can however use Windows Server 2012, Windows 8, Windows Server 2008 R2, and Windows 7 to install the components.

    ## Conclusion

    In order to move forward with the new RC versions of Visual Studio and Team Foundation Server you will need to move to an RTM version of Windows. If you can get the Windows 8.1 or Windows Server 2012 R2 RTM then you are good to go. However you will be unlikely to get them prior to General Availability in October.

    You can however use any of the existing version of Windows and Windows Server that are supported.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-09-unable-to-install-visual-studio-2013-rc-on-windows-8-1-preview\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-09-unable-to-install-visual-studio-2013-rc-on-windows-8-1-preview
- FrontMatter:
    title: What's new in Visual Studio 2013 and TFS 2013 RC
    description: Discover the latest features in Visual Studio 2013 and TFS 2013 RC. Enhance your development experience with powerful tools and agile improvements!
    ResourceId: _YCdFNYKYcM
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10019
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-09-09
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: whats-new-in-visual-studio-2013-rc-with-team-foundation-server
    aliases:
    - /resources/_YCdFNYKYcM
    - /resources/blog/what-s-new-in-visual-studio-2013-and-tfs-2013-rc
    aliasesArchive:
    - /blog/whats-new-in-visual-studio-2013-rc-with-team-foundation-server
    - /whats-new-in-visual-studio-2013-rc-with-team-foundation-server
    - /what's-new-in-visual-studio-2013-and-tfs-2013-rc
    - /blog/what's-new-in-visual-studio-2013-and-tfs-2013-rc
    - /resources/blog/whats-new-in-visual-studio-2013-rc-with-team-foundation-server
    - /resources/blog/what-s-new-in-visual-studio-2013-and-tfs-2013-rc
    tags:
    - Software Development
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-13-13.png
  BodyContent: |
    As you may have noticed the Visual Studio team has just put out a Release Candidate to the log awaited Visual Studio 2013 and TFS 2013.

    If you have been [unable to install Visual Studio 2013 RC on Windows 8.1 Preview](http://nkdagility.com/unable-to-install-visual-studio-2013-rc-on-windows-8-1-preview/) then you want to immediately get to grips with the new features. I would recommend that you have a look at [What's new in Visual Studio 2013 Team Foundation Server Preview](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/) for two reasons. I am going to assume that you have seen the aforementioned features and it should give you some idea of the pace of features improvement you get by being on the same cadence as the TFS product team.

    These are just my initial observations from conducting a little exploratory testing on features that we saw in the TFS 2013 Preview and those things that I knew and suspected were coming down the line. The best way to get a heads up is still to create an account on [http://tfs.visualstudio.com](http://tfs.visualstudio.com) as it is already ahead of the Release Candidate.

    ## Visual Studio 2013 Team Explorer Enhancements

    There have been repeated and increasing enhancements to the Team Explorer. Some of these enhancements have been small experiments and others have been large. Some have been successful and some result is continuous change as the product team evolve things trying to meet our needs. If only every team building software would innovate as often. If like me you take the latest drop at all times you will see the bounding progression of features and enhancements. If you don’t you will see the usual big leaps.

    ### Visual Studio 2013 Team Explorer remembers your TFS Servers

    I was surprised when I opened the connection dialog on my brand new OS with Visual Studio 2013 RC installed and saw a list of TFS servers that I recognised.

    ![image](images/image16-1-1.png "image")  
    { .post-img }
    Figure: Visual Studio 2013 Team Explorer remembers your TFS Servers

    It looks like the team has populated my list of servers with all of the instances from [http://tfs.visualstudio.com](http://tfs.visualstudio.com) that I have permission for, and that's a lot. I am not sure what happens when this list gets bigger than my screen but that's for another day. I had forgotten that I had connected to some of these servers. What would be a nice enhancement to this would be to have local servers that are synched as well. That way I can easily select local servers when I go onsite at customers.

    ### New Team Explorer Home page

    The new layout for the Team Explorer homepage is much more flexible and has way better extension points.

    ![image](images/image17-2-2.png "image")  
    { .post-img }
    Figure: The new Team Explorer in 2013

    Again we have the context of a single Team Project. While administrators may have preferred the old tree view users found it confusing and slow. The new interface added with 2012 has been streamlined and enhanced with a years worth of usability data.

    ### The Project Section

    The project session is topped with a set of useful links:

    - **Configure Workspace** – This takes you to the the configuration page for the Workspaces that you have associated with your Team Project.
    - **Web Portal** – The Web Portal is THE way to access and work with much of the data in TFS 2013. Even more than in 2010 and in 2012 as we now have Test management right there in the web. In addition to Test Case management there are hubs for Agile Planning, Agile Portfolio Management, Work Item Tracking, Build Management, Code Management and now Reporting.
    - **Task Board** – Part of the Agile Planning Tools feature that was introduced in TFS 2012 the Task Board provides you a Scrum style board where Requirement types sit on the left and tasks flow through states associated with the Requirement from left to right. Typical states are To-do –> Doing –> Done.
    - **Team Room** – Each Team gets their own persistent chat and notification room where users can interact and be notified of Builds and work item changes dynamically. Way better than email.

    Although Web Access is now the preferred way to access much of the data in TFS that does not mean that there are no other options. The following sections have been incrementally updated individually but here each of the important nodes use a flow layout so that they are just as accessible regardless of the size of the window. They are each subtly colour coded but the new piece is that many of them have a little ellipse in the bottom right of the button \\ panel. If you click the ellipse you you get a drop down of menu options for that feature. Indeed these panels dynamically change depending on which source control you selected when you created your Team Project. TFS 2013 supports both TFVC and Git.

    - **My Work** – The My Work section gives you access to the up level features like Code Reviews, Suspend Resume and Task switching and focus features that you need to be on Premium or ultimate SKU’s to get. Few of these features yet work of your pick Git as your source control.
    - **Pending Changes** – A new view on the standard pending changes with a docked panel instead of a floating model dialog. You can now break it out of the UI and stick it anywhere you want.
    - **Source Control Explorer** – Only available for TFVC projects this gives you folder and branch access to your code. I have yet to delve into that UI
    - **Work Items** – Gives you access to the standard tree of queries. You can create flat, dependant or tree queries that show whatever columns that you like. There are some Team Explorer only features like opening queries in Excel or MS Project and turning Queries into reports.
    - **Build** – Want continuous delivery? This is your stop. Create both compilation, test and deployment builds that execute on demand, timed or triggered. A special feature added way back in 2010 allows you to pre-moderate your builds which lets you build first and reject check-ins for failed builds.
    - **Reports** – Your gateway to the Reporting Services reports that are available for your Process Template
    - **Settings** – The new settings page now seams like a Launchpad for the Web Portal. I will not miss those model dialog boxes….more power to the web…

    These same features, well mostly, are available in Eclipse as well.

    ### The Solution Section

    The solution section, new in 2013, is awesome. It looks at the scope of your currently selected Workspace and lists all of the Solutions available in Source Control to open. Here I have nothing in source yet and I don’t have my workspace configured. I do believe that there is a limit to the number of solutions that will be listed, but I am not sure what that it.

    ## Visual Studio 2013 Team Foundation Server Enhances

    While the new features in Visual Studio are awesome I sometimes forget what they look like these days. Apart from the projects that I work on myself with the other MVP’s, the Rangers and just for fun I rarely get to play in Visual Studio. (sniff)I do miss it, they even (shock) have me coding in c# these days, but I never stop complaining about that.

    So where do I play, well… sometimes in PowerShell but mostly in Team Foundation Server when I am doing technical stuff. Helping teams and organisations improve their processes is mostly not about tools. However when I need a tool I always turn to TFS. As the TFS Product Team are moving more and more towards agile themselves the product itself is getting better and better at delivering value in the agile space. Although there are many features that are based on reportability that is no longer the focus of the team and the new features concentrate on making your development process as slick as possible.

    ### Team Rooms

    Team Rooms are brand new in TFS 2013 and provide a kina cross between email notifications and persistent chat.

    You can configure notification for various things including Build results and work item changes. The results pop into the window with a little ‘ding’ for other to be notified. If you are unable to get everyone in a physical team room then this is the next best thing. Those of you out there thinking ‘what's the use of that crap’ should give it a try. Find it valuable or don’t as you like but the ability to chat and tag work items just by mentioning #2354 or a person with the usual @Youname mechanism makes the experience much more interactive.

    ![image](images/image18-3-3.png "image")  
    { .post-img }
    Figure: Configure events for Team Rooms in 2013

    I am looking forward to innovations and experiments here.

    ### Agile Portfolio Management Enhancements

    When I looked at [What's new in Visual Studio 2013 Team Foundation Server Preview](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/) I spent a lot of time on the Agile Portfolio Management features and even created a [video walkthrough](http://nkdagility.com/video-new-with-visual-studio-2013-manage-portfolio-backlogs-to-understand-the-scope-of-work/). Here I just want to go back and visit some of the areas that  have been improved.

    ![image](images/image19-4-4.png "image")  
    { .post-img }
    Figure: Backlog View Pick list

    First up is that pick list list that lets you ‘look up’ and ‘look down’. In the earlier version it was not colour coded, it did not have the current level first and the text was just the name of the Work Item in question. The new list is eminently more usable and understandable. Here we get more context; we get the colour of the work item type that we can subconsciously relate. There is also a subtle separator between the ‘current view’ and the alternative views. It was previously easy to forget which level you were at and thus where one had to go to get back to the orderable view. We had the ‘Backlog Items’ highlight on the left, but we had to look way the other side of the screen to figure it out. Now we can easily see where we are and where we are looking. Even the addition of the simple “to \[other work item type\]” test gives us much more of that context.

    This to me is an embodiment of a small simple but extremely valuable enhancement to an existing feature that is only really valuable in short release cycles. In a long cycle it would never make it above the cut line.

    ![image](images/image20-5-5.png "image")  
    { .post-img }
    Figure: Subtle directional chevron on Backlogs

    If you do select another option, in this case I am looking up from ‘Backlog items to Features’ you get a subtle indication on the left as well as to where you are. The little colour coded chevron for "’Backlog items’ narrows at the top to signify that we are looking up. This gives other side of the screen the same information in a subtle enough manor as to not interrupt or clutter the display, but still conveying necessary information.

    ### Mapping from Backlog Items to Features

    Another incremental improvement is the ability to easily associate backlog Items with Feature (or whatever you have above the backlog that you are viewing).

    ![image](images/image21-6-6.png "image")  
    { .post-img }
    Figure: Mapping from Backlog to Parent

    Here we can turn on Mapping and a list of the parent items are listed on the right. You can then drag and drop your backlog items onto the required feature to create the associations that you want. This makes it way easier and more intuitive to work with the hierarchy.

    ### Charting from Queries

    One of the awesome features in TFS in the reporting, even if it is just incidental reporting when you are not actively trying to get traceability. In Visual Studio you can right click on a Query and select “Generate Report”. This feature would look at the fields that were available on the query and determine what sort of reporting was possible with those options. It would then let you build out both static and trend reporting in Excel using a macro. Well, as we move towards more of a cloud based infrastructure we need the same features but unfortunately, or fortunately, there is no Analysis Services in Azure. So what can we do?

    ![image](images/image22-7-7.png "image")  
    { .post-img }
    Figure: Static Analysis reports in TFS 2013

    The product team in superb incremental style have implemented the easy part first; Static Charting. They have created the ability to add charts to you query. To find the options head over to your work item queries and when you select a query you will note an extra tab added to the UI. Where we had only Results and Edit we now get Charts. Once on the charts tab you can create a new chart and select the chart type:

    - Pie
    - Bar
    - Column
    - Stacked bar
    - Pivot table

    While this will never have parity with Excel there is much more value in this being just available in the UI. One you have selected your chart type you get to give it a name and then customise the data displayed. You need to first select the Grouping. This is the field (dimension) that you want to display the data by. After that you select the values (metric) to display.  I don’t hold out hopes for getting trend analysis by RTM of 2013 but if we are lucky some future sprint will bring that functionality.

    ![image](images/image23-8-8.png "image")  
    { .post-img }
    Figure: Adding lots of charts

    You can go ahead and add a bunch of charts giving you different views of the same data and creating a dashboard based on your query data. I love this option…

    ### Multi-reorder of Column Options

    As I was clicking through I notices a little nugget that I have no idea when it was added.

    ![image](images/image24-9-9.png "image")  
    { .post-img }
    Figure:

    Maybe this was added in 2012 and I never noticed but you can, when ordering columns, select multiple columns and change their order together. I don;t know how many times I have moved each one individually and I hope this is a new feature if only to save face…

    ### Creating Test Plans from the Web Portal

    Although web based Testing was added in one of the updates to 2012 there were some serious limitations. We could not create Test Plans and needed to jump into MTM to perform many of those tasks.

    ![image](images/image25-10-10.png "image")  
    { .post-img }
    Figure: Creating Test Plans from the Web Portal

    Now with 2013 you can create a Test Plan directly in the web UI. You can add a name and configure the Area Path and Iteration Path that is relevant. If you want to edit the Test Plan you have to jump into MTM but the team have added a little bottom on the far right off the highlight above to jump strait to that page in the application.

    ### Create Test Cases in a Grid view

    Power users of Microsoft Test Manager have always called for productivity improvements. They were always used to working in Excel before MTM came along and some things are just easier there. Well the MTM team has been listening and they have added some new features to the web to make things easier.

    ![image](images/image26-11-11.png "image")  
    { .post-img }
    Figure: Create test Cases in Grid View

    You can now create Test Cases just like you once did in Excel. You can modify and add new at the same time and save as you go along. If you use to, or currently, create Test Cases in Excel and then port them to MTM you can now copy and paste them into here and save.

    ### Open the Test Plan or Run Test in Microsoft Test Manager Client from Web

    The last feature I want to highlight is the “Run using client” bottom that sends the selected tests to MTM for execution.

    ![image](images/image27-12-12.png "image")  
    { .post-img }
    Figure: Launching MTM from the Web UI

    In MTM you get data collectors like Video, Intellitrace, Event Log scraping, Code Coverage and Test Impact Analysis. Sometimes you want those things and this lets you jump into the right part of MTM and back to the web access making the integration a little bit more seamless.

    ## Conclusion

    Although I knew where some of them were, or where I expected them to exist these were just the few highlights of features that I feel that are important based on my customer engagements. There are a plethora of features in Visual Studio like Code Sense (kind of a heads up display for coding) that go to ALM productivity but I have not yet used them.

    Remember that [Team Foundation Server 2013 is production ready](http://nkdagility.com/team-foundation-server-2013-is-production-ready/).

    If you have the Preview you should upgrade and anyone on 2010or 2012 should seriously consider the features available. Remember also that you can still use VS 2010 and VS 2012 with TFS 2013.

    Originally posted on The Microsoft Award Program Blog as Visual Studio 2013 RC Released ([source](http://blogs.msdn.com/b/mvpawardprogram/archive/2013/09/09/visual-studio-2013-rc-released.aspx))
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-09-whats-new-in-visual-studio-2013-rc-with-team-foundation-server\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-09-whats-new-in-visual-studio-2013-rc-with-team-foundation-server
- FrontMatter:
    title: Upgrading from the TFS 2013 Preview to TFS 2013 RC
    description: Learn how to smoothly upgrade from TFS 2013 Preview to TFS 2013 RC with expert tips and a step-by-step guide for a hassle-free transition.
    ResourceId: WlTNhsC5jek
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10041
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-09-09
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: upgrading-from-the-tfs-2013-preview-to-tfs-2013-rc
    aliases:
    - /resources/WlTNhsC5jek
    aliasesArchive:
    - /blog/upgrading-from-the-tfs-2013-preview-to-tfs-2013-rc
    - /upgrading-from-the-tfs-2013-preview-to-tfs-2013-rc
    - /resources/blog/upgrading-from-the-tfs-2013-preview-to-tfs-2013-rc
    tags:
    - Software Development
    - Install and Configuration
    - Windows
    - System Configuration
    categories:
    - Uncategorized
  BodyContent: |
    With the [TFS 2013 RC](http://nkdagility.com/whats-new-in-visual-studio-2013-rc-with-team-foundation-server/) being made available I need to upgrade one of my main customers from the TFS 2013 Preview.

    I have been working with a fairly progressive customer that has no qualms to using the latest version of any software as long as it is supported. They have around 500 developers in Team Foundation Server and 2-3TB of data. No that was not a typo. Although they have 500 active engineers there are around 9000 user accounts that have permission to TFS. This is the [Engaging with complexity – TFS Edition](http://nkdagility.com/engaging-with-complexity-team-foundation-server-edition/) customer that was moving through many environments. They since managed to streamline their processes and I have been working with them for a while. We have done maybe 10 to 15 upgrades of the 2TB collection across five separate environments over the last few months practicing for the production move. All with Team Foundation Server 2013 Preview. And we have had no problems at all. Indeed when we moved to 2013 many of the issues that we had disappeared.

    Now that the RC is available and with production only a week away I needed to do a trial upgrade of their Sandbox environment to make sure that everything will work for Production. In fact it went so well (took around an hour) that we went ahead and upgraded the soon to be production server that very day. I can also confirm that the move to production of the data and users has been completed successfully…

    ## Upgrading Sandbox 2TB data to Team Foundation Server 2013 RC

    Some thing that I can’t stress more is to always do a trial upgrade. If, unlike this customer, you have limited hardware then I would recommend that you create a new virtual environment to replace your current TFS virtual servers. This will allow you to run a trial upgrade without impacting production and your infrastructure teams can reclaim the old VM’s once you are done.

    ![image](images/image28-1-1.png "image")  
    { .post-img }
    Figure: Current TFS Environment is Server 2008 R2 with TFS 2013 Preview

    I really have no expectation of a long or complicated upgrade form the Preview to the RC however you do want to check that the OS is supported as Windows Server 2012 R2 Preview and Windows 8.1 Preview is not supported by the RC.

    ## Prerequisites – make sure that you have…

    - Passwords for your TF Service & TF Reports accounts
    - Windows Server 2008 R2 or Windows Server 2012 (NOT 2012 R2 or 8.1 Preview)
    - SQL Server 2012 Service Pack 1

    ## Installing TFS 2013 RC when you have TFS 2013 Preview (30 minutes)

    It has been a long time since you had to manually uninstall the old version of TFS to install the new. The installer will take care of all that clean up for you.

    ![image](images/image29-2-2.png "image")  
    { .post-img }
    Figure: Installing Team Foundation Server 2013 RC

    The only reason that the install of the new version takes so long is that it requires two reboots and asks you to do so.

    > It would make sense to ask if reboots are ok at the start of the install and just go for it. Suggestion for Installer Team

    ![image](images/image30-3-3.png "image")  
    { .post-img }
    Figure: Reboot to install the C++ 2013 Runtime

    The first forced reboot is the Microsoft Visual C++ 2013 Runtime. Because we are updating from a preview we will have more reboots than a clean install.

    ![image](images/image31-4-4.png "image")  
    { .post-img }
    Figure: Reboot to install .NET 4.5.1 RC

    The second forced reboot is to get the Microsoft .NET Framework 4.5.1 updated to the RC from the Preview version that you had installed. If you are doing a clean install you will not have to do this one at all..

    ![image](images/image32-5-5.png "image")  
    { .post-img }
    Figure: The Upgrade Wizard will launch automatically

    To be honest this would have taken less time if I was sitting watching the screen, and pinging the server between boots to see when it was back up. As it was I took a leisurely 30 minutes to install Team Foundation Server 2013 RC over the top of the Preview. But that is not us done, this is just the files on disk and dependencies that have been updated. Now comes the real work of upgrading the instance of TFS 2013 Preview to TFS 2013 RC.

    ## Upgrading from the TFS 2013 Preview to TFS 2013 RC (16 Minutes)

    As with the TFS 2013 preview there is really not anything that new in the installer. Things are a little bit slicker and I have noticed a significant drop in failed upgrades, from a few to none. The experience of the team in delivering working software every 3 weeks in 2012 has set the Product Team in good stead to minimise any issues here. I also expect that the shame of TFS 2012 Update 1 and 2 has resulted in a significantly higher quality bar for Done. Suck are the trials of moving a large product group to agility.

    ![image](images/image33-6-6.png "image")  
    { .post-img }
    Figure: make sure that you have a Backup

    Its so important there is a yellow triangle and a checkbox! Make sure, and I mean really sure, that you have a backup of your data. One of the reasons that I always recommend moving to new hardware on an upgrade is that you can always roll back to the old hardware. Makes your back-out plan real simple…

    ![image](images/image34-7-7.png "image")  
    { .post-img }
    Figure: Renter your credentials

    No, the product team don’t store your credentials in reversible encryption. Yes, you will have to enter the passwords again so make sure that you have them, but the username that you used last time will be pre-populated. I tend to try and use the system accounts to negate these issues, but some domain configurations don’t work well with them. Unless you are insane you are likely to be using NTLM. I have no issues with configuring Kerberos but you will need more time and some seriously good AD administrators to get it going.

    ![image](images/image35-8-8.png "image")  
    { .post-img }
    Figure: Do you configure reporting?

    In this environment we do have reporting as it mirrors production. If you don’t configure it now you will have to manfully integrate it later and upgrade the reports yourself. This way the TFS team take the brunt of the configuration.

    ![image](images/image36-9-9.png "image")  
    { .post-img }
    Figure: Select the Reports Server and URL

    Here you can select your Reporting Services Server. This is a multi server (dual tier) environment so our Reporting Services runs on the Application Tier and the SQL Server and Analysis Services run on the Data Tier. If you want to have a friendly URL for Reporting Services then you should add it as a host header to the Reporting Services Configuration tool first for both the Web Services and the Web Site nodes. This will allow the URL’s you specify to appear on the pick lists above.

    ![image](images/image37-10-10.png "image")  
    { .post-img }
    Figure: Select Warehouse to upgrade

    As it takes more than a few hours to create a new warehouse from scratch you can upgrade it. From TFS 2012 onward you should restore the Tfs_Warehouse database as well and the upgrade process will also upgrade the warehouse.

    ![image](images/image38-11-11.png "image")  
    { .post-img }
    Figure: Select the Analysis Services instance

    You can have Analysis Services on it own server but most people go with the standard and documented Dual-Tier architecture. If you are hitting massive performance problems and it looks like Analysis Services is the cause you can break it off to another server later.

    ![image](images/image39-12-12.png "image")  
    { .post-img }
    Figure: The Report Reader Account

    Although you can use the same account as the TFS service account this account really only needs reader access to things. It is best to use an Active Directory account that has no other permissions.

    ![image](images/image40-13-13.png "image")  
    { .post-img }
    Figure: Readiness Checks to validate your configuration

    Gone are the days of TFS 2005 and 2008 where the slightest hiccup would result in a failed and irrecoverable installation. Now the wizard will check everything and anything that it can before giving you the green light to move forward. Maybe it is RAM or maybe it is a reboot required… or maybe…

    ![image](images/image41-14-14.png "image")  
    { .post-img }
    Figure: The installer needs SysAdmin

    Um… can someone make me a SysAdmin?

    Not only does the TFS service account require SysAdmin but all of those people that are registered Team Foundation Console users also require to be SysAdmin. Think of the SQL Server that TFS uses as wholly owned by TFS and it will handle backups and permissions from here on out.

    ![image](images/image42-15-15.png "image")  
    { .post-img }
    Figure: Green light… go … go… go…

    Now that we have all of the readiness checks passed we can really upgrade…

    ![image](images/image43-16-16.png "image")  
    { .post-img }
    Figure: Upgrading the Configuration Database

    The wizard will first upgrade the configuration database and satlight data sets and then tackle the collections asynchronously.

    ![image](images/image44-17-17.png "image")  
    { .post-img }
    Figure: Upgrading the collections

    You may have a number of collections then they will be upgraded asynchronously and there are 92 steps for the Preview to RC. If it gets to 87 and sits there for a while there is nothing to worry about

    ![image](images/image45-18-18.png "image")  
    { .post-img }
    Figure: Green tick… i am happy

    Although the total time end to end was 45 minutes at least some of that time was taken up with looking for passwords and taking screenshots. I would think that if I really tried I could cut 15 minutes of that time, but hey… its done now.

    ![image](images/image46-19-19.png "image")  
    { .post-img }
    Figure: All upgraded to Visual Studio 2013 Team Foundation Server RC

    Second last thing to check is that the admin console shows the correct version. I have of course never seen it not ![Smile](images/wlEmoticon-smile-21-21.png)
    { .post-img }

    ## Conclusion

    If you are on the Preview then it is a no brainer and simple task to go to the RC and if you are on 2010 or 2012 I would recommend that you take a look at \[What's new in Team Foundation Server 2013\] and see what's in there for you.

    ![image](images/image47-20-20.png "image")  
    { .post-img }
    Figure: Primary Team Dashboard in action

    I recommend that you check out this [walkthrough of the ALM features in Team Foundation Server 2013](http://nkdagility.com/video-new-with-visual-studio-2013-manage-portfolio-backlogs-to-understand-the-scope-of-work/). I have never shown users the features of 2013 and not had them immediately upgrade to the Preview. Lets see if I can keep that up with the RC.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-09-upgrading-from-the-tfs-2013-preview-to-tfs-2013-rc\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-09-upgrading-from-the-tfs-2013-preview-to-tfs-2013-rc
- FrontMatter:
    title: Professional Scrum Foundations coming to Glasgow, Scotland in November 2013
    description: Join the Professional Scrum Foundations course in Glasgow this November 2013. Enhance your team's understanding of Scrum and drive agile adoption effectively!
    ResourceId: SO1wlCfiUu4
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10094
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-09-04
    weight: 630
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: professional-scrum-foundations-coming-to-glasgow-scotland-in-november-2013
    aliases:
    - /resources/SO1wlCfiUu4
    aliasesArchive:
    - /blog/professional-scrum-foundations-coming-to-glasgow-scotland-in-november-2013
    - /professional-scrum-foundations-coming-to-glasgow-scotland-in-november-2013
    - /professional-scrum-foundations-coming-to-glasgow,-scotland-in-november-2013
    - /blog/professional-scrum-foundations-coming-to-glasgow,-scotland-in-november-2013
    - /professional-scrum-foundations-coming-to-glasgow--scotland-in-november-2013
    - /blog/professional-scrum-foundations-coming-to-glasgow--scotland-in-november-2013
    - /resources/blog/professional-scrum-foundations-coming-to-glasgow-scotland-in-november-2013
    tags:
    - Software Development
    categories:
    - Scrum
    preview: PSF_Badges-2-2.png
  BodyContent: |
    ![PST-Badge-v2-web-transparent](images/PST-Badge-v2-web-transparent-4-4.png "PST-Badge-v2-web-transparent")For too long has Scotland been ignored in Professional  Scrum Training. I am not sure if there has ever been a Scrum.org course held here as I could not find one and the last time Ken was here was way back in 2004.
    { .post-img }

    ![flag-scotland](images/flag-scotland-1-1.png "flag-scotland")Back in 2009 Ken Schwaber decided to leave the Scrum Alliance and head out on his own to build an organisation that is based on the values that he felt that they had lost. I got involved in early 2010 with the Professional Scrum Developer beta Train-the-Trainer event in Sydney.
    { .post-img }

    The courses from Scrum.org are not just about teaching the mechanics of the Scrum Framework. The standard curriculum used by all Scrum.org trainers drives consistent quality in training, messaging, and coaching. By having a standard library of courseware shared by all trainers, companies can ensure that they are receiving the same high-quality training content from every trainer in every course around the world. And, that course material is collaboratively maintained by all trainers to create a network effect of improvement shared by each and every trainer. This consistent message eliminates confusion that would otherwise impede progress.

    Note If the dates listed below do not suit you or you want to conduct a private course then please [contact us](/contact) today to book your dates.

    ## Professional Scrum Foundations (2 days)

    <iframe width="195" height="489" marginheight="0" src="http://www.eventbrite.com/countdown-widget?eid=7985022417" frameborder="0" allowtransparency="" marginwidth="0" scrolling="no"></iframe>

    For: Stakeholders, Executives, Coders, Testers, Analysis, and anyone else who interacts with the Scrum Team

    [Professional Scrum Foundations](/training/courses/professional-scrum-foundations/)

    Unbeknownst to most the Professional Scrum Foundations course is the answer to “but I don’t want to be a Scrum Master” and “Why would I want 9 Scrum Masters on my team”.  This two day training is perfect for teams adopting agile to get a common and consistent understanding of the framework. My most successful executions of this course include folks from all areas of your business so that everyone understands both what is expected of them and what they should expect from the team under Scrum. Don’t worry you still get a complimentary attempt at the “PSM I” assessment so everyone can get a Scrum Master certification if they wish…

    I have previously run this course in Park City, UT where I had a warehouse supervisor be the biggest dissenter to participation in the first half day. He then went on to be the main proponent and evangelist of the process within the warehouse. That is the power of this course… it is an adoption catalyst that helps everyone get on to the same page.

    If you are looking to create a wide understanding of Scrum within your organisation as a a prelude to full adoption then this is for you.

    ## Professional Scrum Master (2 days)

    ![PSM](images/PSM-400x-3-3.png "PSM")
    { .post-img }

    For: Scrum Masters interested in understanding the advanced techniques of Scrum

    [http://www.scrum.org/Courses/Professional-Scrum-Master](http://www.scrum.org/Courses/Professional-Scrum-Master)

    The Professional Scrum Master course is designed for those few individuals within your teams that are destined to be process overlords. This two day course is a deep dive and discussion on how to best implement Scrum and to anchor the changes within your organisation. You get a complimentary attempt at the “PSM I” and 40% off the “PSM II” assessments.

    If you are experienced at Scrum and are looking to move more towards process coaching then the Scrum Master is for you. It dives into the questions of adoption and many of the strategies to making your path to agility more likely to succeed.

    ## Professional Scrum Developer (3 day)

    [![PSD_Badge](images/PSD_Badge_thumb.png "PSD_Badge")](http://nkdagility.com/wp-content/uploads/2013/09/PSD_Badge.png)
    { .post-img }

    For: Coders, Testers, Analysts, and anyone else working on a Development Team

    [http://www.scrum.org/Courses/Professional-Scrum-Developer](http://www.scrum.org/Courses/Professional-Scrum-Developer)

    The Professional Scrum Developer course is the only official user based training on Microsoft Visual Studio ALM. It comes in both .NET and Java option and is specifically designed to expose your Development Team Members to the Practices and Tools that help you effectively deliver working, high quality software Sprint on Sprint. This course is awesome and you should have a look at the fact sheet above. It is a perfect start for a development team staring Scrum or if your practices have been stalled.

    ## Conclusion

    These courses are awesome and can really help with a Scrum adoption especially early on to help instil the values and principles in your teams. However no amount of training can anchor those values and principles required to achieve true agility and you should look to bring in a coach to help your teams stick to the path. I would expect that the first job of any coach would be to find someone internal to your organisation to mentor into becoming your permanent coach and torchbearer.

    For all your Scrum needs you should head on over to [http://scrum.org](http://scrum.org) and check out the forums and and other offerings.

    If however you are in Europe then you can [find an expert](http://nkdagility.com/company/general-inquiries/) closer to home.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-04-professional-scrum-foundations-coming-to-glasgow-scotland-in-november-2013\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-04-professional-scrum-foundations-coming-to-glasgow-scotland-in-november-2013
- FrontMatter:
    title: 'Review Part 2: Developing with Intel Haswell Harris Beach SDS Ultrabook'
    description: Explore the Intel Haswell Harris Beach SDS Ultrabook in this detailed review. Discover its performance, features, and tips for developers using Windows 8.
    ResourceId: n-WAS50HK1d
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10081
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-09-02
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: review-developing-intel-haswell-harris-beach-sds-ultrabook
    aliases:
    - /resources/n-WAS50HK1d
    aliasesArchive:
    - /blog/review-developing-intel-haswell-harris-beach-sds-ultrabook
    - /review-developing-intel-haswell-harris-beach-sds-ultrabook
    - /review-part-2--developing-with-intel-haswell-harris-beach-sds-ultrabook
    - /blog/review-part-2--developing-with-intel-haswell-harris-beach-sds-ultrabook
    - /resources/blog/review-developing-intel-haswell-harris-beach-sds-ultrabook
    tags:
    - Windows
    categories:
    - Uncategorized
    preview: Web-Intel-Metro-icon-21-21.png
  BodyContent: |
    It has just over a month since I received my Intel Haswell Harris Beach SDS Ultrabook from Intel to review and I have to say that I love this little laptop. I have been trying to use it exclusively and have done pretty well.

    - [Review Part 1: Harris Beach SDS Ultrabook from Intel with Haswell](http://nkdagility.com/review-harris-beach-sds-ultrabook-from-intel-unboxing/)
    - Review Part 2: Developing with Intel Haswell Harris Beach SDS Ultrabook
    - [Review Part 3: Two Months with Intel Haswell Harris Beach SDS Ultrabook](http://nkdagility.com/review-two-months-intel-haswell-harris-beach-sds-ultrabook/)

    There has however been some trouble and strife. This is a Developer Prototype and in my infinite wisdom I decided to go straight to Windows 8.1. This it turns out was a mistake as neither the Drivers not the Bios configuration works well with Windows 8.1. My advice if you are using one of these computers is to avoid 8.1 until the drivers are more mature. I had problems with Sleep, resume as well as touch in a variety of applications. That was however the risk that I took installing a preview version of Windows and I only have myself to blame.

    Now that I am back on Windows 8 everything is good again.

    [![image](images/image_thumb-1-1.png "image")](http://nkdagility.com/wp-content/uploads/2013/09/image-11-11.png)  
    { .post-img }
    Figure: Experience Index is high

    The first thing that you will want to do is download the Windows 8 sample apps. While the Intel ones are good they are all written in C++. When I asked them for .NET versions I got a .NET UI that called a C++ assembly that used the sensors. Not what I was after….

    [![image](images/image_thumb1-2-2.png "image")](http://nkdagility.com/wp-content/uploads/2013/09/image1-12-12.png)  
    { .post-img }
    Figure: Online samples help you get familiar with the capabilities

    If you download the “Full” samples list there are over 270 applications to explore. As I [mentioned in part 1](http://nkdagility.com/review-harris-beach-sds-ultrabook-from-intel-unboxing/) this laptop is all decked out with all of the sensors that you might want to develop Windows 8 or Windows 8.1 apps. I have noticed with this laptop that even with a significant code base this laptop performs very well with Visual Studio 2012 and Visual Studio 2013. The performance is unbelievable and I think owe a lot to the HDD ratting an 8.1; Visual Studio has always been very hard disk intensive with builds, code sense and other cool features that usually take there toll. The laptop eats up all that Visual Studio can throw at it.

    The first thing I wanted to look at was the GPS capability. Now there are not many laptops that have GPS but this one does.

    [![image](images/image_thumb2-3-3.png "image")](http://nkdagility.com/wp-content/uploads/2013/09/image2-13-13.png)  
    { .post-img }
    Figure: Visual Studio runs a dream

    There are many different ways to identify your location and the OS obfuse that a little so that you can use a single API through the Geolocator. Even if you don’t have GPS it will do a little two-step and use Wi-Fi or other methods to get an approximate location.

    [![image](images/image_thumb3-4-4.png "image")](http://nkdagility.com/wp-content/uploads/2013/09/image3-14-14.png)  
    { .post-img }
    Figure: Even developers need to give permission

    When you fire up the demo application you will have to allow,just like any app, the use of the data.

    [![image](images/image_thumb4-5-5.png "image")](http://nkdagility.com/wp-content/uploads/2013/09/image4-15-15.png)  
    { .post-img }
    Figure: Geolocation demo application

    However once you have allowed it you can have live relocation data piped into your application. Although the accuracy here is 100 (I have no idea what the measurement is in, probably 100 meters) I saw it as low as 50 indoors.

    In the sample code you can see the simplicity and ease of attaching to the sensor data, and all of the Windows 8 demo application demonstrate that.

    ```
    private Geolocator _geolocator = null;

    public Scenario1()
    {
        this.InitializeComponent();

        _geolocator = new Geolocator();
    }

    ///
    /// Invoked when this page is about to be displayed in a Frame.
    ///
    ///Event data that describes how this page was reached. The Parameter
    /// property is typically used to configure the page.
    protected override void OnNavigatedTo(NavigationEventArgs e)
    {
        StartTrackingButton.IsEnabled = true;
        StopTrackingButton.IsEnabled = false;
    }

    ///
    /// Invoked immediately before the Page is unloaded and is no longer the current source of a parent Frame.
    ///
    ///
    /// Event data that can be examined by overriding code. The event data is representative
    /// of the navigation that will unload the current Page unless canceled. The
    /// navigation can potentially be canceled by setting e.Cancel to true.
    ///
    protected override void OnNavigatingFrom(NavigatingCancelEventArgs e)
    {
        if (StopTrackingButton.IsEnabled)
        {
            _geolocator.PositionChanged -= new TypedEventHandler(OnPositionChanged);
            _geolocator.StatusChanged -= new TypedEventHandler(OnStatusChanged);
        }

        base.OnNavigatingFrom(e);
    }

    ///
    /// This is the event handler for PositionChanged events.
    ///
    ///
    ///
    async private void OnPositionChanged(Geolocator sender, PositionChangedEventArgs e)
    {
        await Dispatcher.RunAsync(CoreDispatcherPriority.Normal, () =>
        {
            Geoposition pos = e.Position;

            rootPage.NotifyUser("Updated", NotifyType.StatusMessage);

            ScenarioOutput_Latitude.Text = pos.Coordinate.Latitude.ToString();
            ScenarioOutput_Longitude.Text = pos.Coordinate.Longitude.ToString();
            ScenarioOutput_Accuracy.Text = pos.Coordinate.Accuracy.ToString();
        });
    }
    ```

    You can see a simple object, a couple of events and an async process  to update the UI. This is so ridiculously simple even I can figure it out…

    While the Microsoft samples have breadth and show us how to interact with each individual component the Intel samples give us some complete scenarios to look at. There is a simple RTS demo as well as an app that enumerates all of the sensors that are available. Where the Microsoft samples obscure the details the Intel ones revel in them.

    [![image](images/image_thumb5-6-6.png "image")](http://nkdagility.com/wp-content/uploads/2013/09/image5-16-16.png)  
    { .post-img }
    Figure: You will need the DirectX SDK

    To get everything working you will need both the Windows SDK and the DirectX SDK for either Windows 8 or Windows 8.1 respectively. If you have the latest version of Visual Studio 2013 you may hit the ["S1023" error when you install the DirectX SDK (June 2010)](http://support.microsoft.com/kb/2728613/). If you can, then install the DirectX SDK first, otherwise you will have to do some jiggery pokery to get everything working again.

    [![image](images/image_thumb6-7-7.png "image")](http://nkdagility.com/wp-content/uploads/2013/09/image6-17-17.png)  
    { .post-img }
    Figure: Sensor Enumerator

    The first application is a list of all of the sensors. If you wiggle the laptop around you can see the numbers changing. In addition there are a number of cool apps that demonstrate real world uses of the API’s and Sensors.

    [![image](images/image_thumb7-8-8.png "image")](http://nkdagility.com/wp-content/uploads/2013/09/image7-18-18.png)  
    { .post-img }
    Figure: Terrain Editor

    In the Touch folder there is a terrain modification application that lets you paint the landscape with sand.

    [![image](images/image_thumb8-9-9.png "image")](http://nkdagility.com/wp-content/uploads/2013/09/image8-19-19.png)  
    { .post-img }
    Figure: Some kind of Tron cycle application

    The Tron application is pretty cool. It lets you steer the bike by the horizontal orientation of your laptop. Again all of these applications from Intel are in C++ and I find it very difficult to follow the code from an architecture perspective but you can spelunk it yourself.

    [![image](images/image_thumb9-10-10.png "image")](http://nkdagility.com/wp-content/uploads/2013/09/image9-20-20.png)  
    { .post-img }
    Figure: RTS Simulation

    The Real Time Strategy application lets you select units by touching them and then give them orders by tapping on the landscape. We almost always forget the most important and most used sensor of them all… the touch screen.

    ## Conclusion

    I am getting a lot of mileage from this laptop. I basically use it as my main computer except when I need to run VM’s or use the Microphone (I seam to have a driver issue there) wherein I switch to my 8KG Dell that has a terabyte of drive space and 24GB RAM. I have not seen a laptop out there that would let me do what I need in the size and weight that I would like so I carry two. This awesome Haswell kicks ass when it comes to battery. It has been 5 hours since I last charged it and I have been writing this post, surfing the web and running through the demo applications. All the while downloading and installing things. And I still have nearly 40% remaining. While I can’t get a full 8 hour day with one charge I get pretty dam close.

    How far do you get with yours?

    I have basically replaced my Acer Iconia W520 with this laptop and while I would love it to have a detachable screen it is really not an issue. I still use my Iconia but it is on charge in the bathroom.

    If you are a developer working on Window 8 or Windows 8.1 apps then I wholeheartedly recommend this laptop for building them on. If you just need an [Ultrabook](http://www.intel.com/content/www/us/en/ultrabook/shop-ultrabook.html) then make really sure that you get a Haswell processor to get the battery life and I would recommend the hybrids that are also tablets.

    Disclosure of Material Connection: I received one or more of the products or services mentioned above for free in the hope that I would mention it on my blog. Regardless, I only recommend products or services I use personally and believe my readers will enjoy. I am disclosing this in accordance with the Federal Trade Commission’s 16 CFR, Part 255: "[Guides Concerning the Use of Endorsements and Testimonials in Advertising](http://www.access.gpo.gov/nara/cfr/waisidx_03/16cfr255_03.html)."
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-02-review-developing-intel-haswell-harris-beach-sds-ultrabook\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-02-review-developing-intel-haswell-harris-beach-sds-ultrabook
- FrontMatter:
    title: There is no "do agile" there is only "be agile"
    description: Discover why true agility is about being, not just doing. Embrace deep organizational change for lasting value in your agile journey. Learn more!
    ResourceId: QIFsyx_OqLG
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 10058
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-09-01
    weight: 400
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: there-is-no-do-agile-there-is-only-be-agile
    aliases:
    - /resources/QIFsyx_OqLG
    aliasesArchive:
    - /blog/there-is-no-do-agile-there-is-only-be-agile
    - /there-is-no-do-agile-there-is-only-be-agile
    - /there-is-no--do-agile--there-is-only--be-agile-
    - /blog/there-is-no--do-agile--there-is-only--be-agile-
    - /resources/blog/there-is-no-do-agile-there-is-only-be-agile
    tags:
    - Agile Philosophy
    - Agile Transformation
    - Organisational Agility
    - Pragmatic Thinking
    - Software Development
    - Agile Strategy
    - Agile Values and Principles
    - Business Agility
    - Agile Leadership
    categories:
    - Uncategorized
    preview: nakedalm-experts-professional-scrum-1-1.png
  BodyContent: |
    I commented on [Scrum is hard to adopt and disruptive to your organisation](http://nkdagility.com/scrum-is-hard-to-adopt-and-disruptive-to-your-organisation/) before and I think that for most companies this is just beyond their comprehension. They are fundamentally misunderstanding agile and trying to do agile rather than be agile.

    There are no trainings or certifications  or even processes that can provide you with that understanding There is nothing but deep organisational change and hard work that can create that lean-agile way of doing thins that provides many companies with so much value.

    If you want to be agile you will need to embrace:

    > - giving up management command-and-control
    > - going and seeing what the problems are rather than looking at endless reports
    > - encouraging and supporting people to serve as hands-on-master programmers for 15+ years
    > - close engagement between the hands-on developers and customers, without intermediates
    > - managers and architect who are pair-programming coaches
    > - real transparency – of delays, what's wrong each day, …
    > - The candour to say “we don’t know”
    > - stopping sequential lifecycle practices and mind-set
    > - empirical process control
    > - replacing cube farms with team rooms and visual management
    >
    > \-from [Practices for Scaling Lean & Agile Development: Large, Multisite, and Offshore Product Development with Large-Scale Scrum](http://www.amazon.com/gp/product/0321636406/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=0321636406&linkCode=as2&tag=martinhinshe-20)

    I do not believe that is it possible to sell a company agile, they must come to the realisation of what it entails themselves. Oh, you can introduce them to many of the practices and encourage them to experiment. You can teach individuals TDD and other test first methods but all you are doing is priming the pan and creating an environment where that spark of agility can smoulder. Then they will come to you.

    I was recently contacted by a [customer that I have worked with before](http://nkdagility.com/professional-scrum-foundations-in-salt-lake-city-utah/) to help them become more…well.. agile. They feel that they have a good understanding of the mechanics of Scrum and they they are gaining value at the team level, but they want more. They want to realise the greater organisational reality of agility and not just follow the rules.

    In short they want to **Build people, then products**.

    There are a great many thing that we can look at but until I can ‘go see’ how folks are working there is no way I can have any idea of a plan. I can however imply that there are some things that while not constants are good bets to look at and for:

    - **discourage ‘fake agile’** – the first thing to look at is if they really do have just the mechanics down or if they are starting to be agile
    - **encourage ‘Communities of Practice (CoP)’** – Sometimes referred to as **guilds** these **CoP** allow and encourage folks interested in a practice to collaborate regardless of the affinity they have to a particular discipline.
    - **encourage ‘go see’** – Encouraging managers to go to where the work is boing done will be immensely more valuable than looking at reports

    If we can get some amount of time onsite to investigate and work on some of these things then that would make me happy. I am really looking forward to seeing how they have been getting on and how many of the issues we identified in the last engagement have changed.

    Here is looking forward to future collaboration and experimentation.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-01-there-is-no-do-agile-there-is-only-be-agile\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-09-01-there-is-no-do-agile-there-is-only-be-agile
- FrontMatter:
    title: 'Review: The Professional Scrum Masters Handbook'
    description: Explore the insights of 'The Professional Scrum Masters Handbook' with a critical review that highlights key takeaways for new Scrum Masters and Project Managers.
    ResourceId: Truj03gqwvW
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9967
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-08-28
    weight: 790
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: review-the-professional-scrum-masters-handbook
    aliases:
    - /resources/Truj03gqwvW
    aliasesArchive:
    - /blog/review-the-professional-scrum-masters-handbook
    - /review-the-professional-scrum-masters-handbook
    - /review--the-professional-scrum-masters-handbook
    - /blog/review--the-professional-scrum-masters-handbook
    - /resources/blog/review-the-professional-scrum-masters-handbook
    tags:
    - Software Development
    categories:
    - Scrum
    preview: nakedalm-experts-professional-scrum-1-1.png
  BodyContent: |
    I was asked recently to review The Professional Scrum Masters Handbook. As I read this book there were times that I shouted at it and I almost stopped reading in disgust around chapter 4.

    If you were beside me in the gym when I shouted “Noooooo”, “That is the dysfunction”, or “you can’t fix that that way” then I am sorry. If you make it past chapter four however there are some very helpful tips and tricks.

    [![](http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&ASIN=B00CFJGKZS&Format=_SL110_&ID=AsinImage&MarketPlace=US&ServiceVersion=20070822&WS=1&tag=martinhinshe-20)](http://www.amazon.com/gp/product/B00CFJGKZS/ref=as_li_ss_il?ie=UTF8&camp=1789&creative=390957&creativeASIN=B00CFJGKZS&linkCode=as2&tag=martinhinshe-20)
    { .post-img }

    I would however recommend this book for Project Managers that are new to realities and mechanics of the new processes and techniques involved. If you read [What is the role of the Project Manager in Scrum](http://nkdagility.com/what-is-the-roll-of-the-project-manager-in-scrum/), and you decided on Scrum Master then this is an awesome introductory book. The practices described in this book will most definitely help, just watch out for the land mines.  Let me explain…

    At times reading this book I felt that the author has not fully grasped the value and principals of Scrum. She comes across as  more of a mechanic than a process designer. Now don’t get me wrong, this is not a bad thing as mechanics are valuable, but it is something to understand as you follow the stories and anecdotes in the book. It also does not seem that the author has been keeping up with advancements and practice improvements over the last 10 years that have resulted in the upgrades to the Scrum Guide by Ken & Jeff. Every time the author mentions ‘legacy Scrum’ it betrays her woeful lack of knowledge that I believe are required for coaching. As a result it takes an experienced Scrum user and ageist to be able to sift this book for the golden nuggets of information that are in there. without falling fowl of mines it contains.

    That said if you are just starting out on your path to agility and need a few pointers you will find them in The Professional Scrum Masters Handbook.

    Here are a few of my choice anti-patterns from the book:

    - **Is OK to Sprint in Months** – This one hit me right away. On reading it again and again I do not believe that the author intended to have it read that matching your Sprints to the months of the year is a good idea.
      > “I liked the organisation and simplicity of this list \[the backlog\]; note how the product management team divided the backlog into months of work \[\] in a spread sheet. Its easy to group rows under month headings”The Scrum Masters Handbook
    - **Its OK to have to have undone work** – Another no brainer. There is a recommendation that Teams leave a few ‘buffer’ Sprints at the end of the release for… you know… all that undone work they could not get done in the Sprint. I know that the author was talking about planning, but a novice will make assumptions
      > Some teams apply a buffer by leaving empty an entire Sprint or two at the endThe Scrum Masters Handbook
    - **Release Planning is a new thing in Scrum** – Release Planning has always been a strategy to help one execute of delivering software but it has never been and is not a ‘time box’ in Scrum. It may happen at the behest of the Product Owner outside of the Scrum Team but that is as far as it goes.
      > only recently has the Scrum framework been extended to recognise release planning as a bona fide (yet optional) Scrum meeting.The Scrum Masters Handbook
    - **The Scrum Master is responsible for reporting** – I can’t begin to express how wrong this is. The Product Owner is the one responsible for this.
    - **The Release Sprint** – In what twisted Scrum world should there be a release Sprint. I understand that those beginning down their journey may need one from necessity, but it is a dysfunction to be recognised and possible accepted, but always questioned. The Definition of Done should be pushed to ‘no further work required for release’.
    - **There can be multiple Product Owners of one backlog** – There can only be one! Just like highlander there is only one owner that is an individual and not a committee. This allows a decisive vision to be created.
      > The teams themselves should be the product owners of the management Scrum team’s product backlog and attend the sprint reviewsThe Scrum Masters Handbook

    With all of those negatives, that by the way represent only a small subset of the book, I though I would leave you with some of my favourite quotes:

    > It will take a generation to die off before we start to see radical innovation in organisational structure to support agility.The Scrum Masters Handbook

    And the obligatory:

    > Sprints are not clown cars into which the product owner can keep stuffing more and more features.The Scrum Masters Handbook

    Sad but true…

    ## Conclusion

    [![](http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&ASIN=B00CFJGKZS&Format=_SL110_&ID=AsinImage&MarketPlace=US&ServiceVersion=20070822&WS=1&tag=martinhinshe-20)](http://www.amazon.com/gp/product/B00CFJGKZS/ref=as_li_ss_il?ie=UTF8&camp=1789&creative=390957&creativeASIN=B00CFJGKZS&linkCode=as2&tag=martinhinshe-20)
    { .post-img }

    If you are a Project Manager moving to Scrum then this book will help you with the transition to a new way of thinking. Remembering that this is an embodiment of the mechanics and not the principals.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-08-28-review-the-professional-scrum-masters-handbook\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-08-28-review-the-professional-scrum-masters-handbook
- FrontMatter:
    title: The great Team Foundation Server 2013 Upgrade Weekend
    description: Join the Team Foundation Server 2013 Upgrade Weekend on Sept 13-15 for expert support in upgrading and configuring TFS 2013. RSVP now for a smooth transition!
    ResourceId: vBfV--PVVr7
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9989
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-08-27
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: the-great-team-foundation-server-2013-upgrade-weekend
    aliases:
    - /resources/vBfV--PVVr7
    aliasesArchive:
    - /blog/the-great-team-foundation-server-2013-upgrade-weekend
    - /the-great-team-foundation-server-2013-upgrade-weekend
    - /resources/blog/the-great-team-foundation-server-2013-upgrade-weekend
    tags: []
    categories:
    - Uncategorized
  BodyContent: |
    The product team have put some more engineering resources where their mouth is and the great Team Foundation Server 2013 Upgrade Weekend will be on September 13-15.

    [![](images/728x90_VSvNext_Border_EN_US1-1-1.gif)](http://nkdagility.com/vs2013Preview/)
    { .post-img }

    Unless you have been hiding under a rock you will have notices some recent fever over the TFS 2013 Preview. Well as you know that while [Team Foundation Server 2013 is production ready](http://nkdagility.com/team-foundation-server-2013-is-production-ready/) it still has that pesky “Preview” moniker on there. This “Preview” wording has prevented many companies from adopting TFS 2013 immediately, even though it is fully supported. To help resolve some of that resistance and get wider adoption the Product Team has committed some extra engineering resources to not just supporting your TFS 2013 instance, but helping you upgrade as well.

    During the weekend of Friday 13th September until Sunday 15th September there will be Microsoft experts standing by to help you out at no charge with your production upgrade to Team Foundation Server 2013. The will not just be there in case you need help but will be available to assist you with your installation and configuration as well as an upgrade.

    If you don’t want to wait you can [get Visual Studio 2013 Team Foundation Server while its hot](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/) today and start using the features while basing in the full support from Microsoft. However if you want a little more support and help with an upgrade, or a first installation you can take advantage of the [Team Foundation Server 2013 Upgrade Weekend](http://aka.ms/TFSUpgradeWeekend).

    The Upgrade Weekend is an RSVP service so make sure that you sign up early: [http://aka.ms/TFSUpgradeWeekend](http://aka.ms/TFSUpgradeWeekend "http://aka.ms/TFSUpgradeWeekend")

    By registering early you can make sure that Microsoft has the appropriate number of staff engineering and support resources to make your adoption as smooth as possible. Remember you can:

    - [Get TFS 2013 and install it NOW!](http://nkdagility.com/vs2013Preview/ "http://nkdagility.com/vs2013Preview/")
    - [Register for the TFS 2013 Upgrade Weekend](http://aka.ms/TFSUpgradeWeekend "http://aka.ms/TFSUpgradeWeekend")

    Whatever option that you choose you will be happy with the results…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-08-27-the-great-team-foundation-server-2013-upgrade-weekend\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-08-27-the-great-team-foundation-server-2013-upgrade-weekend
- FrontMatter:
    title: The evolution of naked ALM with Pagelines DMS for Wordpress
    description: Discover the evolution of naked ALM with Pagelines DMS for WordPress. Learn how to enhance your site’s customization and functionality effortlessly!
    ResourceId: csMYp4a7yBd
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9964
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-08-27
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: the-evolution-of-naked-alm-with-pagelines-dms-for-wordpress
    aliases:
    - /resources/csMYp4a7yBd
    aliasesArchive:
    - /blog/the-evolution-of-naked-alm-with-pagelines-dms-for-wordpress
    - /the-evolution-of-naked-alm-with-pagelines-dms-for-wordpress
    - /resources/blog/the-evolution-of-naked-alm-with-pagelines-dms-for-wordpress
    tags: []
    categories:
    - Uncategorized
    preview: metro-pagelines-11-11.png
  BodyContent: |
    The evolution of naked ALM with Pagelines DMS for Wordpress is a story of successful change. All you have to do is learn to compromise and aspire to the easy 80%.

    It has been a long time \[since I moved from geeks with blogs to Wordpress\] and I have been supremely happy with the platform. When Live Spaces wrapped up there was good reason that they moved everyone to Wordpress.  When I first moved to Wordpress I was struck by the simplicity of the platform, but if you are a geek like me you will very quickly want more. You will start with the thousands of plugins that already exist and you will switch theme constantly as you try out new looks feels and features. That is until you find [Pagelines](http://pln.so/dy).

    I moved to Pagelines after I notices that Ben Day was using it on [http://benday.com](http://benday.com) and the platform, Pagelines Framework, was amazing. With the [recent changes at home and work](http://nkdagility.com/a-change-for-the-better-4/) some things that I had put off for a while needed to be done.

    1. DONE - [Update brand to reflect new philosophy](http://nkdagility.com/naked-alm-starting-with-why-and-getting-naked/)
    2. IN PROGRESS - Change the site to be more selling me than just the blog
    3. DONE - Move from Wordpress multisite to single site
    4. DONE - Upgrade from Pagelines Framework to Pagelines DMS

    You may have noticed a few of the changes happening over the last 6-8 months that included #1 and come of #2 above and you can read above the reasons behind them in [naked ALM: Starting with why and getting naked](http://nkdagility.com/naked-alm-starting-with-why-and-getting-naked/). #2 is an incremental progression and more changes were completed this week and over the weekend. So if you do stop something strange on the site please let me know so that I can fix it… (why do all of the browsers still insist in rendering things differently)

    ## Move from Wordpress multisite to single site

    Boy did I procrastinate on this one. In the end I just had too many issues with the added complexity that multisites create. Moving is however not a simple thing and is really a migration. Stand up a new site, export your content and then import to the new site.

    - [WordPress WXR File Splitter (RSS XML)](http://www.rangerpretzel.com/content/view/20/1/) – You may need this if your export is big.

    It took me one shot to run through the process as a practice run before I was comfortable. I did however still procrastinate and I had a working import for a good week before I decided to flip the switch…

    ## Pagelines Framework – The old way

    On the old site, even before I [moved to WP-Engine](http://nkdagility.com/the-evolution-of-a-blog-the-race-for-responsiveness-and-even-a-little-support-from-wp-engine/), I have made many small tweaks over the last couple of years. But this is what I ended up with as of last week.

    ![image](images/image-1-1.png "image")  
    { .post-img }
    Figure: naked ALM as of 13th August 2013 with Pagelines Framework

    Like I said this was built up over the last few years and I have lots of customisations. Luckily Pagelines Framework is the king of customisations.

    ![image](images/image1-2-2.png "image")  
    { .post-img }
    Figure: Customising layout and global settings with Pagelines Framework

    With Pagelines Framework there is an administration section added to your Wordpress backend that lets you customise things like the layout and colours to your hearts content without having to edit CSS or PHP (shiver). There is a “custom code” section that allows me to add some custom CSS or JavaScript, but it is optional. I has about 500 lines of CSS in there that just tweaked things on my site. Things like the bullets, fonts and heading sizes that I wanted just so. This was not a thing that I did in an afternoon but neither did I spend days working on it in any one sitting. I just tweaked as I fancied a change or I was stuck on a train…

    ![SNAGHTML6b930e0](images/SNAGHTML6b930e0-12-12.png "SNAGHTML6b930e0")  
    { .post-img }
    Figure: Drag & Drop layout customisation with Pagelines Framework

    The Drag & Drop customisation was awesome. It lets you customise the header and footer above, but also the content area. Just like widgets you can drag a sectio0n from those available to the column on the right. Simple, but way more control than anything out of the box in Wordpress. The Pagelines folks don’t like it when you call it a theme even though that is how you enable it, and you can see why.

    I even created a couple of custom Sections. The adverts that I added to my site use the “ Ads by Lake Quincy Media:” section that I created but the other two were abortions and I never really finished them. These were noting complex, a couple of settings (yes in PHP) and some HTML and CSS. Simples…

    Even with this I was always frustrated with the lack of actual customisation that you could do out-of-the-box and I had over 500 lines of CSS as well as the custom sections. Then Pagelines announced DMS…

    ## Pagelines DMS – The new highness

    Pagelines pushed DMS as a paradigm shift in the way that one can configure your site, and you know what… it is. I can do things that would before have require incredibly fiddly CSS changes if not customisations of the HTML. And that is just yuch!

    I am not saying that I did not do any customisation, just that I had to do a lot less. Let me show you want I ended up with…

    ![image](images/image2-3-3.png "image")  
    { .post-img }
    Figure: naked ALM as of 15th August 2013 with Pagelines DMS

    As you can see I got fairly close very quickly. I have probably spent, all in, about 16 hours on this and that is WAY less than I spent getting my site to look like it did before. I made some compromises and got plenty of new capabilities. I had to raise a few things with the Pagelines Developers, but they are very responsive and fixes I need are in the next version coming down the line.

    ![image](images/image3-4-4.png "image")  
    { .post-img }
    Figure: Customising Pagelines DMS

    [Pagelines DMS](http://pln.so/dy) brings inline editing to Wordpress. Its like a WYSIWYG editor built right into your production site. It supports preview and publish so you can see what you are up to before you go live and is eminently customisable one you get the hang of it. You have to figure out a few things first though.

    it may be a little difficult to see but those little tabs on the left represent a template area. I have this configured for a ‘boxed’ mode so the template areas are not the full width of the screen, but that is just to my taste. Each of those tabs has a Delete, Move, Clone, and a Edit buttons that let you customise each one.You can add sections as contents and you can move them around.

    ![image](images/image4-5-5.png "image")  
    { .post-img }
    Figure: Build in Sections for Pagelines DMS

    If you go to “Add sections | Your Sections” you will find a large list of the built in controls. You get a few more with a “pro” account and most are available as part of the open source project. I would expect more sections to be added over time for Pro account holders.

    ![image](images/image5-6-6.png "image")  
    { .post-img }
    Figure: Drag & Drop in Pagelines DMS

    To get the SimpleNav, for example, onto the page you just drag it from the sections list onto the page and Pagelines will do all of the hard work of where it goes and how it will look once it is there.

    ![image](images/image6-7-7.png "image")  
    { .post-img }
    Figure: Customise MediaBox in Pagelines DMS

    Once you have your Section added you can hit the edit button and customise it how you like. The minimum edit options include the ability to add a custom CSS Class so that you can easily, directly and reusable target a specific area. The MediaBox control allows you to add background and foreground images as well as some text, title and display options. It even includes something called “Viewport Animation” that fades in the content once the page has finished loading. While I am just using the MediaBox for an image you can add video’s as well.

    ![image](images/image7-8-8.png "image")  
    { .post-img }
    Figure: Custom LESS\\CSS with Pagelines DMS

    If you need to add a custom CSS class to get more configuration you can head on over to the Custom LESS\\CSS location and add some customisations or overrides. This gives you a huge amount of flexibility and it not only support pure CSS but also LESS. For those that don’t know what LESS is it is kinda like a programming language for CSS. You get to script your CSS with both variables and If clauses to create a much more sophisticated display.

    ![image](images/image8-9-9.png "image")  
    { .post-img }
    Figure: Section in the Pagelines DMS Store

    If you really can’t get what you want out of the built in Sections you can head to the Store and purchase loads of extras. There are only a few in there just now, but Pagelines DMS was launched less than a month ago. Not only are there Sections but there are Plugins and more importantly Themes. If you want to just buy a look and feel you can.

    ![image](images/image9-10-10.png "image")  
    { .post-img }
    Figure: Save and Apply templates

    You can even create Templates based on how you have configured the pages with all of the settings for the controls. Most controls have both “Global” settings which are templatable and “local” settings which are page specific. This gives you the flexibility to to have one page slightly different without having to work around the defaults.

    ## Conclusion

    With the new Pagelines DMS platform you get some awesome capabilities that makes it ridiculously simple to create and customise each of your pages. Here are my before (Pagelines Framework) and after (Pagelines DMS) shots.

    ![SNAGHTML6bf7c82](images/SNAGHTML6bf7c82-13-13.png "SNAGHTML6bf7c82")
    { .post-img }

    I got really close in just a few days of tinkering and I will pick up the rest as they become important to me. Just looking at these two side by side I prefer the smaller headings and the greater amount of white space on the left of the posts. Simple to fix and by the time you read this it probably will be.

    If you are building a website or blog you will be hard pushed to do better than Wordpress and if you add Pagelines DMS into the mix you enter into a world of whatever you want….

    - [Get Pagelines DMS - Open Source or Pro](http://pln.so/dy "http://pln.so/dy")

    **What blogging platform do you use?**

    **How would you compare it to Pagelines on Wordpress?**
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-08-27-the-evolution-of-naked-alm-with-pagelines-dms-for-wordpress\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-08-27-the-evolution-of-naked-alm-with-pagelines-dms-for-wordpress
- FrontMatter:
    title: 'A change for the better #4 - Homecoming'
    description: Join Martin Hinshelwood on his journey back to Scotland, balancing family life and ALM consulting. Discover insights on agile practices and more!
    ResourceId: yryUrqeINBG
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9951
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-08-19
    weight: 590
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: a-change-for-the-better-4
    aliases:
    - /resources/yryUrqeINBG
    aliasesArchive:
    - /blog/a-change-for-the-better-4
    - /a-change-for-the-better-4
    - /a-change-for-the-better--4
    - /a-change-for-the-better--4---homecoming
    - /blog/a-change-for-the-better--4---homecoming
    - /resources/blog/a-change-for-the-better-4
    tags: []
    categories:
    - Uncategorized
    preview: nakedalm-logo-128-link-4-4.png
  BodyContent: |
    Yet another change for the better as I move in a few months back to Scotland to join my family. My flights are booked.

    As a family we decided not to stay in the USA and while we had financial obligation here we also needed to make sure that the kids got back into the right point in School. In the UK School starts just after 4 years old where as in the USA its 5. As our kids are 4 and 6 now they started in the USA and were already a year behind. My wife and I decided that it would be best to get them into the last school year and so in January I sadly bid farewell to them all and have been relegated to Skype since then…

    ![My Family](images/hinshelwood-family-colage-1-1.png "My Family")  
    { .post-img }
    Figure: Left to right; Kaiden (son), Evangelina (daughter), family vacation in Yosemity, Brothers visit in Washington

    All is however not lost as in just a couple of months (31st October 2013 to be precise) I have a one way ticket back to civilisation and family.

    Other changes for the better:

    - [A change for the better #1 - Merrill Lynch to Aggreko](http://nkdagility.com/a-change-for-the-better-1/)
    - [A change for the better #2 - Aggreko to SSW](http://nkdagility.com/a-change-for-the-better-2/)
    - [A change for the better #3 - SSW to Northwest Cadence](http://nkdagility.com/a-change-for-the-better-3/)

    ## What have I been up to?

    You might be asking yourself what I have been doing in the heathen backwaters of the pacific northwest?

    I have been working for what is arguably the best dedicated ALM Consulting organisation in the world. There are many organisations out there that talk about ALM and maybe have two or three ALM Consultants, but for pure expertise you can’t beat Northwest Cadence.

    [![NWC tagline logo_transparent](images/NWC-tagline-logo_transparent_thumb-5-5.png "NWC tagline logo_transparent")](http://nkdagility.com/wp-content/uploads/2013/08/NWC-tagline-logo_transparent-6-6.png)  
    { .post-img }
    Figure: Northwest Cadence

    I have gotten to work not only for the best ALM Consultancy but with the best ALM Consultants in the world. I have worked with many **customers in government, finance, manufacturing, health and technology** to help them improve their processes and deliver more. There are different challenges of working with companies that have only a few employees to many thousands and I have experience with both, and everything in between.  Not only that but I have written over 200 blog posts in the three years I have been in the USA. No rest for the wicked…

    ## What’s next

    Although most of my customer base has been **US** based with Northwest Cadence I have worked over the years for customers in **UK** and **Australia** and I plan to **bring my experience to bare on the European market** from that September move. Northwest Cadence, and I did not want to be permanently separated so we decided that I will stay in at 25% time. This will be hard, especially the commute for on site work and with the time zone difference but I think we can make it work. For all my existing customers with Northwest Cadence I will still be available to pop out and help them. Those of you that follow this blog will have noticed my name change from [http://blog.hinshelwood.com](http://blog.hinshelwood.com) to [http://nkdagility.com](http://nkdagility.com) and the subsequent branch change from  Visual Studio ALM to naked ALM. These changes were, at least in part, pre-emptive action to the future state of affairs.

    [![metro-logo-banner-linkedin-646x220](images/metro-logo-banner-linkedin-646x220_thumb-2-2.png "metro-logo-banner-linkedin-646x220")](http://nkdagility.com/wp-content/uploads/2013/08/metro-logo-banner-linkedin-646x220-3-3.png)  
    { .post-img }
    Figure: naked ALM Consulting

    So what will I be doing for the other 75% of my time. First I will be spending time with my family to make up for 8 months of absence. I am sure that having me hanging around all that time will start to grate on my wife and to save her sanity I will be looking for consulting work in the UK, Europe, and the rest of the world. I already have a company, “naked ALM Consulting Limited” that is registered in Scotland (Company No. SC451660 if you are interested) and I have already started reaching out the feelers for new business.

    ## Conclusion

    I want to try and find the bulk of my work in Glasgow and the surrounding area but that may not be realistic. I just don’t know how many companies there are in Scotland that have development teams and how many of them are considering changing their practices. Here is the rough gist of the things I will be doing:

    - Agile adoption planning and mentoring
    - Agile practice and technique coaching for Management and Teams
    - Application Lifecycle Management (ALM) practice improvements
    - Install, Migration, Customisation and Adoption of Visual Studio ALM
    - Scrum and Agile Training (Scrum.org)

    As with my continuing work with Northwest Cadence in the USA I will be providing consulting, coaching, and mentoring around lean-agile, Scrum, and Visual Studio ALM in the United Kingdom and Europe.

    **Are you in Scotland? Do you have a need to improve your current practices? Get in touch so that I can start helping you out.**
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-08-19-a-change-for-the-better-4\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-08-19-a-change-for-the-better-4
- FrontMatter:
    title: Integrate reporting and analyses services with Team Foundation Server 2013
    description: Learn how to integrate reporting and analysis services with Team Foundation Server 2013 to enhance your project management and data insights. Get started now!
    ResourceId: nNxCVaaSYOS
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9875
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-08-05
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: integrate-reporting-and-analyses-services-with-team-foundation-server-2013
    aliases:
    - /resources/nNxCVaaSYOS
    aliasesArchive:
    - /blog/integrate-reporting-and-analyses-services-with-team-foundation-server-2013
    - /integrate-reporting-and-analyses-services-with-team-foundation-server-2013
    - /resources/blog/integrate-reporting-and-analyses-services-with-team-foundation-server-2013
    tags:
    - Install and Configuration
    - System Configuration
    - Software Development
    categories:
    - Uncategorized
  BodyContent: |
    Did you skip reporting and now you want to integrate reporting and analyses services with Team Foundation Server 2013?

    Lets assume for a minute that you did not install Reporting Servers or Analysis Services with your install of Team Foundation Server 2013. I often get asked if you can add it later… and the answer is a resounding yes. This might be the same procedure if you want to have Analysis Services and Reporting Services on separate server for performance or if you just choose not to install it or even if you started with TFS Basic.

    ![image](images/image69-18-18.png "image")  
    { .post-img }
    Figure: Creating awesome reports

    There are only a few steps to get this working:

    1. Install SQL Server 2012 Reporting Services and Analysis Services
    2. Configure SQL Server 2012 Reporting Services
    3. Enable reporting and analyses services for your Team Foundation Server
       1. Enable reporting and analyses services at the Team Project Collection
       2. Enable reporting and analyses services for your Team Project Collection

    ## Install SQL Server 2012 Reporting Services and Analysis Services

    The very first thing to do is to create your Analysis Services and Reporting Services instance for you to link into Team Foundation Server 2013. In this case I am adding them both to my existing instance of SQL Server so lets fire up the SQL Server installer.

    ![image](images/image51-1-1.png "image")  
    { .post-img }
    Figure: Add features to an existing implementation

    Once you have mounted the ISO and fired off the installer you should select “Install” and then “New SQL Server stand-alone installation or add features to an existing implementation”. We will get to choose later which one we want to do… As you go through the installer it will check for pre-requisites and other shenanigans. I really do wonder why it makes me click next all of the time on screens with no options. It should only stop and tell me when it can’t proceed.

    ![image](images/image52-2-2.png "image")  
    { .post-img }
    Figure: Select your existing instance

    There is no licence required to use SQL Server Standard with Team Foundation Server but you need to make sure that you are in single or dual server move to take advantage of it. If you scale out to have an Analysis, SharePoint or Reporting farm you will need additional licences for all of the products involved. Here we are choosing to add features to the existing instance specified in the pick-list. There will likely only be one option…

    Note: You also can’t add any other databases to the server or you would also require additional licencing. Keep things clean and by the book and you are free and clear.

    ![image](images/image53-3-3.png "image")  
    { .post-img }
    Figure: Add Analysis and Reporting

    Although you only need to add “Analysis Services” and “Reporting Services – Native” I have gone ahead and also added the “Client Tools Connectivity” as I always have the impression that is it required and I would not want to have to subject myself to the SQL Server installer a third time.

    ![image](images/image54-4-4.png "image")  
    { .post-img }
    Figure: Using the default credentials is recommended

    I would always recommend that you use the default credentials where possible as this minimised customisation and points of failure. When you install application under their default credentials they usually use the machine account in Active Directory. This means that they are automatically granted the correct rights. Did you know that the account that is used for SQL Server required additional privileges in Active Directory to manipulate Service Principal Names (SPN). If it does not have that permission then you could be fumbling around for why something does not work for hours…I know I have before. Default rules…

    ![image](images/image55-5-5.png "image")  
    { .post-img }
    Figure: Add administrator permissions

    For my demo box I am adding all Domain Admins to have administrator permission to Analysis Services by default. This should stop me from being locked out which I have been on occasion.

    ![image](images/image56-6-6.png "image")  
    { .post-img }
    Figure: Reporting Services configuration options

    For some reason I am not able to select “Install and Configure”. I can only assume that this is because I am adding features and not installing afresh, but I have no idea why the restriction is there. Would that the SQL Server team would use the TFS installer. We will need to configure it manually later…

    ![image](images/image57-7-7.png "image")  
    { .post-img }
    Figure: All installed successfully

    Now that we have everything installed we need to pick up the pieces from the deficiencies of the SQL Server installer and configure Reporting Services so that we can use it.

    ## Configure SQL Server 2012 Reporting Services

    Configuring SQL Server 2012 Reporting Services is very strait forward. We need to create the site, the web services and a database to hold the data.

    ![image](images/image58-8-8.png "image")  
    { .post-img }
    Figure: Reporting Services Configuration

    First we need to launch the Reporting Services configuration tool which will have been added to your application links list. Just search for it on your Start page.

    ![image](images/image59-9-9.png "image")  
    { .post-img }
    Figure: Connect to your RS instance

    You need to specify what instance you are configuring. Here ewe are connecting to the local server’s default instance.

    ![image](images/image60-10-10.png "image")  
    { .post-img }
    Figure: Create Web Service

    First select the Web Service URL node on the left and click “Apply”…

    ![image](images/image61-11-11.png "image")  
    { .post-img }
    Figure: Create the Database

    Second click on the ‘Database” node and take all of the defaults. If you have to enter a database name then pick something custom and cryptic… like “ReportingData”.

    ![image](images/image62-12-12.png "image")  
    { .post-img }
    Figure: Configure Website

    And the last thing to do is to select “Report Manager URL” on the left and again click Apply.

    Do you see why I think it is not outside the realm of possibility for the SQL Team to allow auto configuration.

    DONE

    ## Enable reporting and analyses services for your Team Foundation Server

    If all we were doing was installing and configuring Analysis Services and Reporting Services then we would now be done. However we want to have an integrated solution with Team Foundation Server so there eare a few other steps that we need to complete. We need to integrate our new instances into TFS and then enable data services for each of the collections.

    ### Enable reporting and analyses services at the Application Tier

    We need to first tell Team Foundation Server where to store all of that lovely data and reports. So head on over to the Team Foundation Server Administration Console so that we can get started.

    ![image](images/image63-13-13.png "image")  
    { .post-img }
    Figure: Enable and configure Warehouse

    There are 4 things to configure but the first one is a checkbox. Tick the box to “Use Reporting” first and then fill out the details for where you want your data warehouse stored. I would recommend the default of “Tfs_Warehouse”.

    ![image](images/image64-14-14.png "image")  
    { .post-img }
    Figure: Configure Analysis Services

    Now head over to the second tab and enter the database as “Tfs_Analysis” for your analysis services cube. Here you will also want to specify the credentials to be used for the reporting services data sources to connect to. This will add that account to the “TfsDataReader” group.

    ![image](images/image65-15-15.png "image")  
    { .post-img }
    Figure: Configure Reports

    If you fill out the server name, the local server should be already in the pick-list, then you should see the URL’s automatically populated. If you need custom URL’s then you should add them to Reporting Services using the Reporting Services Configuration tools and you will then be able to select them from this drop down list.

    Again enter the credentials that you want to use for reporting, this time TFS will add this to the data sources and the credentials to use.

    ![image](images/image66-16-16.png "image")  
    { .post-img }
    Figure: Rebuild the Warehouse and Cube

    I am fairly sure that a rebuild is automatically kicked off when we configured the setting but just for good measure I hit the “Start Rebuild” button.

    ### Enable reporting and analyses services at the Team Project Collection

    And the last little piece is to enable each of your collections to store data in the reports server. You don’t have to enable every collection but you do have to enable the wans that you want to have data in the cube from.

    ![image](images/image67-17-17.png "image")  
    { .post-img }
    Figure: Enable Collection for Reporting

    This will configure your collection to look for a folder of the name displayed and for a folder for each of the Team Projects under that. Not as versatile as the SharePoint site configuration but enough to get your data  flowing.

    ## Conclusion

    Unfortunately enabling the reporting does not go an add the correct reports to the server. You would need to download the correct reports from the Process Template and import them manually to the location specified above with the addition of the Team Project name. If the power tools for 2013 were available there is a “AddReporting” command line to do this for you.

    Give me a shout if you have any questions or get into trouble…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-08-05-integrate-reporting-and-analyses-services-with-team-foundation-server-2013\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-08-05-integrate-reporting-and-analyses-services-with-team-foundation-server-2013
- FrontMatter:
    title: Searching for self-organisation
    description: Explore the journey to self-organisation in teams. Discover strategies to foster accountability, identity, and high performance for agile success.
    ResourceId: EjoEHTWiJtf
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9741
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-31
    weight: 640
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: searching-for-self-organisation
    aliases:
    - /resources/EjoEHTWiJtf
    aliasesArchive:
    - /blog/searching-for-self-organisation
    - /searching-for-self-organisation
    - /resources/blog/searching-for-self-organisation
    tags:
    - Agile Values and Principles
    - Team Collaboration
    - Team Motivation
    - Social Technologies
    - Self Organisation
    - Organisational Agility
    - Team Performance
    - Agile Philosophy
    - Sociotechnical Systems
    - Organisational Culture
    - Scrum Team
    - Pragmatic Thinking
    categories:
    - Uncategorized
    preview: nakedalm-experts-professional-scrum-1-1.png
  BodyContent: |
    Many companies have started searching for self-organisation. That ideal or nirvana where teams can figure out how to work together effectively with limited or little direction to solve problems.

    Many, including some of my colleagues, believe that this search for self-organisation is ultimately fruitless. While many of our customers don’t initially believe in its existence because they have never seen it my colleagues think it impossible because they see company after company fail to achieve it. This is mostly as companies that call use are not ding so because they are awesome but instead because they see that they have some problem that needs looking into. These companies, while realising the need to change, tend to have an organisational structure and culture that presents an anti-pattern for self organising teams to ever exist. Oh, you will occasionally find small pockets of self-organisation within an organisation but if anyone tries to roll this dynamic out, it is ultimately demonstrated as unworkable due to those anti-patterns and those required traits and patterns are then ground out of people.

    Realism dictates that we need to move slowly towards self-organisation in a way that will build up the self esteem of teams and create an environment for them to thrive. But the organisation also needs to have courage and conviction in order to realise it as the path to agility is a bumpy one and long, depending on how traditional they are to begin with.

    ## Why self-organisation at all?

    If we don’t have self-organisation then don’t we have our least skilled and appropriate individuals (project managers) determining how, when and were any work should be completed. Should we not have the knowledgeable and skilled professionals that we hired to do the job of developing the product decide on the how, when and where?

    If we don’t have self-organisation then how can we hope to hold the Development Team accountable for delivering the work? They can always blame the organiser!

    If we don't have self-organisation then how do we know how much time should we spend on training of new individuals? Do we guess at their current skills or evaluate them with standardised tests that have done so well for our school system? Or should we not rely on their peers to make sure that each team member has the skills and knowledge required to help the Development Team deliver…

    Without self-organisation how do we effectively encourage individuals to work as a team and be responsible for the results?

    ## Encouraging self-organisation

    There are many thing that can impact your ability to get to self-organising teams. Here are a few items to ponder:

    - **Team Accountability** – Moving from Individual accountability for tasks, to collective accountability can improve both the team dynamics and the management of those teams. Peer-pressure within teams and a clear but slight pleasure to deliver can reduce any concerns around collective under performance.
    - **Team Identity** – Although related to accountability, organisations wants to aspire to achieve high-performing teams which is impossible without a team identity. This identity is the same ideal that sports teams strive for and results in a camaraderie that is part of any high-achieving team. Team should be expected to move through [Tuckman's stages of group development](http://en.wikipedia.org/wiki/Tuckman's_stages_of_group_development) (Forming | Storming | Norming | Performing).
    - **Small Teams** – Creating dedicated teams of 6+-3 people will allow you to manage the complexity of the work and the people more effectively. A team should work from a single ordered backlog so that they get good at working together, understanding the backlog, and delivering. You may need multiple teams to work through the backlog at a rate that is acceptable to the customer but you should see significantly better results with many small teams than fewer large teams.
    - **Consistent Teams** – If you are forever inter-changing team member then you will be forever re-forming and never even enter storming let alone getting to performing. If you cant get to performing then high-performing is totally out of reach. Stop thinking in individual allocation to projects and start thinking about team allocation to projects. This will also [help reduce your management overhead](http://nkdagility.com/what-is-the-roll-of-the-project-manager-in-scrum/ "http://nkdagility.com/what-is-the-roll-of-the-project-manager-in-scrum/") and improve your communication by removing layers between the customer and the team.

    Remember that the biggest killer of self-organising teams is a manager who just needs to make sure…

    ## Conclusion

    Without self-organisation, no matter how much we try, all we can ever have is a glorified collection on individuals that think and operate as individuals. Just like with sports teams we want to have those individuals identify as a team, to work together as a team and function as a team. The only way to achieve this is to have them **be a team**. You would not want the coach to swap out players on football game for every match? How effective would that be? So don’t do it to your teams…

    If you get really good at self-organising teams you may find your organisations formula to high-performing teams…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-31-searching-for-self-organisation\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-31-searching-for-self-organisation
- FrontMatter:
    title: Integrate SharePoint 2013 with Team Foundation Server 2013
    description: Learn to seamlessly integrate SharePoint 2013 with Team Foundation Server 2013 for enhanced project management and document handling. Boost your ALM skills!
    ResourceId: LDZObDXc6xV
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9916
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-29
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: integrate-sharepoint-2013-with-team-foundation-server-2013
    aliases:
    - /resources/LDZObDXc6xV
    aliasesArchive:
    - /blog/integrate-sharepoint-2013-with-team-foundation-server-2013
    - /integrate-sharepoint-2013-with-team-foundation-server-2013
    - /resources/blog/integrate-sharepoint-2013-with-team-foundation-server-2013
    tags:
    - Install and Configuration
    - System Configuration
    categories:
    - Uncategorized
  BodyContent: |
    You can integrate SharePoint 2013 with Team Foundation Server 2013 at any time and even link to your corporate SharePoint\*.

    Although I use, install, and configure SharePoint often, I have a saying that I have used in relation to that work with SharePoint and I think it is very relevant now.

    > First you have a problem, you solve it with SharePoint and now you have two problems\-MrHinsh ([tweet this](http://clicktotweet.com/GZUrd))

    While this is only slightly in jest there are some uses that one can put SharePoint to successfully. One of those is to give you dashboards in Team Foundation Server and another is to provide you with somewhere to manage your documents. To be honest I prefer to manage my documents within Version Control but I know that many folks don’t like that as much. And thus we must subject ourselves to SharePoint (sigh)..

    ![image](images/image68-20-20.png "image")
    { .post-img }

    Knowing how to integrate SharePoint 2013 with Team Foundation Server 2013 is a staple of any ALM consultant but I usually do everything that I can to dissuade my customer from installing it. Why you might ask… with the awesome capabilities of SharePoint why oh why would you want to cripple your customers experience. Well, its about support. SharePoint is a high maintenance product that is hard to maintain and administer. If it is running OK you might be fine, but that is no guarantee that something is not festering in there… just waiting for you to get complacent. You need full time support personal that specialise in SharePoint to have any hope of a supported instance; most companies just wing it and hope for the best.

    My local TFS instance does not currently have SharePoint, and I could have really used it in a demo the other day. So I though that I would rectify the situation. I have previously [Integrate SharePoint 2013 with Team Foundation Server 2012](http://nkdagility.com/integrate-sharepoint-2013-with-team-foundation-server-2012/) and [Integrating SharePoint 2010 with Team Foundation Server 2010](http://nkdagility.com/integrate-sharepoint-2010-with-team-foundation-server-2010/). With TFS 2013 in the mix it is time to dust off my SharePoint knowledge (recently [engaged with complexity with SharePoint](http://nkdagility.com/engaging-with-complexity-sharepoint-edition/)) and tackle this one. I really do try to hide my SharePoint knowledge at all costs, but with SharePoint 2013 they are making the product a little better. Not enough to make me admit to understanding SharePoint, but better.

    In my environment I have a single server environment which makes it easy to integrate everything and remove any network issues. I do however run a separate Domain Controller so I have Active Directory on hand. So, what are we going to do, here is a summary:

    1. [Install SQL Server 2012 SP1](http://nkdagility.com/installing-tfs-2012-on-server-2012-with-sql-2012/)
    2. [Install SharePoint Server 2013 Prerequisites](http://www.avivroth.com/2013/07/09/installing-sharepoint-2013-on-windows-server-2012-r2-preview/) (special if you have Server 2012 R2)
    3. [Installing SharePoint Server 2013](http://nkdagility.com/install-sharepoint-2013-on-windows-server-2012-without-a-domain/) (but use a Domain Account and do not create a Site Collection)
    4. Configure Extensions for SharePoint Products
    5. Configure SharePoint Web Applications
    6. Configure SharePoint sites
       1. Configure SharePoint site for a new Team Project
       2. Configure SharePoint site for an existing Team Project

    If you get to [Installing SharePoint Server 2013](http://nkdagility.com/install-sharepoint-2013-on-windows-server-2012-without-a-domain/) and end up with the message that “Windows Server AppFabric is not configured correctly” then you will need to reinstall it following the instructions on [Install SharePoint Server 2013 Prerequisites](http://www.avivroth.com/2013/07/09/installing-sharepoint-2013-on-windows-server-2012-r2-preview/). This is a work around until the SharePoint guys release a fix for the installer.

    Note: If you cant figure out why the AppFabric is not installing from the command line then try running as administrator.

    Once you have completed to step #3 above all we need to do is integrate TFS and SharePoint together. This is not hard but can be a little fiddly.

    ## Configure Extensions for SharePoint Products

    We need to install the extensions for SharePoint products that are part of the TFS 2013 ISO onto all of the SharePoint 2013 front end servers. In this case I only have one and it already has TFS installed so I have everything that I need. You will find the stand alone installer in the root of the TFS ISO under “Extensions for SharePoint” if you need them.

    ![image](images/image32-1-1.png "image")  
    { .post-img }
    Figure: Configure the SharePoint extensions

    If you have an all in one configuration like mine you can just open the Team Foundation Server Administration Console and head to the Extensions for SharePoint Products to configure them. If you are on a SharePoint front end server that does not have TFS installed you will still launch the Team Foundation Server Administration Console but you will not have all of the nodes.

    ![image](images/image33-2-2.png "image")  
    { .post-img }
    Figure: Start the Wizard

    Once you click the link to install the feature you will automatically get sent to the appropriate Wizard node to let you Start the Wizard.

    ![image](images/image34-3-3.png "image")  
    { .post-img }
    Figure: Validate your configuration

    There is really no configuration for the install. You just need to run it through for it to register the bits it needs. At this point it is going to do a bunch of checks and especially for a pending reboot which you can see that I have above… drat… after a reboot I only have the SharePoint warning. This machine is started with 2GB memory but it is set to dynamic. Even if you have 10GB available it will still give you that  warning as SharePoint is a memory hungry beast… you can just ignore the warning.

    note: After an install of SharePoint and without actually using it my memory usage jumped from less than 2GB all the way up to 8-10GB after boot. Minimum for SharePoint Foundation is 10GB and 25GB for a single server running SharePoint proper.

    ![image](images/image35-4-4.png "image")  
    { .post-img }
    Figure: Successful configuration

    All being well you get some beautiful green ticks to let you know that everything is good. Now that we have all of the bits required to install all we need to finalise the SharePoint side is to grant access to a TFS server to where we want it to go in SharePoint.

    ![image](images/image36-5-5.png "image")  
    { .post-img }
    Figure: Enable SharePoint to accept connections

    This allows you, as the SharePoint administrator, to specify only certain sites and paths that the TFS Administrators can connect to. Not only can you specify which TFS Server but also the locations that they can connect to and which Secure Store application definition to use.

    But first click Refresh!

    If you just configured the SharePoint extensions on the TFS Server then it has already decided that since you put SharePoint on the same server as TFS that TFS owns the show. I am good with that…

    ## Configure SharePoint Web Applications

    Now head on over to your Team Foundation Server Administration Console (whatever server it is on) and under the Application Tier node you will see another SharePoint node.

    ![image](images/image37-6-6.png "image")  
    { .post-img }
    Figure: Enable TFS to talk to SharePoint

    This node allows you to configure which SharePoint instances this particular TFS instance can talk to. We need to specify both the application we will be using and the administration url for TFS do do a little orchestration for us. By default, and yes this one was created by default because of the single-server thing, the ‘default location’ is set to “Sites”. I ALWAYS remove this. If you leave it in then TFS will create new site collections for each of your collection. If you remove it you can tell TFS to create sub sites of the root site. Thus your URL for a team project would be [http://caprica/mycollection/myteamproject](http://caprica/mycollection/myteamproject). This is not only cleaner it allows you to create a proper site hierarchy.

    ![image](images/image38-7-7.png "image")  
    { .post-img }
    Figure: Configure the Collections

    Now that we have told TFS about the SharePoint server to talk to we can head on over to our Collection and tell each of them where to store their sites. You can point every collection to the same location, maybe the root, and all Team Project sites would hang of it. This would give you [http://caprica/myteamproject](http://caprica/myteamproject) which may be advantageous. It will err out if you try to create a team project of the same name as that which exists in another collection. I would say that the risk is worth it and there is no risk if you are having only one Team Project per Collection.

    If you do however create a unique path the tool will create a new site on Web Application path. It will be stand alone if you have “Sites” in there or a child of the root if you did not.

    ![image](images/image39-8-8.png "image")  
    { .post-img }
    Figure: Validate the collection site

    Here you can see the child site that has been created.

    Are we there yet?

    ## Configure SharePoint sites

    We have all of out configurations configure and each of our collection had a location that it has been told to create SharePoint portals and link them to the Team Project when it is created. It will however not go and add portals for each of your existing Team Projects. If there were PowerTools for 2013 you could use the “AddTeamProjectPortal” command to create one but for now we need to do it manually.

    ### Configure SharePoint site for a new Team Project

    You will now automatically be asked if you want a SharePoint site to be created as part of the Team Project creation wizard in Visual Studio.

    ![image](images/image40-9-9.png "image")  
    { .post-img }
    Figure: New Team Projects

    It will default to the location that you specified but you can move it to anywhere on the enabled list.

    ### Configure SharePoint site for an existing Team Project

    But what about if we have existing Team Projects? How do we configure the portals without the nice command line tool? Are we hosed? Well no… here is how…

    ![image](images/image41-10-10.png "image")  
    { .post-img }
    Figure: Using the Collection portal

    We have our lovely portal for the Team Project Collection but now we need some Team Project sites.

    ![image](images/image42-11-11.png "image")  
    { .post-img }
    Figure: Create a new Sub site

    If you head on over to the “Site Content” age and create a new subsite we can configure it to be for our Team Project.

    ![image](images/image43-12-12.png "image")  
    { .post-img }
    Figure: Name it the same as the Team Project

    Here I am creating a site using the Team Foundation Server Project Portal site template and really the only things I have to fill out is the name. It does not even have to be the same name as the Team Project, but having it the same will make a little more sense than not. But if you really want to mess with your users heads you could flop names…

    ![image](images/image44-13-13.png "image")  
    { .post-img }
    Figure: Whoa… its blank

    But that's not what I wanted? When you initially create the site it will not be what you were expecting at all. It will be all empty and non-functional. Well first we need t head over to Visual Studio… and then back..

    ![image](images/image45-14-14.png "image")  
    { .post-img }
    Figure: Go to Team Project settings

    In Visual Studio we need to tell the Team Project where to find the site. To do this connect to the Team Project that you want to configure for a SharePoint portal and click the “Settings” hub.

    ![image](images/image46-15-15.png "image")  
    { .post-img }
    Figure: Connect Team Project to SharePoint

    In the settings hub you will see a list of configuration options, the one you want being the “Portal Settings” link. In here we can configure all things portal like. Here we specify that we do indeed want to link to a portal and where that portal is. If you created the SharePoint site at the default location and named it the same as the Team Project then all you will have to do is tick the “Reports and Dashboards” option and click OK to link them up.

    Are we done yet? Nope…

    ![image](images/image47-16-16.png "image")  
    { .post-img }
    Figure: Go to Site Settings

    Head back to your Team Project portal that is now all linked up correctly and head into the “Site Settings”…

    ![image](images/image48-17-17.png "image")  
    { .post-img }
    Figure: Manage site features

    Here we go to “Manage site feature” so that we can add enable the real meat of the integration.

    ![image](images/image49-18-18.png "image")  
    { .post-img }
    Figure: Enable correct features

    Now that's a large list. I have highlighted the only important entries and you will want to select the bottom most option for the Process Template that you created the Team Project with. If you don’t know then here is a rule of thumb:

    - **Product Backlog Items** – Visual Studio Scrum
    - **User Story** – MSF for Agile
    - **Requirement** – MSF for CMMI

    My Team Project was created using the Visual Studio Scrum Process Template so I will be enabling “Scrum Dashboard and Reporting”. The feature will automatically try and enable itself and if you can’t run that level it will fall back up the chain until it finds a working one. I have SharePoint proper but I don’t yet have reporting enabled so I will only get the first option. Once I have increased the available functionality I can come back in and upgrade it.

    ![image](images/image50-19-19.png "image")  
    { .post-img }
    Figure: No longer blank

    Now we have a lovely TFS integrated SharePoint dashboard with first level document integration from Visual Studio.

    Phew… Done…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-29-integrate-sharepoint-2013-with-team-foundation-server-2013\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-29-integrate-sharepoint-2013-with-team-foundation-server-2013
- FrontMatter:
    title: 'Review Part 1: Unboxing the Intel Haswell Harris Beach SDS Ultrabook'
    description: Unbox the Intel Haswell Harris Beach SDS Ultrabook in this detailed review. Discover its features, performance, and why it's a must for developers!
    ResourceId: D-CZSgtpLGe
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9918
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-26
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: unboxing-the-intel-haswell-harris-beach-sds-ultrabook
    aliases:
    - /resources/D-CZSgtpLGe
    aliasesArchive:
    - /blog/unboxing-the-intel-haswell-harris-beach-sds-ultrabook
    - /unboxing-the-intel-haswell-harris-beach-sds-ultrabook
    - /review-part-1--unboxing-the-intel-haswell-harris-beach-sds-ultrabook
    - /blog/review-part-1--unboxing-the-intel-haswell-harris-beach-sds-ultrabook
    - /resources/blog/unboxing-the-intel-haswell-harris-beach-sds-ultrabook
    tags: []
    categories:
    - Uncategorized
    preview: Web-Intel-Metro-icon-4-4.png
  BodyContent: |
    I was contacted just over a week ago and asked if I would like to review the new developer Ultrabook from Intel, a “Harris Beach SDS Ultrabook SDP - PVT2 ISV”. Geek stuff, wohoo… (composure) … Why sure, I would love to review your new device.

    - Review Part 1: Harris Beach SDS Ultrabook from Intel with Haswell
    - [Review Part 2: Developing with Intel Haswell Harris Beach SDS Ultrabook](http://nkdagility.com/review-developing-intel-haswell-harris-beach-sds-ultrabook/)
    - [Review Part 3: Two Months with Intel Haswell Harris Beach SDS Ultrabook](http://nkdagility.com/review-two-months-intel-haswell-harris-beach-sds-ultrabook/)

    This device comes with a [Haswell i5-4350U processor](http://ark.intel.com/products/75033) and lots of sensors and is part of the [Intel Software Development Platform](http://software.intel.com/en-us/windows). This program provides hardware with all of the sensors and components that a developer needs to make sure that they can take advantage of the cooler attributes of their customers hardware. If you are developing a Windows 8 or 8.1 application then this is a must.

    [![Harris Beach SDS Ultrabook Unbox](images/Harris-Beach-SDS-Ultrabook-Unbox-1-1.png "Harris Beach SDS Ultrabook Unbox")](http://youtu.be/msmlRibX2zE)  
    { .post-img }
    Video: Unboxing the Harris Beach SDS Ultrabook

    The machine is very well made and the touch screen is incredibly responsive. While this is only an i5 (5350U) is is one of the new Haswell chipsets and has 4GB of RAM. I run Visual Studio with no problems on my 2GB Atom tablet so I know it will have no issues on here.

    It came with Windows 8 and I immediately upgraded to Windows 8.1. The install was smooth and after I realised that the USB memory stick that came with the machine had some pretty strict and ordered steps to setting up for the first time I even got all of the sensors and other paraphernalia working. As this is a ‘developer platform’ device its not necessarily as simple as those devices that we are used to using that target purely consumers.

    ![image](images/image70-2-2.png "image")  
    { .post-img }
    Figure: Left to right; Dell M6600, Harris Beach SDS Ultrabook, Acer W520

    Even though my Dell M6600 is a powerhouse it is still a consumer device and we expect it to act like one. However this is a very different beast. It pretends, with its slim profile to be some simple consumer device but it has all of the sensors you would expect in a Tablet or Phone. For communication it has a SIM card slot as well as a Near Field Communication (NFC) Device. It has a 5 point touchscreen that does 1920x1080 and some demo applications for working with games.![image](images/image71-3-3.png "image")  
    { .post-img }
    Figure: Bottom to top; Dell M6600, Harris Beach SDS Ultrabook, Acer W520

    So that you can figure out where you are there are GPS, Gyromiter, Acceleriomiter, Inclinomiter, Compass, Orientation, and Ambient Light sensors as well as some demo code for the different ways of accessing and interpreting the sensor data. This is not a development powerhouse but it is [loaded to the gunnels](http://en.wiktionary.org/wiki/to_the_gunnels) with enough gadgets to make even the most hardened geek OD.

    ### Pros

    - **Touchscreen** – The touchscreen is really responsive, much better than my other ones. Not sure how much that has to do with the processor but I am liking it.
    - **Resolution** – At 1920x1080 this screen is awesome. No wanting there.
    - **Smaller than my 18” Dell M6600** – I can’ take an 8kg (17pound) laptop everywhere… although I do try.
    - **Sensors** – Oh my the sensors.
    - **Battery** – I ran for a whole day on one charge of battery! (my M6600 drains in 45 minutes tops.)

    ### Cons

    - **Larger than my Acer W520** – Not only is it larger it is a Ultrabook rather than a Hybrid so no detachable screen.
    - **Fan is a little noisy** – This is not anything like my M6600 but it is noticeable as the machine is so quiet most of the time. It seams to change speed a lot which may be due to firmware. After I got all of the right drivers installed in the right order this happens way less.
    - **Only 4GB  RAM** – I am not sure if it takes more but 4GB is not really enough for me. My main laptop has a ridicules 32GB but I would settle for a minimum of 8GB. However, that said if I am just developing Windows Store apps then it is likely just fine… time will tell.

    It is not going to replace the beast but it is a nice machine to developed Windows 8.1 apps on. Now all I need is ideas….

    Disclosure of Material Connection: I received one or more of the products or services mentioned above for free in the hope that I would mention it on my blog. Regardless, I only recommend products or services I use personally and believe my readers will enjoy. I am disclosing this in accordance with the Federal Trade Commission’s 16 CFR, Part 255: "[Guides Concerning the Use of Endorsements and Testimonials in Advertising](http://www.access.gpo.gov/nara/cfr/waisidx_03/16cfr255_03.html)."
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-26-unboxing-the-intel-haswell-harris-beach-sds-ultrabook\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-26-unboxing-the-intel-haswell-harris-beach-sds-ultrabook
- FrontMatter:
    title: Quality enablement to achieve predictable delivery
    description: Achieve predictable software delivery by establishing quality enablement. Learn key strategies to enhance your development process and reduce bugs.
    ResourceId: Qvzmat4E5NB
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9737
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-24
    weight: 315
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: quality-enablement-to-achieve-predictable-delivery
    aliases:
    - /resources/Qvzmat4E5NB
    aliasesArchive:
    - /blog/quality-enablement-to-achieve-predictable-delivery
    - /quality-enablement-to-achieve-predictable-delivery
    - /resources/blog/quality-enablement-to-achieve-predictable-delivery
    tags:
    - Operational Practices
    - Pragmatic Thinking
    - Product Delivery
    - Software Development
    - Engineering Practices
    - Working Software
    - Value Delivery
    - Continuous Delivery
    - Technical Excellence
    categories:
    - Engineering Excellence
    preview: nakedalm-experts-professional-scrum-2-2.png
  BodyContent: |
    You need quality enablement to achieve predictable delivery for your organisation which takes effort to achieve.

    I do a lot of ALM Assessments for companies and almost every customer that I speak to has unpredictable quality in the software delivery that they receive from their teams. This is not always the Development Teams fault and is often the result of an organisation that is finely tuned to minimise the ability to have a defined and predictable level of quality. In most cases this is due to a lack of a bar that quantifies the minimum things that need to be completed in order for and organisation to understand what i involved in each delivery.

    If you have no bar for delivery and thus no idea what needs to be completed for each thing to be delivered then how can you expect to make accurate (or at least as good as we can get) prediction on when things are going to be delivered? You would effectively have no empirical evidence to rely on for predictability of delivery. In addition, the varied quality level results in more bugs in production, which then puts those individuals’ responsible for adding features under more pressure. If you put developers under pressure they will consistently and increasingly cut quality to meet the same deliverable.

    ![image](images/image11-1-1.png "image")  
    { .post-img }
    Figure: The Iron Triangle

    In addition many product backlogs lack acceptance criteria leaving the Development Team to guess at the basis by which the customer will accept that something is complete. Indeed because if this lack of acceptance criteria backlog items can often be deceptively large which puts the development team under greater pleasure for delivery and thus the cut quality.

    ## Fix quality for improved predictability

    The only way to successfully create predictable software delivery is to fix 3 of the 4 points of the Iron Triangle. In traditional software development quality is the hidden value and if you fix everything else it is Quality that suffers. Quality should be anchored with an explicit definition.

    - **Definition of Done** – Your DoD is the fixed measure or explicit definition of quality for your software development process. It is a short measurable checklist which mirrors shippable that can and is applied to every unit of work delivered. It can be hard to define but without it we don’t know how much work needs to be done in order to ship any backlog item. Apply it at least to the output of the iteration and ideally to every backlog item that you complete.
    - **Acceptance Criteria** – While the DoD is applied equally to every backlog item acceptance criteria only applies to an individual item. All conversations between the Development Team, Product Owner and the Business should be reflected in the acceptance criteria so that things that are discussed are mot missed. This also serves to understand scale and encourages breaking down backlog items into smaller units of work. Once you understand what needs to be done to complete an item, overly large items become transparently obvious.
    - **Automated Builds –** Having automated builds that can measure the quality of your software is paramount to minimising the amount of work that the team needs to do to verify the software and creating automated acceptance tests and unit tests increase the validity of those builds. Ideally you should have an automated test (UI or Unit) for every acceptance criteria that was added to the backlog item.
    - **Automated Deployment** – Having automated deployment will force the team to create working software and allow you to build and maintain something that will minimize the cost of delivery. If the Development Team knows that the business can choose to ship at any time they are then under pressure to maintain that ship-ability and thus quality.

    Doing all of these things will serve to make quality the goal not the lack of it.

    ## Conclusion

    The way that we have traditionally measured our development teams have finely tuned them to fluctuate quality in order to meet aggressive delivery schedules. However this fluctuating quality only serves to reduce our ability to deliver and annoy our customers when they find the resulting bugs.

    The goal is to increase quality not reduce it but first we need to be able to measure that quality and enforce it.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-24-quality-enablement-to-achieve-predictable-delivery\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-24-quality-enablement-to-achieve-predictable-delivery
- FrontMatter:
    title: Team Foundation Server 2013 is production ready
    description: Discover why Team Foundation Server 2013 is production-ready! Learn about its agile journey, major improvements, and why you should upgrade now.
    ResourceId: HxDL5HRMiX4
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9917
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-23
    weight: 390
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: team-foundation-server-2013-is-production-ready
    aliases:
    - /resources/HxDL5HRMiX4
    aliasesArchive:
    - /blog/team-foundation-server-2013-is-production-ready
    - /team-foundation-server-2013-is-production-ready
    - /resources/blog/team-foundation-server-2013-is-production-ready
    tags:
    - Technical Debt
    categories:
    - Uncategorized
  BodyContent: |
    Did you know that Team Foundation Server 2013 is production ready?

    I have already deployed it at two customers with a grand total of zero problems so far. The product team are so confident that they have upgraded their main DevDiv server to 2013.

    [![](images/728x90_VSvNext_Border_EN_US1-1-1.gif)](http://nkdagility.com/vs2013Preview/)
    { .post-img }

    Unfortunately because of the issues around Team Foundation Server 2012 updates #1 and 2 there has been…. resistance to upgrading. To understand why the problems of 2012.1 and 2012.2 are unlikely to affect 2013 you need to look at the history of the TFS team and their path to agility. The TFS  product team, as  part of the 2012 release cycle, moved to 3 week Sprints of working software. It took them less than two years to get there but the journey was really hard. The result has been [http://tfs.visualstudio.com](http://tfs.visualstudio.com) as well as quarterly updates to TFS 2012.

    The first two quarterly updates however suffered from what one might in the agile community affectionately refer to as undone work. This undone work is the result of a team that had not fully embraced agility and struggled to be transparent about the undone work that was the result. This is what happens when teams start down the path. Small teams building small products can usually get away with a little undone work, a few unhappy customers and a quick fix. But what about large teams with enormous code bases, well they kinda sucked at it for a while. This is about how hard it is to change and how bumpy that path to agility can be.

    If you have been following Brian Harrys posts you will see that he has tried to be as transparent as possible about these problems and what they are doing to fix them. When you usually have a 2 year release cycle is is easy, if expensive, to test quality in. Now if you move to a 3 week release cycle you have to build quality in, not just test it in, and if you don’t, or have problems, it will be radically obvious to your customers in the bugs that slip past you…

    > The endgame is very hard to predict, No one knows how much of the iceberg still lies below the water, and therefore how much work remains in the release.Sam Guckenheimer on Technical Debt in [Visual Studio Team Foundation Server 2012: Adopting Agile Software Practices: From Backlog to Continuous Feedback](http://www.amazon.com/gp/product/B00991JRAU/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=B00991JRAU&linkCode=as2&tag=martinhinshe-20)![](http://ir-na.amazon-adsystem.com/e/ir?t=martinhinshe-20&l=as2&o=1&a=B00991JRAU)
    > { .post-img }

    In addition they made some pretty major database changes in 2012.1. That and some automated testing holes that dated back to 2010 caused the team to struggle somewhat under the technical debt that had been built up.

    And the net result? If you are currently running 2012.1 or 2012.2 then you should move immediately to 2012.3. With 2012.3 the TFS team have finally gotten **on top of the undone work** and have **paid back most of the technical debt** that had been run up. With the Team Foundation Server 2013 Preview they have gotten ahead of the curve and have perhaps some of the best integrated ALM features on the market today.

    The latest fully supported version of Team Foundation Server is 2013… [get it now!](http://nkdagility.com/vs2013Preview/)
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-23-team-foundation-server-2013-is-production-ready\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-23-team-foundation-server-2013-is-production-ready
- FrontMatter:
    title: Creating a custom Activity for Team Foundation Build
    description: Learn to create custom activities for Team Foundation Build with this step-by-step guide. Simplify your workflows and enhance your build processes today!
    ResourceId: mgwL4ERT1N3
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9769
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-22
    weight: 790
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: creating-a-custom-activity-for-team-foundation-build
    aliases:
    - /resources/mgwL4ERT1N3
    aliasesArchive:
    - /blog/creating-a-custom-activity-for-team-foundation-build
    - /creating-a-custom-activity-for-team-foundation-build
    - /resources/blog/creating-a-custom-activity-for-team-foundation-build
    tags:
    - Software Development
    - Install and Configuration
    categories:
    - Uncategorized
  BodyContent: |
    You can be creating a custom activity for Team Foundation Build in a few simple steps. There are always advanced steps but this will get you started.

    It is fairly simple to create a custom activity for Team Foundation Server build services. The first thing to do is to create a Class library  and add a reference to “System.Activities.CodeActivity.dll” you will be all set to start creating any build activities that you need. This class library can contain as many activities as you would like to create.

    ![image](images/image20-1-1.png "image")  
    { .post-img }
    Figure: Creating the Activity

    In this example I am creating a custom activity called “NotForProductionActivity” so we need to create a class of the same name. This class should inherit from “CodeActivity” and override the execute method. ultimately you now have a custom activity for Team Build. There are a couple of extra bits like having an assembly attribute called “BuildActivity” that will allow you to specify for Team Foundation Build where this activity is allowed to run. You can use this to force the activity to only run on the agent if you are doing something in code that requires that context. As for the execute method; you can do whatever you can imagine in there.

    ![image](images/image21-2-2.png "image")  
    { .post-img }
    Figure: Design your workflow

    Now that we have our custom attribute we need to be able to add it to a workflow. It is a little weird to do this and to avoid having to GAC and update your assembly on every build you can create an additional class library, I usually call it CustomXaml, to which we add ‘links’ to the xaml files that we want to customise. This will allow you to drag from the toolbar on the left to the Workflow design surface.

    ![image](images/image22-3-3.png "image")  
    { .post-img }
    Figure:Configure your activity

    At the bottom of the Workflow design surface you will see an “Arguments” button that will pop up with a list of scoped “Arguments” that you can use anywhere in your workflow. You can add you own and map the name back to a property that you add to your custom activities. You may want to use the same argument for multiple activities or pass something in from the outside.

    ![image](images/image23-4-4.png "image")  
    { .post-img }
    Figure: Passing in arguments

    Team Foundation Build allows you to present options to the person that is configuring the build or the person that is queuing the build for execution. This allows you to minimise the number of custom builds that you need and thus minimise your maintainance of them.  To pass in arguments from the outside you need to add the argument that you created to the Metadata argument that already exists. This is the thing that tells the UI how to present options to the users.

    ![image](images/image24-5-5.png "image")  
    { .post-img }
    Figure: Runtime setting of arguments

    If you set the visibility of the parameter to allow it to be shown on the Queue a Build form then it can be edited at queue time. Otherwise it can only be edited at build configuration time.

    ## Conclusion

    While there are many complex things that we could go into this is a simple example of how to organise your development environment to make it easy to build and test custom build activities for your build workflows.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-22-creating-a-custom-activity-for-team-foundation-build\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-22-creating-a-custom-activity-for-team-foundation-build
- FrontMatter:
    title: 'Video: New with Visual Studio 2013: Manage portfolio backlogs to understand the scope of work'
    description: Discover how to effectively manage portfolio backlogs in Visual Studio 2013 to enhance your project scope understanding. Watch the video for insights!
    ResourceId: i-oFFVJd0PN
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9718
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-18
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: video-new-with-visual-studio-2013-manage-portfolio-backlogs-to-understand-the-scope-of-work
    aliases:
    - /resources/i-oFFVJd0PN
    aliasesArchive:
    - /blog/video-new-with-visual-studio-2013-manage-portfolio-backlogs-to-understand-the-scope-of-work
    - /video-new-with-visual-studio-2013-manage-portfolio-backlogs-to-understand-the-scope-of-work
    - /video--new-with-visual-studio-2013--manage-portfolio-backlogs-to-understand-the-scope-of-work
    - /blog/video--new-with-visual-studio-2013--manage-portfolio-backlogs-to-understand-the-scope-of-work
    - /resources/blog/video-new-with-visual-studio-2013-manage-portfolio-backlogs-to-understand-the-scope-of-work
    tags: []
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-2-2.png
  BodyContent: |
    New with Visual Studio 2013 is the ability to manage portfolio backlogs to help you understand the scope of work that you have to do.

    In order to organise our work a little better we tend to create something called “Epics” that are representative of things that are too big for any single sprint and may be broken down into smaller items. However these ‘Epics” do not really continue to exist as all we really care about is the leaf nodes. We still need to understand things that are maybe always larger, like Features and Goals.

    [![image](images/2013-Agile-Portfolio-Management-101-play-1-1.png "image")](http://www.screencast.com/t/T6oadOD4AJbh)  
    { .post-img }
    Video: Portfolio Management in Visual Studio 2013

    This video should have given you an introduction to the new Portfolio Management tools. These tools represent only the first taster from Microsoft on what they are doing for Portfolio Management in Visual Studio 2013.

    Don’t forget to [Get Visual Studio 2013 Team Foundation Server while its hot!](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/) The current Preview of Visual Studio 2013 and Team Foundation Server 2013 comes with a go-live licence meaning that it is fully supported in production.

    Go on.. be a kid again…

    _Originally published at Where Technology Meets Teamwork by [Martin Hinshelwood](http://nkdagility.com/about), Senior ALM Consultant. ([source](http://blog.nwcadence.com/video-new-with-visual-studio-2013-manage-project-portfolios-to-understand-the-scope-of-work/))_
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-18-video-new-with-visual-studio-2013-manage-portfolio-backlogs-to-understand-the-scope-of-work\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-18-video-new-with-visual-studio-2013-manage-portfolio-backlogs-to-understand-the-scope-of-work
- FrontMatter:
    title: Modelling Teams in Team Foundation Server 2013
    description: Master Team Foundation Server 2013 with expert insights on modeling teams, managing projects, and optimizing source control for enhanced collaboration.
    ResourceId: Km0aNB0A6C1
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9777
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-16
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: modelling-teams-in-team-foundation-server-2013
    aliases:
    - /resources/Km0aNB0A6C1
    aliasesArchive:
    - /blog/modelling-teams-in-team-foundation-server-2013
    - /modelling-teams-in-team-foundation-server-2013
    - /resources/blog/modelling-teams-in-team-foundation-server-2013
    tags:
    - Software Development
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-6-6.png
  BodyContent: |
    Do you know what to do with Areas, Iteration, Teams, Source Control, and Security when modelling Teams in Team Foundation Server 2013?

    There are a number of things that we need to take into consideration when modelling Teams in Team Foundation Server 2013 and enabling a method of work that supports all of our activities. Lets say that I have a single core product that is then further customised for many customers.  In this circumstance, I have a number of Projects that are run against a single Customer that may have one or more teams. Each of these Projects exists on a single branch off of the Production branch for that customer and all work on that Project is completed against that branch.

    ## Assumptions & Constraints

    I want to detail some of the constraints and then the solutions within Team Foundation Server. Remember that TFS is not purely a source control system and has many moving gears that all need to slot into place to get access to the power that it provides. That power is represented in the relationships between the components that is reflected in the data and reporting that is made available.

    - **Project -** Body of work completed in a single Branch for a single customer.
    - **Team** - Group of individuals that completes work
    - **Team Member** - An individual that works full or part time against one or more projects.

    ## Solution for Teams

    Teams here will be used as both containers for individuals (leaf nodes) and to roll-up the work for reporting and management purposes. We may want to order work, plan and report for the entire boxy of work, for a single Customer, a single Team or even a single Team irrespective of Customer. It just depends on how complicated that our organisational structure is.

    ![image](images/image25-1-1.png "image")  
    { .post-img }
    Figure: Team structure when modelling teams

    Here we have for example an “Alfa Team” entity that provides a container for planning with a Backlog, Sprint Backlog, Capacity Planning and Boards. This allows a Team to focus on the work that has been assigned to them more effectively. In addition a Team is a security group that can be used to secure any area within the bounds of Team Foundation Server. If we want to work outside the bounds of Team Foundation Server then we can make an Active Directory group that also represents that entity.

    ![image](images/image30-4-4.png "image")  
    { .post-img }
    Figure: Role-up backlogs for modelling teams

    In this example I have created roll-up Teams that aggregate both content and functionality  so that someone can maintain and manage the “Customer 1” backlog above. That “Customer 1” backlog will show work from both “Alfa Team”, “Beta Team”, and the “Continuing Engineering” Team that exist under Customer 1 only. The owner of “Customer 1” will then be able to prioritise the work irrespective of Team and have that order reflected in each of the teams individual backlogs. You can see that I have added both the customer and team to the PBI title but this is only for illustrative purposes.

    ## Solution for Source Control

    Although there is no requirement for your source control model to mirror your Area hierarchy it does make things a little easier to understand and to work with.

    ![image](images/image27-2-2.png "image")  
    { .post-img }
    Figure: Simple source control layout

    The layout above reflects the needs of the organisation as well as the facilities in TFS. TFS secures folders in the same way that Windows folder permissions work and you can change the settings at any level.

    ![image](images/image31-5-5.png "image")  
    { .post-img }
    Figure: Remove Contributor

    The first step is to remove Contributor permissions as we are going to give explicit access for each Team to the appropriate Project and thus give them implicit permission to the Source Code under that project. If you go to the web administration section of TFS you can use the Version Control tab to set security permission on the Source Control components. Here we are selecting the root, Contributors and then setting all permissions to “not set” at this level.

    ![SNAGHTML40c31](images/SNAGHTML40c31-7-7.png "SNAGHTML40c31")  
    { .post-img }
    Figure: Giving Teams access to Folders

    If you then select the individual Branch folder you can then give explicit contributor permission \[Check in, Check out, Label, Lock, Merge, and Read\] for a specific Team. In this case it is the “Alfa Team” that we are adding that will give them access and no other teams.

    ## Solution for Areas

    Areas are used in TFS to compartmentalise work items and is used by Teams to identify what bodies of work are shown on their dashboards. A Team will own one or more areas and may or may not show sub items. This is how we can create hierarchical Teams from a flat list.

    ![image](images/image29-3-3.png "image")  
    { .post-img }
    Figure: Teams under Projects

    We may need to represent both work by multiple Teams under a single Project and a single Team under multiple Projects. This allows us to get versatility of reporting and ease of use for the individuals doing work. To achieve that we may have multiple Area paths that represent the same Team but in a different context.

    ## Automation

    All of the configuration necessary for all of the above can be automated and there are only a finite number of actions:

    - Create Customer \[Create SC folder, create customer team, create area & iteration paths\]
    - Create Project (AKA Branch) \[Create Branch, Create area and iteration path, (optional) create team, _create builds_\]
    - Create Team \[Create team, create ad group\]
    - Add Team to Project \[Create area path, add path to team, Add permission to SC, add permission to area\]
    - Add usergroup to Team \[integrate with AD\]

    Each of these actions has a number of identified steps and all steps can be orchestrated using PowerShell. I plan on creating a bunch of PowerShell’s for this as customers demand but for now these actions can be completed manually.

    ## Conclusion

    Creating structure in Team Foundation Server 2013 that model not only your organisation but your ideal structure within your organisation is what makes Team Foundation Server my preferred tool for Application Lifecycle Management. These are things that I have been doing in TFS since TFS 205 but now the product team have added features that directly provide those capabilities.

    Are you getting the most our of your Team Foundation Server deployment?
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-16-modelling-teams-in-team-foundation-server-2013\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-16-modelling-teams-in-team-foundation-server-2013
- FrontMatter:
    title: Issue [ TFS 2013 ] You need elevated privileges to install InRelease
    description: Discover how to resolve the 'elevated privileges' error when installing InRelease 3 on TFS 2013. Follow our step-by-step guide for a smooth installation!
    ResourceId: 8WoqmaS6v99
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9753
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-11
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: issue-tfs-2013-you-need-elevated-privileges-to-install-inrelease
    aliases:
    - /resources/8WoqmaS6v99
    - /resources/blog/issue-tfs-2013-you-need-elevated-privileges-to-install-inrelease
    aliasesArchive:
    - /blog/issue-tfs-2013-you-need-elevated-privileges-to-install-inrelease
    - /issue-tfs-2013-you-need-elevated-privileges-to-install-inrelease
    - /issue-[-tfs-2013-]-you-need-elevated-privileges-to-install-inrelease
    - /blog/issue-[-tfs-2013-]-you-need-elevated-privileges-to-install-inrelease
    - /resources/blog/issue-tfs-2013-you-need-elevated-privileges-to-install-inrelease
    tags:
    - Troubleshooting
    - Install and Configuration
    - Windows
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-3-3.png
  BodyContent: |
    Installing InRelease 3 fails as you need elevated privileges to install InRelease

    When you try to install InRelease as part of your Team Foundation Server 2013 infrastructure you are allowed to fill out all of the fields and then you get a “you need elevated privileges to perform this installation. You can achieve this by running a command prompt”.

    [![image[14]](images/image14_thumb-1-1.png "image[14]")](http://nkdagility.com/files/2013/07/image14.png)  
    { .post-img }
    Figure: For InRelease you need elevated privileges to perform this installation

    ## Applies to

    - InRelease 3
    - Team Foundation Server 2013

    ## Findings

    I don’t know how this got past the testers but even though you are asked to elevate the privileges during the installation the installation will fail with the message that “you need elevated privileges to perform this installation”. It looks like this was built with user account control turned off! Never a good idea…

    In order to bypass this you have two options. You can follow the instructions that are presented, open an elevated command prompt and then execute the MSI installer from there using the msiexec command.

    ## Solution

    Forts we need to open a command prompt

    ![image](images/image15-2-2.png "image")  
    { .post-img }
    Figure: Execute MSIEXEC from an elevated command prompt

    Once you have the command prompt open you need to execute the following command replacing your location to the MSI. You may want to put it in C:temp to make things easyer but I just copied the UNC path from a file explorer window.

    ```
    msiexec -i "\dahakd$DataDownloads_SoftwareVisual StudioVisual Studio 2013 Preview (NDA)InCycleInRelease_Preview.msi"

    ```

    Now that I have the installer running entirely elevated I can install with no problems…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-11-issue-tfs-2013-you-need-elevated-privileges-to-install-inrelease\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-11-issue-tfs-2013-you-need-elevated-privileges-to-install-inrelease
- FrontMatter:
    title: Issue [ TFS 2013 ] You get TF400324 when connecting InRelease to TFS
    description: Resolve the TF400324 error when connecting InRelease to TFS 2013 with effective solutions and PowerShell scripts. Get your TFS running smoothly!
    ResourceId: mpyXOBzFWc3
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9749
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-11
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: issue-tfs-2013-inrelease-you-get-tf400324-when-connecting-inrelease-to-tfs
    aliases:
    - /resources/mpyXOBzFWc3
    - /resources/blog/issue-tfs-2013-you-get-tf400324-when-connecting-inrelease-to-tfs
    aliasesArchive:
    - /blog/issue-tfs-2013-inrelease-you-get-tf400324-when-connecting-inrelease-to-tfs
    - /issue-tfs-2013-inrelease-you-get-tf400324-when-connecting-inrelease-to-tfs
    - /issue-[-tfs-2013-]-you-get-tf400324-when-connecting-inrelease-to-tfs
    - /blog/issue-[-tfs-2013-]-you-get-tf400324-when-connecting-inrelease-to-tfs
    - /resources/blog/issue-tfs-2013-inrelease-you-get-tf400324-when-connecting-inrelease-to-tfs
    - /resources/blog/issue-tfs-2013-you-get-tf400324-when-connecting-inrelease-to-tfs
    tags:
    - Software Development
    - Troubleshooting
    - Install and Configuration
    - System Configuration
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-3-3.png
  BodyContent: |
    If you follow the documentation for the new InRelease 3 for Team Foundation Server 2013 “TF400324: Team Foundation Services are not available from server” with a remote server error of 404.

    - Update 2013-07-12 Removed Solution #1 as it causes more problems down the line
    - Update 2013-07-12 Added Solution #2 from InCycle but DO NOT do what their documentation suggests or you might end up with an unstable TFS Server.
    - Update 2013-07-12 Added Solution #3 which solves the problem in a supported manor with the TFS API.

    ![image](images/image12-1-1.png "image")  
    { .post-img }
    Figure: TF400324: Team Foundation Services are not available from server

    ## Applies to

    - InRelease 3
    - Team Foundation Server 2013

    ## Findings

    This looks  to be a mistake in the documentation for the product. When they say “Enter the URL for the TFS Server” you think that you should enter [http://caprica:8080/tfs](http://caprica:8080/tfs) when in fact you should be entering the full path to the collection that you want to connect to.

    ## Solution #1

    You need to enter [http://caprica:8080/tfs/\[collection](http://caprica:8080/tfs/[collection)\] which you can get by copying it from the web access.

    ![image](images/image13-2-2.png "image")  
    { .post-img }
    Figure: Use the full collection URL instead of the server

    Now when you connect with [http://caprica:8080/tfs/tfs01-scrum/](http://caprica:8080/tfs/tfs01-scrum/) you should not get a 404 any more…

    ## Solution #2 - Call Support

    _Warning Never update the database without explicit instructions from a member of the product team. You will likely end up with an unsupported instance if you much with the database._

    At this time there is no solution for this. The solution provided on the InCycle page listed below will work but it will leave your TFS server in an unsupported state and may result in instabilities in your TFS instance down the road.

    - [Connection to TFS does not work with the error message: The request failed with HTTP status 404: Not Found](http://support.inreleasesoftware.com/entries/24792942)

    Raise a ticket with MSFT customer services and get your server into a supported state…

    ## Solution #3 - Use PowerShell to update the TFS registery

    I knew that if I worked at this long enough that I would find a solution that does not require that you edit the database. Here is a handy dandy PowerShell script that you can save as Set-DefaultCollection.ps1, double click to copy, and then execute.

    ```
     Param(
           [string] $tfscollection
           )
    Add-Type -AssemblyName "Microsoft.TeamFoundation.Client, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a"
    Add-Type -AssemblyName "Microsoft.TeamFoundation.Common, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a"
    Add-Type -AssemblyName "Microsoft.TeamFoundation, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a"
    if ($tfscollection)
    {
        #if collection is passed then use it and select all projects
        $tfs = [Microsoft.TeamFoundation.Client.TfsTeamProjectCollectionFactory]::GetTeamProjectCollection($CollectionUrlParam)
        $project = $(Read-Host -prompt "Project")
    }
    else
    {
        #if no collection specified, open project picker to select it via gui
        $picker = New-Object Microsoft.TeamFoundation.Client.TeamProjectPicker([Microsoft.TeamFoundation.Client.TeamProjectPickerMode]::NoProject, $false)
        $dialogResult = $picker.ShowDialog()
        if ($dialogResult -ne "OK")
        {
            exit
        }
        $tfs = $picker.SelectedTeamProjectCollection
    }
    try
    {
        $tfs.EnsureAuthenticated()
    }
    catch
    {
        Write-Error "Error occurred trying to connect to project collection: $_ "
        exit 1
    }
    $regsvc = $tfs.ConfigurationServer.GetService("Microsoft.TeamFoundation.Framework.Client.ITeamFoundationRegistry");
    Write-Host "Setting DefaultCollection to $($tfs.InstanceId)($($tfs.Name)) on $($tfs.ConfigurationServer.Uri)" -ForegroundColor Yellow
    $regsvc.SetValue("/Configuration/DefaultCollection", $tfs.InstanceId)
    ```

    This PowerShell will first ask you to select the collection that you would like to be the default and then apply that to TFS. You should then be able to connect InRelease correctly to TFS.

    I still think that this is a silly requirement of the product and at the very least it should ask which collection that you want to be the default and set it for you...
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-11-issue-tfs-2013-inrelease-you-get-tf400324-when-connecting-inrelease-to-tfs\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-11-issue-tfs-2013-inrelease-you-get-tf400324-when-connecting-inrelease-to-tfs
- FrontMatter:
    title: Issue [ TFS 2013 ] InRelease account requires make requests on behalf of others
    description: Resolve the TFS 2013 InRelease error requiring 'make requests on behalf of others' with our step-by-step guide to configure permissions effectively.
    ResourceId: SYCGxfoMPjw
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9759
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-11
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: issue-tfs-2013-inrelease-account-requires-make-requests-on-behalf-of-others
    aliases:
    - /resources/SYCGxfoMPjw
    - /resources/blog/issue-tfs-2013-inrelease-account-requires-make-requests-on-behalf-of-others
    aliasesArchive:
    - /blog/issue-tfs-2013-inrelease-account-requires-make-requests-on-behalf-of-others
    - /issue-tfs-2013-inrelease-account-requires-make-requests-on-behalf-of-others
    - /issue-[-tfs-2013-]-inrelease-account-requires-make-requests-on-behalf-of-others
    - /blog/issue-[-tfs-2013-]-inrelease-account-requires-make-requests-on-behalf-of-others
    - /resources/blog/issue-tfs-2013-inrelease-account-requires-make-requests-on-behalf-of-others
    tags:
    - Troubleshooting
    - Install and Configuration
    - Software Development
    - System Configuration
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-5-5.png
  BodyContent: |
    When you try to configure InRelease to connect to your Team Foundation Server 2013 Team Project Collection you get an error message saying that you are unable to connect because you need to be able to requires make requests on behalf of others.

    ![image](images/image16-1-1.png "image")  
    { .post-img }
    Figure: Unable to connect to Team Foundation Server

    If you check the event log you get:

    ```
    Timestamp: 7/11/2013 10:09:16 AM
    Message: Unable to connect to this Team Foundation Server: http://caprica:8080/tfs/Tfs01-Scrum/.

    Possible reasons for failure include:
    - The name, port number, or protocol for the Team Foundation Server is incorrect.
    - The Team Foundation Server is offline.
    - The password has expired or is incorrect.

    Technical information (for administrator):
    Access Denied: Martin Hinshelwood needs the following permission(s) to perform this action: Make requests on behalf of others.
    Category: General
    Priority: -1
    EventId: 0
    Severity: Error
    Title:
    Machine: CAPRICA
    Application Domain: InCycle.InRelease.Console.exe
    Process Id: 1468
    Process Name: C:Program Files (x86)InCycle SoftwareInReleasebinInCycle.InRelease.Console.exe
    Win32 Thread Id: 5904
    Thread Name:
    Extended Properties:
    ```

    ## Applies to

    - InRelease 3
    - Team Foundation Server 2013

    ## Findings

    Just like the TFS Integration Platform if you have a service that requires the “Make requests on behalf of others” then the accounts that it runs under need to be part of the “Team Foundation Service Accounts” group on the Collection. I would think that

    ![image](images/image17-2-2.png "image")  
    { .post-img }
    Figure: You can’t edit Team Foundation Service Accounts Group

    Unfortunately this group is not editable in the UI as a security precaution and in keeping with TFS tradition those things are relegated to the command line so that it scares off those for whom its not really that important.

    Now while in a real server you should have a service account my TFS Server runs under network service and you can’t pick network service in InRelease.

    ## Solution

    Whatever account that you want to run InRelease under you need to add it to the Team Foundation Service accounts group to get the “make requests on behalf of others” capability.

    ![image](images/image18-3-3.png "image")  
    { .post-img }
    Figure: Add permission with TFSSercurity command

    ```
    tfssecurity /g+ "Team Foundation Service Accounts" n:nakedalmTfInRelease ALLOW /server:http://caprica:8080/tfs
    ```

    When you execute the command TFS will go off and add the account to the group. You could do this per collection, but I am just giving it access to every collection on the server.

    ![image](images/image19-4-4.png "image")  
    { .post-img }
    Figure: Green tick for account that now has make requests on behalf of others

    I could have given explicit permission to that account or even created a special group with just that permission but this is the recommended option to solving the problem.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-11-issue-tfs-2013-inrelease-account-requires-make-requests-on-behalf-of-others\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-11-issue-tfs-2013-inrelease-account-requires-make-requests-on-behalf-of-others
- FrontMatter:
    title: Does your company culture resemble Survivor?
    description: Is your company culture a 'Survivor' game? Discover how fostering collaboration can enhance agility and team success in your organization.
    ResourceId: 1VbvpOX1Hg0
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9716
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-10
    weight: 430
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: does-your-company-culture-resemble-survivor
    aliases:
    - /resources/1VbvpOX1Hg0
    aliasesArchive:
    - /blog/does-your-company-culture-resemble-survivor
    - /does-your-company-culture-resemble-survivor
    - /does-your-company-culture-resemble-survivor-
    - /blog/does-your-company-culture-resemble-survivor-
    - /resources/blog/does-your-company-culture-resemble-survivor
    tags:
    - Team Collaboration
    - Sociotechnical Systems
    - Organisational Culture
    - Team Performance
    - Business Agility
    - Organisational Agility
    - Social Technologies
    - Team Motivation
    - Agile Philosophy
    - Pragmatic Thinking
    - Software Development
    categories:
    - Uncategorized
    preview: nakedalm-experts-professional-scrum-1-1.png
  BodyContent: |
    Does your company culture resemble Survivor? Do you have a culture in your organisation where individuals that help others are considered slackers for not getting their own assignments complete?

    If you are trying to achieve agility it is imperative that your team members work together to solve problems. I am not saying that you have to do pair programming but you have to have a culture where collaboration and working together is the norm. This is one of the two main roadblocks to agility ( the other one being requirements management) that companies hit time and time again early in their agile adoptions.

    ![](images/survivor-logo-2-2.jpg)
    { .post-img }

    Changing this part of your culture is something that has much wider implications than just improving your teams ability to deliver value. It is a harbinger of changes to come and if you can change this one thing, you will be more able, and committed, to making more changes to your culture going forward. The goal is to have a culture of change where each of your teams are running small low risk experiments in processes, practices and tools every iteration. It is the catalyst to wider company adoption and buy-in and it requires a certain amount of courage and discipline to achieve.

    - [Release planning and predictable delivery](http://nkdagility.com/release-planning-and-predictable-delivery/)

    As with most impediments to the path to agility this is an issue of culture. To change culture you need commitment and courage not just from those at the coal face but from executive leadership on down. If you are trying to adopt agility from the bottom up you will have limited success and ultimately you are doomed to failure.

    The problem is in how individuals see their work and treat the work done by others. Over many years the US, and in some industries the UK, have moved towards the Survivor model. This is where each individual is measured and encouraged to look out only for themselves. They work in an isolated bubble where they are force fed activities and they are solely responsible for activities in their queue and those individuals are often stack ranked each year. This process only services to isolate not just individual but also their skills and their knowledge.

    Ask yourself this: If you won the lottery and never returned to the office what would be the impact?

    ## You need to foster unit mentality

    If you have see the Mel Gibson movie “We were soldiers” there is a really memorable phrase that has value in the software space. “Learn the job of the man above you, and the man below you”. Software development is a collaborative effort of a Unit (Development Team) working together to achieve a goal. We need to understand each others knowledge, skills and even quirks in order to be effective.

    It is critical to instill a sense of Team and not Individual within your organisation. If you are going to get anywhere on the path to agility you need to let go of the matrix. You need to realise that allowing team members to work on more than one project at a time only creates the illusion that there is more work underway. The reality is simple…individuals that switch between projects lose at least 20% of their time per project that you add.

    ## The loss of the 100% worker

    There is even a greater loss of not working in dedicated Teams; you lose most of your peoples individual ability to solve problems. Software development is all about problem solving, its about puzzles and developers excel at solving them. Remember that software development it is always product development. However if you give your Development Team members the wrong puzzles you will not be utilising them for the thing that you actually employed them for…solving the puzzles.

    Its the background processing power of a developers subconscious that you can utilise to solve the most complicated of problems. Developers will figure things out in the bath, or while playing with the kids or driving home from work. Unfortunately if you give a developer many projects to work on and they have to switch often ( you know… to show progress on many things at once) then what is the greatest problem in their world? You should have guessed it by now: its the problem of juggling their workload. So the problem that their subconscious is trying to solve is how to juggle that work more effectively.

    This has the effect of stretching the amount of time that each thing takes as it takes many more cycles for the developer to figure out the problems and thus your software takes many more months to deliver than it should.

    ## Conclusion

    Don’t have a company culture that resembles Survivor and instead opt for one of Teams. These Teams will be a force multiplier to your ability to deliver software and this will give you a competitive advantage. Don’t wait until your competition figure this out!
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-10-does-your-company-culture-resemble-survivor\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-10-does-your-company-culture-resemble-survivor
- FrontMatter:
    title: Issue [ TFS 2013 ] TF50309 when configuring features in Team Foundation Server 2013
    description: Resolve the TF50309 error in TFS 2013 with expert solutions. Learn how to manage permissions and configure features effectively for your projects.
    ResourceId: JV3MFcDY50C
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9724
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-08
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: issue-tfs-2013-tf50309-when-configuring-features-in-team-foundation-server-2013
    aliases:
    - /resources/JV3MFcDY50C
    - /resources/blog/issue-tfs-2013-tf50309-when-configuring-features-in-team-foundation-server-2013
    aliasesArchive:
    - /blog/issue-tfs-2013-tf50309-when-configuring-features-in-team-foundation-server-2013
    - /issue-tfs-2013-tf50309-when-configuring-features-in-team-foundation-server-2013/
    - /issue-tfs-2013-tf50309-when-configuring-features-in-team-foundation-server-2013
    - /issue-[-tfs-2013-]-tf50309-when-configuring-features-in-team-foundation-server-2013
    - /blog/issue-[-tfs-2013-]-tf50309-when-configuring-features-in-team-foundation-server-2013
    - /resources/blog/issue-tfs-2013-tf50309-when-configuring-features-in-team-foundation-server-2013
    tags:
    - Troubleshooting
    - Install and Configuration
    - System Configuration
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-5-5.png
  BodyContent: |
    You may get a TF50309 when [configuring features in Team Foundation Server 2013](http://nkdagility.com/configure-features-in-team-foundation-server-2013) and you are unable to complete the configuration.

    > TF50309: The following account does not have sufficient permissions to complete the operation: The following permissions are needed to perform this operation: Manage process template.

    ## Applies to

    - Team Foundation Server 2012
    - Team Foundation Server 2013

    ## Findings

    If you are an Team Project Administrator you would expect to be able to configure the new features for your Team Project but you are prompted for the ‘Manage process template’ permission. This permission is a collection level permission and is grated automatically to Project Collection Administrators but not to Project Admins.

    ![image](images/image1-1-1.png "image")  
    { .post-img }
    Figure: Manage process template permission

    You need to [configuring features in Team Foundation Server 2013](http://nkdagility.com/configure-features-in-team-foundation-server-2013) with an account that has this permission.

    ## Solution #1 – Give one user access and configure all projects

    The first solution is to have someone who is a Project Collection Administrator do the configuration. This would be awkward and boring if you have 200 Team Projects, but for one a few this is the simplest and least invasive solution.

    ## Solution #2 – Create a new Group to give Project Admins permission

    If however you have tens or hundreds of Team Project and you need to liaise with each group of users for training for the new features you may want to take a slower approach. I want to be able to delegate this permission out so that I can send an email too each of the Project owners and have them do the training and upgrade at a time that suits them.

    ![image](images/image2-2-2.png "image")  
    { .post-img }
    Figure: Create a Project Upgraders TFS Group

    You need to create a new TFS Group at the Team Collection level that will contain each of the “owners” or “upgraders” for the individual Team Projects.

    ![image](images/image3-3-3.png "image")  
    { .post-img }
    Figure: Set the Manage process template permission only

    Now that we have a group we can select it and set individual permissions. In this case we only need the manage process template permission that will allow this user to complete the configuration of the Team Project to enable the new features.

    ![image](images/image4-4-4.png "image")  
    { .post-img }
    Figure: Add users to the new group

    Now we need to add each user that we want to have this permission. It would be awesome if we could add a Team Project group in here… you know.. like the “Project Administrators” group but “\[ScrumSandbox\]Project Administrators” fails to resolve. Sad, but the workaround is to just add the users we want to have permission..
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-08-issue-tfs-2013-tf50309-when-configuring-features-in-team-foundation-server-2013\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-08-issue-tfs-2013-tf50309-when-configuring-features-in-team-foundation-server-2013
- FrontMatter:
    title: Create a Portfolio Backlog hierarchy in Team Foundation Server 2013
    description: Learn to create a Portfolio Backlog hierarchy in TFS 2013 with step-by-step guidance. Enhance your agile planning and streamline project management!
    ResourceId: O_gTr7ntMcx
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9731
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-08
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: create-a-portfolio-backlog-hierarchy-in-team-foundation-server-2013
    aliases:
    - /resources/O_gTr7ntMcx
    aliasesArchive:
    - /blog/create-a-portfolio-backlog-hierarchy-in-team-foundation-server-2013
    - /create-a-portfolio-backlog-hierarchy-in-team-foundation-server-2013
    - /resources/blog/create-a-portfolio-backlog-hierarchy-in-team-foundation-server-2013
    tags:
    - Install and Configuration
    - Azure Boards
    - Azure DevOps
    - Software Development
    - System Configuration
    - Operational Practices
    - Agile Planning Tools
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-6-6.png
  BodyContent: |
    There are many reasons that you would want to Create a Portfolio Backlog hierarchy in Team Foundation Server 2013 not least of which is modelling your existing processes.

    You can have a hierarchy five items deep with a parent child relationship between them. You will get a backlog for each one as well as cumulative flow and a board. This is awesome as you may have, for instance, Goals that break down into Feature. These goals would be the company or product goals and the features would be those things that go to achieve them.

    ![Only have Features by default](images/image10-1-1.png "Only have Features by default")  
    { .post-img }
    Figure: Only have Features by default

    In order to add a level to the hierarchy we need to customise a Work item Type, the Work Item Categories and the Processing Configuration:

    1. Export all of the configuration to XML
    2. Create Goal work item type definition
    3. Update Category's list to include new type and category
    4. Add new Portfolio Backlog to the Agile Portfolio Tools
    5. Import all of the new configuration to Team Foundation Server

    These steps will allow you to create a Portfolio Backlog hierarchy in Team Foundation Server 2013.

    ## Export all of the configuration to XML

    We need access to first export as XML the configurations that we need from our Team Foundation Server:

    ```
    $TeamProjectName = "ScrumSandboxDemo1"
    $temp = "C:temp"
    $CollectionUrl = "http://caprica:8080/tfs/tfs01-Scrum"
    $WitAdmin = "${env:ProgramFiles(x86)}Microsoft Visual Studio 12.0Common7IDEwitadmin.exe"
    & $WitAdmin exportwitd /collection:$CollectionUrl /p:$TeamProjectName /n:"Feature" /f:"$tempFeature.xml"
    & $WitAdmin exportcategories /collection:$CollectionUrl /p:$TeamProjectName /f:$tempcategories.xml
    & $WitAdmin exportprocessconfig /collection:$CollectionUrl /p:$TeamProjectName /f:$tempprocessingconfig.xml
    ```

    These command will create feature.xml, catagories.xml and a processingconfig.xml files that we can edit offline and then upload into Team Foundation Server 2013 to make the changes.

    ## Create Goal work item type definition

    I am going to make things a little bit easy for me and just copy the Feature type and rename it to Goal. The simplest way to create a new work item type is to diff from an existing one and Feature has the layout that I want to start with.

    ![image](images/image5-2-2.png "image")  
    { .post-img }
    Figure: Changes to make for Goal

    In order to make a new Work Item Type you need only change the name and then import the file. However there in a “Implementation” tab that shows, for Features, the child Product Backlog Items. We need to also change this to load child features instead and feature is going to the be child of Goal.

    ```
    <Tab Label="Implementation">
      <Control Type="LinksControl" Name="Hierarchy" Label="" LabelPosition="Top">
        <LinksControlOptions>
          <LinkColumns>
            <LinkColumn RefName="System.Id" />
            <LinkColumn RefName="System.Title" />
            <LinkColumn RefName="System.AssignedTo" />
            <LinkColumn RefName="System.State" />
          </LinkColumns>
          <WorkItemLinkFilters FilterType="include">
            <Filter LinkType="System.LinkTypes.Hierarchy" FilterOn="forwardname" />
          </WorkItemLinkFilters>
          <ExternalLinkFilters FilterType="excludeAll" />
          <WorkItemTypeFilters FilterType="include">
            <Filter WorkItemType="Feature" />
          </WorkItemTypeFilters>
        </LinksControlOptions>
      </Control>
    </Tab>
    ```

    Here you can see the standard implementation tab that you find on many of the work items that come out of the box. It is basically a query box that shows whatever results that you want. Here it is filtered to “Hierarchy” link types which really just means parentchild and for a particular work item type which in this case is “Feature”.

    ```
    <?xml version="1.0" encoding="utf-8"?>
    <witd:WITD application="Work item type editor" version="1.0" xmlns:witd="http://schemas.microsoft.com/VisualStudio/2008/workitemtracking/typedef">
      <WORKITEMTYPE name="Goal">
        <DESCRIPTION>Tracks a Goal that will be released with the product</DESCRIPTION>
        ...
        <FORM>
          <Layout HideReadOnlyEmptyFields="true" HideControlBorders="true">
            ...
            <Group>
              <Column PercentWidth="50">
                <TabGroup>
                ...
                  <Tab Label="Implementation">
                    <Control Type="LinksControl" Name="Hierarchy" Label="" LabelPosition="Top">
                      <LinksControlOptions>
                        <LinkColumns>
                          <LinkColumn RefName="System.Id" />
                          <LinkColumn RefName="System.Title" />
                          <LinkColumn RefName="System.AssignedTo" />
                          <LinkColumn RefName="System.State" />
                        </LinkColumns>
                        <WorkItemLinkFilters FilterType="include">
                          <Filter LinkType="System.LinkTypes.Hierarchy" FilterOn="forwardname" />
                        </WorkItemLinkFilters>
                        <ExternalLinkFilters FilterType="excludeAll" />
                        <WorkItemTypeFilters FilterType="include">
                          <Filter WorkItemType="Feature" />
                        </WorkItemTypeFilters>
                      </LinksControlOptions>
                    </Control>
                  </Tab>
                </TabGroup>
              </Column>
              ...
            </Group>
          </Layout>
        </FORM>
      </WORKITEMTYPE>
    </witd:WITD>
    ```

    You could obviously customise this work item type to your hearts content and now we need to add it to a category.

    ## Update Category's list to include new type and category

    To create a portfolio backlog we need a custom category so that we can use that for the portfolio backlog.

    ![image](images/image6-3-3.png "image")  
    { .post-img }
    Figure: Adding a custom category for Goal

    A  category can have multiple Work Item Types listed but only one default. This means that you could have multiple Work Item Types for different sorts of Goals. I am however trying to keep this simple…

    ```
    <CATEGORY refname="Microsoft.GoalCategory" name="Goal Category">
      <DEFAULTWORKITEMTYPE name="Goal" />
    </CATEGORY>
    ```

    A simple category that holds a single work item type is fairly easy to create. Just add it to the list of categories below.

    ```
    <?xml version="1.0" encoding="utf-8"?>
    <cat:CATEGORIES xmlns:cat="http://schemas.microsoft.com/VisualStudio/2008/workitemtracking/categories">
      <CATEGORY refname="Microsoft.BugCategory" name="Bug Category">
        <DEFAULTWORKITEMTYPE name="Bug" />
      </CATEGORY>
      <CATEGORY refname="Microsoft.CodeReviewRequestCategory" name="Code Review Request Category">
        <DEFAULTWORKITEMTYPE name="Code Review Request" />
      </CATEGORY>
      <CATEGORY refname="Microsoft.CodeReviewResponseCategory" name="Code Review Response Category">
        <DEFAULTWORKITEMTYPE name="Code Review Response" />
      </CATEGORY>
    <CATEGORY refname="Microsoft.GoalCategory" name="Goal Category">
      <DEFAULTWORKITEMTYPE name="Goal" />
    </CATEGORY>
      <CATEGORY refname="Microsoft.FeatureCategory" name="Feature Category">
        <DEFAULTWORKITEMTYPE name="Feature" />
      </CATEGORY>
      <CATEGORY refname="Microsoft.FeedbackRequestCategory" name="Feedback Request Category">
        <DEFAULTWORKITEMTYPE name="Feedback Request" />
      </CATEGORY>
      <CATEGORY refname="Microsoft.FeedbackResponseCategory" name="Feedback Response Category">
        <DEFAULTWORKITEMTYPE name="Feedback Response" />
      </CATEGORY>
      <CATEGORY refname="Microsoft.HiddenCategory" name="Hidden Types Category">
        <DEFAULTWORKITEMTYPE name="Code Review Request" />
        <WORKITEMTYPE name="Code Review Response" />
        <WORKITEMTYPE name="Feedback Request" />
        <WORKITEMTYPE name="Feedback Response" />
        <WORKITEMTYPE name="Shared Steps" />
      </CATEGORY>
      <CATEGORY refname="Microsoft.RequirementCategory" name="Requirement Category">
        <DEFAULTWORKITEMTYPE name="Product Backlog Item" />
        <WORKITEMTYPE name="Bug" />
      </CATEGORY>
      <CATEGORY refname="Microsoft.SharedStepCategory" name="Shared Step Category">
        <DEFAULTWORKITEMTYPE name="Shared Steps" />
      </CATEGORY>
      <CATEGORY refname="Microsoft.TaskCategory" name="Task Category">
        <DEFAULTWORKITEMTYPE name="Task" />
      </CATEGORY>
      <CATEGORY refname="Microsoft.TestCaseCategory" name="Test Case Category">
        <DEFAULTWORKITEMTYPE name="Test Case" />
      </CATEGORY>
    </cat:CATEGORIES>
    ```

    Once we have the new category and the new Goal work item type we are ready to use them to create the portfolio backlog.

    ## Add new Portfolio Backlog to the Agile Portfolio Tools

    There are three things that we need to do in order to create the new portfolio backlog for Goals in the Team Web Access site.

    ![image](images/image7-4-4.png "image")  
    { .post-img }
    Figure: Customising the Process Configuration for Portfolio Backlogs

    We need to not only add the new portfolio backlog above but also set the parent property on child portfolio backlog and optionally set a colour for our Goals cards and lists.

    Because I just copied the Feature work item type for this I can just copy the Feature entry in the Portfolio Backlogs section. If you have a more customised work item type you may want to customise the States, Columns and the fields that are available in the Add Panel for that Work Item Type in the web UI. Here I am just going with the simple option of copying.

    In addition I need to tell the Feature portfolio backlog that anything in the Goal category that we created is now its parent. This is done simply by adding the category to the parent attribute of the PortfolioBacklog element in question.

    Note You can also check out [customise the colours in Team Foundation Server 2013 Agile Planning Tools](http://nkdagility.com/customise-the-colours-in-team-foundation-server-2013-agile-planning-tools/)

    ```
    <?xml version="1.0" encoding="utf-8"?>
    <ProjectProcessConfiguration>
      ...
      <PortfolioBacklogs>
        <PortfolioBacklog category="Microsoft.GoalCategory" pluralName="Goals" singularName="Goal">
          <AddPanel>
            <Fields>
              <Field refname="System.Title" />
            </Fields>
          </AddPanel>
          <Columns>
            <Column width="100" refname="System.WorkItemType" />
            <Column width="400" refname="System.Title" />
            <Column width="100" refname="System.State" />
            <Column width="50" refname="Microsoft.VSTS.Common.BusinessValue" />
            <Column width="100" refname="Microsoft.VSTS.Scheduling.TargetDate" />
            <Column width="200" refname="System.Tags" />
          </Columns>
          <States>
            <State type="Proposed" value="New" />
            <State type="InProgress" value="In Progress" />
            <State type="Complete" value="Done" />
          </States>
        </PortfolioBacklog>
        <PortfolioBacklog category="Microsoft.FeatureCategory" parent="Microsoft.GoalCategory" pluralName="Features" singularName="Feature">
          <AddPanel>
            <Fields>
              <Field refname="System.Title" />
            </Fields>
          </AddPanel>
          <Columns>
            <Column width="100" refname="System.WorkItemType" />
            <Column width="400" refname="System.Title" />
            <Column width="100" refname="System.State" />
            <Column width="50" refname="Microsoft.VSTS.Common.BusinessValue" />
            <Column width="100" refname="Microsoft.VSTS.Scheduling.TargetDate" />
            <Column width="200" refname="System.Tags" />
          </Columns>
          <States>
            <State type="Proposed" value="New" />
            <State type="InProgress" value="In Progress" />
            <State type="Complete" value="Done" />
          </States>
        </PortfolioBacklog>
      </PortfolioBacklogs>
      ...
      <WorkItemColors>
        <WorkItemColor primary="FF2CFF07" secondary="FFACFF9E" name="Goal" />
        <WorkItemColor primary="FFCC293D" secondary="FFFAEAE5" name="Bug" />
        <WorkItemColor primary="FFFF9D00" secondary="FFFCEECF" name="Code Review Request" />
        <WorkItemColor primary="FFFF9D00" secondary="FFFCEECF" name="Code Review Response" />
        <WorkItemColor primary="FF773B93" secondary="FFEEE2F2" name="Feature" />
        <WorkItemColor primary="FFFF9D00" secondary="FFFCEECF" name="Feedback Request" />
        <WorkItemColor primary="FFFF9D00" secondary="FFFCEECF" name="Feedback Response" />
        <WorkItemColor primary="FFFF9D00" secondary="FFFCEECF" name="Impediment" />
        <WorkItemColor primary="FF009CCC" secondary="FFD6ECF2" name="Product Backlog Item" />
        <WorkItemColor primary="FFFF9D00" secondary="FFFCEECF" name="Shared Steps" />
        <WorkItemColor primary="FFF2CB1D" secondary="FFF6F5D2" name="Task" />
        <WorkItemColor primary="FFFF9D00" secondary="FFFCEECF" name="Test Case" />
      </WorkItemColors>
    </ProjectProcessConfiguration>
    ```

    Simples… now that we have completed all of the changes necessary we are ready for the import.

    ## Import all of the new configuration to Team Foundation Server

    This is really just the revers of the commands used to create the files in the first place.

    ```
    $TeamProjectName = "ScrumSandboxDemo1"
    $temp = "C:temp"
    $CollectionUrl = "http://caprica:8080/tfs/tfs01-Scrum"
    $WitAdmin = "${env:ProgramFiles(x86)}Microsoft Visual Studio 12.0Common7IDEwitadmin.exe"
    & $WitAdmin importwitd /collection:$CollectionUrl /p:$TeamProjectName /n:"Feature" /f:"$tempGoal.xml"
    & $WitAdmin importcategories /collection:$CollectionUrl /p:$TeamProjectName /f:$tempcategories.xml
    & $WitAdmin importprocessconfig /collection:$CollectionUrl /p:$TeamProjectName /f:$tempprocessingconfig.xml

    ```

    We just call them as “import” rather than “export” statements.

    DONE

    ## Conclusion

    We now have a lovely green Goal work item type that sits on its own backlog and is ordered above Features.

    ![image](images/image8-5-5.png "image")  
    { .post-img }
    Figure: Viewing Tasks from the lofty heights of Goals

    Customising the hierarchy for Portfolio Backlogs is easy and the hard part is making sure that you are making the correct change.

    > When you are working with any sort of work item tracking customisation in Team Foundation Server it is best to think twice and customise once.  
    > \-Me

    Make sure you always make the right changes to Team Foundation Server to improve your process and never enshrine dysfunctions…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-08-create-a-portfolio-backlog-hierarchy-in-team-foundation-server-2013\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-08-create-a-portfolio-backlog-hierarchy-in-team-foundation-server-2013
- FrontMatter:
    title: Engaging with complexity - Team Foundation Server Edition
    description: Explore the complexities of Team Foundation Server migrations in Silicon Valley. Learn strategies to streamline processes and enhance development efficiency.
    ResourceId: xr1jtRnRNvp
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9703
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-07-01
    weight: 665
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: engaging-with-complexity-team-foundation-server-edition
    aliases:
    - /resources/xr1jtRnRNvp
    aliasesArchive:
    - /blog/engaging-with-complexity-team-foundation-server-edition
    - /engaging-with-complexity-team-foundation-server-edition
    - /engaging-with-complexity
    - /engaging-with-complexity---team-foundation-server-edition
    - /blog/engaging-with-complexity---team-foundation-server-edition
    - /resources/blog/engaging-with-complexity-team-foundation-server-edition
    tags:
    - Software Development
    - Pragmatic Thinking
    - Install and Configuration
    - System Configuration
    - Azure DevOps
    - Troubleshooting
    - Operational Practices
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-2-2.png
  BodyContent: |
    I have been engaging with complexity for a company in Silicon Valley that is doing one of the most complex Team Foundation Server migrations that I think I have ever seen.

    When large companies sell parts of themselves there is a complicated ‘remediation’ process that is required to make sure that they only take the assets that have been purchased with them. Developers tend to be very greedy when writing software and your code picks up all kinds of references that you may not even know about. This causes problems within the development process as we may use source code for applications that are not being sold as components within the ones that are. They need to remove all of the assets that they are not taking with them and then reload the thing that have been approved by legal.

    ![image](images/image79-1-1.png "image")  
    { .post-img }
    Figure: Proposed Remediation Process

    The current home of the data is the corporate IT infrastructure which is shared and inaccessible by the team that I am working with. This means that the corporate IT guys will not let us any where near the server or give us access and we need to rely on them providing backups. As I arrived on this engagement the customer had just received their first backup from the corporate operations team. This team would only do an offline backup and TFS was offline for 20 hours to complete the process. To make matters worse there was some sort of issue that was crippling the network at the same time and they had to put someone on a plane to fly 1000 miles to pick up a hard disk and back. The joys of large databases (2TB).

    Unfortunately for the customer they followed their corporate IT teams recommendations for server specifications, load-outs and configuration. This has caused all sorts of issues around moving data round and just a general level of unnecessarily added complexity. For example we have physical data tiers for TFS. If you have access to local storage (direct attached) then I would always recommend using virtual SQL Server instances. It gives you a degree of flexibility that you just can’t get from physical boxes like snapshots and moving boxes around. You can even add large attached storage to your VM Host and get phenomenal speeds copying between VHD’s.

    Why are copy speeds so important? Think first about taking a 2TB backup, moving that 2TB backup and then restoring that 2TB backup. And then think about doing that 5 times as we move the TFS instance through the remediation process. With physical boxes and copying the files we are looking at 2-3 days (yes days) per environment and we will have over 500 engineers unable to work until the process is completed. That is not acceptable so we need to get good at this and work the kinks out and to work the kinks our we are running the entire process 3-4 times end to end. Our solution for the speed issue was to use a direct attached storage array that we only had two controllers for. We would then leapfrog the controllers down the chain to reduce the data manipulation process to a few hours instead of days.

    This is what I call engaging with complexity and you can see from the diagram above the entire remediation process is rather convoluted and although I have done each piece, sometimes two at a time, the whole process is something I have not done before. I need to understand for myself what is involved and make sure that I have not forgotten anything. The process of writing this post services that purpose… if I don’t write it down I will soon forget…

    Engaging with complexity means putting boxes around the chaos to get focus…

    - [Step 1: Upgrade to TFS 2012.2](#Step1)
    - [Step 2: Sneaker net](#Step2)
    - [Step 3: Hardware move of Source to Remediation#2](#Step3)
    - [Step 4: Upgrading to Team Foundation Server 2013](#Step4)
    - [Step 5: Strip the source](#Step5)
    - [Step 6: Environment move from Remediation#2 to Remediation#3](#Step6)
    - [Step 6.1: Prep Remediation Domain](#Step6-1)
    - [Step 6.2: All in one Environment and Hardware move](#Step6-2)
    - [Step 7: Validating TFS in Remediation#3](#Step7)
    - [Step 8: Hardware move from Remediation#3 to Remediation#4](#Step8)
    - [Step 9: Reload stripped and approved source code](#Step9)
    - [Step 10: Validate builds on Remediation#4](#Step10)
    - [Step 11: Remediation#4 to Remediation#5 (hardware move)](#Step11)
    - [Step 12: Production.. for a while](#Step12)
    - [Step 12.1: Maintain user continuity in source](#Step12-1)

    We have managed to complete all of the steps up to #8 so far and that has really helped work out the kinks with the process. We are trying to script what we can so I have included them where appropriate. I am a consultant to this process and the real hard work is being done by the awesome TFS remediation team that I am working with: Shu & Kim…

    ## Step 1: Upgrade to TFS 2012.2

    Because this organisation has some ties to Microsoft they have access to some…lets just say less public versions of Team Foundation Server. The first challenge was to get the TFS server to a supportable version. This was handled by the corporate IT department and resulted in significant downtime for the customer but we got onto TFS 2012.2 (the current public release.) This then allows us to at least have that version installed on each of the target servers.

    - [Upgrading Team Foundation Server 2012](http://nkdagility.com/upgrading-to-team-foundation-server-2012-update-1/ "http://nkdagility.com/upgrading-to-team-foundation-server-2012-update-1/")

    Once you are on a supported version of Team Foundation Server the next step is to get a backup…

    ## Step 2: Sneaker net or file copy

    [Understanding Backing Up Team Foundation Server](http://msdn.microsoft.com/en-us/library/vstudio/ms253151.aspx) is critical to this process working and in most cases you can use the [built in Scheduled Backups tool](http://msdn.microsoft.com/en-us/library/vstudio/hh561429.aspx) to complete them. Unfortunately in this case I have no control or access to the production server and we are relying on an external team to complete the process.

    We sent over instruction for [Manually Back Up Team Foundation Server](http://msdn.microsoft.com/en-us/library/vstudio/ms253070.aspx) as we need to backup the entire TFS (Configuration + Collections + Warehouse) as well as Reporting (Databases + Key) so that we can clone the current TFS instance locally in an environment that we control. The corporate operations team should not need to take TFS offline as [Manually Back Up Team Foundation Server](http://msdn.microsoft.com/en-us/library/vstudio/ms253070.aspx) has detailed instructions for creating a _marked transaction log backup_ to remove the likelihood of us getting inconsistencies in the data to be restored.

    - [Northwest Cadence cheat sheet for marked transaction logs from Dan Wood](http://blog.nwcadence.com/manually-backing-up-tfs-2012-with-sql-server/)

    TFS s a system is made up of multiple interdependent databases ad we need to keep them in sync. If we do a point in time backup we may inadvertently have a complete transaction in one database that is only partially complete (thus would be rolled back) in another; thus we would suffer from a data inconsistency and likely unfortunate consequences for the new TFS instance. However if you CAN take TFS offline to did the backup you do not need to use marked transaction logs, but the downside is no one can access TFS while you are taking the backup. In this case the backup takes around 8 hours to complete and we have users in USA, UK & China so downtime will affect someone somewhere. Marked transactions make the most sense.

    Once the backup is complete we would expect to see the following files in the output folder:

    - Tfs_Configuration\*.bak
    - Tfs_Configuration\*. trn
    - Tfs_Collection1\*.bak
    - Tfs_Collection1\*. trn
    - Tfs_Collection2\*.bak
    - Tfs_Collection2 \*. trn
    - Tfs_Warehouse\*.bak
    - Tfs_Warehouse\*. trn
    - ReportServerKey\*.snk
    - ReportServer\*.bak
    - ReportServer\*.trn

    The lack of \*.trn files is a good indication that marked transaction logs were not done and you likely need to ask them to do over… and once you have everything you are ready to restore to your new local (and more importantly, under your control) environment.

    ## Step 3: Hardware move of Source to Remediation#2

    This is probably the simplest transition and apart from the data sneaker net process to retrieve the data it is fairly well documented on MSDN.

    - [Move Team Foundation Server from One Hardware Configuration to Another](http://msdn.microsoft.com/en-us/library/ms404869.aspx "http://msdn.microsoft.com/en-us/library/ms404869.aspx")

    However make sure that when you are practicing the process that you change the server ID each time. Each TFS instance and each Team Project Collection (TPC) has  unique GUID that allows the client computers to identify it even if you move hardware. When a client connects to a new TFS server that has a GUID that matches an existing server of a different name it remaps everything over to that new server. So if you do not change the name on your practice runs then everyone that has connected to the new server but then reconnects to the old one all get very confused clients. This is not fun to debug and is confusing as heck… so change the server ID for everything short of a production move.

    You may have noticed that I have TFS 2013 in the checklist below. We moved to Team Foundation Server 2013 preview ostensibly to fix a couple of issues we were experiencing that have been fixed post 2012 Qu3 (2012.3) and with  Team Foundation Server 2013 having a go-live licence (fully supported in production) we had no issues with this move.

    - [Get Visual Studio 2013 Team Foundation Server while its hot!](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/ "Get Visual Studio 2013 Team Foundation Server while its hot!")

    After we have completed this process a bunch of pre-prepared scripts get run against the servers to strip out all of the source of CompanyA that should not be made available to CompanyB… we are still in the CompanyA domain and after we have completed the checklist below we move onto the next stage…

    ### Checklist

    This is a list of the things that have to happen in order and any validation that needs to happen to get this done:

    1. Validate Backup contents from Source – Should contain a .bak and a .trn for each database (tfs_configuration, tfs_DefaultCollection, tfs_Warehouse, reports, reportstemp)  
       If it does not contain a .trn files then follow: [http://msdn.microsoft.com/en-us/library/vstudio/ms253070.aspx](http://msdn.microsoft.com/en-us/library/vstudio/ms253070.aspx)
    2. Restore Full backup and Transaction backup to Remediation#2
    3. Un-configure TFS & drop old databases
    4. Verify TFS 2013 is installed
    5. ChangeServerId (if practice run)
    6. RemapDB
    7. ResetOwner
    8. Change Service Accounts to Remediation accounts
    9. Run Upgrade Wizard
    10. Reconfigure Reporting
    11. Run remediation process…

    #11 is handled by another team that is deciding what can go and what can stay.

    ## Step 4: Upgrading Remediation#2 to Team Foundation Server 2013

    I went back and forth on this one a lot. What got me was that [in order to fix a major issue](http://nkdagility.com/issue-tfs2012-2-tf30063-you-are-not-authorized-to-access/) we had to install Team Foundation Server 2012 QU2 (2012.3) which is in itself Go-Live…

    - [Upgrading to Team Foundation Server 2013](http://nkdagility.com/upgrading-to-team-foundation-server-2013/)

    So in the end it was a really easy decision. Do you want to be on the old “_not released yet but supported version_”… or the latest one? I don’t know about you, but once I realise that was the choice I made it in but a moment.

    What's even better is that, including a reboot, the entire upgrade process for a 2TB TFS instance took less than 10 minutes.

    ## Step 5: Strip the source from Remediation#2

    The process of removing all of the source that had to run through legal was being conducted in parallel by another team. They were scripting out the removal of all of the problem areas so that when the time comes to run through the entire process it is only a script away…

    ## Step 6: Environment move from Remediation#2 to Remediation#3

    This is a little bit of a complicated one. I have done this a bunch of times before but there is really no good documentation for it. This is a cross between moving hardware and moving environment.

    - [Move Team Foundation Server from One Hardware Configuration to Another](http://msdn.microsoft.com/en-us/library/ms404869.aspx "http://msdn.microsoft.com/en-us/library/ms404869.aspx")
    - [Move Team Foundation Server from One Environment to Another](http://msdn.microsoft.com/en-us/library/ms404883.aspx)

    We have two main steps to perform here:

    - Step 6.1: Prep Remediation Domain
    - Step 6.2: All in one Environment and Hardware move

    These together will migrate the servers and 6.1 is an amalgamation of the two documents above.

    ### Step 6.1: Prep Remediation Domain

    We have a temporary domain that have been created to hold the users, data and applications as they move forward. It will probably hang around for a while as new infrastructure and applications get built out in CompanyB’s systems. Little is known about them at this time and we are concentrating on delivering everything into the temporary domain. If you have ever gone through this process you know that it is a mammoth task and I am in awe of the things that the remediation teams have done already.

    #### Checklist

    1. Create Organisational Unit (OU) to hold users
    2. Create accounts for Users in OU

    This is a necessary step as we will be unable to have folks login in the remediation domain if they don’t exist. This domain may be ‘production’ for as much as a year before the new CompanyB bits are ready and we need everyone that is moving to be able to login.

    #### Scripted: Create accounts for Users in OU

    All we did for this was create a CSV file with the existing username and some meta data to make it work. Then add a little PowerShell to automate the process and voila..

    ```
    Param(
           [string] $csvusers = "C:renusers06032013.csv",
           [string] $adpath = "OU=Test,DC=env,DC=nakedalm,DC=com",
           [string] $addomain = "@rendition.env.nakedalmweb.wpengine.com"
           )
    # Import list of Users From CSV into $Userlist
    $UserList=IMPORT-CSV $csvusers
    # Step through Each Item in the List
    $people = 0
    Foreach ($Person in $UserList) {
        $people++
        $Username=$Person.alias
        # Build the User Principal Name Username with Domain added to it
        $UPN=$Username+"@"+$addomain
        # Create the Displayname
        $Name=$Person.forename+" "+$Person.surname
        # Create User in Active Directory
        $password = ConvertTo-SecureString -AsPlainText 'P2ssw0rd' -Force
        Write-Progress -activity "Adding about $($UserList.Count) users to active directory" -CurrentOperation "Creating user $people of $($UserList.Count) '$Username'" -PercentComplete ((100/$UserList.Count)*$people)
        NEW-ADUSER -path $adpath -GivenName $Person.forename –surname $Person.surname –DisplayName $DisplayName -Name $Username –SamAccountName $Username -AccountPassword $password –UserPrincipalName $UPN
    }
    Write-Progress -Completed
    ```

    You do need to have the Active Directory bits installed but you can add the AD client bits to any server as a feature.

    - [Remote Active Directory Administration with Windows PowerShell](http://technet.microsoft.com/en-us/magazine/gg413289.aspx)

    ### Step6.2: All in one Environment and Hardware move

    When you talk about an environment move in relation to Team Foundation Server we are really talking about changing the domain. We are actually physically moving server at the same time and we need to merge the two MSDN documented processes detailed above.

    #### Checklist

    1. Validate Backup contents from Remediation#2
    2. Restore Full backup and Transaction backup to Remediation#3
    3. Un-configure TFS & drop old databases
    4. Verify TFS 2013 is installed
    5. ChangeServerId (if practice run)
    6. RemapDB
    7. ResetOwner
    8. Add Service Accounts to new domain Remediation#3 accounts
    9. Configure Application Tier Only
    10. Flip Domain Users ( “TFSConfig Accounts /change” for domain)
    11. Create TFS Group and Add All Users
    12. Validate Domain Migration

    You may run into [TF400998 if you have Scheduled Backups configured](http://nkdagility.com/tfs-2012-3-issue-scheduled-backups-gives-a-tf400998) but there is a simple work around for that.

    #### Scripted: Create TFS Group and Add All Users

    As all of the security is currently done with AD and we will not have all of the corporate groups we need a temporary Contributors group on the collection that has all of the server that are moving across. It would be fairly boring to add 400+ users manually so…

    ```
    Param(
           [string] $CollectionUrlParam,
           [string] $GroupName = $(Read-Host -prompt "Group"),
           [string] $csvusers = "C:migrateusers06032013.csv"
           )

      # load the required dlls
    Add-Type -AssemblyName "Microsoft.TeamFoundation.Client, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a",
                            "Microsoft.TeamFoundation.Common, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a",
                            "Microsoft.TeamFoundation, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a"
    $tfs
    $projectList = @()

    if ($CollectionUrlParam)
    {
        #if collection is passed then use it and select all projects
        $tfs = [Microsoft.TeamFoundation.Client.TfsTeamProjectCollectionFactory]::GetTeamProjectCollection($CollectionUrlParam)
        $cssService = $tfs.GetService("Microsoft.TeamFoundation.Server.ICommonStructureService3")
        if ($Projects)
        {
            #validate project names
            foreach ($p in $Projects)
            {
                try
                {
                    $projectList += $cssService.GetProjectFromName($p)
                }
                catch
                {
                    Write-Error "Invalid project name: $p"
                    exit
                }
            }
        }
        else
        {
            $projectList = $cssService.ListAllProjects()
        }
    }
    else
    {
        #if no collection specified, open project picker to select it via gui
        $picker = New-Object Microsoft.TeamFoundation.Client.TeamProjectPicker([Microsoft.TeamFoundation.Client.TeamProjectPickerMode]::NoProject, $false)
        $dialogResult = $picker.ShowDialog()
        if ($dialogResult -ne "OK")
        {
            exit
        }

        $tfs = $picker.SelectedTeamProjectCollection
        $projectList = $picker.SelectedProjects
    }

    try
    {
        $tfs.EnsureAuthenticated()
    }
    catch
    {
        Write-Error "Error occurred trying to connect to project collection: $_ "
        exit 1
    }

    foreach ($project in $projectList)
    {
        Write-Output($project.Name)
    }
    $ims = $tfs.GetService("Microsoft.TeamFoundation.Framework.Client.IIdentityManagementService")
    Write-Progress -activity "Building TFS Groups and Users" -CurrentOperation "Creating Group" -PercentComplete 0
    $groupIdent = $ims.ReadIdentity([Microsoft.TeamFoundation.Framework.Common.IdentitySearchFactor]::General,
                                   $GroupName,
                                   [Microsoft.TeamFoundation.Framework.Common.MembershipQuery]::None,
                                   [Microsoft.TeamFoundation.Framework.Common.ReadIdentityOptions]::None)

    if ($groupIdent -eq $null)
    {
      $groupIdent= $ims.CreateApplicationGroup($null, $GroupName, "All migration users")
      $groupIdent = $ims.ReadIdentity([Microsoft.TeamFoundation.Framework.Common.IdentitySearchFactor]::General,
                                       $GroupName,
                                       [Microsoft.TeamFoundation.Framework.Common.MembershipQuery]::None,
                                       [Microsoft.TeamFoundation.Framework.Common.ReadIdentityOptions]::None)
    }
    Write-Output $groupIdent
    $UserList=IMPORT-CSV $csvusers
    $people = 0
    Foreach ($Person in $UserList) {
        $people++
        Write-Progress -activity "Building TFS Groups and Users" -CurrentOperation "Adding $($Person.alias) to $GroupName " -PercentComplete  ((100/$UserList.Count)*$people)
        $userIdent = $ims.ReadIdentity([Microsoft.TeamFoundation.Framework.Common.IdentitySearchFactor]::General,
                                   $Person.alias,
                                   [Microsoft.TeamFoundation.Framework.Common.MembershipQuery]::None,
                                   [Microsoft.TeamFoundation.Framework.Common.ReadIdentityOptions]::None)

        Write-Output "Adding $($userIdent.DisplayName)"
        $ims.AddMemberToApplicationGroup($groupIdent.Descriptor, $userIdent.Descriptor)
    }

    ```

    You need Team Explorer installed but it works just fine.

    Note You will get an error if you try to add a user to the group that does not actually have permission to TFS. As we flipped all of the users this is likely OK as they did not have permission before anyway.

    ## Step 7: Validating TFS in Remediation#3

    Validating TFS means connecting through the Web Access as well as Visual Studio and validating that you can change work items, check in files and that everything looks good.

    I have never had an installation say that it was successful and for there to be something actually wrong with the data. There was one customer at Northwest Cadence that was before my time and did not find out that the data was broken for 6 weeks but no amount of validation would have detected the issues that they had.

    Like Brian Harry often says… “_\[eventually\] there is no place like production_”. At some point you need to go for it…

    ## Step 8: Hardware move from Remediation#3 to Remediation#4

    Moving to Remediation#4 for may just be another hardware move from there perspective of Team Foundation Server and thus making is something we have done a time of by now but it does have more.

    - [Move Team Foundation Server from One Hardware Configuration to Another](http://msdn.microsoft.com/en-us/library/ms404869.aspx "http://msdn.microsoft.com/en-us/library/ms404869.aspx")

    But for us… it is just another hardware move.

    ### Checklist

    1. Validate Backup contents from Remediation#3
    2. Un-configure TFS & drop old databases
    3. Restore Full backup and Transaction backup to Remediation#4
    4. Verify TFS 2013 is installed
    5. ChangeServerId (if practice run)
    6. RemapDB
    7. ResetOwner
    8. Change Service Accounts to Remediation#4 accounts
    9. Configure Application Tier Only
    10. Reconfigure Reporting

    This is as much as the team I am working with needs to do but that is by no means the end for Remediation#4.

    ## Step 9: Reload stripped and approved source code

    At this point we have a set of checked replacements for the things that we removed in Remediation#2. These need to be load back into Team Foundation Server source control and checked-in. Then the real hard work starts of validating that we still have viable software…

    ## Step 10: Validate builds on Remediation#4

    Now that we have loaded all of the source we need to get it all working again. The development teams will need to validate each and every one of this 1000+ builds on over 250 build servers to make sure that what we have is working software. ComapnyB is obviously buying working software :)

    ## Step 11: Hardware move from Remediation#4 to Remediation#5

    This is the final move for a while and Remediation#5 is configured to support all of the same activities that currently exist in production at CompanyA. We will have separate application and data tiers with lots of build servers.

    ### References

    - MSDN: [Move Team Foundation Server from One Hardware Configuration to Another](http://msdn.microsoft.com/en-us/library/ms404869.aspx "http://msdn.microsoft.com/en-us/library/ms404869.aspx")

    ### Checklist

    1. Validate Backup contents from Remediation#3
    2. Restore Full backup and Transaction backup to Remediation#4
    3. Un-configure TFS & drop old databases
    4. Verify TFS 2013 is installed
    5. ChangeServerId (if practice run)
    6. RemapDB
    7. ResetOwner
    8. Change Service Accounts to Remediation#4 accounts
    9. Configure Application Tier Only
    10. Reconfigure Reporting

    ## Step 12: Production.. for a while

    We are now in temporary production for a year or so. There are a lot more things involved in the transition from CompanyA to CompanyB that does not involve developers and Team Foundation Server. There is customer and users to think about and while ComapnyB takes its time to make a seamless transition our little Team Foundation Server will sit in it temporary home…

    ## Step 12.1: Maintain user continuity in source

    As many of the users that are moving out will still have access to the old domain to create patches and releases where necessary they will be given new  contractor accounts. These accounts will be different from their local full-time accounts and you may want to flip the TFS Identities over so that you maintain the continuity of the users experience.

    This will allow you to view history on a users account and see the history of that user regardless of the account. I you do not do this then you have two histories for each user. One for their old account name and another for the new one.Now that would suck a little…

    This is because unlike a ‘rename’ of the account in active directory all of the new accounts would have new SID’s. SID’s are the way that a user is uniquely identified in Active Directory and TFS uses this to know which account to sync.

    ```
    Param(
         [string] $csvusers = "C:tempusermapping.csv",
         [string] $domainOld = "MyCompanyDomain",
         [string] $domainNew = "MyCompanyDomain"
        )

    $TFSConfig = "${env:ProgramFiles}Microsoft Team Foundation Server 11.0ToolsTFSConfig.exe"

    $UserList=IMPORT-CSV $csvusers

    Foreach ($Person in $UserList) {
        & $TFSConfig identities /change "/fromdomain:$domainOld" "/todomain:$domainNew" "/account:$csvusers.OldAccount" "/toaccount:$csvusers.NewAccount"
    }

    ```

    All you need is a mapping CSV with a column for the old and new account names.

    ## Conclusion and more to come

    This is the first stage of a large complicated move that [involves SharePoint](http://nkdagility.com/engaging-with-complexity-sharepoint-edition/) as well, which I am helping the customer with.  The folks there are awesome and I hope to be back helping them out soon. For now they have lots of practice of this process to do and I wish them lots of luck…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-01-engaging-with-complexity-team-foundation-server-edition\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-07-01-engaging-with-complexity-team-foundation-server-edition
- FrontMatter:
    title: Windows 8.1 Preview Issue - The update is not applicable to your computer
    description: Facing the 'update not applicable' error on Windows 8.1? Discover effective solutions to install the update and enhance your system performance!
    ResourceId: a6j_DLQHNUq
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9914
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-28
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: windows-8-1-preview-issue-the-update-is-not-applicable-to-your-computer
    aliases:
    - /resources/a6j_DLQHNUq
    - /resources/blog/windows-8.1-preview-issue-the-update-is-not-applicable-to-your-computer
    aliasesArchive:
    - /blog/windows-8-1-preview-issue-the-update-is-not-applicable-to-your-computer
    - /windows-8-1-preview-issue-the-update-is-not-applicable-to-your-computer
    - /windows-8-1-preview-issue
    - /windows-8-1-preview-issue---the-update-is-not-applicable-to-your-computer
    - /blog/windows-8-1-preview-issue---the-update-is-not-applicable-to-your-computer
    - /resources/blog/windows-8-1-preview-issue-the-update-is-not-applicable-to-your-computer
    - /resources/blog/windows-8.1-preview-issue-the-update-is-not-applicable-to-your-computer
    tags:
    - Troubleshooting
    - Windows
    - Install and Configuration
    - System Configuration
    categories:
    - Uncategorized
    preview: nakedalm-windows-logo-12-12.png
  BodyContent: |
    Some system are receiving an error when trying to install the Windows 8.1 Update patch (“Windows8-RT-KB2849636-x64.msu”) and they get a “The update is not applicable to your computer” error.

    ![image](images/image68-1-1.png "image")  
    { .post-img }
    Figure: Windows 8.1 Preview - The update is not applicable to your computer

    ## Applies to

    - Windows 8.1 Preview
    - Windows 8

    ## Findings

    Unfortunately Microsoft looks to have done a poor job of detecting the region of the user. This update is supposed to be for US customers only and has some checks to make sure that you have the correct region set. If you have a “en-us” copy of windows (installed from “en_windows_8_x64_dvd_915440.iso”) you can easily bypass this protection by either changing your windows regional settings to “United States”, rebooting and retrying. If however you have installed another language   (installed perhaps from “en-gb_windows_8_x64_dvd_915412.iso”) then you may need to install a fresh copy of Windows.

    There are a couple of tricks to try first though:

    ## Solution #1 – Change your region to get Windows 8.1 Preview update to work

    Most likely is that you have a US OS that has been set to a different region. If this is the case you can probably get away with changing your region to “United States” until the update is done.

    ![image](images/image69-2-2.png "image")  
    { .post-img }
    Figure: Start | Search:”Region” | Region

    Open your regional settings by typing “region” when you are at the start menu and selecting “Settings”. You should then see Region on the left.

    ![image](images/image70-3-3.png "image")  
    { .post-img }
    Figure: “Region | Administrative | Change local settings | Current System Local”

    Temporarily set your region to “United States” and this may fix your issue. If like me it does not then goto #2…

    ## Solution #2 – Manually unpack the Windows 8.1 Preview update

    You can bypass this check here by unpacking KB2849636 manually and applying the update directly.

    ### **#1 Place and rename the MSU file in an easily accessible place**

    ![image](images/image71-4-4.png "image")  
    { .post-img }
    Figure: Find the file

    Here I have used C:tempWindows8-RT-KB2849636-x64.msu as I can easily find this…

    ### **#2 Open command prompt in administrator mode**

    ![image](images/image72-5-5.png "image")  
    { .post-img }
    Figure: You open as administrator by right clicking on the icon

    You must be running in administrator mode or you will get lots of undecipherable errors.

    ### **#3 Unpack the files that you need from Windows8-RT-KB2849636-x64.msu**

    ![image](images/image73-6-6.png "image")  
    { .post-img }
    Figure:

    To do this you need to execute the following command:

    ```
    Expand –F:* C:tempWindows8-RT-KB2849636-x64.msu C:temp
    ```

    ### **#4 Now execute an install of the correct update directly**

    ![image](images/image74-7-7.png "image")  
    { .post-img }
    Figure:  Install the KB2849636 Patch manually

    Run the following command to install KB2849636 manually making sure that you replace “-x64” with “-x32” or “-arm” depending on the version the file that you have.

    ```
    DISM.exe /Online /Add-Package /PackagePath:c:tempWindows8-RT-KB2849636-x64.cab
    ```

    ### **#5 DONE - Reboot**

    ![image](images/image75-8-8.png "image")  
    { .post-img }
    Figure: You now get a message to update

    #### Problem #2: The Windows 8.1 Preview isn’t available right now. Please try again later.

    You may still have a problem if you installed Windows with a non US language version…

    ![image](images/image76-9-9.png "image")  
    { .post-img }
    Figure: Go ahead and install

    Everything looks fine… but…

    ![image](images/image77-10-10.png "image")  
    { .post-img }
    Figure: The Windows 8.1 Preview isn’t available right now. Please try again later.

    If you get this message than you will have to install a clean copy of windows… goto #3…

    ## Solution #3 – Install a clean copy of Windows 8.1 Preview

    There are two options for this. If you [download the Windows 8.1 Preview ISO files](http://windows.microsoft.com/en-us/windows-8/preview-iso) and you have Windows 8 you can mount it by just double-clicking the file or  “Right-click | Mount” it. This will add it as if it was a CD ROM and allow you to execute the install.

    ![image](images/image78-11-11.png "image")  
    { .post-img }
    Figure: Windows 8.1 Preview install from scratch

    You can also burn the ISO to a DVD or [create a bootable USB](http://www.hanselman.com/blog/StepByStepTurningAWindows7DVDOrISOIntoABootableVHDVirtualMachine.aspx), reboot your computer with it in a drive (not USB 3) and press “F12” to enter the boot loader and select USB to boot from.

    You can however only keep your personal files this way and you will have to reinstall all of your applications once you are up and running…

    ## Conclusion

    Windows 8.1 is awesome but I was only able to use the Windows 8.1 Store Update option on my Tablet that was a US device. My Desktop and my VM’s had to be done with #3 above and nether #1 or #2 worked with an en-GB version of the OS.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-28-windows-8-1-preview-issue-the-update-is-not-applicable-to-your-computer\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-28-windows-8-1-preview-issue-the-update-is-not-applicable-to-your-computer
- FrontMatter:
    title: 'Issue [ TFS 2013 Preview ] TF400654: Unable to configure Planning Tools'
    description: Resolve the TF400654 error in TFS 2013 Preview with our step-by-step guide. Learn to configure Planning Tools and streamline your process template.
    ResourceId: vjwgG3uy0lI
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9911
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-27
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: issue-tfs-2013-preview-tf400654-unable-to-configure-planning-tools
    aliases:
    - /resources/vjwgG3uy0lI
    - /resources/blog/issue-tfs-2013-preview-tf400654-unable-to-configure-planning-tools
    aliasesArchive:
    - /blog/issue-tfs-2013-preview-tf400654-unable-to-configure-planning-tools
    - /issue-tfs-2013-preview-tf400654-unable-to-configure-planning-tools
    - /issue-[-tfs-2013-preview-]-tf400654--unable-to-configure-planning-tools
    - /blog/issue-[-tfs-2013-preview-]-tf400654--unable-to-configure-planning-tools
    - /resources/blog/issue-tfs-2013-preview-tf400654-unable-to-configure-planning-tools
    tags:
    - Troubleshooting
    - Install and Configuration
    - System Configuration
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-2-2.png
  BodyContent: |
    If you have the ‘team field’ enabled you will receive a “TF400654: Unable to configure Planning Tools” when you try to use the automatic configuration.

    > \[Error\] TF400654: Unable to configure Planning Tools. The following element contains an error: TypeFields/TypeField\[type='Team'\]. TF400517: The value of this element is set to: HinshLabs.Team. You must set the value to a field that exists in all of the work item types that are defined in Microsoft.FeatureCategory. The field does not exist in the following work item types: Feature.

    ![image](images/image40-1-1.png "image")  
    { .post-img }
    Figure: TF400654 Unable to configure Planning Tools

    ## Applies to

    - Team Foundation Server 2013 Preview

    ## Findings

    When you get a “TF400654 Unable to configure Planning Tools” error after an upgrade and you are trying to ‘configure’ the new features that have been added to TFS it is because you have customised the Process Template. The “Configure Features” wizard does a really good job of figuring out which process template and

    - Changed to use ‘team field’
    - Modifying the States

    In the case of the ‘team field’ I am really hoping that they will be able to fix this for the RTM. The Field ‘HinshLabs.Team’ is already there in the Collection and if the wizard could just add it to the fields of the vanilla Feature and then pick a known UI point to add it. The customer can always move it later but this would give them a much slicker experience…

    ## Solution

    You need to manually update your process template by following the instructions on the link provides or you can follow [Upgrading to Visual Studio Scrum 3.0 process template in TFS 2013](http://nkdagility.com/upgrading-to-visual-studio-scrum-3-0-process-template-in-tfs-2013/).

    1. Download the Visual Studio Scrum 3.0 Process Template
    2. Edit Task, Bug, Product Backlog Item, Issue and Feature to have the same custom field… in this case “HinshLabs.Team”
    3. Re-implement any other customisations that you had
    4. Import the work items

    This process is much easier and less time consuming if you have only [One Team Project](http://nkdagility.com/one-team-project-collection-to-rule-them-allconsolidating-team-projects/) or use the same Process Template across all of your Team Projects.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-27-issue-tfs-2013-preview-tf400654-unable-to-configure-planning-tools\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-27-issue-tfs-2013-preview-tf400654-unable-to-configure-planning-tools
- FrontMatter:
    title: Customise the colours in Team Foundation Server 2013 Agile Planning Tools
    description: Learn how to customize colors in Team Foundation Server 2013 Agile Planning Tools for better visibility and organization of work items. Enhance your workflow now!
    ResourceId: 2kvi44Dp0xl
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9682
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-27
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: customise-the-colours-in-team-foundation-server-2013-agile-planning-tools
    aliases:
    - /resources/2kvi44Dp0xl
    aliasesArchive:
    - /blog/customise-the-colours-in-team-foundation-server-2013-agile-planning-tools
    - /customise-the-colours-in-team-foundation-server-2013-agile-planning-tools
    - /resources/blog/customise-the-colours-in-team-foundation-server-2013-agile-planning-tools
    tags:
    - Install and Configuration
    - System Configuration
    categories:
    - Uncategorized
  BodyContent: |
    If you want to customise the colours in Team Foundation Server 2013 Agile Planning Tools you need to download and edit the Process Configuration file that tells TFS how to configure many of the features in the Web Access.

    There used to be two files in Team Foundation Server 2012 but this was confusing and the amalgamation to a single configuration file just made sense.

    [![image47](images/image47_thumb-1-1.png "image47")](http://nkdagility.com/files/2013/06/image471.png)  
    { .post-img }
    Figure: Colour coded Work Item Types are easy to distinguish

    The colours that you pick will be displayed wherever a work item is displayed. Wither that is in a list or a card on one of the boards the same coloured bar will be displayed on the left. This really helps distinguish between them and highlights things like Bugs in a list of Product Backlog Items.

    To configure this we need to first export (download) the existing processing configuration to a location we can find.

    ```
    $TeamProjectName = "teamswithareas"
    $tempFolder = "C:temp"
    $CollectionUrl = "http://kraken:8080/tfs/tfs01"
    $WitAdmin = "${env:ProgramFiles(x86)}Microsoft Visual Studio 12.0Common7IDEwitadmin.exe"

    # Export the existing Processing configuration
    & $WitAdmin exportprocessconfig /collection:$CollectionUrl /p:$TeamProjectName /f:"$tempFolderProcessConfiguration.xml"
    ```

    Once you have that we need to find and edit the colours and Paint as usual does not cut the mustard. You will need to know the hex value of the colours and that can be easily found if you use something like Paint.Net or [http://www.colorpicker.com/](http://www.colorpicker.com/ "http://www.colorpicker.com/") where they let you pick colours.

    Note These colours are 8 digit HEX as they include transparency. The first two digits are the setting for transparency and “FF” denotes fully visible.

    ```
    <workitemcolors>
      <workitemcolor name="Product Backlog Item" secondary="FFD6ECF2" primary="FF009CCC" />
      <workitemcolor name="Feature" secondary="FFEEE2F2" primary="FF773B93" />
      <workitemcolor name="Task" secondary="FFF6F5D2" primary="FFF2CB1D" />
      <workitemcolor name="Bug" secondary="FFFAEAE5" primary="FFCC293D" />
      <workitemcolor name="Code Review Request" secondary="FFFCEECF" primary="FFFF9D00" />
      <workitemcolor name="Code Review Response" secondary="FFFCEECF" primary="FFFF9D00" />
      <workitemcolor name="Feedback Request" secondary="FFFCEECF" primary="FFFF9D00" />
      <workitemcolor name="Feedback Response" secondary="FFFCEECF" primary="FFFF9D00" />
      <workitemcolor name="Impediment" secondary="FFFCEECF" primary="FFFF9D00" />
      <workitemcolor name="Shared Steps" secondary="FFFCEECF" primary="FFFF9D00" />
      <workitemcolor name="Test Case" secondary="FFFCEECF" primary="FFFF9D00" />
    </workitemcolors>
    ```

    If you open the XML and look for the “workitemcolors” element (no idea why they insist on spelling it wrong) you will find an entry for each of the Work Item Types available.

    ```
    $TeamProjectName = "teamswithareas"
    $tempFolder = "C:Temp"
    $CollectionUrl = "http://kraken:8080/tfs/tfs01"
    $WitAdmin = "${env:ProgramFiles(x86)}Microsoft Visual Studio 12.0Common7IDEwitadmin.exe"

    # Import the new Processing configuration
    & $WitAdmin importprocessconfig /collection:$CollectionUrl /p:$TeamProjectName /f:"$tempFolderProcessConfiguration.xml"
    ```

    All we need to do is edit the colour codes and then import (upload) the process configuration again. Here I am going to change the PBI to Pink (#FF16D0) which has a value of FFFF16D0 with a secondary (faded) colour of FFFFD1D0.

    ![image](images/image64-2-2.png "image")  
    { .post-img }
    Figure: Lovely pink PBI’s

    And voilà you now have just what you always wanted… pink PBI’s.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-27-customise-the-colours-in-team-foundation-server-2013-agile-planning-tools\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-27-customise-the-colours-in-team-foundation-server-2013-agile-planning-tools
- FrontMatter:
    title: Configure features in Team Foundation Server 2013
    description: Unlock the full potential of Team Foundation Server 2013 by configuring essential features with our step-by-step guide. Enhance your project management today!
    ResourceId: MbkXNCfuEU2
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9912
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-26
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: configure-features-in-team-foundation-server-2013
    aliases:
    - /resources/MbkXNCfuEU2
    aliasesArchive:
    - /blog/configure-features-in-team-foundation-server-2013
    - /configure-features-in-team-foundation-server-2013
    - /resources/blog/configure-features-in-team-foundation-server-2013
    tags:
    - Install and Configuration
    categories:
    - Uncategorized
  BodyContent: |
    So you have upgraded to Team Foundation Server 2013 but you still don’t have some of the features that you upgraded for. There is a wizard for that but it is not supper discoverable that allows you to configure features in Team Foundation Server 2013.

    Note If you want to completely replace your current process template with the new on you can follow [Upgrading to Visual Studio Scrum 3.0 process template](http://nkdagility.com/upgrading-to-visual-studio-scrum-3-0-process-template-in-tfs-2013/) instead.

    - [Get Visual Studio 2013 & Team Foundation Server 2013 while its hot!](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/)

    This processes will, depending on the version of TFS that you are upgrading from, add one or more features to your Team Project that are not enabled by default. Strait off  the bat you will get Team Rooms and the new Test hub functionality as well as the better placement and access to the Boards. However you will see a distinct lack of a Feature backlog. This Feature backlog needs a new work item type “Feature” and a a change to the configuration of the underlying boards to support it.

    Luckily the TFS Product Team think of everything and have provided a wizard that works in 90% of cases.

    ![image](images/image41-1-1.png "image")  
    { .post-img }
    Figure: Open “Team Project | Control Panel”

    You need to go to your Team Projects Control Panel by clicking on the little cog on the top right of Web Access, right next to your name.

    ![image](images/image42-2-2.png "image")  
    { .post-img }
    Figure: Click “Overview | Project Profile | Configure features”

    I am not sure about the placement and discoverability of this panel, but then it is a preview and they may stick it somewhere else. I would like to see a “Features” hub where I can enable and disable features and maybe a dismissible call to action near the heading for enabling things that are new.

    > As a Team Administrator I would like to have a Feature hub where I can enable or disable specific features for my teams  
    > Suggestion for TFS

    Anyhoo, you can click “Configure features” to get started.

    Note If you are coming from TFS 2008 or TFS 2010 you will get a much more prominent “Configure features” option as none of the Boards will work without configuring.

    ![image](images/image43-3-3.png "image")  
    { .post-img }
    Figure: Discover which features to configure in Team Foundation Server 2013

    The configure features in Team Foundation Server 2013 wizard will then let you know what features will be configured. You can see here that I am coming from a Team Foundation Server 2012 instance as I already have most of those features enabled. Go ahead and verify…

    ![image](images/image44-4-4.png "image")  
    { .post-img }
    Figure: Check the Process Template match before you configure features in Team Foundation Server 2013

    When you verify the configure features in Team Foundation Server 2013 wizard will identify which process template best matches so that it can load the settings from that template. If you get an error at this point because it can’t match the Process Template then you may need to manually configure and there will be a link on the screen to do that.

    - [Issue \[ TFS 2013 Preview \] TF400654: Unable to configure Planning Tools](http://nkdagility.com/issue-tfs-2013-preview-tf400654-unable-to-configure-planning-tools/ "TF400654: Unable to configure Planning Tools")

    ![image](images/image45-5-5.png "image")  
    { .post-img }
    Figure: Congratulations

    And that's it.. you are done…

    ![image](images/image46-6-6.png "image")  
    { .post-img }
    Figure: Start using your new features

    At this point you should now have access to the new awesome features. Now go play…

    - [Get Visual Studio 2013 & Team Foundation Server 2013 while its hot!](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/)

    Be a kid again…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-26-configure-features-in-team-foundation-server-2013\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-26-configure-features-in-team-foundation-server-2013
- FrontMatter:
    title: What's new in Visual Studio 2013 Team Foundation Server Preview
    description: Discover the latest features in Visual Studio 2013 Team Foundation Server! Enhance your agile practices with powerful tools for collaboration and testing.
    ResourceId: V5OQtr0U1IS
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9677
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-26
    weight: 740
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: get-visual-studio-2013-team-foundation-server-while-its-hot
    aliases:
    - /resources/V5OQtr0U1IS
    - /resources/blog/what-s-new-in-visual-studio-2013-team-foundation-server-preview
    aliasesArchive:
    - /blog/get-visual-studio-2013-team-foundation-server-while-its-hot
    - /get-visual-studio-2013-team-foundation-server-while-its-hot
    - /what's-new-in-visual-studio-2013-team-foundation-server-preview
    - /blog/what's-new-in-visual-studio-2013-team-foundation-server-preview
    - /resources/blog/get-visual-studio-2013-team-foundation-server-while-its-hot
    - /resources/blog/what-s-new-in-visual-studio-2013-team-foundation-server-preview
    tags:
    - Software Development
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-14-14.png
  BodyContent: |
    Steve Ballmer just announced the Visual Studio 2013 Go-Live preview at the Build summit not more than an hour ago so get Visual Studio 2013 Team Foundation Server while its hot! Remember that this Preview is covered by a Go-Live licence and is fully supported for production use.

    There are tones of new features in both Visual Studio 2013 and Team Foundation Server 2013 and we are all interested in the new Visual Studio ALM features.

    [![Visual Studio 2013 Download](images/728x90_VSvNext_Here_EN_US-1-1.gif "Download Visual Studio 2013 now!")](http://nkdagility.com/vs2013Preview/)
    { .post-img }

    Go get the download started and while you are waiting let me show you three of the new killer ALM features that you will love:

    - **Agile Portfolio Management with Team Foundation Server 2013** – versatile and customisable multi level backlogs
    - **Team Collaboration with Team Foundation Server 2013** – Unlimited Team Rooms for collaboration
    - **Testing with Team Foundation Server 2013** – Web based test management and execution

    Let look at each one…

    ## Agile Portfolio Management with Team Foundation Server 2013

    With the recent announcement of Visual Studio 2013 and some of the bigger rocks that the team have been working on. There will be many, many more announcements, but the bits that I have been waiting on have already arrived on Team Foundation Service. What is amusing is that Team Foundation Service is already a Sprint ahead and there are even more features on there. Its Sprint 48 in the Team Foundation Server 2013 Preview and they are already on Sprint 49 on Team Foundation Service. I am going to try and do a point in time look at the features and will be mentioning both as many of the features that are currently in the service will hit the server on the next drop…

    ### Main Attributes of Agile Portfolio Management

    The new Agile Portfolio Management features are by far my favourite. We have been creating work arounds for years as these features are sorely needed. At last they are here…

    ![image](images/image50-2-2.png "image")  
    { .post-img }
    Figure: Top 4 changes with Agile Portfolio Management in 2013

    We can start with the idea that we get multiple backlogs. The purpose here is to have high level items at the top and then break them down into smaller items. In the new Out-of-the-box template you get Features that break down into Product Backlog Items. Features are something that transcend a single sprint add you may have to complete many Product Backlog Items across multiple Sprints and maybe even Releases to achieve them.

    Add to that the ability to look-up or look-down from that backlog to see how those items fit into the grand schema and you get a powerful Portfolio Management capability while still maintaining your agility.

    Up until now the “board” buttons have been a little confusing as they were on different menus and it was difficult to fathom the navigation between them. Now all of the boards are on the same level and this enables the additional feature of being able to view the boards of each sprint as well as the current one. That one was a much requested feature and now it is here..

    ### From the current backlog you can look-up or look-down

    This is going to be a little bit confusing to explain for Team Foundation Server 2013 as this feature is ‘almost’ there.

    ![image](images/image51-3-3.png "image")  
    { .post-img }
    Figure: Navigating Portfolio Management

    If I am looking at my list of “Backlog Items”, selected above, I get the usual list of Product Backlog Items that I can order and reorder. But I may want to look, from here, **down** at how they are broken down into tasks or up and which **features** they are related to. If my team comes to me and identifies a blocked task I want to see what the impact is up the chain. Conversely if the business want to reprioritise a Feature then I might want to see which backlog items I need to reorder.

    Once you are in this mode however you can’t currently reorder the items as you \[cant reorder a hierarchy\] and you need to switch back to the flat list to perform that task.

    ### Adding PBI’s to Features

    There have been parentchild relationships in Team Foundation Server since they were introduced in TFS 2010 but the new tools that are being built on top of that core capability are starting to really take advantage of it.

    ![image](images/image53-4-4.png "image")  
    { .post-img }
    Figure: Adding a new Product Backlog Item to a Feature

    By far the easiest way to break an item down is to open it and use the Implementation tab. The Feature is no exception and you can easily open it and start creating children.

    ![image](images/image54-5-5.png "image")  
    { .post-img }
    Figure: Adding an existing Product Backlog Item to a Feature

    When you add a parent or child as an existing item in the Web Access you need to know the ID of one or the other. You open the work item, add  link and add the ID. It will lazy load it to give you a hint that you have the right one but that is about it. In Visual Studio you get a rich search function to help you…

    Again as people start to use the new features the product team are getting feedback and iteratively delivering more value to us.

    ### Portfolio Backlogs

    I have been told that you can have up to seven levels of work items from Task at the bottom all the way up. While anyone that has seven levels is ridiculously dysfunctional having a few lets us have different management levels prioritising their needs and seeing that priority reflected at each level.

    Some of the demos I have seen have the following hierarchy:

    - **Goal** – Embodies the 5-10 high level strategic goals that the organisation has and is likely owned by strategic leadership
    - **Feature** – A list of features that reflects what the business need and when it should be delivered and is likely owned by Product Owner Office (POO)
    - **Product Backlog Item** – Owned by the Product Owner it embodies their order for delivery

    This gives you both the flexibility and visibility require to transparently present each levels desires.

    ### Colour coding of work items

    Making it easier to to tell the work items apart. Watch out for a post on Friday telling you how...

    ![image](images/image56-6-6.png "image")  
    { .post-img }
    Figure: Colour code each of your Work Item Types

    Each of the Work Item Types are represented on all of the boards by a different colour. This colour can be configured and gives you a left pipe of that colour for lists and cards alike.

    ## Team Collaboration with Team Foundation Server 2013

    Team collaboration is a major focus of the product team this time around. We just discussed features for hierarchical teams but what about getting the communication lines flowing. Email is painful and IM is not persistent enough so there must be some middle ground. In the old days teams used IRC chat and today there are a plethora of these sorts of tools for the community. Many such tools for agile teams are starting to spring up and the TFS team needed a solution as well.

    ![image](images/image57-7-7.png "image")  
    { .post-img }
    Figure: Team Room

    Each Team gets a Team Room link right on their dashboard that takes them to that teams room. You can create any rooms that you like with any members that you like in addition to the default room.

    ![image](images/image58-8-8.png "image")  
    { .post-img }
    Figure: You can tag people and work items

    When you are typing messages you can tag people and work items to allow you to have a much more interactive experience. Try it… I think you will be surprised how useful it is.

    ![image](images/image59-9-9.png "image")  
    { .post-img }
    Figure: Create alerts

    You can create ‘alerts’ that ping onto the team room when work items are edited or is a build completes. You can even have an alert when code changes. These features make team rooms very effective, but be warned… you should have small agile teams for this to work. That does not mean that you can’t have 50 people working on a single product but it does mean that they will probably operate as at least 5 teams…

    ## Testing with Team Foundation Server 2013

    The Test tools were introduced in Team Foundation Server 2010 and made to work in Team Foundation server 2012. From Team Foundation Server 2012 QU2 you have been able to create and edit tests cases in the Web Access and even to run those tests.

    ![image](images/image60-10-10.png "image")  
    { .post-img }
    Figure: Creating Test plans and Suits in the Web Access

    Now that we are in the first, and early, stages of Team Foundation Server 2013 we can add Test Plan and Test Suite management to that already powerful capability. This allows us to spend more of out time in the web access and enables both user acceptance testing and cross platform capabilities.

    ![image](images/image61-11-11.png "image")  
    { .post-img }
    Figure: Edit augmentations in Team Foundation Server 2013

    While we were able to edit test steps in the web form 2012.2 there are a plethora of small but significant improvements to the UI that make it eminently more usable. The tabbing has been improved and it is now really intuitive to manage the test steps here. You can even add attachments to a test step which I know a few of my customers asked for.

    ![image](images/image62-12-12.png "image")  
    { .post-img }
    Figure: Test Runner in the Web Access for Team Foundation Server 2013

    With the web based test runner you get cross platform web test results and while you don’t get the fantastic data adapters that you get in Microsoft Test Manager you do get awesome abilities. If your test team are anything like my customers you might be using Excel and Word to store you test cases and can’t figure our which tests you have run against which build or even if they have been run at all.

    Even if you are just using the web capabilities you get reporting and coverage information at your fingertips.

    ![image](images/image63-13-13.png "image")  
    { .post-img }
    Figure: Creating bugs was never easier

    Even though we don’t have the rich data adapters we still get our steps to reproduce filled out for us… and you can’t turn your nose up at that.

    ## Conclusion

    These are but a few of the new features in Team Foundation Server 2013 let alone what is available in Visual Studio 2013 for developers and don’t forget the new iterative nature of feature delivery mean that thing just keep getting better Sprint on Sprint…

    [![Visual Studio 2013 Download](images/728x90_VSvNext_Here_EN_US-1-1.gif "Download Visual Studio 2013 now!")](http://nkdagility.com/vs2013Preview/)
    { .post-img }

    I have already done one upgrade of a customers two terabyte TFS 2012 instance with no issues and I am hopefully working on my next one as you read this… Download, install & Play… be a kid again with Team Foundation Server 2013.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-26-get-visual-studio-2013-team-foundation-server-while-its-hot\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-26-get-visual-studio-2013-team-foundation-server-while-its-hot
- FrontMatter:
    title: Upgrading to Team Foundation Server 2013
    description: Upgrade to Team Foundation Server 2013 effortlessly! Discover essential tips, backup strategies, and a smooth installation process for your TFS environment.
    ResourceId: Ni5lk4V30pb
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9907
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-26
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: upgrading-to-team-foundation-server-2013
    aliases:
    - /resources/Ni5lk4V30pb
    aliasesArchive:
    - /blog/upgrading-to-team-foundation-server-2013
    - /upgrading-to-team-foundation-server-2013
    - /resources/blog/upgrading-to-team-foundation-server-2013
    tags:
    - Software Development
    - Install and Configuration
    - System Configuration
    - Windows
    categories:
    - Uncategorized
  BodyContent: |
    With the release of Team Foundation Server 2013 I need to upgrade all of my servers. I have a few customer installs getting prepped and I wanted to get a look see.

    I run a TFS server locally to do demos; prove out the existence, or lack, of bugs; and to figure out what is going on under the covers. This server (Kraken) is a virtual machine running locally and can easily be backed up and restored. My recommendation is to never attempt an upgrade without a backup and preferably upgrade to a new server.

    - Update 2013-07-23 - Another seamless upgrade. This time with 8 collection and then a consolidation down to a single Team Project

    - [Get Visual Studio 2013 & Team Foundation Server 2013 while its hot!](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/)

    The main reason for a new server is that there are some major changes to the OS as part of the Team Foundation Server install. There is usually some sort of .NET update as well as core Windows components. Backup and Snapshot or use a new VM its up to you…

    ![image](images/image12-1-1.png "image")  
    { .post-img }
    Figure: Taking a backup is easy with Scheduled Backups on Team Foundation Server 2012

    My first order of business is to take an in place backup and a snapshot of my VM. In this case I am upgrading in place and I can rollback with both of these options. If you are moving to a new server and will be changing the location of the backups make sure you check out [TFS 2012.3 Issue – Scheduled Backups gives a TF400998 when reconfigured](http://nkdagility.com/tfs-2012-3-issue-scheduled-backups-gives-a-tf400998/) as I ran into a little issue with that recently. It is most likely to occur when also doing a domain migration, but can just be moving servers.

    ![image](images/image13-2-2.png "image")  
    { .post-img }
    Figure: Set the Install path for Team Foundation Server 2013

    I always opt for the default path and recommend that you do the same. This is no value to moving it to another disk and that only adds complexity. Certainly have all of your data on another disk, but putting files that you need to reinstall anyway on another disk is a little silly.

    ![image](images/image14-3-3.png "image")  
    { .post-img }
    Figure: Installing Team Foundation Server 2013

    The install is smooth as always and the polish is amazing. The only thing that I can grip about is the need to reboot.

    ![image](images/image15-4-4.png "image")  
    { .post-img }
    Figure: Rebooting during install of Team Foundation Server 2013

    I always feel that this is unnecessary but when you are talking about some of the core components for Windows I guess you have to just suck it up and reboot.

    ![image](images/image16-5-5.png "image")  
    { .post-img }
    Figure: 5 minutes later we have Team Foundation Server 2013 installed

    No really, it only took 5 minutes to install and I did not prep the machine at all. I am however using Windows Server 2012 with SQL Server 2012 and I have the latest updates for both. And that includes **SQL Server 2012 SP1 which is required** for Team Foundation Server 2013.

    - [Download Service Pack 1 for Microsoft® SQL Server® 2012](http://www.microsoft.com/en-us/download/details.aspx?id=35575)

    After you have everything up to scratch you can go ahead and configure. I will be using the Upgrade wizard but you may be installing from scratch so read the text on the right for each option carefully to get it right. Pay close attention to anything that mentions SQL Express as you may or may not want that.

    ![image](images/image17-6-6.png "image")  
    { .post-img }
    Figure: Running the Upgrade gauntlet with Team Foundation Server 2013

    Running the upgrade is pretty easy but you will need a few bits of information. First up is the acceptance that you do indeed have a backup. If you don’t… go make one now… yes… even if this is your trial box. Have a backup..

    ![image](images/image18-7-7.png "image")  
    { .post-img }
    Figure: Renter your service account for Team Foundation Server 2013

    As all of the account details are encrypted and as a security measure for your data you need to re-enter your passwords to connect everything up. Enter the password and click “test'”.. did you get a green tick?

    ![image](images/image19-8-8.png "image")  
    { .post-img }
    Figure: Configure reporting services for Team Foundation Server 2013

    As I have all of the reporting bits installed I will need to configure them. SharePoint however I don’t have here, but I will be creating another post for that.

    ![image](images/image20-9-9.png "image")  
    { .post-img }
    Figure: Validate your Report Server Instance for Team Foundation Server 2013

    Most of these screens are just validation and while I am restoring to the same server you may be having to change a few things to match a new environment. If you are moving your reporting services server off to another environment you should un-tick the box on the first screen for Reporting and reconfigure it after.

    Once you have validated all of the details and entered the Report Reader account password (did you get all green ticks) you can move on to the upgrade validation step (remember I have no SharePoint here.)

    ![image](images/image21-10-10.png "image")  
    { .post-img }
    Figure: Validate that the settings are correct for Team Foundation Server 2013

    The Readiness Checks make sure that everything that can be checked is. It validates that what you entered works and that the servers and services are available. It checks permissions and access so you are fairly certain at this point that everything will work. There be odd and occasional data issues but I rarely see them beyond server that have multi terabyte databases.

    I get a TF255193 warning because I am using the same account for reporting as for the TFS Service account and that is deemed a risk. On a production box I agree, here I don't care.

    ![image](images/image22-11-11.png "image")  
    { .post-img }
    Figure: Upgrading the Configuration data of Team Foundation Server 2013

    The upgrade really happens in three stages. The first stage is the flat installation of the files. TFS 2012 has been uninstalled and the new bits for Team Foundation Server 2013 which we did before we started any configuration of Team Foundation Server.

    ![image](images/image23-12-12.png "image")  
    { .post-img }
    Figure: Success at upgrading the Configuration to Team Foundation Server 2013

    The second is the setup of the system and upgrade of the Configuration database. This sets up IIS, creates the websites, application pools and configures reporting before upgrading the Configuration database. And we have not yet even looked at the collections

    ![image](images/image24-13-13.png "image")  
    { .post-img }
    Figure: Collections upgrade asynchronously in Team Foundation Server 2013

    Each of the Team Project Collection will be attached and upgraded asynchrony and the bigger they are the longer they take. In this case I don’t have a Team Project Collection over a couple of gig and it was all over in under 10 minutes. Now you may be thinking "But Martin you have a really small databases of course it only took 10 minutes but I have more data". Well for this I wanted to maintain a table of expectant times as this has often been a common:

    How long does it take to upgrade to TFS 2013?
    | Instance | Source Version | Component | Size | Time to complete (m) |
    | --- | --- | --- | --- | --- |
    | #1 - Sandbox | 2012.3 RC2 | Configuration | 1054.88 MB | <1 |
    | Tfs01 (Collection) | 727.06 MB | <2 |
    | Tfs02 (Collection) | 142.63 MB | <1 |
    | Tfs_MTest (Collection) | 217.31 MB | <1 |
    | Collection #4 | 156.63 MB | <1 |
    | #2 - Customer | 2012.2 | Configuration | 100GB | <2 |
    | Collection #1 | 1GB | <1 |
    | Collection #2 | 2TB | <4 |
    | #3 - Customer | 2012.1 | Configuration | 0.5GB | <3 |
    | Collection #1 | 40GB | <5 |
    | #4 - Customer | 2012 (RTM) | Configuration | 1GB | <4 |
    | Collection #1 | 1GB | <5 |
    | Collection #2 | 1GB | <4 |
    | Collection #3 | 1GB | <6 |
    | Collection #4 | 1GB | <6 |
    | Collection #5 | 2GB | <8 |
    | Collection #6 | 1GB | <8 |
    | Collection #7 | 1GB | <5 |
    | Collection #8 | 1GB | <9 |

    ![image](images/image25-14-14.png "image")  
    { .post-img }
    Figure: Success upgrading to Team Foundation Server 2013

    This upgrade was totally painless (which does not mean that yours will be) and I could not believe that the Team Foundation Server Product Team would yet again make it easier but it just seams a little slicker than before.

    So did it work?

    ![image](images/image26-15-15.png "image")  
    { .post-img }
    Figure: Successful upgrade to Team Foundation Server 2013

    Awesome.. Now all I have to do is upgrade the process templates to the new version and I will get all of the awesome features.

    Guess what I am doing next?

    ## Conclusion

    I would definitely recommend that you move to Team Foundation Server 2013 as soon as you are able, especially if you are on 2012.3 already. If you are happy to work with Go-Live then you should look no further than 2013… at least until 2013.1 comes around…

    - [Get Visual Studio 2013 & Team Foundation Server 2013 while its hot!](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/)

    Go download it now and be a kid again…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-26-upgrading-to-team-foundation-server-2013\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-26-upgrading-to-team-foundation-server-2013
- FrontMatter:
    title: Installing Visual Studio 2013 on Server 2012
    description: Learn how to install Visual Studio 2013 on Server 2012 effortlessly. Follow this guide for a quick setup and explore new features to enhance your development!
    ResourceId: LAt1NHw5pbR
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9908
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-26
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: installing-visual-studio-2013-on-server-2012
    aliases:
    - /resources/LAt1NHw5pbR
    aliasesArchive:
    - /blog/installing-visual-studio-2013-on-server-2012
    - /installing-visual-studio-2013-on-server-2012
    - /resources/blog/installing-visual-studio-2013-on-server-2012
    tags:
    - Install and Configuration
    categories:
    - Uncategorized
  BodyContent: |
    I will be installing Visual Studio 2013 on Server 2012 side-by-side with Visual Studio 2012 on my development rig.

    Installing and configuring Visual Studio has always been a cinch and Visual Studio 2013 is no exception. As most of you know I always run developer tools in a VM. The main reason for this is the ability to reinstall my host OS and get up and running very quickly. So for example when Windows8.1 becomes available I will not have to think twice about upgrading and just do it. I will be back up and running with Visual Studio in my VM within 15 minutes of starting the process. This level of flexibility is awesome.

    - [Get Visual Studio 2013 & Team Foundation Server 2013 while its hot!](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/)

    In this case both Visual Studio 2012 and Visual Studio 2013 will live side by side on the same system. This has been the case for every major Visual Studio release and I know folks that have Visual Studio 2005 as well.

    ![image](images/image27-1-1.png "image")  
    { .post-img }
    Figure: Visual Studio 2013 Ultimate install is huge

    One thing I did note is that the installation requirements have jumped from 7.5GB to over 11GB for Visual Studio 2013 Ultimate. I am not sure what they are for Premium or Professional but this is fairly hefty. It is however no big deal and I am happy to give up the space for Visual Studio.

    ![image](images/image28-2-2.png "image")  
    { .post-img }
    Figure: Choose what to install with Visual Studio 2013

    As a rule I always install everything, which is the default. Too many times I have been hit by missing features whenever I don’t. Its up to you, but removing features does not free up that much disks space as it is the core of Visual Studio that is the largest component by far.

    ![image](images/image29-3-3.png "image")  
    { .post-img }
    Figure: Installing Visual Studio 2013 Ultimate

    The install itself will take no linger than 5-10 minutes (I am running on SSD’s) unless you have to “Acquire” the contents. I have everything downloaded in an ISO so do need to reach out to the internet for anything large.

    ![image](images/image30-4-4.png "image")  
    { .post-img }
    Figure: Reboot during install of Visual Studio 2013 Ultimate

    There are a lot of new features under the covers and you may need to reboot, as I did, before you can complete the install.

    ![image](images/image31-5-5.png "image")  
    { .post-img }
    Figure: Successful installation of Visual Studio 2013 Ultimate

    And that's it… the install end to end including the reboot took less than 10 minutes and I had no errors on a box that has been around the block with preview versions of all sorts of things.

    ![image](images/image32-6-6.png "image")  
    { .post-img }
    Figure: New Launch has optional Microsoft ID

    As a sign of the times you can optionally log into Visual Studio 2013 with your Microsoft ID. Its not required, but I expect that for things like [http://tfs.visualstudio.com](http://tfs.visualstudio.com) it will make things simpler. You should however be aware that this will likely at some point link into the MSDN licence that you have associated with your Microsoft ID. I currently have no evidence that this is the case but it is a logical next step.

    I want all of the cool integrated experiences of Visual Studio linking seamlessly to [http://tfs.visualstudio.com](http://tfs.visualstudio.com) and with my Azure account so I will be signing in.

    ![image](images/image33-7-7.png "image")  
    { .post-img }
    Figure: Links into normal Microsoft ID login

    Not only does it just display the right stuff it worked seamlessly with two-step authentication that I have enabled. I just entered my code when prompted and away I go.

    ![image](images/image34-8-8.png "image")  
    { .post-img }
    Figure: Enter your details for Visual Studio 2013

    If you log in with your live credentials you will need to accept the new Terms of Service and provide a few other details.

    ![image](images/image35-9-9.png "image")  
    { .post-img }
    Figure: Configure Visual Studio 2013 how you like

    Then all you need to do is chose your theme and development settings. Again you guys know I am a stickler for defaults and her is no exception. But you should experiment to see what you like as all of these options are available in “Tools | Options” in the IDE.

    ![image](images/image36-10-10.png "image")  
    { .post-img }
    Figure: New Visual Studio 2013 UI

    The new UI looks fairly clean and the new Team Explorer interaction looks a lot more intuitive. Only time will tell and I am sure that I will have lots of information for you as I use it more.

    - [Get Visual Studio 2013 & Team Foundation Server 2013 while its hot!](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/)

    Go download it now and be a kid again…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-26-installing-visual-studio-2013-on-server-2012\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-26-installing-visual-studio-2013-on-server-2012
- FrontMatter:
    title: Upgrading to Visual Studio Scrum 3.0 process template in TFS 2013
    description: Upgrade your TFS 2013 with the Visual Studio Scrum 3.0 Process Template. Follow our simple steps to enhance your project management and agile practices!
    ResourceId: hp378aoGMNz
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9913
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-26
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: upgrading-to-visual-studio-scrum-3-0-process-template-in-tfs-2013
    aliases:
    - /resources/hp378aoGMNz
    - /resources/blog/upgrading-to-visual-studio-scrum-3.0-process-template-in-tfs-2013
    aliasesArchive:
    - /blog/upgrading-to-visual-studio-scrum-3-0-process-template-in-tfs-2013
    - /upgrading-to-visual-studio-scrum-3-0-process-template-in-tfs-2013
    - /resources/blog/upgrading-to-visual-studio-scrum-3-0-process-template-in-tfs-2013
    - /resources/blog/upgrading-to-visual-studio-scrum-3.0-process-template-in-tfs-2013
    tags:
    - Install and Configuration
    - Software Development
    categories:
    - Uncategorized
  BodyContent: |
    You want to upgraded to the Visual Studio Scrum 3.0 Process Template in Team Foundation Server 2013 but you really want to upgrade your whole process template in place and not jut enable new features.

    This will enable the new features and give you the latest layout. Just like creating a new Team Project but with your data intact.

    Note If you want to only enable the new features in your existing process template you can follow [Configure features in Team Foundation Server 2013](http://nkdagility.com/configure-features-in-team-foundation-server-2013/) instead.

    - [Get Visual Studio 2013 & Team Foundation Server 2013 while its hot!](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/)

    When you upgrade your TFS instance to a new version it does not upgrade the process for any of your existing Team Projects. It is kind of like building a house from blueprints. Once it is built and you have been living in it how happy would you be if the original builder came back and switched the rooms around?

    [![image[2]](images/image2_thumb-1-1.png "image[2]")](http://nkdagility.com/files/2013/06/image210.png)  
    { .post-img }
    Figure: Feature Backlog is missing from Agile Planning tools

    My favourite features in TFS 2013 is the Agile Portfolio Management tools and unless you create a new project you will not get them. I am sure that the product team will include a wizard to add the features once 2013 matures but for right now we need another solution. Indeed when the product team do provide a solution they are usually ‘injecting’ the new features into your already existing template. This means that you don’t get the new template… just the new features. I prefer getting the new template…

    Upgrading your Visual Studio Scrum Team Project to Visual Studio Scrum 3.0 is relatively simple.

    1. Download Visual Studio Scrum 3.0 Process Template from TFS
    2. Re-apply any customisations that you use
    3. Import your new Process Template

    These are all fairly simple steps but you will need to be an Administrator on the Team Foundation Server 2013 Team Project Collection and be using the latest Visual Studio 2013 Team Explorer tools.

    Note No, there is no version of the Power Tools that currently works with Visual Studio 2013. I expect we will see one fairly soon.. just not quite yet.

    ## Download Visual Studio Scrum 3.0 Process Template from TFS

    To get going we need to first download the latest version of the Process Template that we want to move to. In this case it is the Visual Studio Scrum 3.0. To do that we need to use Visual Studio 2013 Team Explorer and be familiar with the WitAdmin.exe tools (remember no Process Template Editor yet and the 2012 tools cant work with the new features.)

    ![image](images/image47-2-2.png "image")  
    { .post-img }
    Figure: Use “Team Explorer | Connect” to pick a Team Project

    We need to be connected to the Team Foundation Server 2013 that we want to get the Process Template from and the easiest way to do this is to connect to any Team Project in the list.

    ![image](images/image48-3-3.png "image")  
    { .post-img }
    Figure: Go to “Team Explorer | Home | Settings”

    While you marvel at the new cleaner UI head on over to the “Settings” option for your project.

    ![image](images/image49-4-4.png "image")  
    { .post-img }
    Figure: Go to “Process Template Manager | Microsoft Visual Studio Scrum 3.0 – Preview | Download”

    We then need only to open the Process Template Manager and download the Process Template to the desktop. If you just select “desktop” the tool will create a folder of the same name as the process template.

    ## Re-apply any customisations that you use

    Now comes the bit that I am only going to give you general guidance on. This one is totally dependant on the types and number of customisations that you have made to your existing template. If you are doing any form of agile and you have not yet migrated to the Visual Studio Scrum process template then I suggest that you do so…

    - [Upgrading your process template from MSF for Agile 4 to Visual Studio Scrum 2.x](http://nkdagility.com/upgrading-your-process-template-from-msf-for-agile-4-to-visual-studio-scrum-2-x/ "Upgrading your process template from MSF for Agile 4 to Visual Studio Scrum 2.x")

    As I have always maintained that the “MSF for Agile” template was designed for and by Microsoft Consulting Services nearly 10 years ago and there is very little ‘agile’ about it. It is a light weight traditional template that will not help you in your quest for agility.

    Anyway… You need to identify all of the customisations that you made to your template and implement them fresh in the new Microsoft Visual Studio Scrum 3.0 template. This will take time and you get to play with the XML until you get it right.

    I would always recommend that you practice on a test server and that you make as minimal changes as you can possibly get away with. Some common legitimate changes to the Scrum template:

    - **Adding Original Estimate and Completed Work on Task** – Pointless in the agile world but gives some of your more Neolithic project managers warm fuzzies.
    - **Enabling ‘team field’ for Teams without Areas** – Many teams already use “Area Path” for product and have a drop down list for Team…

    Once you are happy that your template works and that you data maps you can move onto updating your Team Project.

    ## Import the custom Visual Studio Scrum 3.0 Process Template

    Now that we have our custom Process Template we can go ahead and overwrite our old Visual Studio Scrum 2.0 or 1.0 instances. Remember to test this process as well and the easiest way to do that is to clone your TFS instance to other hardware and try out the upgrades there.

    Note Don’t forget to change the server ID ([tfsconfig changeserverid](http://msdn.microsoft.com/en-us/library/vstudio/ee349259.aspx)) if you are doing a clone ([Jeff](https://twitter.com/tfsjeff).. that means you)

    ```
     Param(
           [string] $CollectionUrlParam = $(Read-Host -prompt "Collection (enter to pick):"),
           [string] $TeamProjectName = $(Read-Host -prompt "Team Project:"),
           [string] $ProcessTemplateRoot = $(Read-Host -prompt "Process Template Folder:")
           )

    $TeamProjectName = "teamswithareas"
    $ProcessTemplateRoot = "C:UsersmrhinshDesktopTfsProcessTemplatesMicrosoft Visual Studio Scrum 3.0 - Preview"
    $CollectionUrl = "http://kraken:8080/tfs/tfs01"


    $TFSConfig = "${env:ProgramFiles}Microsoft Team Foundation Server 11.0ToolsTFSConfig.exe"
    $WitAdmin = "${env:ProgramFiles(x86)}Microsoft Visual Studio 12.0Common7IDEwitadmin.exe"

    $witds = Get-ChildItem "$ProcessTemplateRootWorkItem TrackingTypeDefinitions"

    foreach( $witd in $witds)
    {
        Write-Host "Importing $witd"
        & $WitAdmin importwitd /collection:$CollectionUrl /p:$TeamProjectName /f:$($witd.FullName)
    }
    & $WitAdmin importcategories /collection:$CollectionUrl /p:$TeamProjectName /f:"$ProcessTemplateRootWorkItem TrackingCategories.xml"
    & $WitAdmin importprocessconfig /collection:$CollectionUrl /p:$TeamProjectName /f:"$ProcessTemplateRootWorkItem TrackingProcessProcessConfiguration.xml"
    ```

    The PowerShell above loops through the Work Item Types defined in the downloaded Process Template and uploads each one. It then goes on to update the Categories and the new Process Configuration. In 2012 we had both a Common Process and an Agile Process configuration but it looks like the team have amalgamated it to a single configuration. Which does make sense as one could never remember which order to upload each one and there were dependencies.

    DONE

    ## Conclusion

    You should now have not just ‘enabled features’ but we have architected and rebuilt the building to be faithful too the new look and feel for the updated Microsoft Visual Studio Scrum 3.0 Process Template.

    - [Get Visual Studio 2013 & Team Foundation Server 2013 while its hot!](http://nkdagility.com/get-visual-studio-2013-team-foundation-server-while-its-hot/)

    Enjoy…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-26-upgrading-to-visual-studio-scrum-3-0-process-template-in-tfs-2013\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-26-upgrading-to-visual-studio-scrum-3-0-process-template-in-tfs-2013
- FrontMatter:
    title: Engaging with complexity - SharePoint Edition
    description: Explore complex SharePoint migrations with expert insights on consolidation and upgrades to SharePoint 2013. Simplify your transition today!
    ResourceId: Lzmlul_Elhj
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9909
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-25
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: engaging-with-complexity-sharepoint-edition
    aliases:
    - /resources/Lzmlul_Elhj
    aliasesArchive:
    - /blog/engaging-with-complexity-sharepoint-edition
    - /engaging-with-complexity-sharepoint-edition
    - /engaging-with-complexity
    - /engaging-with-complexity---sharepoint-edition
    - /blog/engaging-with-complexity---sharepoint-edition
    - /resources/blog/engaging-with-complexity-sharepoint-edition
    tags:
    - Install and Configuration
    - System Configuration
    - Software Development
    categories:
    - Uncategorized
    preview: metro-sharepoint-128-link-2-2.png
  BodyContent: |
    I have been working with a company in Silicon Valley that is doing one of the most complex Team Foundation Server migrations that I think I have ever seen. Just to pile on the complexity they also threw a SharePoint consolidation at me so I caught that as well.

    As with the previous TFS Edition we are moving SharePoint data through multiple environments and in the case of SharePoint we are only worried about consolidation. There are many SharePoint sites used by this organisation that are strung around the corporate network and we first need to consolidate them onto a single server so that we can easily migrate them to SharePoint 2013.

    ![image](images/image37-1-1.png "image")  
    { .post-img }
    Figure: Production SharePoint Environment

    Initially we are doing a single server trial consolidation and upgrade to prove out the process and make sure that everything works. Here we will find all of the issues and tribulations that will inhibit our ability to make this transition easy. Lets get started…

    ## Setting up the environment

    We have a bunch of things that need to be installed and I have previously documented each one. As these installations are consistent with how I always install these products and the only variants are referenced.

    1. [Install SQL Server 2012 SP1](http://nkdagility.com/installing-tfs-2012-on-server-2012-with-sql-2012/) (Step #2 only & use default accounts)
    2. [Installing SharePoint Server 2013](http://nkdagility.com/install-sharepoint-2013-on-windows-server-2012-without-a-domain/) (but use a Domain Account and do not create a Site Collection)
    3. [Installing Project Server 2013](http://nkdagility.com/integrating-project-server-2013-with-team-foundation-server-2012/) (Step #3 only)

    If you are able to create a snapshot at each stage then it may save you time if you forget to add a feature or if something fails. Once you have these three steps complete then you should remove all of the old Snapshots and create a new clean one for the server.

    ## For each Content database you are consolidating

    There are only a few simple steps to importing and upgrading your SharePoint 2010 content databases to SharePoint 2013. Note that there are additional steps listed below that you can run each time or all at the end.

    1. Copy backup locally
    2. Restore the SharePoint 2010 Content Database
    3. Create a Web Application to host the Content Collection (the first one will already exist)
    4. Call SP PowerShell: “Mount-SPContentDatabase -Name iptvsigportal -DatabaseServer reno-sp -WebApplication [http://reno-sp](http://reno-sp)”
    5. Upgrade the site collection to 2013: “Site Settings | Site Collection Administration | Site Collection Upgrade”

    Note: You may need to run a few fixes for pages that have been customised with SharePoint Designer ([SharePoint 2013 Issue – Custom Web Part results in Could not load file or assembly after upgrade](http://nkdagility.com/sharepoint-2013-issue-custom-web-part-results-in-could-not-load-file-or-assembly-after-upgrade/).)

    ## Post Mount Activities

    Because we are both moving from multiple server and consolidating with an upgrade to a new version of the product we have a couple of post-consolidation steps to make sure that everything is accessible and above board.

    1. Add Firewall rules for other ports
    2. Rename Web Applications
    3. [Migrate users to Claim Based Authentication](http://nkdagility.com/sharepoint-2013-issue-after-migration-from-2010-user-permission-not-working/?preview=true)
    4. Moving environment (domain) {Optional}

    These activities are required for good operation and support of SharePoint 2013 with upgraded

    ### Add Firewall rules for other ports

    This one took me by surprise and I had not realised that SharePoint 2013 does not add the firewall rules to allow access when you create a new site on a new port. In this case we have 80, 81 and 82. Only 80 has been granted access by default and we need to add the other two.

    You can take the slow approach and add rules through the UI but recently I have been preferring to use the scriptable approach so in PowerShell you do:

    ```
    netsh advfirewall firewall add rule name="SharePoint80" dir=in action=allow protocol=TCP localport=80
    netsh advfirewall firewall add rule name="SharePoint81" dir=in action=allow protocol=TCP localport=81
    netsh advfirewall firewall add rule name="SharePoint82" dir=in action=allow protocol=TCP localport=82
    ```

    This will allow ports 80 through 82 incoming requests.

    ### Rename Web Applications

    This is a simple piece of PowerShell to do the rename. You can’t do it through the UI except when you do the initial creation and it is easier to determine which site is which if the name reflects the content.

    ```
    $wa=Get-SPWebApplication | where {$_.Name -match "SharePoint - 80"}
    $wa.Name="SiteAwesome"
    $wa.Update()

    ```

    Simples.

    ### Moving environment (domain) {Optional}

    When we do a domain migration from DomainA to DomainBdomains we will have an additional step of telling SharePoint what the mapping is between the users in DomainA to DomainB.

    To do this we need to create a “usermapping.csv” that has “OldUsername” and “NewUsername” columns with a row for each of the users and the mapping.

    ```
    Param(
         [string] $csvusers = "C:spconsolusermapping.csv"
        )
    Add-PSSnapIn Microsoft.SharePoint.PowerShell

    foreach ($wa in get-SPWebApplication)
    {
       $UserList=IMPORT-CSV $csvusers
       Foreach ($Person in $UserList) {
            Move-SPUser –Identity "DomainA$Person.OldUsername" –NewAlias "DomainA$Person.NewUsername"
       }
    }

    ```

    This PowerShell will map each of the users across to the new domain and allow them to access the SharePoint sites with the name accounts as well as maintaining traceability.

    ## Conclusion

    Upgrading SharePoint 2012 to SharePoint 2013 is not quite as easy as it is with Team Foundation Server. There are quite a few pitfalls and it took some amount of research to get the above all working.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-25-engaging-with-complexity-sharepoint-edition\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-25-engaging-with-complexity-sharepoint-edition
- FrontMatter:
    title: Issue [ TFS 2012.2 ] Detaching collection fails on SnapshotIdentities with object reference not set to an instance of an object
    description: Discover solutions for detaching Team Project Collections in TFS 2012.2. Learn to resolve 'object reference not set' errors and ensure smooth migrations.
    ResourceId: 1jIPsnnKuNK
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9661
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-24
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: tfs-2012-2-issue-detaching-collection-fails-on-snapshotidentities
    aliases:
    - /resources/1jIPsnnKuNK
    - /resources/blog/issue-tfs-2012.2-detaching-collection-fails-on-snapshotidentities-with-object-reference-not-set-to-an-instance-of-an-object
    aliasesArchive:
    - /blog/tfs-2012-2-issue-detaching-collection-fails-on-snapshotidentities
    - /tfs-2012-2-issue-detaching-collection-fails-on-snapshotidentities
    - /issue-[-tfs-2012-2-]-detaching-collection-fails-on-snapshotidentities-with-object-reference-not-set-to-an-instance-of-an-object
    - /blog/issue-[-tfs-2012-2-]-detaching-collection-fails-on-snapshotidentities-with-object-reference-not-set-to-an-instance-of-an-object
    - /resources/blog/tfs-2012-2-issue-detaching-collection-fails-on-snapshotidentities
    - /resources/blog/issue-tfs-2012.2-detaching-collection-fails-on-snapshotidentities-with-object-reference-not-set-to-an-instance-of-an-object
    tags:
    - Troubleshooting
    - Software Development
    - System Configuration
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-2-2.png
  BodyContent: |
    When you try to detach a Team Project Collection in Team Foundation Server the process fails on SnapshotIdentities with an "object reference not set to an instance of an object" error. While this does not inhibit the execution of TFS there is likely a good reason that you wanted to detach and found this issue.

    [![image13](images/image13_thumb-1-1.png "image13")](http://nkdagility.com/files/2013/06/image131.png)  
    { .post-img }
    Figure: object reference not set to an instance of an object

    In this case I was trying to move the Collection to another server and this is a blocking issue.

    ## Applies To

    - Team Foundation Server 2012
    - Team Foundation Server 2012.1
    - Team Foundation Server 2012.2
    - Team Foundation Server 2012.3
    - Team Foundation Server 2013 Preview

    ## Findings

    When you get these sorts of errors make sure that you look in the Event Log of the server and at the logs generated by TFS. In the event of an error there will be a link on the page that will open the relevant log in the Team Foundation Server Administration Console.

    ```
    [11:16:24.010] ++ Executing - Operation: Snapshot, Group: Snapshot.TfsIdentities
    [11:16:25.010] Executing step: Copy identities to collection database
    [11:16:25.010]   Executing step: 'Copy identities to collection database' Identity.SnapshotIdentities (16 of 28)
    [11:18:15.873]   [Error] Object reference not set to an instance of an object.
    [11:18:15.877]   System.NullReferenceException: Object reference not set to an instance of an object.
    [11:18:15.877]      at Microsoft.TeamFoundation.Framework.Server.IdentityTransferHandler.Transfer()
    [11:18:15.877]      at Microsoft.TeamFoundation.Framework.Server.IdentityTransferHandler.Execute()
    [11:18:15.877]      at Microsoft.VisualStudio.Services.Framework.IdentityStepPerformer.SnapshotIdentities(TeamFoundationRequestContext requestContext, ServicingContext servicingContext)
    [11:18:15.877]      at Microsoft.TeamFoundation.Framework.Server.TeamFoundationStepPerformerBase.Microsoft.TeamFoundation.Framework.Server.IStepPerformer.PerformStep(String servicingOperation, String stepType, String stepData, ServicingContext servicingContext)
    [11:18:15.877]      at Microsoft.TeamFoundation.Framework.Server.ServicingStepDriver.PerformServicingStep(ServicingStep step, ServicingContext servicingContext, ServicingStepGroup group, ServicingOperation servicingOperation, Int32 stepNumber, Int32 totalSteps)
    [11:18:15.877] Step failed: Copy identities to collection database. Execution time: 110 seconds.
    [11:18:15.883]   Clearing dictionary, removing all items.

    ```

    In the log you can clearly see that the step that is failing is the “Snapshot.TfsIdentities”. What I believe that this does is create a package inside of the Collection database for the new TFS Instance that you are moving it to. This package needs to contain all of the Identities that have interacted with this TFS Instance. The likely cause of this error is that there are orphaned group memberships in the Configuration database that do not exist within the Collection.

    I would suggest that this would be the result of a TFS server that has backed up without the use of a ‘marked transaction log’ and that backup restored at some point. If you have large databases and you don't use the [built in Scheduled Backups tool](http://msdn.microsoft.com/en-us/library/vstudio/hh561429.aspx) or the documented process to [manually back up Team Foundation Server](http://msdn.microsoft.com/en-us/library/vstudio/ms253070.aspx) then you are leaving yourself open for this type of inconsistency.

    To find out if your have any orphaned identities then you should run:

    _Warning Do not make any changes to any of your TFS Databases manually unless specifically instructed by the Product Team. If you do then you can no longer be supported by Microsoft._

    ```
    SELECT  gm
    FROM    tbl_GroupMembership gm
    WHERE   gm.PartitionId = 1
        AND NOT EXISTS (
            SELECT  *
            FROM    tbl_Group g
            WHERE   g.PartitionId = 1
                AND g.Id = gm.MemberId
        )
        AND NOT EXISTS (
            SELECT  *
            FROM    tbl_Identity i
            WHERE   i.PartitionId = 1
                AND i.Id = gm.MemberId
        )

    ```

    If you get results from this query then you have this problem and you should immediately raise a support ticket with Microsoft to get this fixed.

    ## Solution

    You need to remove all of the orphaned identities from your server in order to fix this. To achieve that you should work with Microsoft by raising a support ticket and cleaning the instance.  If an invalid backup has been restored there are likely other things that need to happen to get into a supported state and changing the database yourself will not get you there.

    Raise a ticket and get your server into a supported state…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-24-tfs-2012-2-issue-detaching-collection-fails-on-snapshotidentities\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-24-tfs-2012-2-issue-detaching-collection-fails-on-snapshotidentities
- FrontMatter:
    title: Creating a Work Item with defaults in Team Foundation Server
    description: Learn how to create a Work Item with defaults in Team Foundation Server, streamlining user access and guidance for efficient project management.
    ResourceId: v1HLcU8PfsS
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9686
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-24
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: creating-a-work-item-with-defaults-in-team-foundation-server
    aliases:
    - /resources/v1HLcU8PfsS
    aliasesArchive:
    - /blog/creating-a-work-item-with-defaults-in-team-foundation-server
    - /creating-a-work-item-with-defaults-in-team-foundation-server
    - /resources/blog/creating-a-work-item-with-defaults-in-team-foundation-server
    tags: []
    categories:
    - Uncategorized
  BodyContent: |
    In some cases you want to be creating a Work Item with defaults in Team Foundation Server so that you can give access to users but also give them guidance on what to fill out.

    The best option for this is to create your own UI that leverages the TFS API and gives the users access to only the fields that you deme pertinent. This would be the full control option. If however you don’t have time or want to do that there is a simple solution. You can create a ‘template URL’ that pre-populated the field values of a Work Item.

    ![image](images/image65-1-1.png "image")  
    { .post-img }
    Figure: New PBI form with defaults

    To do this you need to open your Team Project in the Web Access and click to create a new Work Item for whatever type that you want. In this case it is the Product Backlog Item. I have then gone ahead and changed the Area Path, Iteration Path and added a value for Business Value.

    ![image](images/image66-2-2.png "image")  
    { .post-img }
    Figure: Copy template to clipboard

    Now that we have the customisations how we like we can click the “Copy template URL” button and it will create a URL with the field data on it and save it to your clipboard.

    > [http://kraken:8080/tfs/Tfs01/TeamsWithAreas/\_workItems/create/Product%20Backlog%20Item?%5BMicrosoft.VSTS.Common.BusinessValue%5D=56&%5BSystem.AreaPath%5D=TeamsWithAreas%5CTeam+A&%5BSystem.IterationPath%5D=TeamsWithAreas%5CRelease+1%5CSprint+3](http://kraken:8080/tfs/Tfs01/TeamsWithAreas/_workItems/create/Product%20Backlog%20Item?%5BMicrosoft.VSTS.Common.BusinessValue%5D=56&%5BSystem.AreaPath%5D=TeamsWithAreas%5CTeam+A&%5BSystem.IterationPath%5D=TeamsWithAreas%5CRelease+1%5CSprint+3 "http://kraken:8080/tfs/Tfs01/TeamsWithAreas/_workItems/create/Product%20Backlog%20Item?%5BMicrosoft.VSTS.Common.BusinessValue%5D=56&%5BSystem.AreaPath%5D=TeamsWithAreas%5CTeam+A&%5BSystem.IterationPath%5D=TeamsWithAreas%5CRelease+1%5CSprint+3")

    You you look closely at the URL you will see that it has the field name “Microsoft.VSTS.Common.BusinessValue” followed by the value of “56” pre filled out in the URL.

    ![image](images/image67-3-3.png "image")  
    { .post-img }
    Figure: New PBI form with custom defaults

    If you drop that URL into a browser you will see the new work item page with your work item pre-populated. Now if you want you can now create a simple html page that has a list of predefined links to create work items of different types and defaults…

    Simples…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-24-creating-a-work-item-with-defaults-in-team-foundation-server\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-24-creating-a-work-item-with-defaults-in-team-foundation-server
- FrontMatter:
    title: Issue [ TFS2012.2 ] TF30063 You are not authorized to access
    description: Discover how to resolve the TF30063 authorization error in TFS 2012.2 after moving environments. Upgrade to 2012.3 for a seamless experience!
    ResourceId: 6o-nqY9A5OP
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9910
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-23
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: issue-tfs2012-2-tf30063-you-are-not-authorized-to-access
    aliases:
    - /resources/6o-nqY9A5OP
    - /resources/blog/issue-tfs2012.2-tf30063-you-are-not-authorized-to-access
    aliasesArchive:
    - /blog/issue-tfs2012-2-tf30063-you-are-not-authorized-to-access
    - /issue-tfs2012-2-tf30063-you-are-not-authorized-to-access
    - /issue-[-tfs2012-2-]-tf30063-you-are-not-authorized-to-access
    - /blog/issue-[-tfs2012-2-]-tf30063-you-are-not-authorized-to-access
    - /resources/blog/issue-tfs2012-2-tf30063-you-are-not-authorized-to-access
    - /resources/blog/issue-tfs2012.2-tf30063-you-are-not-authorized-to-access
    tags:
    - Troubleshooting
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-3-3.png
  BodyContent: |
    If you have TFS 2012 Update 2 (2012.2) installed you might get an error after you [move Team Foundation Server from one environment to another](http://msdn.microsoft.com/en-us/library/ms404883.aspx) (change domain.)

    ![image](images/image38-1-1.png "image")  
    { .post-img }
    Figure: TF30063 you are not authorised to access server

    ## Applies to

    - Team Foundation Server 2012.2

    ## Findings

    Not only are you unable to change the URL but you are also to edit permissions or in any way connect to TFS even from the server.

    ![image](images/image39-2-2.png "image")  
    { .post-img }
    Figure: TF30063 you are not authorised to access localhost

    This is not one that I have encountered before and was at a loss to help the customer. I ran the flag up and got a little help from [Grant Holiday](http://blogs.msdn.com/b/granth/). He identified this as a bug…

    ## Solution

    This bug is fixed in Team Foundation Server 2012.3. 2012.3 is currently  at RC2 but it does come with a Go-Live licence meaning that it is fully supported in production. After installing 2012.3 all of the problems went away and the server started functioning normally.

    Woot… yet another reason for 2012.3 and Go-Live…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-23-issue-tfs2012-2-tf30063-you-are-not-authorized-to-access\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-23-issue-tfs2012-2-tf30063-you-are-not-authorized-to-access
- FrontMatter:
    title: SharePoint 2013 Issue - After migration from 2010 user permission not working
    description: Resolve SharePoint 2013 migration issues with user permissions. Discover effective PowerShell solutions to ensure seamless access and authentication.
    ResourceId: M-S-kXIX-ar
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9906
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-21
    weight: 875
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: sharepoint-2013-issue-after-migration-from-2010-user-permission-not-working
    aliases:
    - /resources/M-S-kXIX-ar
    aliasesArchive:
    - /blog/sharepoint-2013-issue-after-migration-from-2010-user-permission-not-working
    - /sharepoint-2013-issue-after-migration-from-2010-user-permission-not-working
    - /sharepoint-2013-issue
    - /sharepoint-2013-issue---after-migration-from-2010-user-permission-not-working
    - /blog/sharepoint-2013-issue---after-migration-from-2010-user-permission-not-working
    - /resources/blog/sharepoint-2013-issue-after-migration-from-2010-user-permission-not-working
    tags:
    - Troubleshooting
    - Install and Configuration
    - System Configuration
    categories:
    - Uncategorized
    preview: metro-sharepoint-128-link-1-1.png
  BodyContent: |
    Users coming from a SharePoint 2010 system that try to access SharePoint 2013 after a migration receive a “this site has not been shared with you” message. This mean that they are not able to authenticate to SharePoint 2013.

    Further you see authentication issues with user profiles not matching recent changes to Active Directory.

    ## Applies to

    - SharePoint 2013
    - SharePoint 2010 Upgrade to 2013

    ## Findings

    Man this was a hard one. I was searching for ages and pulling my hair out when [Tushar Malu](http://www.linkedin.com/in/tusharmalu) found some awesome information that saved my bacon.

    In SharePoint 2013 there is a new authentication mechanism called Claim based authentication. Be default through the UI all Applications are created in this mode. There is a way to [create web applications that use classic mode authentication in SharePoint 2013](http://technet.microsoft.com/en-us/library/gg276326.aspx) but if you have already created your application tier and you import a Collection from a SharePoint 2010 server then you might find that no one can access your server at all.

    After you have [imported your SharePoint 2010 data into SharePoint 2013](http://nkdagility.com/integrate-sharepoint-2013-with-team-foundation-server-2012/) with the “Mount-SPContentDatabase” command you then need to update all of the user accounts as per:

    - MSDN: [Migrate from classic-mode to claims-based authentication in SharePoint 2013](http://technet.microsoft.com/en-us/library/gg251985.aspx)

    This while fairly simple is a little difficult to fins and figure out and I spent many hours trying to configure SharePoint User Profile Synchronisation to no avail. In fact all you need is a simple PowerShell to do the synchronisation.

    ## Solution

    Although finding this was not simple the execution is. I created a PowerShell script that loops through all of your SharePoint 2013 web applications and upgrades each one to claim’s based authentication.

    ```
     Param(
        [string]  $account = $(Read-Host -prompt "UserAccount")
        )
    Add-PSSnapIn Microsoft.SharePoint.PowerShell

    foreach ($wa in get-SPWebApplication)
    {
        Write-Host "$($wa.Name) | $($wa.UseClaimsAuthentication )"
        #http://technet.microsoft.com/en-us/library/gg251985.aspx
        $wa.UseClaimsAuthentication = $true
        $wa.Update()
        $account = (New-SPClaimsPrincipal -identity $account -identitytype 1).ToEncodedString()
        $zp = $wa.ZonePolicies("Default")
        $p = $zp.Add($account,"PSPolicy")
        $fc=$wa.PolicyRoles.GetSpecialRole("FullControl")
        $p.PolicyRoleBindings.Add($fc)
        $wa.Update()
        $wa.MigrateUsers($true)
        $wa.ProvisionGlobally()
    }

    ```

    These commands tool less than 10 minutes to run on 3 content databases with nearly 100GB of data. In addition some bright spark had added “NT AuthorityAuthenticated Users” to one of the main sites '”Contributors” group. While this sounds like something that I would do, if I had done it I would have added them to “Readers”…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-21-sharepoint-2013-issue-after-migration-from-2010-user-permission-not-working\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-21-sharepoint-2013-issue-after-migration-from-2010-user-permission-not-working
- FrontMatter:
    title: SharePoint 2013 Issue - Custom Web Part results in Could not load file or assembly after upgrade
    description: Resolve SharePoint 2013 upgrade issues with custom web parts. Discover effective solutions to fix 'Could not load file or assembly' errors easily!
    ResourceId: dOYcFVzZg42
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9905
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-20
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: sharepoint-2013-issue-custom-web-part-results-in-could-not-load-file-or-assembly-after-upgrade
    aliases:
    - /resources/dOYcFVzZg42
    aliasesArchive:
    - /blog/sharepoint-2013-issue-custom-web-part-results-in-could-not-load-file-or-assembly-after-upgrade
    - /sharepoint-2013-issue-custom-web-part-results-in-could-not-load-file-or-assembly-after-upgrade
    - /sharepoint-2013-issue
    - /sharepoint-2013-issue---custom-web-part-results-in-could-not-load-file-or-assembly-after-upgrade
    - /blog/sharepoint-2013-issue---custom-web-part-results-in-could-not-load-file-or-assembly-after-upgrade
    - /resources/blog/sharepoint-2013-issue-custom-web-part-results-in-could-not-load-file-or-assembly-after-upgrade
    tags:
    - Troubleshooting
    - Install and Configuration
    categories:
    - Uncategorized
    preview: metro-sharepoint-128-link-8-8.png
  BodyContent: |
    After an upgrade of a SharePoint 2010 content database to SharePoint 2013 you may get an error message “Could not load file or assembly ‘MyCustomWebPart, Version=1.0.0.0, Culture=neutral, Public Token=6912jju2191j213ggv10’ or one of its dependants. The system cannot find the file specified” when you try to access a page.

    This is fairly common when upgrading but the solution is very hard to find.

    ![image](images/image2-3-3.png "image")  
    { .post-img }
    Figure: Could not load file or assembly

    You may not have access to the custom Web Part or it may only work in SharePoint.vLast.

    ## Applies to

    - SharePoint 2013
    - SharePoint 2010

    ## Findings

    If you just take the SharePoint databases and restore them to the new environment you may not have, or even be able to migrate the custom web parts that have been added.

    In this case the custom web part was created and compiled for SharePoint 2010 and we will not be recompiling it for SharePoint 2013 but we still need to get the site running now. There are two main ways to solve this problem:

    - **Reset to Site Definitions** – This will reset an individual page or the entire site to the out-of-the-box definition of the page.
    - **Edit with SharePoint Designer** – This is a much more invasive option, but if things have been edited with SharePoint Designer you may be left with no choice.

    Always start with resetting to Site Definitions option as it is the easiest, least invasive and quickest option.

    ## Solution #1 – Reset to Site Definitions

    This is the solution of first resort. It will fix most small issues and minimises the impact and risk to all users. If you reset your site to the site dentitions all of the little customisations that have been made to pages will be reset to the defaults. So if customisations have been made through the UI this will work a dream.. there is however one problem first… how do we get into the admin.

    ![image](images/image3-4-4.png "image")  
    { .post-img }
    Figure: To access the admin page use ?content=1

    If you add “?content=1” to the end of the URL you will find the SharePoint “Web Part Page Maintenance” screen for that page. Here you will have access to the rest of the settings that you need. And it shows that the site works, just not that page that we had a problem with.

    ![image](images/image4.png "image")  
    { .post-img }
    Figure: Getting to the Web Part Page Maintenance

    We can then see the little cog (settings) button on the top right and we get access to Site Settings.

    ![image](images/image5.png "image")  
    { .post-img }
    Figure: Finding Reset to site definition on Site Settings

    Go to “Site Settings | Site Actions | Reset to site definition” to get access to the feature that we need to fix this issue.

    ![image](images/image6.png "image")  
    { .post-img }
    Figure: Reset all pages in this site to site definition version

    Once on the “Reset Page to Site Definition Version” page you should select the “Reset all pages in this site to site definition version” so that we don’t have to do it for every page. This is something that I have always done for upgraded sites as the definition that you are resetting to is the one from the new version (SharePoint 2013 in this case) and that will improve the look and feel of the pages.

    Unfortunately in this case there have been customisations made to the “default.aspx” file using SharePoint Designer and we need SharePoint Designer to fix them.

    ## Solution #2 – Edit with SharePoint Designer

    SharePoint Designer is a [free download from Microsoft](http://www.microsoft.com/en-us/download/details.aspx?id=35491) and will let you edit each individual page. I would never recommend using SharePoint Designer to edit pages but sometimes its evil has already been instilled in the pages and we need to get rid of it.

    ![image](images/image7-5-5.png "image")  
    { .post-img }
    Figure: Open SharePoint Designer and the Site that you need to edit

    Once you open the site (use “Open Site | [http://myshareppoint:81/](http://myshareppoint:81/)”)

    ![image](images/image8-6-6.png "image")  
    { .post-img }
    Figure: Switch to All Files to get access to the default pages

    We need to find the ‘default.aspx’ file in this case and for that we need to access “All Files”.

    ![image](images/image9-7-7.png "image")  
    { .post-img }
    Figure: Check Out to Edit

    In order to edit files in SharePoint you need to check them out first. This prevents random tampering and makes you check the changes in deliberately before they are visible on the site.

    ![image](images/image10-1-1.png "image")  
    { .post-img }
    Figure: Some of the code is Protected

    Now that I have found the culprit I can edit the page to remove it… except that I cant. In SharePoint Designer 2013 all of the wrapper code for the page is protected and cant be edited. The yellow highlight around the text is the indication that it is in this protected mode. if you want to exit it you need to switch to scary evil mode first.

    This is a good thing as it will help limit the scope of the changes that people make with this tool unless they know what they are doing.

    ![image](images/image11-2-2.png "image")  
    { .post-img }
    Figure: Switch to Advanced Mode (Scary evil mode)

    Once in Advanced mode you will be able to edit all of the protected sections. We need to delete the line that references the Assembly that we do not have in the new instance. Make sure that you search for the Tag Prefix (In this case “WpNs5”) to make sure that you are not leaving any orphaned controls. You would need to remove them as well.

    Once you have made your changes you can save and remember to check in to see the changes.

    In this case all of the Register tags with the TagPrefix of "WpNs\*" needs to be removed and any associated controls removed.

    This will fix any issues with the pages loading.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-20-sharepoint-2013-issue-custom-web-part-results-in-could-not-load-file-or-assembly-after-upgrade\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-20-sharepoint-2013-issue-custom-web-part-results-in-could-not-load-file-or-assembly-after-upgrade
- FrontMatter:
    title: TFS 2012.3 Issue - Scheduled Backups gives a TF400998 when reconfigured
    description: Resolve the TF400998 error in TFS 2012.3 when reconfiguring Scheduled Backups after migration. Discover solutions to streamline your backup process!
    ResourceId: _XqGOC9TbpP
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9904
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-19
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: tfs-2012-3-issue-scheduled-backups-gives-a-tf400998
    aliases:
    - /resources/_XqGOC9TbpP
    - /resources/blog/tfs-2012.3-issue-scheduled-backups-gives-a-tf400998-when-reconfigured
    aliasesArchive:
    - /blog/tfs-2012-3-issue-scheduled-backups-gives-a-tf400998
    - /tfs-2012-3-issue-scheduled-backups-gives-a-tf400998
    - /tfs-2012-3-issue
    - /tfs-2012-3-issue---scheduled-backups-gives-a-tf400998-when-reconfigured
    - /blog/tfs-2012-3-issue---scheduled-backups-gives-a-tf400998-when-reconfigured
    - /resources/blog/tfs-2012-3-issue-scheduled-backups-gives-a-tf400998
    - /resources/blog/tfs-2012.3-issue-scheduled-backups-gives-a-tf400998-when-reconfigured
    tags:
    - Troubleshooting
    - System Configuration
    - Windows
    - Software Development
    - Install and Configuration
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-3-3.png
  BodyContent: |
    After a server migration Scheduled Backups gives a TF400998 when you try to reconfigure it. You may also see timeouts and errors when trying to add Team Foundation Console Users.

    ![image](images/image-1-1.png "image")  
    { .post-img }
    Figure: You get TF400998 and TF246017 when anything hits Scheduled Backup

    ## Applies to

    - Team Foundation Server 2012
    - Team Foundation Server 2012.2 (QU2)
    - Team Foundation Server 2012.3 (QU3)
    - Team Foundation Server 2013

    ## Findings

    We had the Scheduled Backups configured for the old environment (const-dt-01 & const-at-01) that was in the old domain. We then did a full backup and restore of TFS to the new domain and followed the documentation for both a hardware and environment move.

    It looks like there are a bunch of referenced, specifically in the “Scheduled Backups” tools that are left at the old server. If you just try to reconfigure you get the nasty errors above and the log below.

    ```
    [Info   @16:26:10.509] ====================================================================
    [Info   @16:26:10.510] Team Foundation Server Administration Log
    [Info   @16:26:10.510] Version  : 11.0.60521.0
    [Info   @16:26:10.510] DateTime : 06/18/2013 09:26:10
    [Info   @16:26:10.510] Type     : Scheduled Backups
    [Info   @16:26:10.510] User     : CONSTMrHinsh
    [Info   @16:26:10.510] Machine  : CONST3-AT-01
    [Info   @16:26:10.510] System   : Microsoft Windows NT 6.1.7601 Service Pack 1 (AMD64)
    [Info   @16:26:10.510] ====================================================================
    [Info   @16:30:26.252] -----------------------------------------------------
    [Info   @16:30:26.252]
    [Info   @16:30:26.252] +-+-+-+-+-| Running VerifySqlServiceAccountCanBeGrantedPermission: Verifying SQL service account is not a local account |+-+-+-+-+-
    [Info   @16:30:26.252]
    [Info   @16:30:26.252] +-+-+-+-+-| Verifying SQL service account is not a local account |+-+-+-+-+-
    [Info   @16:30:26.252] Starting Node: SQLISNOTLOCAL
    [Info   @16:30:26.252] NodePath : Container/Progress/SQLISNOTLOCAL
    [Info   @16:30:26.268] Verify that account 'CONSTCONST3web' is not local service or local system.
    [Info   @16:31:30.603] Node returned: Error
    [Error  @16:31:30.603] TF400998: The current user failed to retrieve the SQL Server service account information from CONST-DT-01. Please make sure you have permissions to retrieve this information.
    [Info   @16:31:30.604] Completed VerifySqlServiceAccountCanBeGrantedPermission: Error
    [Info   @16:31:30.656] -----------------------------------------------------
    [Info   @16:31:30.656]
    [Info   @16:31:30.656] +-+-+-+-+-| Running VerifyCollectionDatabases: Verifying connection strings are valid |+-+-+-+-+-
    [Info   @16:31:30.657]
    [Info   @16:31:30.657] +-+-+-+-+-| Verifying connection strings are valid |+-+-+-+-+-
    [Info   @16:31:30.657] Starting Node: BACKUPDBSREACHABLE
    [Info   @16:31:30.657] NodePath : Container/Progress/BACKUPDBSREACHABLE
    [Info   @16:31:30.657] Verifying connection strings to all backup databases
    [Info   @16:31:30.658] Looking for database Tfs_Configuration on CONST3-DT-01
    [Info   @16:31:30.699] Checking if database Tfs_Configuration on CONST3-DT-01 is online
    [Info   @16:31:30.732] Looking for database Tfs_IMF on CONST3-DT-01
    [Info   @16:31:30.760] Checking if database Tfs_IMF on CONST3-DT-01 is online
    [Info   @16:31:30.790] Looking for database ReportServer on CONST-DT-01
    [Info   @16:31:52.103] Node returned: Error
    [Error  @16:31:52.103] TF246017: Team Foundation Server could not connect to the database. Verify that the server that is hosting the database is operational, and that network problems are not blocking communication with the server.
    [Info   @16:31:52.103] Completed VerifyCollectionDatabases: Error
    [Info   @16:31:52.117] -----------------------------------------------------
    [Info   @16:31:52.117]
    [Info   @16:31:52.117] +-+-+-+-+-| Running VerifySqlServerPermissionsGranted: Verifying TFS Job Agent has permissions to create and alter databases |+-+-+-+-+-
    [Info   @16:31:52.121]
    [Info   @16:31:52.121] +-+-+-+-+-| Verifying TFS Job Agent has permissions to create and alter databases |+-+-+-+-+-
    [Info   @16:31:52.121] Starting Node: ALTERCREATEDATABASE
    [Info   @16:31:52.121] NodePath : Container/Progress/ALTERCREATEDATABASE
    [Info   @16:32:56.264] Node returned: Error
    [Error  @16:32:56.264] TF246017: Team Foundation Server could not connect to the database. Verify that the server that is hosting the database is operational, and that network problems are not blocking communication with the server.
    [Info   @16:32:56.264] Completed VerifySqlServerPermissionsGranted: Error
    [Info   @16:32:56.264] -----------------------------------------------------
    [Info   @16:32:56.264]
    [Info   @16:32:56.264] +-+-+-+-+-| Running VerifySqlDatabasesPermissionsGranted: Verifying TFS Job Agent has permissions to backup databases, create tables, and execute stored procedures |+-+-+-+-+-
    [Info   @16:32:56.268]
    [Info   @16:32:56.268] +-+-+-+-+-| Verifying TFS Job Agent has permissions to backup databases, create tables, and execute stored procedures |+-+-+-+-+-
    [Info   @16:32:56.268] Starting Node: BACKUPEXECUTECREATE
    [Info   @16:32:56.268] NodePath : Container/Progress/BACKUPEXECUTECREATE
    [Info   @16:32:56.268] Granting account CONSTCONST3web permissions to initiate database backups of Tfs_Configuration
    [Info   @16:32:56.309] Granting account CONSTCONST3web permissions to initiate database backups of Tfs_IMF
    [Info   @16:32:56.619] Granting account CONSTCONST3web permissions to initiate database backups of ReportServer
    [Info   @16:33:17.634] Node returned: Error
    [Error  @16:33:17.634] TF246017: Team Foundation Server could not connect to the database. Verify that the server that is hosting the database is operational, and that network problems are not blocking communication with the server.
    [Info   @16:33:17.634] Completed VerifySqlDatabasesPermissionsGranted: Error
    [Info   @16:33:17.634] -----------------------------------------------------
    ```

    This then prevents us from being able to reconfigure however you can disable and reset.

    ## Solution

    If we instead click “Disable Scheduled Backup” and weight for the timout we get a “Network Path not found” exception when it tries to access the backup location but it has actually done the disable.

    ![image](images/image1-2-2.png "image")  
    { .post-img }
    Figure: Disable results in path not found

    If you hit the refresh button above the Scheduled Backup node will return to its un-configured state.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-19-tfs-2012-3-issue-scheduled-backups-gives-a-tf400998\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-19-tfs-2012-3-issue-scheduled-backups-gives-a-tf400998
- FrontMatter:
    title: Writing .NET in PowerShell and creating TFS Teams
    description: Discover how to leverage PowerShell for .NET and TFS API to create teams programmatically. Unlock new coding possibilities with practical insights!
    ResourceId: 52GnS0fI67Q
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9903
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-06-13
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: writing-net-in-powershell-and-creating-tfs-teams
    aliases:
    - /resources/52GnS0fI67Q
    - /resources/blog/writing-.net-in-powershell-and-creating-tfs-teams
    aliasesArchive:
    - /blog/writing-net-in-powershell-and-creating-tfs-teams
    - /writing-net-in-powershell-and-creating-tfs-teams
    - /writing--net-in-powershell-and-creating-tfs-teams
    - /blog/writing--net-in-powershell-and-creating-tfs-teams
    - /resources/blog/writing-net-in-powershell-and-creating-tfs-teams
    - /resources/blog/writing-.net-in-powershell-and-creating-tfs-teams
    tags:
    - Software Development
    categories:
    - Uncategorized
    preview: image11-1-1.png
  BodyContent: |
    Did you know that you could be writing .NET in PowerShell? PowerShell can be used to instanciate and call any .NET object and that includes the TFS API.

    On of my [colleagues](http://b4root.com/) today suggested that it was harder to create a new Team programmatically in PowerShell than it would in c#. Well I have been playing with PowerShell a lot recently and I decided to give it a go… And do you know what… it is harder… that is.. until you know how.

    I have been confused by PowerShell for a while now. I have struggled and struggled to create and run PowerShell until just a few days ago I had an epiphany:

    > PowerShell is just c# with all of the bad bits taken out. No case sensitivity, no pointless semi-colon at the end of lines and no unnecessary parentheses to tell the compiler something that it should already know.  
    > \-Martin Hinshelwood, 2013

    Now I am not all there with the syntax and there are a bunch of things I think are really silly and hard, but if you squint at PowerShell just right it is really just the syntax of c# with all of the good bits of VB rolled into a nice code pie.

    The first thing that In need to do to create a Team in TFS is to get a hold of a collection object and this resulted in my first problem…

    ```
    TfsTeamProjectCollectionFactory.GetTeamProjectCollection(new Uri(CollectionUri));

    ```

    Not only does the code above (c#) have a static method call, but the object that is called has been shortened by using an Include in the c# code. So how do we both reference an object and ask PowerShell to do something with it.

    ```
    [Microsoft.TeamFoundation.Client.TfsTeamProjectCollectionFactory]::GetTeamProjectCollection($CollectionUrlParam)

    ```

    Interesting… so we just bracket the object and do the old double colon to get that effect. Not what I thought but I have seen this before (not sure where) and I can work with that… so is that the same for an enum?

    ```
    [Microsoft.TeamFoundation.Client.TeamProjectPickerMode]::NoProject

    ```

    So it is...

    And thus we hit the second problem that I alluded to earlier… how do we import a namespace to gain access to the classes. We need to reference the DLL in a project so there must be some way to do that here. A little searching around and you will find the Add-Type command that will add any assembly as a reference.

    ```
    Add-Type -AssemblyName "Microsoft.TeamFoundation.Client, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a",
                           "Microsoft.TeamFoundation.Common, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a",
                           "Microsoft.TeamFoundation, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a"


    ```

    So now we can add assemblies we can do pretty much whatever we like. PowerShell is a little more flexible than .NET directly sometime as you can just quote a type and it will get converted for you. This was especially painful in c#…

    So… my final script to add a new Team to TFS looked something like.

    ```
     Param(
           [string] $CollectionUrlParam = $(Read-Host -prompt "Collection"),
           [string] $TeamName = $(Read-Host -prompt "Team"),
           [string] $project = $(Read-Host -prompt "Project")
           )

    # load the required dlls
    Add-Type -AssemblyName "Microsoft.TeamFoundation.Client, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a",
                           "Microsoft.TeamFoundation.Common, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a",
                           "Microsoft.TeamFoundation, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a"

    # Get TFS
    $tfs = [Microsoft.TeamFoundation.Client.TfsTeamProjectCollectionFactory]::GetTeamProjectCollection($CollectionUrlParam)
    $tfs.EnsureAuthenticated()
    # Get Team Project
    $cssService = $tfs.GetService("Microsoft.TeamFoundation.Server.ICommonStructureService3")
    $teamProject += $cssService.GetProjectFromName($project)
    # Create Team
    $teamService = $tfs.GetService("Microsoft.TeamFoundation.Client.TfsTeamService")
    $Team = $teamService.CreateTeam($teamProject.Uri, $TeamName, "", $null)
    # Show what we created
    $team

    ```

    But wait… you must be thinking ‘well what about the other programming constructs’? What I have done able is all fairly simple what if I want to go ahead and call the TFS built in project picker so that I don’t have to do all that variable nonsense. Now we are talking ‘if’ and dialogs…

    ```
    $picker = New-Object Microsoft.TeamFoundation.Client.TeamProjectPicker([Microsoft.TeamFoundation.Client.TeamProjectPickerMode]::NoProject, $false)
    $dialogResult = $picker.ShowDialog()
    if ($dialogResult -ne "OK")
    {
        exit
    }
    $tfs = $picker.SelectedTeamProjectCollection
    $projectList = $picker.SelectedProjects

    ```

    But what about if you make it mad? YOu can’t just throw a Try Catch in there we would have to do some crazy “On Error” and “GOTO” wouldn't we?

    ```
    try
    {
        $tfs.EnsureAuthenticated()
    }
    catch
    {
        Write-Error "Error occurred trying to connect to project collection: $_ "
        exit 1
    }

    ```

    Now we begin to get a picture of what is possible inside PowerShell. Would the above be easier if  there were nice easy commands like “Add-Team” or “Add-TeamProject” existed? Well yes it would, but that they don’t is not going to cripple us. We can get buy without them..

    In short, anything you can do in code you can do in PowerShell.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-13-writing-net-in-powershell-and-creating-tfs-teams\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-06-13-writing-net-in-powershell-and-creating-tfs-teams
- FrontMatter:
    title: Restore TFS backups from SQL Enterprise to SQL Express
    description: Learn how to successfully restore TFS backups from SQL Enterprise to SQL Express by removing enterprise features. Troubleshoot errors and optimize your setup!
    ResourceId: Rtjw5m2qP3t
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9902
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-05-27
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: restore-tfs-backups-from-sql-enterprise-to-sql-express
    aliases:
    - /resources/Rtjw5m2qP3t
    aliasesArchive:
    - /blog/restore-tfs-backups-from-sql-enterprise-to-sql-express
    - /restore-tfs-backups-from-sql-enterprise-to-sql-express
    - /resources/blog/restore-tfs-backups-from-sql-enterprise-to-sql-express
    tags:
    - Troubleshooting
    - Install and Configuration
    - Software Development
    - System Configuration
    categories:
    - Uncategorized
    preview: lazy1-5-5.jpg
  BodyContent: |
    You can get an error when trying to restore TFS backups that certain features are only supported on SQL Server Enterprise Edition.

    If you try to restore a SQL Server database that you backed up from an Enterprise version of SQL Server (and that includes Developer Edition) you may encounter an error when trying to restore that database to another SQL Server that is Standard or Express edition.

    - Update I got an email from [Grant Holiday](http://blogs.msdn.com/b/granth/) with a little titbit of information.
      > Instead of running a bunch of ALTER INDEX commands, you can just follow the instructions at http://support.microsoft.com/kb/2712111, which is what the error message refers to. Essentially, run this command in each of the TFS Configuration & Collection databases:
      >
      > ```
      > EXEC [dbo].[prc_EnablePrefixCompression] @online = 0, @disable = 1
      >
      > ```
      >
      > \-[Grant Holiday](http://blogs.msdn.com/b/granth/)

    ![Error restoring databases that uses compression to SQL Express](images/image16-1-1.png "Error restoring databases that uses compression to SQL Express")  
    { .post-img }
    Figure: Error restoring databases that uses compression to SQL Express

    This is due to features that are provided in the Enterprise edition of SQL that are not present in anything lower. What sometimes gets folks confused is that Developer Edition has feature parity with Enterprise.

    ```
    TITLE: Microsoft SQL Server Management Studio
    ------------------------------

    Restore of database 'Tfs_Tfs01' failed. (Microsoft.SqlServer.Management.RelationalEngineTasks)

    ------------------------------
    ADDITIONAL INFORMATION:

    An exception occurred while executing a Transact-SQL statement or batch. (Microsoft.SqlServer.SmoExtended)

    ------------------------------

    Database 'Tfs_Tfs01' cannot be started in this edition of SQL Server because part or all of object 'tbl_LocalVersion' is enabled with data compression or vardecimal storage format. Data compression and vardecimal storage format are only supported on SQL Server Enterprise Edition.
    Database 'Tfs_Tfs01' cannot be started because some of the database functionality is not available in the current edition of SQL Server. (Microsoft SQL Server, Error: 909)

    For help, click: http://go.microsoft.com/fwlink?ProdName=Microsoft%20SQL%20Server&EvtSrc=MSSQLServer&EvtID=909&LinkId=20476

    ------------------------------
    BUTTONS:

    OK
    ------------------------------

    ```

    In this case some of the objects (tables & indices) have compression enabled and compression is only available in SQL Enterprise and Developer Editions.

    You also can’t say that you were not warned as when you detached the collection from your old TFS server you ignored the warning that resulted in the very message above. How do I know that you did? Coz I did as well…

    ![image](images/image17-2-2.png "image")  
    { .post-img }
    Figure: This collection has SQL Enterprise features enabled

    When you detach a collection you will get a warning if it is using enterprise features. I had always gotten into the habit of ignoring this as I had never encountered any issue. Now I have…

    ```
    This collection has SQL Enterprise features enabled. If you are moving the collection across SQL Server Editions please read the documentation (http://go.microsoft.com/fwlink/?LinkId=166007) to see how this impacts you.

    ```

    Now that we know what the problem is we need to take steps to remove the compression that is enabled on the objects within our collection. When you create a collection with the enterprise features enabled TFS enabled the compression automatically so we will always need to down-level our databases if we encounter this issue. But first we need to find the objects…

    ```
    SELECT
    SCHEMA_NAME(sys.objects.schema_id) AS [SchemaName]
    ,OBJECT_NAME(sys.objects.object_id) AS [ObjectName]
    ,[rows]
    ,[data_compression_desc]
    ,[index_id] as [IndexID_on_Table]
    FROM sys.partitions
    INNER JOIN sys.objects
    ON sys.partitions.object_id = sys.objects.object_id
    WHERE data_compression > 0
    AND SCHEMA_NAME(sys.objects.schema_id) <> 'SYS'
    ORDER BY SchemaName, ObjectName

    ```

    This SQL statement allows you to find all of the index objects that are currently enabled for compression. Just because it is enabled does not mean that it is in use, but just having it enabled will disallow your ability to import your database into SQL Standard or SQL Express.

    ![List of objects that have compression enabled in SQL Enterprise](images/image18-3-3.png "List of objects that have compression enabled in SQL Enterprise")  
    { .post-img }
    Figure: List of objects that have compression enabled in SQL Enterprise

    We can then use this list to alter the objects and remove the compression. To do this we need to rebuild the indices without compression enabled as it is not just an on/off flag.

    ```
    ALTER INDEX ALL ON LinkTreesLatest REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_AuthorizationObject REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_Branch REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_BranchMapping REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_LocalVersion REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_nodes REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_PendingChange REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_PendingChangeRecursive REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_PendingMerge REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_PendingRollback REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_PropertyValue REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_RegistryItems REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_SecurityAccessControlEntry REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_Version REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_WorkingFolder REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_WorkingFolderHistory REBUILD WITH (DATA_COMPRESSION = None);
    ALTER INDEX ALL ON tbl_WorkspaceMapping REBUILD WITH (DATA_COMPRESSION = None);
    GO

    ```

    If you have a large amount of data than this can and will take some time. Or considerably longer!

    For me, my collection was less than 100mb so the entire script ran in milliseconds. On hundreds of gigabyte's I would  expect this to take a very long time.

    ![SQL backup restore is now successful](images/image19-4-4.png "SQL backup restore is now successful")  
    { .post-img }
    Figure: SQL backup restore is now successful

    Woot.. now that I have removed that enterprise only feature SQL Express now no longer chokes on the restore.

    ## Conclusion

    Although the enterprise features are useful at scale they can get in the way when you are tinkering or if your instance is just that small. If your TFS instance is small enough to go into SQL Express I would recommend using [http://tfs.visualstudio.com](http://tfs.visualstudio.com) instead as you will always have the latest features and someone else maintains your server.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-27-restore-tfs-backups-from-sql-enterprise-to-sql-express\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-27-restore-tfs-backups-from-sql-enterprise-to-sql-express
- FrontMatter:
    title: Remote Execute PowerShell against each Windows 8 VM
    description: Learn how to remotely execute PowerShell scripts on Windows 8 VMs using Hyper-V, streamlining updates and management with minimal effort.
    ResourceId: T_5NKsLxoK7
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9901
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-05-23
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: remote-execute-powershell-against-each-windows-8-vm
    aliases:
    - /resources/T_5NKsLxoK7
    aliasesArchive:
    - /blog/remote-execute-powershell-against-each-windows-8-vm
    - /remote-execute-powershell-against-each-windows-8-vm
    - /resources/blog/remote-execute-powershell-against-each-windows-8-vm
    tags:
    - Windows
    - Software Development
    - System Configuration
    - Install and Configuration
    categories:
    - Uncategorized
    preview: image11-1-1.png
  BodyContent: |
    Running a remote execute PowerShell against each Windows 8 VM on your Hyper-V host can help you maintain the guest VM's in a minimal amount of time.

    With all of the work going on at the office around PowerShell I wanted to have a go and solve another problem I have. I kept running into an issue when using Hyper-V on my local computer. Every so often, to keep them relent, I need to boot each of the virtual machines and run windows updates. My first thought was to create a PowerShell that would update the them automatically, by then I thought… why can’t I push the script out to each of them.

    - DONE Remote Execute PowerShell against each VM
    - DONE Execute PowerShell against VM

    This will require two distinct Scripts.

    ## Remote Execute against each VM

    I am using Windows 8 with Hyper-V so all of the virtual machines are local. So the first step is to get a list of the VM’s and loop though them.

    ```
    $VMs = Get-VM
    foreach ($vm in $VMs)
    {
        Write-Host  " $($vm.Name)" -ForegroundColor Yellow
    }

    ```

    Note Watch out as Get-VM does not error out when you are not running under elevated privileges it just returns no machines. Now that vexed me for a while.

    You can combat this by doing a check for elevated privileges and starting a new elevated process if your are not currently running in elevated mode.

    ```
    If (-NOT ([Security.Principal.WindowsPrincipal][Security.Principal.WindowsIdentity]::GetCurrent()).IsInRole([Security.Principal.WindowsBuiltInRole] "Administrator"))
    {
        $arguments = "& '" + $myinvocation.mycommand.definition + "'"
        Start-Process powershell -Verb runAs -ArgumentList $arguments
        Break
    }

    ```

    We will see how this works out remotely, but that's for later.

    So for each VM we can now execute something. However, what I want to do is run the script on my host (My main computer) and have it execute a portion of that script on the VM. For this I choose to have a separate ps1 file that did all of the local actions. There are really two ways to do this, first with a “\[remote region\]” that executes anything within that code block on the remote VM and second with a “Invoke-Command -ComputerName \[computerName\]”. The former sounds like it will complicate my scripts, making them too long, so I went with the latter. “Invoke-Command” has an option to pass another ps1 that does the actual execution which in turn allows me test that script separately.

    So what do I end up with?

    ```
    Try{
        Invoke-Command -ComputerName $compName -ScriptBlock {Set-ExecutionPolicy Unrestricted} -Credential $Cred
        Invoke-Command -ComputerName $compName -FilePath $RemoteScript -Credential $Cred
    }

    catch {
        "any other undefined errors"
        $error[0]
    }

    ```

    You will note that I have set the execution policy to ‘unrestricted’ prior to executing the code. As I am not signing the PowerShell scripts I need to do that in order to get them to run. Although all of the guest VM’s are within a domain my local computer, the one running the master script, is not. This does pose a number of interesting issues that means that you need to pass a ‘-Credential’ object into the invoke method.

    ```
    $Username = 'nakedalmmrhinsh'
    $Password = 'P2ssw0rd'
    $pass = ConvertTo-SecureString -AsPlainText $Password -Force
    $Cred = New-Object System.Management.Automation.PSCredential -ArgumentList $Username,$pass

    ```

    This object will then allow the ‘Invoke-Command’ to authenticate correctly with the remote server. However the first time that you run this script you might get an error because the local computer is not trusted. If it was joined to the domain this would not be an issue but as it is in a workgroup the domain joined VM will reject you.

    ```
    Set-Item wsman:localhostclienttrustedhosts *

    ```

    Just run the above on the VM to prep it or you can explicitly trust the host name. As these are all demo and not production VM’s I am not particularly worried about locking them down.

    Now we can loop through the VM’s and execute a remote script against them. This then sounds like we are nearly done, however what happens when the VM’s are off or saved or paused. Well… nothing as you can’t execute a script against a machine that is not running. I needed to find a way to start the machines and luckily hyper-v can be totally managed by PowerShell and thus there is a command for that. The current state of the machine is stored in “$vm.State” which has a number of vaues that we need to do different things for.

    ```
    switch ($vm.State)
    {
         default {
              Write-Host  " Don't need to do anything with $($compName) as it is $($vm.State) "
         }
         "Paused"
         {
              Write-Host  "$($vm.Name) is paused so making it go "
              Resume-VM –Name *$compName* -Confirm:$false
         }
         "Saved"
         {
              Write-Host  "$($vm.Name) is paused so making it go "
              Start-VM –Name *$compName* -Confirm:$false
          }
         "Off"
         {
              Write-Host  "$($vm.Name) is stopped so making it go "
              Start-VM –Name *$compName* -Confirm:$false
         }
    }

    ```

    Here I use a case statement to choose what to do with each VM based on its current state. Therefore if it is ‘paused’ I need to ‘resume’ it to the running state. In addition I also store the current state in a variable so that I can reset each VM to its original state after I have run the script. This would allow me to boot each VM in turn rather than all at one and thus not overload my local computer.

    So there is one last thing to do. When you change the state of  VM using “Start-VM” it can take some time to load. You could guess and insert a delay but what if the VM takes a long time to do a group policy update or maybe a windows update needs to finish.

    ```
    do {
         Start-Sleep -milliseconds 100
         Write-Progress -activity "Waiting for VM to become responsive" -SecondsRemaining -1
    }
    until ((Get-VMIntegrationService $vm | ?{$_.name -eq "Heartbeat"}).PrimaryStatusDescription -eq "OK")
    Write-Progress -activity "Waiting for VM to become responsive" -SecondsRemaining -1 -Completed

    ```

    So I monitor the ‘heartbeat’ of the VM to determine when it becomes available. This will return “OK” once the VM has booted far enough to start responding to Hyper-V. This should mean that the VM will now be responsive to commands. As this can take some time I also want some sort of progress bar to be visible to let anyone monitoring the script know that we are waiting. There is a built in ‘Write-Progress’ command that lets us do this and it renders in the appropriate form for the medium that the script is executing in.

    ```
    $Username = 'nakedalmmrhinsh'
    $Password = 'P2ssw0rd'
    $nameRegex = "[d*][(?.*)](?.*)[(?.*)]"
    $RemoteScript = D:DataUsersMrHinshDesktopcmdService-VM.ps1
    #------------------------------------------------------------------------
    If (-NOT ([Security.Principal.WindowsPrincipal][Security.Principal.WindowsIdentity]::GetCurrent()).IsInRole([Security.Principal.WindowsBuiltInRole] "Administrator"))
    {
        $arguments = "&amp; '" + $myinvocation.mycommand.definition + "'"
        Start-Process powershell -Verb runAs -ArgumentList $arguments
        Break
    }
    #------------------------------------------------------------------------
    $pass = ConvertTo-SecureString -AsPlainText $Password -Force
    $Cred = New-Object System.Management.Automation.PSCredential -ArgumentList $Username,$pass
    $confirm = $false
    $VMs = Get-VM
    Write-Output "Found $($VMs.Count) virtual computers"
    foreach ($vm in $VMs)
    {
        Write-Host  "Execute for $($vm.Name)" -ForegroundColor Yellow
        $matches = [Regex]::Matches($vm.Name,$nameRegex)
        if ($matches.count -gt 0)
        {
            $compName = $matches[0].groups["name"].value.Trim()

            $startState = $vm.State
            switch ($vm.State)
            {
                default {

                   Write-Host  " Don't need to do anything with $($compName) as it is $($vm.State) "
                }
                "Paused"
                {
                    Write-Host  "$($vm.Name) is paused so making it go "
                    Resume-VM –Name *$compName* -Confirm:$false
                }
                "Saved"
                {
                    Write-Host  "$($vm.Name) is paused so making it go "
                    Start-VM –Name *$compName* -Confirm:$false
                }
                "Off"
                {
                     Write-Host  "$($vm.Name) is stopped so making it go "
                     Start-VM –Name *$compName* -Confirm:$false
                }
            }

            Write-Host  " Waiting for '$($compName)' to respond "
            do {
                    Start-Sleep -milliseconds 100
                    Write-Progress -activity "Waiting for VM to become responsive" -SecondsRemaining -1
                }
            until ((Get-VMIntegrationService $vm | ?{$_.name -eq "Heartbeat"}).PrimaryStatusDescription -eq "OK")
            Write-Progress -activity "Waiting for VM to become responsive" -SecondsRemaining -1 -Completed


            Write-Host  " Remote execution for '$($compName)' :) "

            Try{
                Invoke-Command -ComputerName $compName -ScriptBlock {Set-ExecutionPolicy Unrestricted} -Credential $Cred
                Invoke-Command -ComputerName $compName -FilePath $RemoteScript -Credential $Cred
            }

            catch {
                "any other undefined errors"
                $error[0]
            }

             switch ($startState)
            {
                "Off"
                {
                    Stop-VM  –Name *$compName* -Force -Confirm:$false
                }
                "Paused"
                {
                    Suspend-VM –Name *$compName* -Confirm:$false
                }
                "Saved"
                {
                    Save-VM –Name *$compName* -Confirm:$false
                }
                default {

                    Write-Host  " Leaving $($compName) running $startState "
                }
            }

        }
        else
        {
            Write-Host  "Unable to determin name of $($vm.Name) as it is in a crappy format. Needs to be '$nameRegex'" -ForegroundColor Red
        }
    }
    ```

    Be warned that this is my first pass at this script and more scarily my first actual PowerShell script. As such I have no idea if this is the right way to do things, but it does seam to work. It lets you execute another PowerShell script against each of my VM’s.

    ## Execute against VM

    The second script that I need will do all of the work to configure and update the VM after it has been started. This will be a remote execution script that installs anything that it needs as well as getting and installing all of the outstanding Microsoft Updates.

    ```
    Param(
      [string]$computerName = $env:COMPUTERNAME
    )
    If (!(Test-Path C:Chocolatey))
    {
        Write-Host  " Install Chocolatey "
        iex ((new-object net.webclient).DownloadString("http://bit.ly/psChocInstall"))
    }
    Else
    {
        chocolatey update
    }
    cinst enablepsremoting
    cinst PSWindowsUpdate -Version 1.4.6
    Write-Output "--SERVICE"
    Write-Output "-Allow ping for whatever"
    netsh advfirewall firewall add rule name="All ICMP V4" dir=in action=allow protocol=icmpv4
    Write-Output "-Enable File and Print Sharing for possible Lab Management use"
    netsh advfirewall firewall set rule group=”File and Printer Sharing” new enable=Yes
    Write-Output "-Check all Updates"
    Import-Module PSWindowsUpdate
    Get-WUInstall -MicrosoftUpdate -IgnoreUserInput -acceptall -autoreboot -verbose

    ```

    I will likely go though a bunch more iterations on this script but for right now it:

    1. Makes sure that Chocolatey is installed
    2. Installed Chocolatey packages including ‘PSWindowsUpdate’
    3. Validates some firewall changes that I need
    4. Downloads and installs all Microsoft Updates

    This may change and I want to test out some hierarchical PowerShell script option, but until then this makes it easy to update all of my VM’s.

    ## Conclusion

    Although I have tinkered with PowerShell now and then this is the first executable script that I have written. I am still in copy/paste mode but I can sure see the value of learning and using PowerShell for everything from installing applications to configuring systems.

    You can just about do anything with PowerShell that you like.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-23-remote-execute-powershell-against-each-windows-8-vm\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-23-remote-execute-powershell-against-each-windows-8-vm
- FrontMatter:
    title: Enable Feedback support for users in Team Foundation Server 2012
    description: Learn how to enable feedback support in Team Foundation Server 2012 with simple configurations and permissions. Enhance user engagement effortlessly!
    ResourceId: 7WxWYWI5PI2
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9494
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-05-21
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: enable-feedback-support-for-users-in-team-foundation-server-2012
    aliases:
    - /resources/7WxWYWI5PI2
    aliasesArchive:
    - /blog/enable-feedback-support-for-users-in-team-foundation-server-2012
    - /enable-feedback-support-for-users-in-team-foundation-server-2012
    - /resources/blog/enable-feedback-support-for-users-in-team-foundation-server-2012
    tags:
    - Install and Configuration
    categories:
    - Uncategorized
  BodyContent: |
    The focus of this article is to show you how to easily enable feedback support for users in Team Foundation Server 2012 with a few simple permissions. This works great with Team Foundation Server and even better with Team Foundation Service.

    Team Foundation Server works better because you have an on-premise installed on TFS 2012 therefore, those who you want to grant access require an Active Directory account in your domain. All of your internal users already have this, but you can also give VPN access for externals. However, this does not work for many publicly shippable applications. If however you are using Team Foundation Service from [http://tfs.visualstudio.com](http://tfs.visualstudio.com) all you need is a user Live ID and permission.

    ![image](images/image.png "image")  
    { .post-img }
    Figure: Providing Feedback on an application

    There are a couple of things that you need to configure in order to enable feedback support for users in Team Foundation Server 2012. Although these may seem trivial they are a little hidden:

    1. **DONE Configure email settings to enable feedback support**
    2. **DONE Configure permissions to enable feedback support**

    With these complete you are good to go!

    ## Configure email settings to enable feedback support

    The first thing to configure is the email settings in order to make sure that we can both use the service and that email in fact does get sent. If you do not have email settings configured then you should see a bunch of warning messages when you try to use features that depend on them.

    ![Figure: TF400264: Team Foundation Server is not configured to send email notifications ](images/image1.png "Figure: TF400264: Team Foundation Server is not configured to send email notifications ")  
    { .post-img }
    Figure: TF400264: Team Foundation Server is not configured to send email notifications

    If this is the case then you need to go into your Team Foundation Server Administration Console on the server and configure the email settings. This will require a mail server to actually send the mail to be prepared with specified details.

    Note: Many mail servers restrict the ‘from’ address for sending mail and this can mean that emails don’t send when you think they will be. If an email is not being sent, then check the event log on the server for errors.

    ![Figure: Enter the mail settings to enable feedback support](images/image2.png "Figure: Enter the mail settings to enable feedback support")  
    { .post-img }
    Figure: Enter the mail settings to enable feedback support

    Once you have completed and saved this, the email sending feature will work not only for feedback, but also for the built in alerts manager for teams…

    ## Configure permissions to enable feedback support

    The permissions are a bit more complex and may be much more specific to the project. You need two very specific permissions sets, one is obvious and the other… well… not so much.

    Note: You do not need any version of Visual Studio nor a CAL for TFS to provide feedback. You simply need to request it.

    ![Figure: Create a group to to enable feedback support](images/image3.png "Figure: Create a group to to enable feedback support")  
    { .post-img }
    Figure: Create a group to enable feedback support

    Now, we need to create a group that we can add folks to without having to make them “Contributors”. Unfortunately, “Contributors” get access to our Source Code and builds by default so we really want to lock it down, even if it is just a little.

    ![Figure: You need ‘create test runs’ to enable feedback support](images/image4.png "Figure: You need ‘create test runs’ to enable feedback support")  
    { .post-img }
    Figure: You need ‘create test runs’ to enable feedback support

    As mentioned earlier, the non-obvious permission is required to provide feedback. For some reason you need to have the ‘create test runs’ permission at the root of the project. Don’t ask…

    ![Figure: Join new group to Readers to enable feedback support](images/image5.png "Figure: Join new group to Readers to enable feedback support")  
    { .post-img }
    Figure: Join new group to Readers to enable feedback support

    This new group should only be “Readers” so that we can grant them access to only what is needed to get feedback submitted. What we have now will allow them to view things within the Team Project but not to edit. Now we need to add explicit permission to our root “Area” node.

    ![Figure: Edit the security for the root area](images/image6.png "Figure: Edit the security for the root area")  
    { .post-img }
    Figure: Edit the security for the root area

    Getting into the security settings for an “Area” is simple but a little obscure. There is a little node that only appears when you hover over the node which allows you to get into the Security settings.

    ![Figure: Add the ‘Feedback Provider’ group](images/SNAGHTML1b65f95.png "Figure: Add the ‘Feedback Provider’ group")  
    { .post-img }
    Figure: Add the ‘Feedback Provider’ group

    Simply type or select the ‘Feedback Provider’ group from the drop down list and save the changes.

    ![Figure: Allow edit work items in this node for ‘Feedback Provider’](images/image7.png "Figure: Allow edit work items in this node for ‘Feedback Provider’")  
    { .post-img }
    Figure: Allow edit work items in this node for ‘Feedback Provider’

    Now we have added permission only to allow the editing of work items. Unfortunately, this current state means that any users in this group can edit work items and requires a CAL.

    Make sure that you also add the appropriate users to the ‘Limited” access level which is found in the administration control panel for the collection.

    ![Figure: Add feedback users to the Limited access level](images/image8.png "Figure: Add feedback users to the Limited access level")  
    { .post-img }
    Figure: Add feedback users to the Limited access level

    And now everyone in that group has access.

    ## Conclusion

    The feedback features are incredibly useful and require only minimal configuration. There is no excuse for not having tractability from Feedback through your Backlog to the detail of implementation, allowing you to revisit the feedback when complete.

    With the added bonus of zero licensing requirements in order to provide feedback, we can safely roll out the Feedback Client internally to whoever is needed.

    **Warning: always back up your data before attempting any changes.**

    _Originally published at Where Technology Meets Teamwork by [Martin Hinshelwood](http://blog.hinshelwood.com/about), Senior ALM Consultant. ([source](http://blog.nwcadence.com/enable-feedback-support-for-users-in-team-foundation-server-2012/))_
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-21-enable-feedback-support-for-users-in-team-foundation-server-2012\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-21-enable-feedback-support-for-users-in-team-foundation-server-2012
- FrontMatter:
    title: Quality enablement with Visual Studio 2012
    description: Discover how Visual Studio 2012 enables continuous quality in software development, helping you meet modern user expectations and enhance brand differentiation.
    ResourceId: YcLApPV4Zgj
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9487
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-05-15
    weight: 540
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: quality-enablement-with-visual-studio-2012
    aliases:
    - /resources/YcLApPV4Zgj
    aliasesArchive:
    - /blog/quality-enablement-with-visual-studio-2012
    - /quality-enablement-with-visual-studio-2012
    - /resources/blog/quality-enablement-with-visual-studio-2012
    tags:
    - Continuous Delivery
    - Software Development
    - Continuous Improvement
    - Engineering Practices
    - Frequent Releases
    - Release Management
    - Shift-Left Strategy
    - Technical Excellence
    - Value Delivery
    - Application Lifecycle Management
    - Working Software
    - Operational Practices
    - Product Delivery
    - Pragmatic Thinking
    - Technical Mastery
    categories:
    - Engineering Excellence
    - DevOps
    preview: nakedalm-experts-visual-studio-alm-18-18.png
  BodyContent: |
    In the modern application lifecycle one of the key messages is one of quality enablement. Quality will be the key differentiator between you and your competitors over the next few years and the old excuses are just that… old.

    All companies are now software companies and require more and more to deliver software that is a level of quality that wows your users. Gone are the days when your employees have access to better technology in the office as they are now way ahead at home and upgrading at a faster pace. As this technology has infiltrated the home so the expectations of the consumers (your customers or employees) has increased.

    This new level of expectation has added more attributes to the qualities required of even your internal line-of-business applications. Users now expect that you can deliver usable, high-quality applications that work on any platform. This is [the new normal for software development](http://blog.hinshelwood.com/the-new-normal-of-the-modern-application-lifecycle/) and we need to rise to meet it…

    ![Quality Enablement means Continuous quality for modern business applications](images/image31-1-1.png "Quality Enablement means Continuous quality for modern business applications")  
    { .post-img }
    **Figure: Quality Enablement means continuous quality for modern business applications**

    In order to achieve this goal we need to stop testing only at the end of our release cycle and start to test continuously and repeatedly to enable the quality levels that we need. We need to change our practices, and we need better tools to help. Visual Studio 2012 is a great tool for this…

    ### Continuous brand differentiation in quality enablement

    You must continuously differentiate your brand in order to compete in the marketplace and to do that you must continuously satisfy consumers whether they are customers or employees … and to do that without crashing and burning you must have a solid quality foundation…

    ![Modern business applications require continuous quality](images/image32-2-2.png "Modern business applications require continuous quality")  
    { .post-img }
    **Figure: Modern business applications require continuous quality**

    The quality of your inventory control systems will denote how quickly and efficiently you can serve your consumers and if your customer care team don’t have the caller’s information to hand how does that make your consumer feel?

    #### Systems of engagement in quality enablement

    Your systems of engagement are just that: those systems through which your consumers engage with your organisation’s data. These could be your awesome Twitter application that you sell through the Windows Store, or it could be your call centre management system that your customer representatives use to view customer data. Many companies assume that your internal applications are just line-of-business but when they fail it is your customers that feel the pain…

    I don’t know how many times I have spoken to a sales representative, either in store or over the phone to hear the fateful phrases “the systems are running slow today”, or “there was a crash, can you call back later?”.  This could be due to a fault, excessive load or the inability of the operator to use it properly. What about call in systems that ask you for your account numbers to get in the queue, only to be asked again when you talk to a representative. These are all deficiencies in the quality of the software that is delivered.

    #### Systems of record in quality enablement

    The places where you store your single point of truth for your data would be considered your “systems of record” and while users do not directly, or should not, interact with them they do use the services that they provide. You must be able to deliver updates to  your systems of record without breaking your engagement systems and even if these engagement system are not primarily software, this is where you are a software company wither you like it or not. This is one of the core issues that your organisation will need to solve in order to increase quality in response to the changes in modern applications and delivery.

    In the last 5 years the consumers of our technology have been asking more of us. Modern applications are demanding, and our previous systems of delivery aren’t enough to meet that demand, we need a modern application lifecycle too.

    ### Continuous value delivery with modern business applications

    In order to be successful at delivering value to the business we know that we need to deliver more frequently. This allows for the business to apply corrective action as needed without interfering in the delivery process.

    ![Continuous value delivery with modern business applications](images/image33-3-3.png "Continuous value delivery with modern business applications")  
    { .post-img }
    **Figure: Continuous value delivery with modern business applications**

    In order to be successful at delivering value to the business we know that we need to deliver more frequently. This allows for the business to correct our course as we go and us to build a better product that more closely matches their needs.

    Let’s also note that this is not a strictly speaking agile diagram. If you go round this loop in 2 years then it is not agile… If you go round in more frequent iterations it may be Spiral or Iterative. Only once you get this cycle down to 30 days or less can you consider it truly agile…

    …why does that matter?

    Well these modern applications we’ve been talking about, these are not systems where you can get away with updating them every few years or even yearly. The new normal is really quarterly at a minimum, right, and probably shrinking. Modern app users are not going to wait around for months for a new feature.  So whether you call it agile or something else, the point is, your process needs to be nimble enough to support these more frequent release cycles. Conventional thinking and scheduling will not do.

    ![Conventional QA in the modern application lifecycle](images/image34-4-4.png "Conventional QA in the modern application lifecycle")   
    { .post-img }
    **Figure: Conventional QA in the modern application lifecycle**

    In a conventional model you would leave QA, UAT and operations verification until you have complete development. Unfortunately this results in:

    - Rework of development efforts long after the developer has forgotten how that part of the system works
    - Unmet user expectations as users see for the first time things that it is too late to change
    - Increased costs as operations teams find performance and deployment issues to late in the game

    Ultimately this result in an enormous increase in the cycle time for delivery and most often result in late delivery. We buffer for rework that we think we will get, but we are mostly wrong.

    ### Quality enablement

    Modern applications are delivered continuously and as such you need to practice continuous delivery to build them. In order to begin to deliver continuously we need to discern how to enable the level of quality that we need to achieve for our software. The ideas behind quality enablement are simple.

    > Find and fix problems as close as possible to the time that they are created. Accept that acceptance testing is a continuous activity, it starts when the original product or features are imagined and it continues throughout the lifecycle, not just at the end.

    This includes problems encountered when testing, building, packaging and deploying in addition to identifying defects from either poorly met requirements, or poorly met expectations.

    ![Continuous quality for continuous value delivery](images/image35-5-5.png "Continuous quality for continuous value delivery")  
    { .post-img }
    **Figure: Continuous quality for continuous value delivery**

    There are four key areas that we need to look at to enable our ability to continually deliver high quality working software: acceptance test planning, continuous acceptance testing, testing in production & reducing mean-time-to-resolution.

    ![Acceptance test planning for Quality Enablement](images/image36-6-6.png "Acceptance test planning for Quality Enablement")  
    { .post-img }
    **Figure: Acceptance test planning for quality Enablement**

    The thing that results in more unmet user expectations than any other single thing is poorly defined requirements. If you are going to succeed at building software you need actionable requirements. While you should consider your backlog of work under lean inventory control you still need firm requirements for your development team to work from. This doesn’t mean you write longer and denser specs that no one reads. Instead it means you engage with stakeholders and constantly check, re-check, get their feedback, show them small samples, you do this as a continuous cycle of feedback and responsiveness.

    There are many inputs to actionable requirements and you need to consider not just quality and operations requirements but the goal that your business has. This should be represented in a list of actionable requirements but does not end there. Your requirements are now actionable to the point of being able to break them down into acceptance criteria.

    Building out tight acceptance criteria, usually in the Given->When->Then model helps you elicit more actionable details to your requirements and gives you an acceptance test plan. That is you have a short measurable checklist for things that if you fulfil them the customer will accept that you have completed it correctly. This effectively brings User Acceptance Testing (UAT) inside of the continuous quality circle.

    ![Continuous acceptance testing for Quality Enablement](images/image37-7-7.png "Continuous acceptance testing for Quality Enablement")  
    { .post-img }
    **Figure: Continuous acceptance testing for quality enablement**

    So now that we have acceptance criteria we really want to turn them into something that we can execute. This can be done at various levels and certainly at the user interface level it would initially consist of manual testing. But as we build our software and add more features we need to both make sure that we have implanted the correct features and that we have not broken something that we have already delivered. This is hard and time-consuming as it means that we need to be continuously checking our acceptance criteria again and again to be sure. This will increase our cycle time as we move forward if we are adding tens of additional acceptance criteria for each integration. The only way, short of guessing which to run when we hit time constraints, to continuously run our acceptance criteria is to continuously automate them.

    On each pass through our cycle we should have all of our tests automated. If we are working against our services, perhaps practicing Test Driven Development (TDD), we are likely starting with automated tests written in a unit testing framework. These tests would consist of unit tests, integration tests and performance / load tests which are likely already automated. Once we start testing the user interface thing get a little more complicated and creating and managing tests and test cases get a little more difficult but regardless, if we don’t automate those tests as well we will end up with an unreasonable and unsustainable burden on our testers.

    Just like putting coders under pressure to deliver forces them to increasingly reduce quality to meet the deadline, so putting testers under pressure will encourage them to repeatedly and consistently reduce the breadth of your test coverage.

    To make matters worse it is not just the time for testers to execute the tests that impacts on the ability to enable continuous quality but it is also the time it takes to build and deploy your software…

    ![Virtual Lab automation for Quality Enablement](images/image38-8-8.png "Virtual Lab automation for Quality Enablement")  
    { .post-img }
    **Figure: Virtual lab automation for quality enablement**

    Whatever types of automation you create will all be for naught if you don't have an automated deployment. And for automated deployment to work we need to have some sort of automated virtual labs so that we can dynamically spin up pre-configured environments to somewhere.

    - [Virtual labs in the modern application lifecycle](http://blog.hinshelwood.com/virtual-labs-in-the-modern-application-lifecycle/ "http://blog.hinshelwood.com/virtual-labs-in-the-modern-application-lifecycle/")

    We need to be able to quickly and easily provision environments for development, testing and fault reproduction in a consistent and automated manor. The time that this saves can be calculated using the Null Build technique which will show you just how much of your cycle time you are burning with deployments and configuration.

    > _I learned about null builds from Brian Harry. A null build is a process by which you measure how long it takes you to deploy from source code. Immediately following a successfully deployment to production, create a new build of the same code and do it again. This time measuring how long it takes and where it gets hung up._

    ![Testing in production for Quality Enablement](images/image39-9-9.png "Testing in production for Quality Enablement")  
    { .post-img }
    **Figure: Testing in production for quality enablement**

    Even once we get to production we do not stop applying Application Lifecycle Management processes. We need feedback on our application and that comes from two main sources once we hit production; Consumers and supporters. Once we get our completed increment of software in front of our users and stakeholders we can then get real world feedback that allows us to reconcile our backlog with what they now need. In addition our support organisation are monitoring the health of our software and provide the same service to the non-functional aspects of our software.

    This can only be done in production.

    ![Mean time to resolution with Quality Enablement](images/image40-10-10.png "Mean time to resolution with Quality Enablement")  
    { .post-img }
    **Figure: Mean time to resolution with Quality Enablement**

    How quickly can you fix bugs? The quicker that a bug is found, diagnosed and fixed the cheaper it is to fix so the mean time to resolution directly relates to cost of maintenances. But more than that it directly related to your consumers’ satisfaction. Ideally you want to be able to escalate directly from your incident management software to your development tools as well as include actionable diagnostics with the report. You don’t want to give developers access to production so we need enough information to reproduce the problem or at least understand the issue.

    In addition, whatever the result we need to make sure that that issue once fixed never rears its ugly head again.

    ![The business value of Quality Enablement](images/image41-11-11.png "The business value of Quality Enablement")  
    { .post-img }
    **Figure: The business value of quality enablement**

    So now that we understand what quality enablement means, the impact to our software, our teams and potentially our organisation, what do we get?

    > Quality Enablement: What have you done for me lately?

    So what do you get?

    Well, it is much easier to get to the root of what the business requires when you are able to show them something working now and to have their involvement as you deliver continuous value. As you loop round your cycle at least every 30 days working with the consumers of your application we are able to correct or even change the course of your requirements to achieve a more tailored solution to the objectives of the business.

    With the short delivery cycle with smaller changes that your consumer is able to assimilate frequently you are able to get your efforts, the things that you are building, into the hands of your consumers much more quickly. This the results in much higher satisfaction from all of you consumers and stakeholders as they can not only see what you are doing, but give you suggestions and feedback that you can quickly iterate on.

    The resulting reduction of cost is directly attributed to the increased quality in your software. Not only do you more closely meet the needs, so less rework, but you also have fewer defects in production so less of those expensive maintenance costs.

    ![Measure for Quality Enablement](images/image42-12-12.png "Measure for Quality Enablement")  
    { .post-img }
    **Figure: Measure for quality enablement**

    And now that we know what we get and we want it… how do we measure where we are in this process? How do we know whether it is working?

    The first thing that we can measure is value delivered to our business. For every requirement that you deliver you should have a “value” figure. This can be in dollars or time, but is often a relative value estimate. Just as we will be asking your development teams to create relative effort estimates so that we can gauge how many things that they can achieve your business can do relative value estimates to give you an idea how you might order items on a backlog. If you are ordering items by value or ROI (value / effort) then you will quickly see the most relevant requirements float to the top. This will help you reduce the cycle time on your releases as you can stop when there is no longer enough ROI in the backlog to continue with the project.

    Measuring how long it takes, on average, to deliver a single unit of work can help you identify places in your software where things are overly complex or places where your process can be improved to help reduce that number. If it takes two weeks for a tester to get to something that the coders built, or to verify a bug then this gives us an idea of where to focus our improvement efforts and how well we are doing.

    In addition we want to look at the numbers of defects being found and fixed. There should be fewer defects found over time not more. If there are more defects being found then you may be looking at a reduction in quality (or an increase in the skill of your testers) and whatever the reason it will help you focus on quality.

    All of this goes to reducing the amount of rework and thus reducing the cost.

    ![Solution characteristics in Quality Enablement](images/image43-13-13.png "Solution characteristics in Quality Enablement")  
    { .post-img }
    **Figure: Solution characteristics in quality enablement**

    In order to solve the problems that I am sure you have been envisaging throughout we need tools to help manage some of the complexities around continuous quality practices and the work that we have to do to achieve them.

    To do this we need tools that are tailored specifically for the types of user (their role) that will be using them. You don’t really want your business users to have to learn your development IDE tools, do you?

    They need to be extensible because there is no way that any one company can provide you the tools to solve all of your problems, but we still want our problems to be solved. Above all we need to have a toolset that supports any conceivable platform that we might be developing for…

    ![Solution architecture requirements for Quality Enablement](images/image44-14-14.png "Solution architecture requirements for Quality Enablement")  
    { .post-img }
    **Figure: Solution architecture requirements for Quality Enablement**

    At a high level we are talking about having a set of tools that are tailored for all of your roles that are on a unified set of services that includes the ability to connect to any platform…

    ![Solution architecture for Quality Enablement](images/image45-15-15.png "Solution architecture for Quality Enablement")  
    { .post-img }
    **Figure: Solution architecture for quality enablement**

    … And if we delve in deeper into the roles actions and requirements we can start to build a profile of what is required, and its complex… we could build this by knitting together a plethora of open source tools and building custom integration between them…or we could find a single unified Application Lifecycle Management solution that does it all…

    Where might we find one of those \[looks confused and rub chin\]….

    ### The Microsoft Solution

    For the last seven years Microsoft has been working on a system that embodies that quality enablement.

    ![The Microsoft solution for Quality Enablement](images/image46-16-16.png "The Microsoft solution for Quality Enablement")  
    { .post-img }
    **Figure: The Microsoft solution for quality enablement**

    Microsoft Team Foundation Server (on-premises) and Team Foundation Service (cloud) services are the backbone that provides features for both Windows and Java clients.

    For each hat that your users may wear that equates to roles there are separate tailored tools that allow then to interact with Team Foundation Services in a way that is specific to their role.

    ![Differentiation for Quality Enablement](images/image47-17-17.png "Differentiation for Quality Enablement")  
    { .post-img }
    **Figure: Differentiation for quality enablement**

    With these continuous quality practices, coupled with tools that are tailored for each role we are able to more easily and effectively achieve continuous value delivery at least every 30 days.

    _Originally published at Where Technology Meets Teamwork by [Martin Hinshelwood](http://blog.hinshelwood.com/about), Senior ALM Consultant. ([source](http://blog.nwcadence.com/quality-enablement-with-microsoft-visual-studio-2012/))_
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-15-quality-enablement-with-visual-studio-2012\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-15-quality-enablement-with-visual-studio-2012
- FrontMatter:
    title: 'TFS Integration Tools - Issue: unable to find a unique local path'
    description: Resolve the 'unable to find a unique local path' error in TFS Integration Tools with effective workarounds and tips for smoother source control migration.
    ResourceId: -dAwZr3zpgy
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9495
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-05-13
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: tfs-integration-tools-issue-unable-to-find-a-unique-local-path
    aliases:
    - /resources/-dAwZr3zpgy
    aliasesArchive:
    - /blog/tfs-integration-tools-issue-unable-to-find-a-unique-local-path
    - /tfs-integration-tools-issue-unable-to-find-a-unique-local-path
    - /tfs-integration-tools
    - /tfs-integration-tools---issue--unable-to-find-a-unique-local-path
    - /blog/tfs-integration-tools---issue--unable-to-find-a-unique-local-path
    - /resources/blog/tfs-integration-tools-issue-unable-to-find-a-unique-local-path
    tags:
    - Troubleshooting
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-2-2.png
  BodyContent: |
    When you are doing a Source Control migration using the TFS Integration Platform you receive a “unable to find a unique local path” runtime conflict.

    [![image](images/image_thumb2.png)](http://blog.nwcadence.com/wp-content/uploads/2012/07/image2.png)  
    { .post-img }
    Figure: You get a “MigrationException: unable to find a unique local path”

    At this point the migration fails and you are unable to continue.

    ### Applies to

    - TFS Integration Tools, version 2.2, March 2012
    - TFS Team Explorer \[All Versions\]

    ### Finding

    In order for the TFS Integration Platform to minimise the likelihood of hitting the 258 character limit of Windows it shortens the mapped path.

    [![image](images/image_thumb3.png)](http://blog.nwcadence.com/wp-content/uploads/2012/07/image3.png)  
    { .post-img }
    Figure: Shortened Local Folders

    This works only when there are enough characters after the last “” to be able to get a distinct path. If there are no enough characters then a Local path is unable to be mapped and the exception results.

    ### Workarounds

    The duplicates tend to come from multiple applications being stored under a single Team Project and all being mapped at once. If you chop your list of migrations down to a smaller list you are less likely to get duplicates.

    [![image](images/image_thumb4.png)](http://blog.nwcadence.com/wp-content/uploads/2012/07/image4.png)  
    { .post-img }
    Figure: ![](images/metro-icon-cross-1-1.png)Bad example, chance of collision is very high
    { .post-img }

    Reduce the number of mappings by grouping them. You still want to include all of the things within a branch structure together, but make sure that you have distinct names.

    _Originally published at Where Technology Meets Teamwork by [Martin Hinshelwood](http://blog.hinshelwood.com/about), Senior ALM Consultant. ([source](http://blog.nwcadence.com/tfs-integration-tools-issue-unable-to-find-a-unique-local-path/))_
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-13-tfs-integration-tools-issue-unable-to-find-a-unique-local-path\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-13-tfs-integration-tools-issue-unable-to-find-a-unique-local-path
- FrontMatter:
    title: Configure Test Plans for web access in TFS 2012.2
    description: Master TFS 2012.2 by configuring Test Plans for web access. Learn essential tips to ensure your team sees the right plans and streamline your testing process.
    ResourceId: eNRpc70Z73R
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9900
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-05-10
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: configure-test-plans-for-web-access-in-tfs-2012-2
    aliases:
    - /resources/eNRpc70Z73R
    - /resources/blog/configure-test-plans-for-web-access-in-tfs-2012.2
    aliasesArchive:
    - /blog/configure-test-plans-for-web-access-in-tfs-2012-2
    - /configure-test-plans-for-web-access-in-tfs-2012-2
    - /resources/blog/configure-test-plans-for-web-access-in-tfs-2012-2
    - /resources/blog/configure-test-plans-for-web-access-in-tfs-2012.2
    tags:
    - Install and Configuration
    - Azure DevOps
    - Software Development
    categories:
    - Uncategorized
  BodyContent: |
    Configure Test Plans for web access in TFS 2012.2 is a little tricky and we need to be very specific on how we configure it so that our Team can see the right test Plans.

    If you are working with the Test tab that is new in TFS 2012.2 then you may be wondering where your Test Plans are. In most cases if you have existing Test Plans you will not see any of the ones that you have already created.

    - Breaking newsWith [TFS 2013 Update 3 (TFS 2013.3)](http://support.microsoft.com/kb/2933779) the Test team have converted Test Plan and Test Suit to Work Items and enabled Team Field support. Awesome!

    ![Naked ALM: Test Hub in TFS 2012.2 Web Access](images/image3-7-7.png "Naked ALM: Test Hub in TFS 2012.2 Web Access")  
    { .post-img }
    Figure: Test Hub in TFS 2012.2 Web Access

    Or you may be wondering where your Test Plans have gone after you change its configuration.

    ![Naked ALM: Three Test Plan exist but don't show up in the Test Hub](images/image4-8-8.png "Naked ALM: Three Test Plan exist but don't show up in the Test Hub")  
    { .post-img }
    Figure: Three Test Plan exist but don't show up in the Test Hub

    As it turns out you need to have an exact match between the areas of backlog ownership that are configured for your Team and with the Area path set on your Test Plan. The product team also ‘forgot’ to allow this to work with the ‘team field’ configuration so ware are forced to include a work around for that.

    ![Naked ALM: Your team backlog values must match exactly the Area path set on the Test Plan](images/image5.png "Naked ALM: Your team backlog values must match exactly the Area path set on the Test Plan")  
    { .post-img }
    Figure: Your team backlog values must match exactly the Area path set on the Test Plan

    While a little annoying that this is not more easily configurable I can only imagine it getting better in the future… well I hope so anyway…

    ## Configure Test Plans for Area Paths

    If you are using Team Foundation Service or an out-of-the-box configured Team Foundation Server then you will be able to assign Area Paths to Teams.

    ![Naked ALM: Team A is assigned a particular area](images/image6.png "Naked ALM: Team A is assigned a particular area")  
    { .post-img }
    Figure: Team A is assigned a particular area

    So with an area set for the team this gets passed to the Team tab and with “sub-areas are included” we get a filtered list of Test Plans based on that area path.

    ![Naked ALM: Only showing area paths from “TeamsWithAreasTeam A” and below](images/image7-9-9.png "Naked ALM: Only showing area paths from “TeamsWithAreasTeam A” and below")  
    { .post-img }
    Figure: Only showing area paths from “TeamsWithAreasTeam A” and below

    In addition this means that my top level, and default, “Product Owner Team” will see both Test Plans I have in here. This is because one Test Plan is set to “TeamsWithAreasTeam A” and the other to “TeamsWithAreasTeam B”. Only Team B sees Team B’s Test Plans but the parent Team sees both.

    ![Naked ALM: Root team can see both sets of Test Plans](images/image8-10-10.png "Naked ALM: Root team can see both sets of Test Plans")  
    { .post-img }
    Figure: Root team can see both sets of Test Plans

    This can be very useful when you have many, many Test Plans and you can use Area Path for Team identification. However if you are currently using Area Path for Product Identification then you will have to specify the Product or Product Component for both the Test Plan and the Team.

    ![Naked ALM: Duplicate Team nodes to cope with multiple teams](images/image9-11-11.png "Naked ALM: Duplicate Team nodes to cope with multiple teams")  
    { .post-img }
    Figure: Duplicate Team nodes to cope with multiple teams

    If I now have three Products but I have my same two Teams I then need to have each of the teams represented at all of the leaf nodes for my Area hierarchy so that I can have two web portals with the data split between the teams. This becomes even more complicated if you have 10 teams and 15 products. You can imagine…

    - [Multiple Teams with Microsoft Team Foundation Server 2012 & Visual Studio Scrum V2.0](http://blogs.ripple-rock.com/colinbird/2012/11/19/MultipleTeamsWithMicrosoftTeamFoundationServer2012VisualStudioScrumV20.aspx)  
       Colin Bird is a proponent of this type of splitting and it does have some merits. I find it way to complicated to manage even with only a few teams and products within a single team project.

    Now that we have this structure we need to have our Test Plans set to “TeamsWithAreas-ProductProduct 1Component 1Team A” in order for them to appear in the web UI and be associated correctly.

    There is however another way…

    ## Configure Test Plans for team field

    You can use ‘[team field](http://nkdagility.com/team-foundation-server-2012-teams-without-areas/ "Team Foundation Server 2012 Teams without Areas")’ which allows you to use a drop-down field on your Work Item for Team in order to free up your Area Hierarchy to use for your Product Hierarchy. As your Team structure tends to be fairly flat this this is a good model.

    Note If you are an organisation like Microsoft where you can have a dedicated Team for each level of your Product Hierarchy then you would not use Teams without Areas. You would instead use the above option.

    However the Product Team for the Test tools  kind of forgot, or more likely did not know, that you can configure the Agile Planning Tools to use a custom drop-down-list for Team and have hard coded the Area Path to Team mapping.

    ![Naked ALM: No Test Plans show up with a custom Team field](images/image10-1-1.png "Naked ALM: No Test Plans show up with a custom Team field")  
    { .post-img }
    Figure: No Test Plans show up with a custom Team field

    This results in none of your Test Plans ever being able to appear in the Test Hub.

    All is not lost however as there is a workaround. Because the Agile Planning tools are doing the right thing and passing back the list of values selected as related to your team we can fake out the Test Hub to do the right thing.

    The Test Hob is being passed “Team A” from the drop-down-list rather than the expected “TeamsWithAreas-ProductProduct 1Component 1Team A;TeamsWithAreas-ProductProduct 1Component 2Team A;TeamsWithAreas-ProductProduct 2Component 1Team A;etc.” that it was expecting. It then uses this “Team A” value and matches it against our Area Paths set on our Test Plans and comes up blank…

    To work around this we can go to our drop-down-list, which is likely a global list, and add an entry that matches the Test Plan area path that is set. So if we add “TeamsWithoutAreas” to the global Team list we can then add that as an additional entry that the team owns.

    ![Naked ALM: Add additional values to Team](images/image11-2-2.png "Naked ALM: Add additional values to Team")  
    { .post-img }
    Figure: Add additional values to Team

    Now that we have that in place if we refresh the Test Hub we can see all of the Test Plans that ‘exactly’ match that fake area path. Unfortunately there is no supported way to make that recursive like you can with areas but you can do it and I will show that later.

    ![Naked ALM: Test Plans are now showing up](images/image12-3-3.png "Naked ALM: Test Plans are now showing up")  
    { .post-img }
    Figure: Test Plans are now showing up

    This means that all of the test plans need to be shown and can get a little cluttered if you have many Test Plans per product. On option may be to have one Test Plan per Product+Sprint but then sub split that by team by using Test Suites.

    ![Naked ALM: Many Teams on the same cadence and product](images/image13-4-4.png "Naked ALM: Many Teams on the same cadence and product")  
    { .post-img }
    Figure: Many Teams on the same cadence and product

    This does have some advantages for reporting as you can roll up a little more easily and would be especially good for many Scrum teams working on a single sprint and needing to be integrated by the end of each sprint.

    ### Danger, danger Will Robinson no filtering allowed

    When you try to add an area path of “TeamsWithoutAreasProduct 1” to the global list so that you can filter which Team see which Products you will get a TF26204 as the global list validation things it is a domain account or group.

    ![Naked ALM: TF26204 when you have a backslash in a global list entry](images/image14-5-5.png "Naked ALM: TF26204 when you have a backslash in a global list entry")  
    { .post-img }
    Figure: TF26204 when you have a backslash in a global list entry

    As, by default, for Teams configured for “team fields” there is no recursion you will never see any Test Plan that is set to anything other than what you can explicitly set in the list. As we can’t add a backslash then we cant get an exact match for any sub levels. This is unfortunate as it means that we have to have all of our Test Plans Area Path set to the root, the same as the team Project name, to be able to see them at all.

    ### Configure Test Plans Recursion

    _Warning Never update the database without explicit instructions from a member of  the product team. You will likely end up with an unsupported instance if you much with the database._

    There is however one way to allow your teams to set whatever Area Path on the Test Case they like and have it all match up correctly. To do so we need to set that single “TeamsWithoutAreas” value to be recursive. When you are using Area Path for the value you get an option in the UI to do this. But with the ‘team field’ you don’t…. but you can still do it if needed.

    ![Naked ALM: Set ‘IncludeChildren’ to true to enable recursion](images/image15-6-6.png "Naked ALM: Set ‘IncludeChildren’ to true to enable recursion")  
    { .post-img }
    Figure: Set ‘IncludeChildren’ to true to enable recursion

    If you open up “tbl_TeamConfigurationTeamFields” collection table and find the references to the ‘TeamFieldValue’ of “TeamsWithoutAreas” (the Team Project name), which is the root area path that we want to enable recursion on. You can now change the ‘IncludeChildren’  value to ‘True’ for those entries.

    This is a completely unsupported way to get all of the Test Plan’s to show even if a specific area has been selected.

    ## Conclusion

    I am finding fewer and fewer companies that are able to use Area Path for Team. This is just a reflection of the maturity increasing while the scale still sits at small to medium companies. This is companies that have two to twenty Teams andor two or more products.

    Note I am really hoping that the product team can fix Test Manager so that it supports ‘team field’ by the time that the [Blue wave of updates](http://www.zdnet.com/are-microsoft-updates-like-blue-really-more-than-service-packs-7000015219/) comes along. I don’t expect anything but a dirty fix (so we don’t have to edit the database) in the Update 3 timeframe,  but I am really hoping for a proper fix in Blue.

    Get used to the idea that you will likely need to work with a Team drop-down even though it adds come complexity.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-10-configure-test-plans-for-web-access-in-tfs-2012-2\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-10-configure-test-plans-for-web-access-in-tfs-2012-2
- FrontMatter:
    title: 'TFS2012.2 - Issue: Object not set to instance of object with TF400898, TF53010 & TF30065'
    description: Discover solutions for the 'Object not set to instance of object' error in TFS 2012.2. Learn about known bugs and fixes to enhance your workflow.
    ResourceId: aTblgfZ5dUo
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9899
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-05-08
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: tfs2012-2-issue-object-not-set-to-instance-of-object-with-tf400898-tf53010-tf30065
    aliases:
    - /resources/aTblgfZ5dUo
    - /resources/blog/tfs2012.2-issue-object-not-set-to-instance-of-object-with-tf400898-tf53010-tf30065
    aliasesArchive:
    - /blog/tfs2012-2-issue-object-not-set-to-instance-of-object-with-tf400898-tf53010-tf30065
    - /tfs2012-2-issue-object-not-set-to-instance-of-object-with-tf400898-tf53010-tf30065
    - /tfs2012-2
    - /tfs2012-2---issue--object-not-set-to-instance-of-object-with-tf400898,-tf53010-&-tf30065
    - /blog/tfs2012-2---issue--object-not-set-to-instance-of-object-with-tf400898,-tf53010-&-tf30065
    - /tfs2012-2---issue--object-not-set-to-instance-of-object-with-tf400898--tf53010-&-tf30065
    - /blog/tfs2012-2---issue--object-not-set-to-instance-of-object-with-tf400898--tf53010-&-tf30065
    - /resources/blog/tfs2012-2-issue-object-not-set-to-instance-of-object-with-tf400898-tf53010-tf30065
    - /resources/blog/tfs2012.2-issue-object-not-set-to-instance-of-object-with-tf400898-tf53010-tf30065
    tags:
    - Troubleshooting
    - Software Development
    - Install and Configuration
    - Windows
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-4-4.png
  BodyContent: |
    You may get an exception when working with Areas or Teams in Team Foundation Server 2012.2 that results in an Object not set to instance of object with TF51011, TF400898, TF53010 & TF30065 errors.

    It may affect only one collection or all of them.

    ![TF51011: The specified area path does not exist](images/image-1-1.png "TF51011: The specified area path does not exist")  
    { .post-img }
    Figure: TF51011: The specified area path does not exist

    As well as this error you may get many other errors doing other actions from both the web interface and Visual Studio around the interaction with and use of Areas and Iterations.

    ## Applies to

    - Visual Studio Team Foundation Server 2012.2

    ## Findings

    I first encountered this error on TF Service where I could really access no event or exception information. I raised it with the Product Team and they fixed it in place. I have however now encountered this error on an on premises server running Visual Studio Team Foundation Server 2012.2 and this has been identified as a know bug with Update 2.

    The two main error number you will see in the event log really give us very little information. There is the TF400898 message that is thrown in the UI whenever there is a problem that can’t be identified. In addition the TF30065 number represents an unhandled internal exception. In either case you will need to do a little investigation to find the real cause. The TF51011 error shown above can happen if you have deleted an area and the UI has not caught up.

    Note if at this point your are on TF Service then you need to raise it on the [Team Foundation Service](http://social.msdn.microsoft.com/Forums/en-US/TFService/threads) forum for the product team to investigate.

    If you look in your event log and you see a whole bunch of TF30065 exceptions, that catch all number I mentioned, we need to take a look at the details. In this case there were many “Object reference not set to an instance of an object” references for the same method.

    ```
    The description for Event ID 3000 from source TFS Services cannot be found. Either the component that raises this event is not installed on your local computer or the installation is corrupted. You can install or repair the component on the local computer.

    If the event originated on another computer, the display information had to be saved with the event.

    The following information was included with the event:

    TF53010: The following error has occurred in a Team Foundation component or extension:
    Date (UTC): 5/7/2013 3:35:43 PM
    Machine: tfs01
    Application Domain: /LM/W3SVC/1/ROOT/tfs-1-130124092008301462
    Assembly: Microsoft.TeamFoundation.Framework.Server, Version=11.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a; v4.0.30319
    Service Host: 6c1bb0c0-680e-43df-9b8a-597b6115b996 (Applications)
    Process Details:
      Process Name: w3wp
      Process Id: 15084
      Thread Id: 14752
      Account name: mycompanyuser1

    Detailed Message: TF30065: An unhandled exception occurred.

    Web Request Details
        Url: http://tfs.company.com:8080/tfs/Applications/ProcessManager/_admin/_Areas/UpdateAreasData?__v=3 [method: POST]
        User Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.31 (KHTML, like Gecko) Chrome/26.0.1410.64 Safari/537.31
        Headers: Connection=keep-alive&Content-Length=330&Content-Type=application%2fx-www-form-urlencoded&Accept=application%2fjson%2c+text%2fjavascript%2c+*%2f*%3b+q%3d0.01&Accept-Charset=ISO-8859-1%2cutf-8%3bq%3d0.7%2c*%3bq%3d0.3&Accept-Encoding=gzip%2cdeflate%2csdch&Accept-Language=en-US%2cen%3bq%3d0.8&Cookie=__RequestVerificationToken_L3Rmcw2%3dbSrXe1NADPk0KOFx1ZMoJpOaQ1kF89uytx2_2uRy0q4VMov6se_B1HSGJf2b8L-B_bGnCWJmXh1gNEM3Cb9m9izhd7o2EEUjFzJZoCyJm9XX4Lytj-t8oKeqFvCSkA37IMchvg2%3b+__RequestVerificationToken2a5503d65-91f7-467c-b1ed-39dffe94a223%3dbSrXe1NADPk0KOFx1ZMoJpOaQ1kF89uytx2_2uRy0q4VMov6se_B1HSGJf2b8L-B_bGnCWJmXh1gNEM3Cb9m9izhd7o2EEUjFzJZoCyJm9XX4Lytj-t8oKeqFvCSkA37IMchvg2&Host=tfs.dlgroup.com%3a8080&Referer=http%3a%2f%2ftfs.dlgroup.com%3a8080%2ftfs%2fApplications%2fProcessManager%2f&User-Agent=Mozilla%2f5.0+(Windows+NT+6.1%3b+WOW64)+AppleWebKit%2f537.31+(KHTML%2c+like+Gecko)+Chrome%2f26.0.1410.64+Safari%2f537.31&Origin=http%3a%2f%2ftfs.dlgroup.com%3a8080&X-Requested-With=XMLHttpRequest
        Path: /tfs/Applications/ProcessManager/_admin/_Areas/UpdateAreasData
        Local Request: False
        Host Address: 10.1.140.59
        User: companyuser [authentication type: NTLM]

    Exception Message: Object reference not set to an instance of an object. (type NullReferenceException)
    Exception Stack Trace:    at Microsoft.TeamFoundation.WorkItemTracking.Server.SyncBase.ProcessStructureChanges()
       at Microsoft.TeamFoundation.WorkItemTracking.Server.DataAccessLayerImpl.SyncTree(String userSid, String projectURI)
       at Microsoft.TeamFoundation.Server.WebAccess.WorkItemTracking.Common.KanbanUtils.CreateExtensionPredicate(TeamFoundationRequestContext requestContext, CommonStructureProjectInfo project, TeamFoundationTeam team, IEnumerable`1 allowedStates)
       at Microsoft.TeamFoundation.Server.WebAccess.WorkItemTracking.Common.KanbanUtils.CreateExtension(TeamFoundationRequestContext requestContext, CommonStructureProjectInfo project, CommonProjectConfiguration commonSettings, ITeamSettings teamSettings, TeamFoundationTeam team, Int32 reconcileTimeout)
       at Microsoft.TeamFoundation.Server.WebAccess.WorkItemTracking.Common.KanbanUtils.CreateBoardSettings(TeamFoundationRequestContext requestContext, CommonStructureProjectInfo project, TeamFoundationTeam team, Int32 reconcileTimeout, Boolean validateTeamSettings)
       at Microsoft.TeamFoundation.Server.WebAccess.WorkItemTracking.Common.TeamConfigurationService.EnsureKanbanBoardIsProvisionAndUpToDate(TeamFoundationRequestContext requestContext, TeamFoundationTeam team)
       at Microsoft.TeamFoundation.Server.WebAccess.WorkItemTracking.Common.TeamConfigurationService.SaveTeamFields(TeamFoundationRequestContext requestContext, TeamFoundationTeam team, ITeamFieldValue[] fieldValues, Int32 defaultValueIndex)
       at Microsoft.TeamFoundation.Server.WebAccess.Admin.AdminAreasController.UpdateAreasData(TeamFieldData saveData)
       at lambda_method(Closure , ControllerBase , Object[] )
       at System.Web.Mvc.ReflectedActionDescriptor.Execute(ControllerContext controllerContext, IDictionary`2 parameters)
       at System.Web.Mvc.ControllerActionInvoker.InvokeActionMethod(ControllerContext controllerContext, ActionDescriptor actionDescriptor, IDictionary`2 parameters)
       at System.Web.Mvc.Async.AsyncControllerActionInvoker.<>c__DisplayClass42.b__41()
       at System.Web.Mvc.Async.AsyncControllerActionInvoker.<>c__DisplayClass37.<>c__DisplayClass39.b__33()
       at System.Web.Mvc.Async.AsyncControllerActionInvoker.<>c__DisplayClass4f.b__49()
       at System.Web.Mvc.Async.AsyncControllerActionInvoker.<>c__DisplayClass4f.b__49()
       at System.Web.Mvc.Async.AsyncControllerActionInvoker.<>c__DisplayClass4f.b__49()
       at System.Web.Mvc.Async.AsyncControllerActionInvoker.<>c__DisplayClass4f.b__49()
       at System.Web.Mvc.Async.AsyncControllerActionInvoker.<>c__DisplayClass4f.b__49()
       at System.Web.Mvc.Async.AsyncControllerActionInvoker.<>c__DisplayClass37.b__36(IAsyncResult asyncResult)
       at System.Web.Mvc.Async.AsyncControllerActionInvoker.<>c__DisplayClass25.<>c__DisplayClass2a.b__20()
       at System.Web.Mvc.Async.AsyncControllerActionInvoker.<>c__DisplayClass25.b__22(IAsyncResult asyncResult)
       at System.Web.Mvc.Controller.<>c__DisplayClass1d.b__18(IAsyncResult asyncResult)
       at System.Web.Mvc.Async.AsyncResultWrapper.<>c__DisplayClass4.b__3(IAsyncResult ar)
       at System.Web.Mvc.Controller.EndExecuteCore(IAsyncResult asyncResult)
       at System.Web.Mvc.Async.AsyncResultWrapper.<>c__DisplayClass4.b__3(IAsyncResult ar)
       at System.Web.Mvc.Controller.EndExecute(IAsyncResult asyncResult)
       at System.Web.Mvc.MvcHandler.<>c__DisplayClass8.b__3(IAsyncResult asyncResult)
       at System.Web.Mvc.Async.AsyncResultWrapper.<>c__DisplayClass4.b__3(IAsyncResult ar)
       at System.Web.Mvc.MvcHandler.EndProcessRequest(IAsyncResult asyncResult)
       at System.Web.HttpApplication.CallHandlerExecutionStep.System.Web.HttpApplication.IExecutionStep.Execute()
       at System.Web.HttpApplication.ExecuteStep(IExecutionStep step, Boolean& completedSynchronously)


    ```

    The “Microsoft.TeamFoundation.WorkItemTracking.Server.DataAccessLayerImpl.SyncTree” method is to do with the Area and Iteration trees and Sync’ing them with work item tracking. Something is not right here.

    ![TF400898: An Internal Error Occurred](images/image1-2-2.png "TF400898: An Internal Error Occurred")  
    { .post-img }
    Figure: TF400898: An Internal Error Occurred

    Again the catch all web error, but this time it is for creating a new Team. This is due to Team and Area being tied together by default. You may be able to bypass the error by un-ticking the “Create an area with the name of the team” option, but this does not fix the underlying issue.

    You may also experience the list of Areas or Iterations that are listed on a Work Item not matching up with what it says in the Tree. This is again due to that “Sync” method failing.

    ![Operational Interface job status graph](images/image2-3-3.png "Operational Interface job status graph")  
    { .post-img }
    Figure: Operational Interface job status graph

    If you load operational interface from the [http://mytfsserver:8080/tfs/\_oi](http://mytfsserver:8080/tfs/_oi) (yes you just put “\_oi” after the URL for your TFS server.) Then you should see a graph of all of the running jobs and their status. If the “Work Item Tracking Integration Synchronisation” job is failing and the other characteristics above are also true then you might be hitting a known bug:

    > "◦When you create a new area path, and then you move an existing area path under the newly-created one, the "Work Item Tracking Integration Synchronization" job may fail with a "System.NullReferenceException" exception."[KB2835600 Visual Studio 2012 Update 3 RC 1](http://support.microsoft.com/kb/2835600)

    ## Solution

    It looks like this is a known bug in Update 2 that has been fixed in Update 3. As luck would have it the product team just put Update 3 RC1 live and are providing a go-live licence.

    Note Go-live refers to a type of licence that allows you to use pre-release software in production in a fully supported manor. These tend to be more tested than hotfixes but less than a ‘released’ product. The TFS team has been using go-live as a medium to allow their product or update to be tested in production before they stick that RTM label on it. As most bugs that are not caught in development are caught by early adopters in the first few weeks of a release this is incredibly valuable for the team.

    As I had encountered this error before I knew there was a fix so I asked around and got this response:

    > _I’m really sorry but your customers are running into a known bug in Update 2 with the sync between CSS system and WIT system. The bug is fixed in the QU3 RC release that went out today and ideally the customer should upgrade to that to take the fix._

    I have absolutely no problems recommending that my customer install [Visual Studio 2012 Update 3 RC 1 (KB2835600)](http://support.microsoft.com/kb/2835600). I have been using the go-live licence with customers for many years with few, but not no, issues. In fact I would say that I have had fewer issues with a TFS go-live version than with most other RTM’ed products.

    If you are installing the [Visual Studio 2012.3 (Update 3) “go-live” CTP](http://blogs.msdn.com/b/bharry/archive/2013/05/07/visual-studio-2012-3-update-3-go-live-ctp-is-now-available.aspx) then you just want to make sure that you test it first on a pre-production system and that you install the RTM upgrade as soon as it is available.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-08-tfs2012-2-issue-object-not-set-to-instance-of-object-with-tf400898-tf53010-tf30065\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-08-tfs2012-2-issue-object-not-set-to-instance-of-object-with-tf400898-tf53010-tf30065
- FrontMatter:
    title: 'TFS 2012 Issue: Get Workspace already exists connecting with VS 2008 or VS 2010'
    description: Resolve the 'workspace already exists' error in TFS 2012 when using VS 2008 or VS 2010. Discover effective workarounds to streamline your workflow!
    ResourceId: ZbdFc4NfQUe
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9496
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-05-06
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: tfs-2012-issue-get-workspace-already-exists-connecting-with-vs-2008-or-vs-2010
    aliases:
    - /resources/ZbdFc4NfQUe
    aliasesArchive:
    - /blog/tfs-2012-issue-get-workspace-already-exists-connecting-with-vs-2008-or-vs-2010
    - /tfs-2012-issue-get-workspace-already-exists-connecting-with-vs-2008-or-vs-2010
    - /tfs-2012-issue--get-workspace-already-exists-connecting-with-vs-2008-or-vs-2010
    - /blog/tfs-2012-issue--get-workspace-already-exists-connecting-with-vs-2008-or-vs-2010
    - /resources/blog/tfs-2012-issue-get-workspace-already-exists-connecting-with-vs-2008-or-vs-2010
    tags:
    - Troubleshooting
    - Install and Configuration
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-1-1.png
  BodyContent: |
    You may get a "workspace already exists" when you have VS 2008 or VS 2010 installed as well as VS 2012 and you try to connect them to TFS 2012.

    [![image](images/image_thumb.png)](http://blog.nwcadence.com/wp-content/uploads/2012/07/image.png)  
    { .post-img }
    Figure: The Workspace already exists on computer

    This results in this error ever time you start VS 2010 or VS 2008.

    ### Applies to

    - Visual Studio 2008 connecting to Team Foundation Server 2012
    - Visual Studio 2010 connecting to Team Foundation Server 2012

    ### Finding

    If Visual Studio 2012 is the first thing that you open to create a new workspace against a new collection a default workspace of “computername;username” will be created as a “**Local**” workspace.

    When you subsequently open VS 2008 or VS 2010, which do not support Local Workspaces, you get this error when it tries to create a workspace. Visual Studio does not detect that this workspace already exists as when it queries the server the “agent” filtering does not return local workspaces.

    ### Workaround

    Manually create a “Server” workspace for use in VS 2010 and VS 2008.

    [![image](images/image_thumb1.png)](http://blog.nwcadence.com/wp-content/uploads/2012/07/image1.png)  
    { .post-img }
    Figure: Create a new Workspace with a new Name

    1. Select “File | Source Control | Workspaces… | Add…”
    2. Fill out a new name and then select “OK”
    3. Select your new Workspace from the drop down

    You can now connect to Source Control..

    _Originally published at Where Technology Meets Teamwork by [Martin Hinshelwood](http://blog.hinshelwood.com/about), Senior ALM Consultant. ([source](http://blog.nwcadence.com/tfs-2012-issue-get-workspace-already-exists-connecting-with-vs-2008-or-vs-2010/))_
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-06-tfs-2012-issue-get-workspace-already-exists-connecting-with-vs-2008-or-vs-2010\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-06-tfs-2012-issue-get-workspace-already-exists-connecting-with-vs-2008-or-vs-2010
- FrontMatter:
    title: 'Naked ALM: starting with why and getting naked'
    description: Discover the essence of Application Lifecycle Management with Martin Hinshelwood. Learn to improve software delivery by starting with 'why' and embracing agility.
    ResourceId: SrQHWVkcvAL
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9499
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-05-02
    weight: 540
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: naked-alm-starting-with-why-and-getting-naked
    aliases:
    - /resources/SrQHWVkcvAL
    aliasesArchive:
    - /blog/naked-alm-starting-with-why-and-getting-naked
    - /naked-alm-starting-with-why-and-getting-naked
    - /naked-alm--starting-with-why-and-getting-naked
    - /blog/naked-alm--starting-with-why-and-getting-naked
    - /resources/blog/naked-alm-starting-with-why-and-getting-naked
    tags:
    - Working Software
    categories:
    - Uncategorized
    preview: nakedalm-logo-128-link-1-1.png
  BodyContent: |
    For a long time now I have been searching for that perfect domain that epitomised the vision, the why, of what I am trying to achieve with my customers and the industry at large. Now I have found it in [http://nkdagility.com](http://nkdagility.com)

    I have bought a number of domains over the years that caught my eye but none of them really resonated with me on a deeper level and I lost interest after only a few short weeks. There is a lot of pain and suffering with a healthy dose of monitoring in changing your domain. Its just hassle…and not one you want to take lightly.

    1. [http://realitydysfuncation.co.uk](http://realitydysfuncation.co.uk) – just as long as Hinshelwood and I have found that most folks can’t spell ‘dysfunction’ correctly.
    2. [http://rddotnet.com](http://rddotnet.com) – shot and sweet if a little bit of an inside joke, but it just did not have the ring that I wanted. I completely discounted it when I moved into the world of ALM from that of software development alone
    3. [http://vsalmconsulting.com](http://vsalmconsulting.com) – While I was enamoured, and indeed traded under, with this for  while it ties me to specifically to Visual Studio. While I expect to continue to be in the Visual Studio space it is a product that provides the mechanics of the solution and not the solution in, and of, itself.
    4. [http://vsalm.co.uk](http://vsalm.co.uk) – Again I would be tied to tightly to Visual Studio and while short, which is awesome, I could not get [http://vsalm.com](http://vsalm.com) which is owned by Mr Cogan in Australia.

    I did try to get [http://visualstudioalm.com](http://visualstudioalm.com) but it has been bought be another ALM focused guy in Poland. There were may other short lived ideas over the years and I did seriously consider using [http://hinshelwood.com](http://hinshelwood.com) and potentially reviving my fathers company name “Hinshelwood & Co.” at some point in the future. Unfortunately no matter what font you use you just can’t fit “Hinshelwood” on anything of a reasonable size. Its one of the reasons that when picking a name for his estate agency he ended up with “Allan & Harris” even though there was never an “Allen” or a “Harris” in the organisation.

    ## Getting naked

    My boss, Steven Borg, has been encouraging all of the consultants to think about how consulting works and how to give our customers a much better experience. Steve was so impressed with the book that he bought all of his consultants a copy of [Getting Naked: A Business Fable About Shedding The Three Fears That Sabotage Client Loyalty](http://www.amazon.com/gp/product/B0032ZD0OI/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=B0032ZD0OI&linkCode=as2&tag=martinhinshe-20)![](http://www.assoc-amazon.com/e/ir?t=martinhinshe-20&l=as2&o=1&a=B0032ZD0OI). This book really made me think about how we offer ALM services and how we might improve our interaction with our customers.
    { .post-img }

    We are engaged by customers to delve into the layers of process that have built up over years to get to the root cause of their inability to quickly, easily and consistently deliver software. If you hire an ALM consultant their job is not really to do just do what you ask, it is to figure out what you need to do to deliver more value. There are many ‘ins’ to this process and sometimes, when we are called in to solve a purely technical problem we will spot some the putter showing through. This process of discovery is the real reason for or being.

    No matter the maturity level of the customer, when we start to peel away the layers of ceremony and rhetoric, we discover all sorts skeletons and blemishes that are a drag on the slick and agile process that they aspire to.

    ## Starting with why

    At around the same time one of my colleagues, [Bryon Root](http://b4root.wordpress.com/), suggested a [talk by Simon Sinek](https://www.ted.com/talks/simon_sinek_how_great_leaders_inspire_action "Simon Sinek: How great leaders inspire action") that inspired me to read the speakers book, [Start with Why: How Great Leaders Inspire Everyone to Take Action](http://www.amazon.com/gp/product/B002Q6XUE4/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=B002Q6XUE4&linkCode=as2&tag=martinhinshe-20)![](http://www.assoc-amazon.com/e/ir?t=martinhinshe-20&l=as2&o=1&a=B002Q6XUE4), and that started me on **why** I do Application Lifecycle Management (ALM) and **why** I am trying to help my customers.
    { .post-img }

    [![simon-sinek-the-golden-circle](images/simonsinekthegoldencircle_thumb-2-2.jpg "simon-sinek-the-golden-circle")](http://blog.hinshelwood.com/files/2013/05/simonsinekthegoldencircle.jpg) Figure: Simon Sinek’s golden circle
    { .post-img }

    Starting with why is utterly obvious once it has been explained and the golden circle enabled us to focus on our core mission and formulate our **why** that guides or every action…

    > I believe that every company deserves working software that frequently, successfully and consistently meets their consumers needs.My why

    There is nothing more frustrating as a consumer of software for that software to; not be what I need; crash when I need it; not be updated frequently. These are all forgivable once and a while but not when it happens time and time again. There is a better way and you can be part of it…

    ## Conclusion

    I believe that every company deserves working software that can be delivered on a consistent cadence. That cadence needs to be shorter than 30 day) and they need to get continuous feedback that is fed back into their backlog.

    No matter how far away from this desired state your software process is right now, there are things that you can do to create a steady movement towards that dream of better software more frequently. That is what I am trying to achieve with my career and this blog embodies my journey in convincing customers to change and helping them stretch towards agility.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-02-naked-alm-starting-with-why-and-getting-naked\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-05-02-naked-alm-starting-with-why-and-getting-naked
- FrontMatter:
    title: Release Management with Team Foundation Server 2012
    description: Enhance your release management strategy with Team Foundation Server 2012. Discover automation techniques and best practices for seamless deployments.
    ResourceId: GqwYV8fekzQ
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9468
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-04-24
    weight: 340
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: release-management-with-team-foundation-server-2012
    aliases:
    - /resources/GqwYV8fekzQ
    aliasesArchive:
    - /blog/release-management-with-team-foundation-server-2012
    - /release-management-with-team-foundation-server-2012
    - /resources/blog/release-management-with-team-foundation-server-2012
    tags:
    - Working Software
    - Release Management
    - Product Delivery
    - Software Development
    - Operational Practices
    - Deployment Strategies
    - Technical Excellence
    - Deployment Frequency
    - Frequent Releases
    - Continuous Delivery
    - Application Lifecycle Management
    - Pragmatic Thinking
    categories:
    - Engineering Excellence
    - DevOps
    preview: nakedalm-experts-visual-studio-alm-8-8.png
  BodyContent: |
    Northwest Cadence has been working hard with customers to improve their release management in Team Foundation Server 2012. While on the surface it looks like TFS 2012 has little in the way of support for release management, you would be wrong. There are many features in Team Foundation Server, many of them added in TFS 2010 that can aid you in creating a release management strategy.

    > _A professional Development Team is supposed to create potentially shippable quality output that has no further work required for delivery._

    There are many facets to release management and contrary to popular belief not a single one of them revolves around branching or code. There, I said it, its not about the code. Its about what you deploy. You may have a passing resemblance between code branching and your release process but they are two independent and only occasionally related processes. Intertwining them is where many organisations start to see friction, it is however avoidable.

    ![Workflow and relationships in Team Foundation Server 2012](images/image24-1-1.png "Workflow and relationships in Team Foundation Server 2012")  
    { .post-img }
    **Figure: Workflow and relationships in Team Foundation Server 2012**

    Above I have a rough workflow for working with Team Foundation Server 2012. In this model you would create a ‘build’ from source control and the output would be ‘dropped’ to a well known location. I have builds that just output binaries to network shares and I have builds that create Chocolatey packages. I even have builds that continuously deliver the output to production…

    ![Automated Build in Team Foundation Server 2012](images/image25-2-2.png "Automated Build in Team Foundation Server 2012")  
    { .post-img }
    **Figure: Automated Build in Team Foundation Server 2012**

    So now that I have a uniquely identifiable “build” I now need some way to repeatedly and consistently promote it through my environments. This is about deployment and we need to make sure that we deploy the same artefacts, hence the unique build, through the same process. Why, well so that we can be sure that not only does our application work, but that our deployment does as well.

    In the case of most customers a hap hazard mish mash of technologies is then used by an overworked and under manned Configuration Management team, or worse Operations is just left of their own, to deploy that application to a variety of environments through to production.

    _**Not only is this unnecessary for modern teams delivering modern software it is wholly unprofessional!**_

    If you have people doing repetitive and mundane manual tasks then you not only doing them a disservice, but you are injecting unnecessary risk into the process. Automate everything and use your knowledge workers effectively!

    The first thing that we need to consider for release management is some sort of delivery interface.

    You, or your configuration management team, are not going to be able to really understand all of the tens and maybe thousands of applications that you will be asked to deploy. And nor should they; Microsoft does not ask us to understand the complexities of Office, they have an auto installer.

    We need some rules around which our teams can create a concrete interface that shields teams beyond the development organisation from the complexities of delivery. We have Engineering, Configuration Management, DevOps and likely Operations that all need to consume this interface. We could come up with our own, but there are well defined interfaces out there that were specifically designed around solving some of these, or similar, problems.

    Creating ‘installers’ has been the tool of choice from yesteryear but they are wildly clunky and unwieldy in modern software development. I for one have always hated them…

    So what to use instead?

    You may have been using a little technology called [NuGet](http://nuget.org/) recently. As of Visual Studio 2012 it ships out of the box and is a packaging and deployment technology for adding references to projects within Visual Studio. It has many satellite implementations that are based on that technology, Chocolatey for one, and you can implement it however you like. What is it? Well, it is fundamentally a Zip file with a Manifest, a Script and some files. It also takes care of dependency management.

    There is a learning curve… its not all sweetness and light and there is no silver bullet. You still need to get the development teams to create and maintain the package and to fix it when things go wrong. But make no mistake… this **is** the responsibility of a processional development team.

    **A professional Development Team is supposed to create potentially shippable quality output that has no further work required for delivery.**

    So lets assume that we have some quality output and that output includes the scripts necessary for deployment, ideally contained within a NuGet package. Even in that happy state we need to take that output and get it to an environment, deploy it and potentially tests it.

    ## Lab Management for Release Management

    For delivery to environments owned by your engineering teams you can use Lab Management to deploy to almost any sort of environment that you want. Remembering that just because I say ‘engineering teams’ does not mean that there are not representatives from operations on those teams, because there should be.

    ![Release Management with Lab Management for Feedback](images/image26-3-3.png "Release Management with Lab Management for Feedback")  
    { .post-img }
    **Figure: Release Management with Lab Management for Feedback**

    _Note This can be used to deploy all the way to production but it tends not to be. Operations frown upon installing development tools in production for some unknown reason._

    You can [create Standard Environments](http://blog.hinshelwood.com/standard-environments-for-automated-deployment-and-testing/) or use System Centre Virtual Machine Manager (SCVMM) dynamic environments that are constructed from one or multiple machines into a single identifiable thing that we can deploy to.

    ![Environments in Lab Centre for Release ManagementEnvironments in Lab Centre for Release Management](images/image27-4-4.png "Environments in Lab Centre for Release Management")  
    { .post-img }
    **Figure: Environments in Lab Centre for Release Management**

    Lab Management leverages Team Foundation Build (TFB) and allows you to not only see each of the machines within an environment but also to deploy a pre-compiled build to that environment and orchestrate running of your integration tests against it. This is fantastically powerful as with no customisation we can have a scheduled and automatic deployment of our software to an environment and then have a chosen set of automated tests run against it.

    _Note Team Foundation Build (TFB) is not just for compile and test. It is built around Windows Workflow and can do pretty much anything your want across one or many machines._

    In addition if we are able to spring for a System Centre Virtual Machine Manager (SCVMM) environment you can have your environments automatically spun-up from template environments and snapshots created prior to the deployment and test. And all that is still out of the box functionality. You could add some capabilities with some simple customisation of the build workflow to for example; deploy and verify an environment for each of our 20 testers. The capabilities are endless…

    _Note You do not need Hyper-V or SCVMM to take advantage of Standard Environments. You can use VMWare or even bare metal._

    So if we are building, deploying, verifying and testing within our engineering teams then we would gain the most capabilities from using Lab Management. Lab Management is likely part of your existing licensing (you just need > \[Test Professional | Premium | Ultimate\] ) and can be used at no additional cost. You can setup and configure ‘standard environments’ in minutes to start taking advantage of this now…

    ## Octopus for Release Management

    Remember I mentioned earlier that your operations teams would be… uncooperative… if you wanted to use Lab Management deploy to production? While I have some customers that are perfectly happy to have a Build Agent or Test Agent installed on their servers it does feel a little… dirty. We really want a clean orchestration engine that is much less invasive and our operations will accept.

    At this stage we already have a ‘package’, probably a NuGet package, that has been deployed and promoted by the engineering teams through their verification paths and they have marked certain ‘builds’ as ‘done’. Those ‘done’ builds have likely, if they are NuGet packages, been deployed to a repository that we can easily call for our operational deployments.

    ![Release Management with Octopus for Production](images/image28-5-5.png "Release Management with Octopus for Production")  
    { .post-img }
    **Figure: Release Management with Octopus for Production**

    The reason that I am again mentioning NuGet again is that there is an application called Octopus that has been specifically designed to deploy NuGet packages with ease. Make no mistake, this is an operations tool that has been designed from the ground up to support deploying the output from professional Development Teams to production.

    ![Octopus for Operations](images/image29-6-6.png "Octopus for Operations")  
    { .post-img }
    **Figure: Octopus for Operations**

    You create Environments and then Releases and you can have those releases promoted through those Environments. You can control permissions on who can promote releases through which environments and generally get and idea of what is deployed where.

    If you are using NuGet packages you will even know what is deployed.

    ## Conclusion

    There are lost of options for the automation of your application deployment. I can’t say this enough but:

    > _**A professional Development Team is supposed to create potentially shippable quality output that has no further work required for delivery.**_

    If we fail any sort of stage gate that occurs after the engineering team has said that it is ‘done’ then we need to seriously look at why that happened and what we can put in place to make sure that it never happens again. That sort of attitude will improve the quality of your software and reduce the risk of delivery vastly.

    ![Release Management Workflow in Team Foundation Server 2012](images/image30-7-7.png "Release Management Workflow in Team Foundation Server 2012")  
    { .post-img }
    **Figure: Release Management Workflow in Team Foundation Server 2012**

    This flow of building once and then repeated validation will help weed out those last quality issues so that you don’t get many, if any, issues in production. Teams that follow models like this, when combined with good engineering practices, spend less time fighting fires and more time delivering real customer value. The goal would be to get from Check-In to your Production Environment at least every 30 days. That means that you need to be using the very best Processes, Practices and Tools to make it as slick as possible.

    **How long is your release process?**

    **How sure are you of your quality?**
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-24-release-management-with-team-foundation-server-2012\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-24-release-management-with-team-foundation-server-2012
- FrontMatter:
    title: Upgrading your process template from MSF for Agile 4 to Visual Studio Scrum 2.x
    description: Learn how to safely upgrade your process template from MSF for Agile 4 to Visual Studio Scrum 2.x with simple scripts and expert tips. Upgrade confidently!
    ResourceId: tT1kPVxzv3D
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9456
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-04-22
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: upgrading-your-process-template-from-msf-for-agile-4-to-visual-studio-scrum-2-x
    aliases:
    - /resources/tT1kPVxzv3D
    - /resources/blog/upgrading-your-process-template-from-msf-for-agile-4-to-visual-studio-scrum-2.x
    aliasesArchive:
    - /blog/upgrading-your-process-template-from-msf-for-agile-4-to-visual-studio-scrum-2-x
    - /upgrading-your-process-template-from-msf-for-agile-4-to-visual-studio-scrum-2-x
    - /resources/blog/upgrading-your-process-template-from-msf-for-agile-4-to-visual-studio-scrum-2-x
    - /resources/blog/upgrading-your-process-template-from-msf-for-agile-4-to-visual-studio-scrum-2.x
    tags:
    - Software Development
    - Install and Configuration
    - Pragmatic Thinking
    categories:
    - Uncategorized
  BodyContent: |
    Upgrading your process template from MSF for Agile 4 to Visual Studio Scrum 2.x can be a daunting and scary task. While you do need to be careful it is relatively simple to achieve safely.

    _UPDATE For a newer version of this script check out:  [Process Template migration script updated](http://nkdagility.com/tfs-process-template-migration-script-updated/)_

    Although I describe this process in [Process Template Upgrade #7 – Rename Work Items and Import new ones](http://blog.hinshelwood.com/process-template-upgrade-7-overwrite-retaining-history-with-limited-migration/) I wanted to pull it together as a simple script to do the upgrade so that you can easily upgrade your Team Project. This process and these exact scripts can be used to also upgrade from Visual Studio Scrum 2.0 (Team Foundation Server 2012) and Visual Studio Scrum 2.1 (Team Foundation Server 2012.1) to Visual Studio Scrum 2.2 (Team Foundation Server 2012.2).

    There are two stages that we need to go through:

    1. DONE Setting up for upgrading your Process Template
    2. DONE Completing upgrading your Process Template

    WARNING: It is easy to loose data when doing this. Make sure that you read all supporting material before attempting!

    ## Setting up for upgrading your Process Template

    The first thing to consider is wither you have made any customisations to your existing process templates. You will need to identify what those are and reapply them to the new Visual Studio Scrum template before you proceed with the scripts below. Ideally you should download your target Process Template, in this case the Visual Studio 2.x from Team Foundation Server and put it under source control.

    ![image](images/image22-1-1.png "image")  
    { .post-img }
    **Figure: Downloading a Process Template from Team Foundation Server 2012**

    Having a good format for keeping your Process Template under source control will make things easier going forward.

    ![image](images/image23-2-2.png "image")  
    { .post-img }
    **Figure: Process Template under source control in Team Foundation Server 2012**

    One of the other things that I always do when setting up is to export all of the existing work item types and save them under Builds\[OldTemplate\]. This allows us to push forward with the upgrade even if we have forgotten something. We can always get back to our old fields…

    On of my colleagues has created an awesome utility to hep you [keep track of your Team Projects Process Template version](http://osnabrugge.wordpress.com/2013/04/04/keep-track-of-your-team-projects-process-template-version/). This utility simply allows you to keep track of your team project version in your team project.

    ## Completing upgrading your Process Template

    Now that you have your old template and new template under version control in TFS and you have migrated all of your customisations into the new template we can do the migration:

    First lets set a couple of variables so that we can keep our commands short and sweet:

    ```
    set pt=C:ws\ProcessTemplateR1Source
    set tpc=http://kraken:8080/tfs/tfs01
    set tp=MyAgileTP

    ```

    This sets out Process Template (pt) location as well as our Team Project Collection (tpc) URL to variables and allows it then ignore that complexity. I have set the Process Template location to the “Sources” folder that I did a get latest for locally from TFS. This way when I make tweaks during the migration they are preserved and can just be checked in.

    Then we get down to the Nitti-gritty of changing the template. The goal is to end up with a functional Visual Studio Scrum 2.2 process template.

    ```
    REM #1 Do Renames
    witadmin renamewitd /collection:%tpc% /p:%tp% /n:"User Story" /new:"Product Backlog Item" /noprompt
    witadmin renamewitd /collection:%tpc% /p:%tp% /n:"Issue" /new:"Impediment" /noprompt

    ```

    First priority to make sure we maintain the fidelity of your requirement data is to do a couple of renames. We are renaming the existing “User Story” work item type to “Product Backlog Item” so that when we upload the new “Product Backlog Item” from the Process Template all of our existing work items are kept.

    ```
    #2 REM Apply new Template
    witadmin importwitd /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingTypeDefinitionsBug.xml"
    witadmin importwitd /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingTypeDefinitionsCodeReviewRequest.xml"
    witadmin importwitd /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingTypeDefinitionsCodeReviewResponse.xml"
    witadmin importwitd /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingTypeDefinitionsFeedbackRequest.xml"
    witadmin importwitd /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingTypeDefinitionsFeedbackResponse.xml"
    witadmin importwitd /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingTypeDefinitionsImpediment.xml"
    witadmin importwitd /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingTypeDefinitionsProductBacklogItem.xml"
    witadmin importwitd /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingTypeDefinitionsSharedStep.xml"
    witadmin importwitd /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingTypeDefinitionsTask.xml"
    witadmin importwitd /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingTypeDefinitionsTestCase.xml"

    ```

    This is where you needed to think about the customisations you have made and the field differences  between your source and target Process Templates. If you have not added all of the fields from the old template to the new one, and at least the field definition then you will not ‘see’ the field changes listed in the history. This is just a quirk of how the work item trackign system is implemented and it will only enumerate the fields that it knows about.

    I usually add the old fields ‘only’ to the field list and not to the UI so that users scan see the data in the history, but not interact with it. It is important not to add all of the of fields to the new Work Item UI as that will encourage users to use it. If they still want to use all of the old fields in the old process then you likely don’t want to be doing any of this!

    ```
    REM #3 Import Link Types just in case coming from 2008
    witadmin importlinktype /collection:%tpc% /f:"%pt%WorkItem TrackingLinkTypesSharedStep.xml"
    witadmin importlinktype /collection:%tpc% /f:"%pt%WorkItem TrackingLinkTypesTestedBy.xml"

    ```

    It is likely not required to import the Link types but I always do for two reasons. The first is that you might be coming from a 2008 environment, which you will already know. If your server as ever a 2008 server and this project was created then it is likely that no one eve added the new new link types. So fix it now…

    ```
    REM #4 Import Categories
    witadmin importcategories /collection:%tpc% /p:%tp% /f:"%pt%WorkItem Trackingcategories.xml"

    ```

    Adding the correct categories will start the main configuration efforts and configures which of the work item types are viable, which are hidden and which sit is which category. So for example in the MSF Agile template only “**User Story**” is in the “**Requirement Category**” while in the Scrum template both “**Product Backlog Item**” and “**Bug**” are considered requirement items and would be visible on the Product Backlog.

    ```
    REM #5 Upload the new Common Config and Agile Config
    witadmin importcommonprocessconfig /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingProcessCommonConfiguration.xml"
    witadmin importagileprocessconfig /collection:%tpc% /p:%tp% /f:"%pt%WorkItem TrackingProcessAgileConfiguration.xml"
    ```

    There are WAY to many things configured as part of these two files. They effectively control how the tooling that is built on top of Work Item Tracking interprets that data from the Product Boards to the Task Boards and how [Teams are configured](http://blog.hinshelwood.com/team-foundation-server-2012-teams-without-areas/). There is [good documentation on MSDN for both the Agile & Common configuration](http://msdn.microsoft.com/en-us/library/hh500413.aspx).

    Are you Done now? Well, nearly…

    There are however a few thins that we did not change that might be part of the process template that we just moved to.

    - **Permissions** – You may need to tweak the permissions but they are largely the same between the three stock templates. There may be new security groups added as the template moves forward to support filtering of Assigned To, but you will need to deal with that as it comes.
    - **Reports** – You will want to upload the reports that go with your new template. This can be done manually or through the Power Tools “addprojectreports” command.
    - **SharePoint Portal** – This is easy to accomplish manually, but there is also a “addprojectportal” command in the Power Tools.
    - **Queries** – All of your queries will be broken once you are finished. There is a queries folder under your process template that will provide you with the stock queries that you can import with visual studio.
    - **Areas** – No help here… manual configuration and depends on how you are currently using them
    - **Iterations** - No help here… manual configuration and depends on how you are currently using them

    ## Conclusion

    If you are willing to accept the limitations then changing your process template is a fairly strait forward exercise ( unless of course you are using the Scrum for Team System templates: sorry)  and is easily achievable even across many Team Projects.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-22-upgrading-your-process-template-from-msf-for-agile-4-to-visual-studio-scrum-2-x\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-22-upgrading-your-process-template-from-msf-for-agile-4-to-visual-studio-scrum-2-x
- FrontMatter:
    title: Migration from TF Service to TF Server with the TFS Integration Platform
    description: Learn how to seamlessly migrate from TF Service to TF Server using the TFS Integration Platform. Ensure compliance and protect your data effectively!
    ResourceId: M3QCV-Dusfq
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9443
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-04-18
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: migration-from-tf-service-to-tf-server-with-the-tfs-integration-platform
    aliases:
    - /resources/M3QCV-Dusfq
    aliasesArchive:
    - /blog/migration-from-tf-service-to-tf-server-with-the-tfs-integration-platform
    - /migration-from-tf-service-to-tf-server-with-the-tfs-integration-platform
    - /resources/blog/migration-from-tf-service-to-tf-server-with-the-tfs-integration-platform
    tags:
    - Software Development
    - Install and Configuration
    categories:
    - Uncategorized
  BodyContent: |
    Are you worried that you will not be able to migrate from [http://tfs.visualstudio.com](http://tfs.visualstudio.com) when they start charging for it and you don’t want to pay? Fear not as we have the technology to migration from TF Service to TF Server with the TFS Integration Platform.

    ![image](images/image14-1-1.png "image")  
    { .post-img }
    **Figure: Successful migration from TF Service to TF Server**

    We are working with a customer next week who is using [http://tfs.visualstudio.com](http://tfs.visualstudio.com) but due to a misapplication of the rules governing the management of data they are having to move their Team Foundation Service data local.

    You see many organisations come under HIPA, SOX or CFR-11 which requires separation of duties and that none of your data ends up at risk. This is awesome as it is designed to protect your organisation and your customers from the risks associated with restricted data. However this almost never needs to be interpreted as something that governs your code, your builds or your work item tracking data.

    Sometimes it is for simple ‘warm and fuzzes’ and sometimes it is because of the way that your internal compliance department has interpreted the rules. But wrongly or rightly you  have to move your data…

    ## Configuring the migration from TF Service to TF Server

    Wither you are familiar with the TFS Integration Platform or not there are only a couple of ‘small’ things that we need to worry about for this migration. Both of those things revolve around user accounts.

    In TF Service all of the user accounts are Microsoft Accounts (was Live ID) and they do not directly relate to anything that you have in your Domain. Even if you [configure Corporate Live ID’s](http://blog.hinshelwood.com/using-corporate-ids-with-visual-studio-11-team-foundation-service/) they will still never match what you have locally in your Active Directory controlled environment.

    - [TFS Integration Platform – What is the Lookup Service? Q&A-27](http://blogs.msdn.com/b/willy-peter_schaub/archive/2010/04/10/tfs-integration-platform-what-is-the-lookup-service-q-a-27.aspx)
    - [TFS Integration Tools – How do I map users between domains or systems? Q&A-44](http://blogs.msdn.com/b/willy-peter_schaub/archive/2011/02/05/tfs-integration-tools-how-do-i-map-users-between-domains-or-systems-q-amp-a-44.aspx)
    - [TFS Integration Tools – How do I define user mappings for version control using the SVN adapter?](http://blogs.msdn.com/b/willy-peter_schaub/archive/2011/08/15/tfs-integration-tools-how-do-i-define-user-mappings-for-version-control-using-the-svn-adapter.aspx)

    We effectively have two places we need to do a little mapping. Source Control and Work Item Tracking. Both of these are done is slightly different ways…both are however easy to configure.

    We can use the [TFS Integration Platform](https://tfsintegration.codeplex.com/) to pull all of your data for Source and Work Items, including the relationships and attachments but we do leave behind some information.

    - No Labels
    - No Builds
    - No Lab
    - No Test Cases

    Probably the one least easy to swallow is the Test Cases. You may be able to write something against the API afterwards to get it to work but I have not tried…

    ### Source Control

    The thing to remember for Source Control is that your identity is referenced as “Windows Live IDmartin@hinshelwood.com” in source. This means that you need to collect every users Live ID and create a mapping file from old to new.

    In this case we are moving from our Live ID to a Domain account and this method can just as easily be used to move between two TF Service instances or to move into TF Service.

    Once you have this mapping created you can update the “UserIdentityMappings” section of your TFS Integration Platform configuration.

    ### Work Item Tracking

    Work Item tracking is, if anything, easier to configure. You can use the built in field mapping to equate “Martin Hinshelwood (MrHinsh) {NWC}” to whatever you use in your domain.

    In this scenario you need have both a “FieldMap” and “ValueMap” to push them together based on the value you would select in the work item Assigned To drop-down.

    You will need to collect the _exact_ display name of each person and ask them not to change them until you have pushed across the work items.

    ## Conclusion

    While you can move from Team Foundation Service to Team Foundation Server it will take some planning and forethought…the scenarios detailed above will maintain continuity of your users between the two systems and authentication methods.

    It is not however for the faint of heart… it took us a few hours to figure out the solution above and about 12-15 failed migrations to get it right…

    All of this is in the documentation for the TFS Integration Platform…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-18-migration-from-tf-service-to-tf-server-with-the-tfs-integration-platform\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-18-migration-from-tf-service-to-tf-server-with-the-tfs-integration-platform
- FrontMatter:
    title: New un-versioned repository in TFS 2012
    description: Discover the benefits of the new un-versioned repository in TFS 2012, streamlining build drop management and enhancing your development workflow.
    ResourceId: AoTaD6481iE
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9452
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-04-18
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: new-un-versioned-repository-in-tfs-2012
    aliases:
    - /resources/AoTaD6481iE
    aliasesArchive:
    - /blog/new-un-versioned-repository-in-tfs-2012
    - /new-un-versioned-repository-in-tfs-2012
    - /resources/blog/new-un-versioned-repository-in-tfs-2012
    tags: []
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-6-6.png
  BodyContent: |
    In the last wave of updates to Team Foundation Service the product team has added a new “staging location” and we now have an un-versioned repository in TFS 2012.

    Why do you care you might ask… well I will tell you.

    ## Why we needed an un-versioned repository in TFS 2012

    Usually we store our build drops on a network share. As part of a build you have always (with Team Foundation Service) been able to store those build drops inside of your Version Control repository… and this has been both a blessing and a curse.

    ![image](images/image17-1-1.png "image")  
    { .post-img }
    **Figure: Copy build output to the following source control folder.**

    It allowed us to remove the dependency on a network share to store our drop files and more importantly it results in our drop folders being backed up with the same rigor as TFS.

    ![image](images/image18-2-2.png "image")  
    { .post-img }
    **Figure: Drops in version control**

    Unfortunately it also meant that  we clogged up our version control repository with files and sometimes big files. When files are added to a versioned repository there are a lot of computing power used to figure out versions and deltas and other need things, but for a drop folder we don't need those.

    Worse when you want to remove old stuff you need to call a “[destroy](<http://msdn.microsoft.com/en-us/library/bb386005(v=vs.100).aspx>)” command to be sure that you don’t leave all of those files taking up space forever.

    ## Using the new un-versioned repository in TFS 2012

    To the rescue comes an un-versioned repository for storing your build drops.

    ![image](images/image19-3-3.png "image")  
    { .post-img }
    **Figure: Copy build output to the server**

    By editing your build definition and changing the staging location for your build defaults to the new option you can remove all of your files from Version Control and have them stored somewhere else. Select “Copy build output to the server” to enable this feature.

    ![image](images/image20-4-4.png "image")  
    { .post-img }
    **Figure: Download from un-versioned repository in TFS 2012**

    Now when we click “Open Drop Folder” we get redirected to the build page in Team Web Access and are presented with a “Download drop as zip”.

    Currently there is no ‘browser’ for the files that are stored in the un-versioned repository in TFS 2012 but I would expect one to be fourth coming. This is however an REST API that you can use to access not just zips but the individual files as well. More to come on that…. but to fill in the gap:

    - [TfsDropDownloader from the SharePoint Team](https://officesharepointci.codeplex.com/releases/view/102774)

    ## Cleaning up after the versioned build repository in TFS 2012

    You will likely want to remove all of the old files that you have been pumping into version control and the only way to do that is to use the Destroy command:

    ```
    tf destroy $/TfsExtensions/Drops /collection:https://mrhinsh.visualstudio.com/defaultcollection

    ```

    This will completely remove all of the files from source control and eradicate them from history.

    ![image](images/image21-5-5.png "image")  
    { .post-img }
    **Figure: Destroy a folder from TFS version control**

    While heavy handed it does clean up things nicely.

    ## Conclusion

    We can only hope that this will be a feature of dev12! And what else might the product team decide to do with an un-versioned store? Symbols; Nuget Packages… the options are endless…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-18-new-un-versioned-repository-in-tfs-2012\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-18-new-un-versioned-repository-in-tfs-2012
- FrontMatter:
    title: 'TFS 2012 Issue: TF215097 an error occurred while initializing a build for build definition'
    description: Resolve the TF215097 error in TFS 2012 builds with our detailed guide. Learn to load custom assemblies and streamline your build process effectively!
    ResourceId: Esy-i2Fcamk
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9446
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-04-18
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: tfs-2012-issue-tf215097-an-error-occurred-while-initializing-a-build-for-build-definition
    aliases:
    - /resources/Esy-i2Fcamk
    aliasesArchive:
    - /blog/tfs-2012-issue-tf215097-an-error-occurred-while-initializing-a-build-for-build-definition
    - /tfs-2012-issue-tf215097-an-error-occurred-while-initializing-a-build-for-build-definition
    - /tfs-2012-issue--tf215097-an-error-occurred-while-initializing-a-build-for-build-definition
    - /blog/tfs-2012-issue--tf215097-an-error-occurred-while-initializing-a-build-for-build-definition
    - /resources/blog/tfs-2012-issue-tf215097-an-error-occurred-while-initializing-a-build-for-build-definition
    tags:
    - Troubleshooting
    - Software Development
    - Install and Configuration
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-3-3.png
  BodyContent: |
    When you are running a build you get a “TF215097 an error occurred while initializing a build for build definition” message and you don’t even get a build number.

    ![image](images/image15-1-1.png "image")  
    { .post-img }
    **Figure: TF215097 an error occurred while initializing a build for build definition**

    And you get the following nasty long error.

    ```
    TF215097: An error occurred while initializing a build for build definition NWCTfsCommandLine.Compile:
    Exception Message: Cannot create unknown type '{clr-namespace:TfsBuildExtensions.Activities.TeamFoundationServer;assembly=TfsBuildExtensions.Activities}TfsVersion'. (type XamlObjectWriterException)
    Exception Data Dictionary:
    MS.TF.Diagnostics.Logged = True

    Exception Stack Trace:    at System.Xaml.XamlObjectWriter.WriteStartObject(XamlType xamlType)
       at System.Xaml.XamlServices.Transform(XamlReader xamlReader, XamlWriter xamlWriter, Boolean closeWriter)
       at System.Activities.XamlIntegration.FuncFactory`1.Evaluate()
       at System.Activities.DynamicActivity.OnInternalCacheMetadata(Boolean createEmptyBindings)
       at System.Activities.Activity.InternalCacheMetadata(Boolean createEmptyBindings, IList`1&amp; validationErrors)
       at System.Activities.ActivityUtilities.ProcessActivity(ChildActivity childActivity, ChildActivity&amp; nextActivity, Stack`1&amp; activitiesRemaining, ActivityCallStack parentChain, IList`1&amp; validationErrors, ProcessActivityTreeOptions options, ProcessActivityCallback callback)
       at System.Activities.ActivityUtilities.ProcessActivityTreeCore(ChildActivity currentActivity, ActivityCallStack parentChain, ProcessActivityTreeOptions options, ProcessActivityCallback callback, IList`1&amp; validationErrors)
       at System.Activities.ActivityUtilities.CacheRootMetadata(Activity activity, LocationReferenceEnvironment hostEnvironment, ProcessActivityTreeOptions options, ProcessActivityCallback callback, IList`1&amp; validationErrors)
       at System.Activities.Validation.ActivityValidationServices.InternalActivityValidationServices.InternalValidate()
       at Microsoft.TeamFoundation.Build.Workflow.WorkflowHelpers.ValidateWorkflow(Activity activity, ValidationSettings validationSettings) in d:a1ddalmtfs_coreBuildWorkflowWorkflowHelpers.cs:line 392
       at Microsoft.TeamFoundation.Build.Hosting.BuildProcessCache.LoadFromXaml(String workflowXaml, TextExpressionImports textExpressionImports) in d:a1ddalmtfs_coreBuildMachineHostingBuildProcessCache.cs:line 136
       at Microsoft.TeamFoundation.Build.Hosting.BuildControllerWorkflowManager.PrepareRequestForBuild(WorkflowManagerActivity activity, IBuildDetail build, WorkflowRequest request, IDictionary`2 dataContext) in d:a1ddalmtfs_coreBuildMachineHostingBuildControllerWorkflowManager.cs:line 652
       at Microsoft.TeamFoundation.Build.Hosting.BuildWorkflowManager.TryStartWorkflow(WorkflowRequest request, WorkflowManagerActivity activity, BuildWorkflowInstance&amp; workflowInstance, Exception&amp; error, Boolean&amp; syncLockTaken) in d:a1ddalmtfs_coreBuildMachineHostingBuildWorkflowManager.cs:line 628

     No zip file of logs was created because the archive operation failed: System.AggregateException: One or more errors occurred. ---> System.AggregateException: One or more errors occurred. ---> System.Exception: Getting list of logs to archive failed with Http reason: Not Found
       at Microsoft.TeamFoundation.Build.Hosting.BuildControllerWorkflowManager.ArchiveLogsInvoker.<archivelogs>d__5.MoveNext() in d:a1ddalmtfs_coreBuildMachineHostingBuildControllerWorkflowManager.cs:line 985
       --- End of inner exception stack trace ---
       --- End of inner exception stack trace ---
       at Microsoft.TeamFoundation.Build.Hosting.BuildControllerWorkflowManager.ArchiveLogsInvoker.End(IAsyncResult result) in d:a1ddalmtfs_coreBuildMachineHostingBuildControllerWorkflowManager.cs:line 954
       at Microsoft.TeamFoundation.Build.Hosting.OperationInvokerPool.EndInvoke(IAsyncResult result) in d:a1ddalmtfs_coreBuildMachineHostingOperationInvokerPool.cs:line 212
    ---> (Inner Exception #0) System.AggregateException: One or more errors occurred. ---> System.Exception: Getting list of logs to archive failed with Http reason: Not Found
       at Microsoft.TeamFoundation.Build.Hosting.BuildControllerWorkflowManager.ArchiveLogsInvoker.</archivelogs><archivelogs>d__5.MoveNext() in d:a1ddalmtfs_coreBuildMachineHostingBuildControllerWorkflowManager.cs:line 985
       --- End of inner exception stack trace ---
    ---> (Inner Exception #0) System.Exception: Getting list of logs to archive failed with Http reason: Not Found
       at Microsoft.TeamFoundation.Build.Hosting.BuildControllerWorkflowManager.ArchiveLogsInvoker.</archivelogs><archivelogs>d__5.MoveNext() in d:a1ddalmtfs_coreBuildMachineHostingBuildControllerWorkflowManager.cs:line 985< ---
    <---
    .
    ```

    ## Applies to

    - Team Foundation Server 2010
    - Team Foundation Server 2012
    - Team Foundation Service

    ## Findings

    If you delve into the error and exception log above it looks like it is failing to load a perticulat type

    ```
    {clr-namespace:TfsBuildExtensions.Activities.TeamFoundationServer;assembly=TfsBuildExtensions.Activities}TfsVersion

    ```

    This type is actually from the [Community TFS Build Extensions](https://tfsbuildextensions.codeplex.com/) project and not one of the built in assemblies. Either the built in build workflows have been changed to include new funcationality or this is a completely custom workflow that loads non standard components.

    ## Solution

    You need to load those assemblies into Source Control and set a reference to that location for your controller.

    ![image](images/image16-2-2.png "image")  
    { .post-img }
    **Figure: Set the version control path to custom assemblies path**

    To do this, go to your “**Build**” page in the new Team Explore. So Go to “**Team Explorer| Build | Actions | Manage Build Controllers**” and look at your list of Controllers. You should be able to figure out which controller your build is going through from your build settings and if you are on Team Foundation Service it will be called “Hosted Build Controller (Hosted)”.

    Select your desired controller and click “**Properties**” to see the settings that are configured. The one that we care about is the “**Version control path to custom assemblies**”. Here we need to select a single source folder from which our controller will load any custom assemblies referenced.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-18-tfs-2012-issue-tf215097-an-error-occurred-while-initializing-a-build-for-build-definition\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-18-tfs-2012-issue-tf215097-an-error-occurred-while-initializing-a-build-for-build-definition
- FrontMatter:
    title: Working within a single Team Project with Team Foundation Server 2012
    description: Explore best practices for managing a single Team Project in TFS 2012, enhancing collaboration and efficiency across teams while minimizing administrative overhead.
    ResourceId: mV9NzUQYyjY
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9431
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-04-08
    weight: 630
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: working-within-a-single-team-project-with-team-foundation-server-2012
    aliases:
    - /resources/mV9NzUQYyjY
    aliasesArchive:
    - /blog/working-within-a-single-team-project-with-team-foundation-server-2012
    - /working-within-a-single-team-project-with-team-foundation-server-2012
    - /resources/blog/working-within-a-single-team-project-with-team-foundation-server-2012
    tags:
    - Software Development
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-5-5.png
  BodyContent: |
    Working within a single Team Project with Team Foundation Server 2012 provides a lot of benefits. There are however many design consideration for working within a single team project and we need to consider all of the complexities that is entails.

    One of the customers that I work with has over 200 departments in their organisation that are currently using TFS and each one of those supports one or more teams building multiple products in a single team project. They do not give any of those divisions “Project Administrator” on their Team Projects and in itself sounds like a management nightmare. Why? Well that means that ANY security change needs to go through a central administrator. In order to support this type of situation we need to create some workflow for making sure that everything is setup correctly and some automation so that we can build out the correct permissions without needing direct access. But before we do that we need to look at all of the angles and design our implementation to take advantage of the features in Team Foundation Server 2012.

    ![The TfPlugable Team is part of the TfsExtension Team Project](images/image10-1-1.png "The TfPlugable Team is part of the TfsExtension Team Project")  
    { .post-img }
    **Figure: The TfPlugable Team is part of the TfsExtension Team Project**

    Unfortunately the implementation of Team Project is a little flawed as it imposed some technical restrictions that are difficult to live with and if you look at the top items on the [Team Foundation Server User Voice](http://visualstudio.uservoice.com/forums/121579-visual-studio/category/30925-team-foundation-server) site you can begin to get a handle on the issues. Even worse, the inability to rename your Team Project is the least of your worries; You can query across Team Project but that's not the default; You can’t load cross Team Project queries in Excel; You can’t move a work item created in one Team Project to another.

    Ultimately we should always have been working in a single Team Project even if we did not know that we were supposed to.

    > “_What you describe \[single team project\] is what we generally do internally and what we recommend. We make very heavy use of area path to categorize the work within a larger project_.”  
    > – **[Brian Harry](http://blogs.msdn.com/bharry/)**, Microsoft Technical Fellow & Product Unit Manager for Team Foundation Server

    ## Design considerations for Working within a single Team Project with TFS 2012

    Because Team Foundation Server is a group of tightly coupled but flexible services it does not force you into any one way of working like many other tools. So we do need to think about how we are organising our Source Control, Areas, Iterations and Teams to understand how we might be impacted across the board and what our automation workflows are. In our deliberations we have three main entities that we need to cater for:

    - **Team** – This automatically creates our Security Group that we will be using and has an Administrator is set for that group
    - **Product** – When you create a product you will likely need both a Source Control location for that Product to reside and an Area to contain the related work items. You can break your product down into components inside that Area and you may have branches under the Source Control folder but the layout and organisation should be up to the product owners and the team.
    - **Project** – A Project is something time limited so lends itself to an Iteration within TFS but you would not prescribe the cadence. Your Project many be waterfall or Scrum or Kanban and it should not matter.

    There many be other things like Work Stream or Cost Code or other flat categorisation elements that you might want to use in your single Team Project. These can easily exist as drop-down-lists on the work items that exist in our requirement work item and don't necessarily impact the workflows described above.

    > _“Using areas in existing team project instead of creating a new team project (a.k.a. “prefer small number of big team projects over large number of small team projects”) has been established best practice for long time. Microsoft works that way internally and they recommend everyone should. We use it internally and all of our partners have been thought to use it as well.”_  
    > \-[**Ognjen Bajic**](http://ognjenbajic.com/blog), Visual Studio ALM MVP, Product Owner of Team Companion at Ekobit

    Note You may want to have Teams own projects. If you have many projects and your teams own more than one at ay time you can use [Teams without areas](http://blog.hinshelwood.com/team-foundation-server-2012-teams-without-areas/) but instead of having a list of “Teams” you create a list of Projects and define which Teams own which projects in the Team configuration.

    ### Team in a single Team Project

    In Team Foundation Server 2012 everything within a Team Project revolves around a new feature called Team. A Team is ultimately a security group with a bunch of meta data and features hanging from it (Yes..unlike a Team Project you can rename a Team). In the agile world a “Team” represents a long running tight group of individuals that operate more like a sports team but building software. If you are not an agile team, or in that half way phase of trying to get there, then you might also think of “Team” as something more akin to “Project”. In that scenario you have a time limited group of individuals that operate either full or part time together only for the duration of said “Project”. While the latter would reduce the effectiveness of the Team and would thus be considered a dysfunction it can often be a reality of that awkward transition towards agility.

    ![Adding teams working in a single Team Project](images/image11-2-2.png "Adding teams working in a single Team Project")  
    { .post-img }
    **Figure: Adding teams working in a single Team Project**

    In either of these cases you can use Team as the thing that you create instead of Team Project. This Team gives you the bucket of compartmentalisation of work items while allowing those teams to interact in a tightly integrated manor as needed. You also gain the ability to move work items between teams and query cross team with ease. If you are working on a large software project you might have many teams on the same cadence and while you want them to have their own space they still need to integrate and report things together. Or you might have multiple cadences across multiple products and only teams working on the same product work in the same cadence. The Team feature gives you the flexibility to choose you own way and adapt as you grow.

    ### Product in a single Team Project

    Product is a thing that you version, create instances of, and then deploy to production. A version of this entity is what is promoted through your release process although you may need to break it down into components if it is really big. Some of your Products will be built in an agile fashion and release at least every 30 days while other will have longer iterations and be delivered less regularly. We need to come up with some way to wrap all of our Products regardless of the things that may be different between them. This interface will allow us to control creation and security by following a pattern that we can automate.

    ![Area as Product when working in a single Team Project](images/image12-3-3.png "Area as Product when working in a single Team Project")  
    { .post-img }
    **Figure: Area as Product when working in a single Team Project**

    Considerations for your Product hierarchy:

    - **Area Hierarchy** – Within a Product we may have components or trees of components. Area support roughly 254 nodes per level and can be 11 deep so there are limitations to consider. You will always see all of the nodes and you can control security at each and every level.
    - **Version Control Hierarchy** – Each of our Products are going to have source code and other associated files. We need somewhere to keep them in isolation now that we don’t have Team Project so that we can control permissions and isolation.

    Note If we maintain the level at which Product exists in both Area hierarchy and in Version Control then we can easily automate against it.

    Note The same rules apply and you can use the same physical organisation as [Project of Projects with Team Foundation Server 2010](http://blog.hinshelwood.com/project-of-projects-with-team-foundation-server-2010/).

    ### Project in a single Team Project

    Project is that time limited group of deliverables that results in a new release of one or more Products. The Project may contain many releases or it may be one. A Product may have many Projects or even just one that contains many releases. We need a model that supports whatever our teams need and that is reflected in Iteration Path.

    ![Iteration as Project cadence when working in a single Team Project](images/image13-4-4.png "Iteration as Project cadence when working in a single Team Project")  
    { .post-img }
    **Figure: Iteration as Project cadence when working in a single Team Project**

    Considerations for Project hierarchy:

    - **Iteration Hierarchy** – Creating a hierarchy in Iteration gives us the ability to have single or multiple strands of time allocation. It can be split by Team or Product or Project and each of those things can have their own cadence. That cadence should not be determined arbitrarily by the process overlords, but instead we can allow each unit to determine their own cadence.

    ## Conclusion

    While I can’t hope to provide a method of using Team Foundation Server 2012 and its features that work for everyone I am trying to create a versatile wrapper for any sort of work that is done within a Team Project. Ideally you would have only a single Team Project within your Team Project Collection and using Teams, Area Hierarchy and Iteration Hierarch we can map to but not into Teams, Products and Projects. The hope is that this wrapper described in the design guidelines above can allow you to automate against the TFS API’s and thus minimise your administration overhead while providing that versatility. There is an awesome post on [backlog grooming](http://osnabrugge.wordpress.com/2013/04/07/tfs-as-perfect-tool-for-scrum-part-2-product-backlog-grooming/) that shows you how to configure more advanced team organisation in Team Foundation Server with Teams and there are plenty of other options.

    If you are using Team Foundation Server already then there may be a lot of work that needs to be done to reorganise your existing work before you start as well as implementing your new and specific workflows based on the generic implementation above. This is however the only way for an enterprise, or really any organisation with more than one team, to take advantage of the new Agile Project Planning features of Visual Studio Team Foundation Server 2012.

    It can however be a lot of work and the [great god Murphy](http://en.wikipedia.org/wiki/Murphy's_law) can strike at any time. Plan carefully and make deliberate and tested changes to TFS and your structure to support this.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-08-working-within-a-single-team-project-with-team-foundation-server-2012\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-08-working-within-a-single-team-project-with-team-foundation-server-2012
- FrontMatter:
    title: Reserve an Agent for a special build in Team Foundation Server 2012
    description: Learn how to reserve a build agent in Team Foundation Server 2012 to streamline your build process and avoid conflicts. Optimize your CI/CD workflow now!
    ResourceId: SrsgdgZeWGm
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9359
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-04-04
    weight: 690
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: reserve-an-agent-for-a-special-build-in-team-foundation-server-2012
    aliases:
    - /resources/SrsgdgZeWGm
    aliasesArchive:
    - /blog/reserve-an-agent-for-a-special-build-in-team-foundation-server-2012
    - /reserve-an-agent-for-a-special-build-in-team-foundation-server-2012
    - /resources/blog/reserve-an-agent-for-a-special-build-in-team-foundation-server-2012
    tags:
    - Software Development
    - Install and Configuration
    - System Configuration
    - Continuous Integration
    - Azure DevOps
    - Azure Pipelines
    - Pragmatic Thinking
    - Technical Mastery
    - Troubleshooting
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-11-11.png
  BodyContent: |
    By the time you hit the AgentScope activity in a TF Build workflow you are already running on the agent and if you have things you need to configure you need to figure out some way to reserve an agent before you get there.

    - **Update 2013-04-04** - All three of the activities below have been added to the [TFS Community Build Extensions](http://tfsbuildextensions.codeplex.com/documentation) project on Codeplex and will be in a future release

    There are a number of reasons that you might want to reserve your TF Build Agent in Visual Studio 2012 Team Foundation Server before you hit the default AgentScope. The one I am working on with a customer is that they have a build that can only be executed once on a Build server and then always fails. Yes, the build breaks the Build Agent. Yes, I know that this is something that the development team responsible should fix but the Software Configuration Management (SCM) team that owns the servers can only encourage good behaviour and not enforce it.

    ![image](images/image-1-1.png "image")  
    { .post-img }
    **Figure: Agent Scope runs on the agent**

    The current solution is to revert the build server to a snapshot after every build. This causes a bunch of knock on problems:

    1. **Revert to Snapshot**  
       We need to revert the VM Ware server to a Snapshot after every build
    2. **Removed from Domain**  
       As the snapshot can be more than 30 days old the Active Directory machine security token may have expired in which case you would need to re-join that server to the domain. The result of this is that the Infrastructure teams will not have these build servers on the domain. And rightly do…
    3. **Shadow accounts need to be used**  
       As our computers are now in a workgroup we need to setup and maintain Shadow accounts for access.
    4. **You can only use one AppTier**  
       As we need to maintain shadow accounts and thee needs to be one on each AppTier we end up with either AppTier1MyAccount or AppTier2MyAccount. So on the build server we get a conflict of Workgroup as these two accounts vie for workspace mappings.

    So what can we do to alleviate this. One idea, the one that we re going to try,  is to take the snapshot at the beginning of the build and revert at the end. That way the Snapshot we are reverting to is only a few hors old at worst and our Build computers can continue to be services normally. Unfortunately we only know the agent… on the agent..

    The way to solve this is to either rewrite the AgentScope Activity (not going to happen) or to do something a little sneaky. How about if we add another AgentAcope, reserve the agent in some way and then run the real agent scope…

    1. DONE Reserve Agent in some way
    2. Execute some action against the Agent
    3. DONE Run on Reserved Agent
    4. Execute some action against the Agent
    5. DONE Reset the Reservation

    While this does complicate the build process it does indeed looks to be the best bet in this circumstance.

    ![image](images/image1-2-2.png "image")  
    { .post-img }
    **Figure: Reserve an agent before you execute the build for real**

    ## Reserve an Agent in some way

    This should be simple even though it looks a little convoluted.

    1. Add additional AgentScope
    2. DONE Add a Tag to the Agent
    3. DONE Get Machine name of the Agent
    4. Exit AgentScope

    ![image](images/image2-3-3.png "image")  
    { .post-img }
    **Figure: Add additional AgentScope to reserve an agent**

    In this additional Agent Scope we can now call GetBuildAgent to populate the data we need and gain access to the Tags. However we need to do a couple of things that are not normally done:

    ### Add a Tag to the Agent

    In order to add a tag to an agent we need to create our first custom activity. This one, as with all of the activities for this process are really simple. It takes the IBuildAgent variable that we just got and a string Tag that it then adds to that agent.

    ```
    namespace MrHinsh.TfsBuildExtensions
    {
        using System;
        using System.Activities;
        using System.ComponentModel;
        using Microsoft.TeamFoundation.Build.Client;
        using Microsoft.TeamFoundation.Client;

        [BuildActivity(HostEnvironmentOption.All)]
        public sealed class BuildAgentTags : CodeActivity
        {
            [RequiredArgument]
            [Browsable(true)]
            public InArgument BuildAgent { get; set; }

            [RequiredArgument]
            [Browsable(true)]
            public InArgument Action { get; set; }

            [RequiredArgument]
            [Browsable(true)]
            public InArgument Tag { get; set; }

            protected override void Execute(CodeActivityContext context)
            {
                if (context == null)
                {
                    throw new ArgumentNullException("context");
                }

                IBuildAgent buildAgent = context.GetValue(this.BuildAgent);
                TagActions action = context.GetValue(this.Action);
                String tag = context.GetValue(this.Tag);
                switch (action)
                {
                    case TagActions.Add:
                        buildAgent.Tags.Add(tag);
                        break;
                    case TagActions.Remove:
                        buildAgent.Tags.Remove(tag);
                        break;
                    default:
                        break;
                }
            }
        }

        public enum TagActions
        {
            Add,Remove
        }
    }
    ```

    **Figure: Add a Tag to the Agent custom build activity**

    Once compiled and added to your custom assemblies location you can then add that new activity to your Build Workflow and configure it.

    ![image](images/image3-4-4.png "image")  
    { .post-img }
    **Figure: Add a Tag to the Agent workflow**

    We already got the BuildAgent variable from the GetBuildAgent activity and we can pass it in here. I am also choosing to use the Build Number, that we get from the BuildDetail object,  to add as a tag. This makes sure that it is unique to this execution and allows us a simple way to clean it up afterwards.

    ![image](images/image8-9-9.png "image")  
    { .post-img }
    **Figure: Tag added to agent**

    As you can see this successfully adds the tag to the agent.

    ### Get Machine name of the Agent

    The second activity we need is to retrieve the physical server name for the agent that we are running on. We need to call into wither VMWare or HyperV to snapshot the server and for that I need to know what server to call.

    This was even easier to get although it did take a little while poking at the API’s to find the right thread to pull. I had thought that I could get the server name from a property of an existing object but it was conspicuously missing. I decided that rather than trying to be difficult I would just parse it out of a URL. Simples…

    ```
    namespace MrHinsh.TfsBuildExtensions
    {
        using System;
        using System.Activities;
        using System.ComponentModel;
        using Microsoft.TeamFoundation.Build.Client;
        using Microsoft.TeamFoundation.Client;

        [BuildActivity(HostEnvironmentOption.All)]
        public sealed class GetBuildAgentMachineName : CodeActivity
        {
            [RequiredArgument]
            [Browsable(true)]
            public InArgument BuildAgent { get; set; }

            [RequiredArgument]
            [Browsable(true)]
            public OutArgument AgentMachineName { get; set; }

            protected override void Execute(CodeActivityContext context)
            {
                if (context == null)
                {
                    throw new ArgumentNullException("context");
                }
                IBuildAgent buildAgent = context.GetValue(this.BuildAgent);
                context.SetValue(this.AgentMachineName, buildAgent.Url.Host);
            }
        }
    }

    ```

    **Figure: Get Machine name of the Agent custom activity**

    You can see that I am just using the build agent object and parsing the servers host name from the URL. This seamed a lot easier than using any of the other methods that I could think of and even after spelunking the API’s for a few hours I could not find a better approach.

    ![image](images/image4-5-5.png "image")  
    { .post-img }
    **Figure: URL from Build Configuration page of TFS Administration Console**

    This will give me the fully qualified name of the server as it is configured in the Build Configuration of the TFS Administration Console on the Build Agent server.

    ![image](images/image5-6-6.png "image")  
    { .post-img }
    **Figure: Get Machine name of the Agent workflow config**

    Again I am using the BuildAgent object and passing back the value as AgentMachineName to a veriable that I can use outside of the scope of the “Reserve on Agent” sequence.

    ## Run on Reserved Agent

    Rather than creating something custom we really want to hook into what is already there. When you configured a build you were able to define some information on what agent to select and run on. In this configuration you were able to select things like Agent Name and Tags to filter by.

    ![image](images/image6-7-7.png "image")  
    { .post-img }
    **Figure: Selecting the Agent Settings**

    Using Agent Name will not provide us any value as we do not want another build to snag this agent but instead to ignore it. To do that we need to set the “Tag Comparison Operator” to “MatchExactly” and make sure that only the agents we want have the desired tag set. In this case it is NONE. With no tags added this build should select any agent with no tags and ignore agents that have even one tag.

    So when we execute the first agent scope above our agent will be selected and we harvest the name and add a tag that is the same as the build number. Now all we need to do is update the Agent Settings above to include a tag that is the same as the build name and the second Agent Scope with only be able to choose our tagged Agent. And for that we need another custom Activity.

    ```
    namespace MrHinsh.TfsBuildExtensions
    {
        using System;
        using System.Activities;
        using System.ComponentModel;
        using Microsoft.TeamFoundation.Build.Client;
        using Microsoft.TeamFoundation.Client;
        using Microsoft.TeamFoundation.Build.Workflow.Activities;

        [BuildActivity(HostEnvironmentOption.All)]
        public sealed class AgentSettingsTags : CodeActivity
        {
            [RequiredArgument]
            [Browsable(true)]
            public InArgument AgentSettings { get; set; }

            [RequiredArgument]
            [Browsable(true)]
            public InArgument Action { get; set; }

            [RequiredArgument]
            [Browsable(true)]
            public InArgument Tag { get; set; }

            protected override void Execute(CodeActivityContext context)
            {
                if (context == null)
                {
                    throw new ArgumentNullException("context");
                }
                AgentSettings agentSettings = context.GetValue(this.AgentSettings);
                TagActions action = context.GetValue(this.Action);
                String tag = context.GetValue(this.Tag);
                switch (action)
                {
                    case TagActions.Add:
                        agentSettings.Tags.Add(tag);
                        break;
                    case TagActions.Remove:
                        agentSettings.Tags.Remove(tag);
                        break;
                    default:
                        break;
                }
            }
        }
    }

    ```

    **Figure: Add Tag to Agent Settings custom activity**

    All this code does is take the Agent Settings object and add a tag to make sure that we get the right agent the second time through the AgentScope.

    **![image](images/image7-8-8.png "image")  
    { .post-img }
    Figure: Add Tag to Agent Settings Workflow**

    So we just pass the AgentSettings object and feed it the same build number that we used before as the tag. Now we can only get this agent to “Match Exactly” and thus the build should run on this agent.

    ## Reset the Reservation

    And to reset the reservation all that needs done is to remove that tag from the agent. For this activity we just set the “Action” attribute to be “Remove” and we remove the tag of the build name and free up the Agent for other builds. It is worth noting that if a build is cancelled then you my need a separate clean-up routine that runs and un reserves machines that are reserved due to failed or stopped builds.

    ## Conclusion

    This process while requiring the customisation of your build process can allow you to do a bunch of things with your build server that you may not want to enshrine in it. You may want to do the snapshot and revert not because your developers are breaking the build, but because you want to start with a clean build machine each time to test your install process as well.

    ![image](images/image9-10-10.png "image")  
    { .post-img }
    **Figure: Successfully reserved agent and then used same agent**

    If we are trying to achieve “configuration as code” then we need to be installing all of our pre-requisites with our build script.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-04-reserve-an-agent-for-a-special-build-in-team-foundation-server-2012\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-04-04-reserve-an-agent-for-a-special-build-in-team-foundation-server-2012
- FrontMatter:
    title: Connect a Test Controller to Team Foundation Service
    description: Learn how to connect a Test Controller to Team Foundation Service for streamlined automated deployment and testing. Simplify your configuration today!
    ResourceId: D5NhnVpHAwD
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9348
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-27
    weight: 790
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: connect-a-test-controller-to-team-foundation-service
    aliases:
    - /resources/D5NhnVpHAwD
    aliasesArchive:
    - /blog/connect-a-test-controller-to-team-foundation-service
    - /connect-a-test-controller-to-team-foundation-service
    - /resources/blog/connect-a-test-controller-to-team-foundation-service
    tags:
    - Install and Configuration
    categories:
    - Uncategorized
  BodyContent: |
    Did you know that you can connect a Test Controller to Team Foundation Service? And if you can do that, can you create [standard environments for automated deployment and testing](http://blog.hinshelwood.com/standard-environments-for-automated-deployment-and-testing/ "Standard Environments for Automated Deployment and Testing") against the cloud?

    I did not realise that this was supported and I only stumbled across it as I was tinkering with my local Test Controller and saw my TF Service instance in the connection menu and wondered what would happen.

    ![image](images/image48-1-1.png "image")  
    { .post-img }
    **Figure:** [**Connect a Test Controller to Team Foundation Service**](http://msdn.microsoft.com/en-us/library/vstudio/hh546460.aspx)

    To get the Test Controller you need to get a hold of the [Agents ISO](http://www.microsoft.com/visualstudio/eng/downloads#d-additional-software) from the download site and run the install.

    ![image](images/image49-2-2.png "image")  
    { .post-img }
    **Figure: Run configuration to connect a Test Controller to Team Foundation Service**

    Once you have the agent installed you can then get on with the configuration. This is simple and the only surprise was that it worked.

    ![image](images/image50-3-3.png "image")  
    { .post-img }
    **Figure: Configure to connect a Test Controller to Team Foundation Service**

    This is so simple it is ridicules. Just select your hosted Team Foundation Service environment from the ‘browse’ list. You will likely have to configure the additional account to talk to your local agents as the account that you use to connect to TFS does not have that permission.

    Under the covers the controller will be detecting that it is TF Service which is why the “use different credentials to connect to Team Foundation Server” is disabled but that did confuse me for a while. That was until I remembered that the Build Controller automatically retrieves the [Service Credentials](http://blog.hinshelwood.com/tfs-service-credential-viewer/) from TF Service and this was likely doing the same. It is however not that obvious and as I am in a hotel on a hotel speed connection I battled with error messages for a while. But they were all in the tubes and not in the controller.

    ![image](images/image51-4-4.png "image")  
    { .post-img }
    **Figure: TF400324 Team Foundation services are not available from server**

    This however is a red hearing as you can see from the log:

    ```
    E, 2013/03/26, 19:22:10.502, Microsoft.TeamFoundation.TeamFoundationServiceUnavailableException: TF400324: Team Foundation services are not available from server https://mrhinsh.visualstudio.com/defaultcollection.
    Technical information (for administrator):
      The underlying connection was closed: An unexpected error occurred on a receive. ---> System.Net.WebException: The underlying connection was closed: An unexpected error occurred on a receive. ---> System.IO.IOException: Unable to read data from the transport connection: An existing connection was forcibly closed by the remote host. ---> System.Net.Sockets.SocketException: An existing connection was forcibly closed by the remote host
    at System.Net.Sockets.Socket.Receive(Byte[] buffer, Int32 offset, Int32 size, SocketFlags socketFlags)
    at System.Net.Sockets.NetworkStream.Read(Byte[] buffer, Int32 offset, Int32 size)
    --- End of inner exception stack trace ---
    at System.Net.Sockets.NetworkStream.Read(Byte[] buffer, Int32 offset, Int32 size)
    at System.Net.FixedSizeReader.ReadPacket(Byte[] buffer, Int32 offset, Int32 count)
    at System.Net.Security._SslStream.StartFrameHeader(Byte[] buffer, Int32 offset, Int32 count, AsyncProtocolRequest asyncRequest)
    at System.Net.Security._SslStream.StartReading(Byte[] buffer, Int32 offset, Int32 count, AsyncProtocolRequest asyncRequest)
    at System.Net.Security._SslStream.ProcessRead(Byte[] buffer, Int32 offset, Int32 count, AsyncProtocolRequest asyncRequest)
    at System.Net.TlsStream.Read(Byte[] buffer, Int32 offset, Int32 size)
    at System.Net.PooledStream.Read(Byte[] buffer, Int32 offset, Int32 size)
    at System.Net.Connection.SyncRead(HttpWebRequest request, Boolean userRetrievedStream, Boolean probeRead)
    --- End of inner exception stack trace ---
    at System.Net.HttpWebRequest.GetResponse()
    at Microsoft.TeamFoundation.Client.Channels.TfsHttpWebRequest.SendRequestAndGetResponse(HttpWebRequest webRequest, WebException& webException)
    --- End of inner exception stack trace ---

    ```

    **Figure: TF400324 because The underlying connection was closed**

    Man I hate hotel connections and their flakiness.

    However after a little perseverance and clicking at just the right time to get on the maintenance plunger cycle for the hotel WiFi and you are connected.

    ![image](images/image52-5-5.png "image")  
    { .post-img }
    **Figure: Configured to connect a Test Controller to Team Foundation Service**

    Now that we are configured we can head over to Microsoft Test Manager, switch to the Lab Centre and configure an environment.

    What did you do with your environments connected to TF Service?
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-27-connect-a-test-controller-to-team-foundation-service\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-27-connect-a-test-controller-to-team-foundation-service
- FrontMatter:
    title: The Insufficiency of Scrum is a fallacy
    description: Explore the myth of Scrum's insufficiency and learn how effective engineering practices can enhance Agile success. Elevate your team's performance today!
    ResourceId: n9OhtpbJs0-
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9338
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-23
    weight: 230
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: the-insufficiency-of-scrum-is-a-fallacy
    aliases:
    - /resources/n9OhtpbJs0-
    aliasesArchive:
    - /blog/the-insufficiency-of-scrum-is-a-fallacy
    - /the-insufficiency-of-scrum-is-a-fallacy
    - /resources/blog/the-insufficiency-of-scrum-is-a-fallacy
    tags:
    - Software Development
    - Agile Frameworks
    - Technical Debt
    - Engineering Practices
    - Pragmatic Thinking
    - Team Performance
    categories:
    - Engineering Excellence
    preview: nakedalm-experts-professional-scrum-3-3.png
  BodyContent: |
    The insufficiency of Scrum is a fallacy perpetrated by teams that don’t step up their practices in concert with their planning and don't really want to make it work anyway. You can fail doing Kanban, XP, Merise and SSADM just as easily unless you have good engineering practices as well.

    The goal of Agile it to have you fail sooner and for it to cost less. So what happens when you try to make your management practices more agile but forget about your engineers practices?

    Well [José Manuel Nieto](http://aventuraspuntonet.wordpress.com/) contacted me on twitter after joining a team that was suffering from what he called [The Insufficiency of Scrum](http://aventuraspuntonet.wordpress.com/2013/03/16/the-insufficiency-of-scrum/) and asked for thoughts and after a conversation some advice.

    <blockquote class="twitter-tweet"><p>@<a href="https://twitter.com/mrhinsh" target="_blank">mrhinsh</a> Hi What do you think about the thoughts I published? "The Insufficiency of SCRUM" <a title="http://wp.me/p33ULi-5k" href="http://t.co/piKoVTO9YM" target="_blank">wp.me/p33ULi-5k</a></p><p>— José Manuel Nieto (@SuperJMN) <a href="https://twitter.com/SuperJMN/status/315446020039397378" target="_blank">March 23, 2013</a></p></blockquote>

    When we fail at something it is only human to look for something to blame other than ourselves as the implementers and the things that we did not take care of.

    We have to accept the fact that no process is perfect and that we will need to work hard at anything to make it work. Unfortunately we worked at traditional software development for over 40 years to prove that it did not work. But that is not really true…. it works in the small scale or if we are building something simple. I can’t think of any modern software that is either of those things. However Agile is not a silver bullet. I will say that again… **Agile is not a silver bullet** and you should read [Scrum is hard to adopt and disruptive to your organisation](http://blog.hinshelwood.com/scrum-is-hard-to-adopt-and-disruptive-to-your-organisation/ "http://blog.hinshelwood.com/scrum-is-hard-to-adopt-and-disruptive-to-your-organisation/").

    <blockquote class="twitter-tweet"><p>@<a href="https://twitter.com/mrhinsh" target="_blank">mrhinsh</a> It WAS agile until bugs started to riddle the app. SCRUM only has short-term planning.</p><p>— José Manuel Nieto (@SuperJMN) <a href="https://twitter.com/SuperJMN/status/315513979948642304" target="_blank">March 23, 2013</a></p></blockquote>

    Most of the Agile Frameworks only cater for planning the ‘what’ and tells you to let the team decide on ‘how’ to build the software. Scrum, Kanban & Scaled Agile all focus on the Management process not the engineering practices. This does not mean that you don’t also need good engineering practices, and in fact the [Scrum Guide](http://www.scrum.org/Scrum-Guides) explicitly tells you that your team needs “good engineering practices’ in order to succeed.

    ![image](images/image46-1-1.png "image")  
    { .post-img }
    **Figure: Testing is core to inspecting and adapting your engineering practices**

    If you don’t have those good engineering practices then you will spend more time sprint on sprint struggling with the technical debt that is built up and you will end up down an engineering blind ally.

    <blockquote class="twitter-tweet"><p>@<a href="https://twitter.com/mrhinsh" target="_blank">mrhinsh</a> Right. It lacks all of those -able adjectives. But, how to recover from the mess. How to refactor?</p><p>— José Manuel Nieto (@SuperJMN) <a href="https://twitter.com/SuperJMN/status/315532905977876481" target="_blank">March 23, 2013</a></p></blockquote>

    But now I am hosed, how to I get out of this?

    ## Step 1: Hold effective retrospectives to prevent the insufficiency of scrum

    On of the reasons our team gets into this position is that they did not know that they was in a broken state until it is too late. If our organisation fails to understand the purpose of the retrospective as an inspect and adapt moment for ‘how’ we worked during our Sprint then one will fail to improve.

    <blockquote class="twitter-tweet"><p>@<a href="https://twitter.com/mrhinsh" target="_blank">mrhinsh</a> it was as soon as I entered the team. 6th sprint.</p><p>— José Manuel Nieto (@SuperJMN) <a href="https://twitter.com/SuperJMN/status/315532343857266688" target="_blank">March 23, 2013</a></p></blockquote>

    The accountable and responsible party here is the Scrum Master. Without an effective Scrum Master to guide the team you WILL fail. If you do not have an effective Scrum Master then you or they don’t fully understand the [42 Tasks for a Scrum Master’s Job](http://agiletrail.com/2011/11/14/42-tasks-for-a-scrum-masters-job/ "42 Tasks for a Scrum Master’s Job").

    According to the Scrum Guide the Development Team can ‘choose’ their Scrum Master to make sure that they get some one as effective as possible.

    Yes, this also means that they can ‘un-choose’ their current one.

    ## Step 2: Stop creating technical debt to prevent the insufficiency of scrum

    You need to first stop creating technical debt. To do this you only need to focus on one thing; **Working software at lease every 30 days**. If you are not able to create working software every sprint then you need to stop and look at why that is.

    Note I prefer ‘working software on every checkin’ and ‘continuous delivery’. That way I can ship working software at any time.

    Now I am not talking about that flaccid rendition of working software that lead you to this place of horror and despair. But instead take ‘working software’ at face value and have it mean ‘everything that I have delivered works with no further work required’. Does that mean that it meets the customers expectations? No it does not; unless their only expectation is for what you show them to work with no errors and that if they say ‘ship-it’ you can deploy what you have. If you have to reply with… “Well, maybe next sprint as we still have some bugs.” then you have failed as a professional and as a team to deliver the minimum bar.

    <blockquote class="twitter-tweet"><p>@<a href="https://twitter.com/mrhinsh">mrhinsh</a> The core is basically wrong. Now, nobody can fix that. No time for redesigns in a sprint</p><p>— José Manuel Nieto (@SuperJMN) <a href="https://twitter.com/SuperJMN/status/315519701960777729">March 23, 2013</a></p></blockquote>

    But if we do get into that state then you are in the very same ‘brownfield’ situation as software that have been built over years with no unit tests. So if the primary goal now is working software that meets our customers expectations and we augment our Definition of Done to reflect that then we will be delivering less features of higher quality.

    ![image](images/image47-2-2.png "image")  
    { .post-img }
    **Figure: There is [1000% return of investment for every test written in TDD](https://www.sugarsync.com/pf/D057810_69933305_087616)**

    While we are still paying back our excessive build up of technical debt, using those engineering practices that will prevent future build up, we will be delivering less value to the customer.

    ## Conclusion

    Remember that the software that you are building is an organisational asset and decisions to cut quality affect the value of that asset and thus must be reflected in your organisations financial statements .Cutting quality in your software without first gaining the approval to do so from your financial executives is unprofessional at best and fraud at worst and always incompetence.

    Don’t be incompetent. Don't commit fraud.

    **Be a professional…**
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-23-the-insufficiency-of-scrum-is-a-fallacy\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-23-the-insufficiency-of-scrum-is-a-fallacy
- FrontMatter:
    title: Visual Studio 2012 Update 2 supports 2010 Build Servers
    description: Discover how Visual Studio 2012 Update 2 enables seamless integration with 2010 Build Servers, simplifying upgrades and enhancing your development workflow.
    ResourceId: wOYxXY4OsUH
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9336
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-22
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: visual-studio-2012-update-2-supports-2010-build-servers
    aliases:
    - /resources/wOYxXY4OsUH
    aliasesArchive:
    - /blog/visual-studio-2012-update-2-supports-2010-build-servers
    - /visual-studio-2012-update-2-supports-2010-build-servers
    - /resources/blog/visual-studio-2012-update-2-supports-2010-build-servers
    tags:
    - Install and Configuration
    - System Configuration
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-11-11.png
  BodyContent: |
    Did you know that Visual Studio 2012 Update 2 supports 2010 Build Servers? Being able to connect TF Build 2010 Controllers to TFS 2012 is opening up upgrade paths for customers that are currently blocked from upgrading to TFS 2012.

    - Update - This is supported on Team Foundation Server 2013 as well as Team Foundation Server 2012 Update 2 +

    Most of my customers have a small foot print for their build infrastructure (< 5 TF Build 2010 servers) and can upgrade to the latest version at the same time as their TFS Server. However a growing number of customers have substantial (> 20 TF Build 2010) server that facilitate builds across hundreds of products each with their own custom build workflow.

    If you have ever tried to upgrade a workflow from 2010 to 2012 you will no that it can be a little tricky at times if you have heavy customisations. Not only do you need to rebuild all of your custom activities for the new framework, you need to get them into your XAML and test it. This can be a major undertaking.

    ![image](images/image36-1-1.png "image")  
    { .post-img }
    **Figure: Updating all of your XAML workflows is daunting enough**

    Not only that but many folks are still using Windows Server 2003 as their standard environment and are likely using 32bit. Those in the know will already have cringed as a 32bit server CAN NOT be upgraded to the Windows Server 2008 R2 64but or Windows Server 2012 64bit that are the only operating system supported by Team Foundation Build 2012. So not only do I have to move to a newer OS, but I also have to wipe and rebuild all of my build servers for a new bit’edness.

    So to support this adoption blocker the build team have worked night and day to honour the existing API that your Team Foundation Build 2010 Controllers are looking for. This means that you can keep all your TF Build 2010 Controllers and Agents on the same OS but move your TFS server forward to TFS 2012 Update 2.

    ## Connect existing TFS 2010 Build Agent to TFS 2012

    If you have upgraded your TFS 2010 server to TFS 2012 Update 2 and you have moved hardware then you will need to reconfigure each of your TF Build 2010 Controllers and Agents to talk to the new TFS 2012 Server.

    ![image](images/image37-2-2.png "image")  
    { .post-img }
    **Figure: Change the TFS Server configured for Build**

    or you can call "tfsconfig setup uninstall:all" to reset your build agent to defaults and run the wizard again. When you do you will be asked is you want to ‘replace’ and existing build machine and you can replace the one you are are current on.

    Simples…

    ## Connect new TFS 2010 Build Agent to TFS 2012

    You can have Team Foundation Build 2010 installed on any [operating system that supports it](<http://msdn.microsoft.com/en-us/library/vstudio/dd578592(v=vs.100).aspx>) which includes 32bit Windows Server 2003. If you have existing TF Build 2010 instances and you are doing either an in-place upgrade or you use a friendly name to connect then you need do nothing and everything will work seamlessly after the upgrade.

    If however you are moving your TFS server to new hardware, always recommended  for major version upgrades, then you will need to reconfigure your Build Controller and Agents to talk to the new server URL.

    ![image](images/image38-3-3.png "image")  
    { .post-img }
    **Figure: TFS 2010 Build Agent installed**

    You then need to make sure that you have Service Pack 1 installed before you try to connect your server to TFS 2012. Once you have that installed, I got mine from Windows Update, you are good to go for configuration.

    ![image](images/image39-4-4.png "image")  
    { .post-img }
    **Figure: Connect your TF Build 2010 to TFS 2012**

    In this case I am using Windows Server 2012 64bit, but this works just as well on Windows Server 2003 32bit. We then come to how we want our TF Build 2010 to connect to TFS 2012. This only really applies if you are adding a new TF Build 2010 Agent to the mix.

    ![image](images/image40-5-5.png "image")  
    { .post-img }
    **Figure: Adding a new Controller you can scale out or replace**

    If you are replacing and existing controller you can select it here, or if you are adding a new 2010 Agent to a 2010 Controller that can also be selected. You do however need to make sure that you do not try to add a 2010 Agent to a 2012 Controller as that will not work.

    ![image](images/image41-6-6.png "image")  
    { .post-img }
    **Figure: I have 2 Controllers on here so I need to change the port**

    A already have a TF Build 2012 controller on this box so I am configuring this new one to work on another port. While not usually necessary it does allow this scenario. If you are going to do that in production however you want to make sure that you have enough cores and RAM to support it.

    Info You can’t have both your controllers configured at the same time. I have turned my 2012 controller off to configure my 2010 on on the same server.

    ![image](images/image42-7-7.png "image")  
    { .post-img }
    **Figure: TF255466 .NET Framework 3.5 is not installed**

    If you are running on Server 2012 or Server 2008 R2 you will have to explicitly add .NET 3.5 to the stack. This is very easy with the “Add Roles & Features” wizard.

    ![image](images/image43-8-8.png "image")  
    { .post-img }
    **Figure: Adding the .NET Framework 3.5 feature for TF Build 2010 to work**

    Now that we have everything in place we can run the configuration of TF Build 2010 and plug it into our TFS 20912 server.

    ![image](images/image44-9-9.png "image")  
    { .post-img }
    **Figure: My 2010 Controller and Agent are configured against 2012**

    Now all of my existing builds will work as is with no upgrade required. I can even run TF Build 2010 on servers that do not have .NET 4.5 on them.

    ![image](images/image45-10-10.png "image")  
    { .post-img }
    **Figure: Woot, 2010 and 2012 together having fun**

    Now I can choose wither to send my build to my 2010 build system or my 2012 one.

    ## Conclusion

    This is one of the major features of Team Foundation Server 2012 Update 2. I know that it looks like a little fix, but I have customers that were thinking that they would never be able to upgrade to TFS 2012. If your TFS server is managed by a central corporate IT department and you have many business units using it can they all take the time to upgrade all of their Custom Activities, Build Workflows and Servers all at once?

    Well now they don’t have to. There is no longer any excuse not to upgrade to TFS 2012 Update 2 now!
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-22-visual-studio-2012-update-2-supports-2010-build-servers\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-22-visual-studio-2012-update-2-supports-2010-build-servers
- FrontMatter:
    title: Batched domain migration with TFS while maintaining Identity
    description: Learn how to execute a batched domain migration with TFS while preserving user identities. Avoid pitfalls and ensure a smooth transition for your team.
    ResourceId: vzIIFAI5ygR
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9324
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-20
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: batched-domain-migration-with-tfs-while-maintaining-identity
    aliases:
    - /resources/vzIIFAI5ygR
    aliasesArchive:
    - /blog/batched-domain-migration-with-tfs-while-maintaining-identity
    - /batched-domain-migration-with-tfs-while-maintaining-identity
    - /resources/blog/batched-domain-migration-with-tfs-while-maintaining-identity
    tags:
    - Troubleshooting
    - Software Development
    - System Configuration
    - Install and Configuration
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-5-5.png
  BodyContent: |
    If you are moving from one domain to another, but you have lots of users you may do a batched domain migration with Visual Studio 2012 Team Foundation Server. Make suer that you read all of the fine print and don't get caught with duplicate Identities and no traceability.

    In this case you need to carefully mange the users over to the new environment as Visual Studio 2012 Team Foundation Server actively syncs all domain accounts into its internal identity system. Why do you care? Well, lets suppose you have a domain group called domain1domaingroup1 and this group contains domain1user1 and domain1user2.

    ![image](images/image32-1-1.png "image")  
    { .post-img }
    **Figure: Domain1**

    Now when you add this “Group1” to Team Foundation Server it goes and syncs all of the accounts in that group. If it syncs an account that does not currently have an internal identity it creates that wrapper TFS Identity. TFS uses wrapper identities so that you can change the contents of that identity and so that you can have multiple Active Directory users with the same username, but in different domains.

    ![image](images/image33-2-2.png "image")  
    { .post-img }
    **Figure: Domain1 Sync**

    This is all fine until you try to switch domains. This is not a switch of the domain of which TFS is a member, but a switch of the domain of which the accounts are members. This usually happens at the same time, but you may move TFS from your “Department” domain to your “Corporate” domain while still maintaining trust between the two. Or you may have multiple “Departmental” or “IBoughtThisComany” domains that all have trust relationships with your “Corporate” domain and can log into TFS.

    ![image](images/image34-3-3.png "image")  
    { .post-img }
    **Figure: Bad example, we created duplicate identities**

    But at some point you want to move your users from signing in with “Domain1” credentials to using “Corporate” ones. When this happens and we do the workflow wrong we can mess up the identities in TFS and effectively have new users when we want the same ones.

    This can happen when the new users are given permission, perhaps through an active directory group to your TFS server in the new domain before you have done a little work to make sure this does not happen. What we really want to happen is to change the active directory users that the TFS Identity refers to to the new domain without creating a new Identity.

    **_Warning If you do end up with a duplicate identity then there is NO way to fix this! You would need to restore from backup and start your migration again making sure not to add any of the new domains users to the server._**

    ![image](images/image35-4-4.png "image")  
    { .post-img }
    **Figure: Good example, we have mapped the user across**

    If you have a lot of users you are probably going to stage or batch your users across to the new domain. So how do we manage that?

    1. Move TFS Server from Domain1 to Domain2 with full trust
    2. For each user:
       1. Make 100% sure that domain2User1 has NEVER been added to TFS
       2. Remove User1 from group1 in domain1
       3. Migrate User1 to Domain2 and disable account on Domain1
       4. Run TfsIdentities command line to remap the TFS Identity to the user in the new domain
       5. Add domain2user1 to TFS and remove domain1user1
       6. Add user1 to group1 of domain2

    _Info You may see that under the covers TFS has created a new  Identity wrapper for the old domain1user1 account after you have mapped it across. Note that this would be a NEW TFS Identity object and we can safely ignore it. You can prevent it from being created by removing user1 from Domain1Group1 prior to running the TfsIdentity command._

    If for any reason we need to back out then you can follow the reverse process. Remember that the server is joined to Domain2 at this point and it is just the users identities that we are messing with.

    This is the theory, but in the real world things may be different. In the case of one customer it will take up to a year to move all users across. This poses a problem as the Active Directory migration tool automatically adds the new user to all of the existing Groups and thus the user would likely already be synced to the new server ![Sad smile](images/wlEmoticon-sadsmile-6-6.png)
    { .post-img }

    One way around this would be to move to TFS groups for the migration. You can create a TFS group that is equivalent to the Active Directory group and thus remove the automatic syncing as you can then remove the Active Directory groups from TFS. While this does mean that you need to manage the users that are members of those groups manually it will avoid the duplicate users.

    1. Convert all Domain1 AD Groups to TFS Groups
    2. Move TFS Server from Domain1 to Domain2 with full trust
    3. For each user:
       1. Migrate User1 to Domain2 and disable account on Domain1
       2. Run TfsIdentities command line to remap the TFS Identity to the user in the new domain
    4. Convert all TFS Groups to AD Domain Groups on Domain2

    Either of these two workflows for moving users will work. It depends on how your Operations teams are moving the accounts around. However you do this, if you are batching users, it will take some time. This particular customer thinks it will take them up to a year to move all of their users and are in this for the long term.

    - [In-Place upgrade of TFS 2008 to TFS 2010 with move to new domain](http://blog.hinshelwood.com/in-place-upgrade-of-tfs-2008-to-tfs-2010-with-move-to-new-domain/ "http://blog.hinshelwood.com/in-place-upgrade-of-tfs-2008-to-tfs-2010-with-move-to-new-domain/")

    Hopefully your domain move goes more smoothly and that you watch out for the pitfalls.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-20-batched-domain-migration-with-tfs-while-maintaining-identity\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-20-batched-domain-migration-with-tfs-while-maintaining-identity
- FrontMatter:
    title: Migrating source code with history to TFS 2012 with Git-Tf
    description: Learn how to migrate source code with history to TFS 2012 using Git-Tf. Discover robust methods for seamless transitions and efficient version control.
    ResourceId: tiIa1A7zPP-
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9313
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-19
    weight: 840
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: migrating-source-code-with-history-to-tfs-2012-with-git-tf
    aliases:
    - /resources/tiIa1A7zPP-
    aliasesArchive:
    - /blog/migrating-source-code-with-history-to-tfs-2012-with-git-tf
    - /migrating-source-code-with-history-to-tfs-2012-with-git-tf
    - /resources/blog/migrating-source-code-with-history-to-tfs-2012-with-git-tf
    tags:
    - Software Development
    categories:
    - Uncategorized
  BodyContent: |
    Its hard to migrate source code even from one Visual Studio 2012 Team Foundation Server to another, especially when you also want to have your history. We have been forced in the past to use some hokie migration tools that only really partially work.

    - Update Anthony Borton gave me a hard time for not being able to get this working. However I had no problem with second set of code below.

    With Git-Tf we can Clone a Team Foundation Server repository and with plane old Git we can do a Pull from one to the other and then push up to our target repository.

    ![image](images/image30-1-1.png "image")  
    { .post-img }
    **Figure: Running Git from the Command Line**

    The first thing we need to do in install Git-Tf and its dependencies. This will add the Git Bash command line and the TFS integration required to connect everything up. This is really me first time using Git as I have just not had time to play with it, but it looks solid so far.

    ![image](images/image31-2-2.png "image")  
    { .post-img }
    **Figure: Install with the cint Git-Tf command line call**

    When you clone a Team Foundation Server repository you can either get the tip or you can go deep. If you add the --deep  parameter on end you will effectively clone the history as well. For this particular task I only need the tip and I am really only need to go one way. You can however push source code back and fourth at will between the two servers or any other environment. A browse of the internet will also show you other source control systems that you can clone to Git. If you can clone you can pull and if you can pull you can checkin…

    ```
    git tf clone https://mrhinsh.visualstudio.com/DefaultCollection $/TfsExtensions/TfPlugable ~/wsgitmrhinshTfPlugable
    git tf clone http://kraken:8080/tfs/tfs01 $/TfsExtensions/TfPlugable  ~/wsgitkTfs01TfPlugable
    git pull ~/wsgitmrhinshTfPlugable
    git checkin

    ```

    **Figure: Git commands to move from TFS to TFS**

    ```
    git tf clone https://nakedalm.visualstudio.com/DefaultCollection $/TfsExtensions/TfPlugable c:\temp\TfPlugable
    cd C:\Users\MrHinsh\Source\Repos\TfPlugable
    git remote add tfplugable-tfvc-branch c:\temp\TfPlugable
    git pull tfplugable-tfvc-branch master --deep
    git checkin

    ```

    **Figure: Git commands to move from TFVC to TFS Git**

    The result of this is a move from my Team Foundation Service cloud account to my local test Team Foundation Server virtual machine.

    If you are trying to move your source code from anything to Team Foundation Server this may be a good option. Its robust and will bring history across. I have not tested this at load but it should support reasonable sized repositories, large however will need some testing…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-19-migrating-source-code-with-history-to-tfs-2012-with-git-tf\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-19-migrating-source-code-with-history-to-tfs-2012-with-git-tf
- FrontMatter:
    title: 'Lab Management Issue: Enable File and Printer Sharing for Lab Management Standard Environments'
    description: Resolve file and printer sharing issues in Visual Studio 2012 Lab Management on Windows 8 and Server 2012. Follow our guide for seamless integration!
    ResourceId: JuqjGCN5X6g
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9288
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-17
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: windows-server-2012-core-issue-enable-file-and-printer-sharing-for-lab-management-standard-environments
    aliases:
    - /resources/JuqjGCN5X6g
    aliasesArchive:
    - /blog/windows-server-2012-core-issue-enable-file-and-printer-sharing-for-lab-management-standard-environments
    - /windows-server-2012-core-issue-enable-file-and-printer-sharing-for-lab-management-standard-environments
    - /lab-management-issue--enable-file-and-printer-sharing-for-lab-management-standard-environments
    - /blog/lab-management-issue--enable-file-and-printer-sharing-for-lab-management-standard-environments
    - /resources/blog/windows-server-2012-core-issue-enable-file-and-printer-sharing-for-lab-management-standard-environments
    tags:
    - Windows
    - Troubleshooting
    - System Configuration
    - Install and Configuration
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-6-6.png
  BodyContent: |
    If you try to add any servers to Standard Environments in Visual Studio 2012 Lab Management you get a message that you need to enable file and printer sharing and you are unable to configure or communicate with those machines.

    ![image](images/image11-1-1.png "image")  
    { .post-img }
    **Figure: Unable to verify that machines are accessible**

    There are three main causes:

    - The File and Printer Sharing exception is not enabled on these machines
    - The username or password is not valid
    - The machines have Windows XP

    I know that the second two are not true so what to do now?

    ## Applies To

    - Standard Environments (Visual Studio 2012 Lab Management\*)
    - SCVMM Environments (Visual Studio 2012 Lab Management\*)
    - Physical Environments (Visual Studio 2010 Lab Management\*)
    - Windows Server 2012\*
    - Windows 8\*

    \* this applies to all versions of Windows that you want to use with both Visual Studio 2012 and Visual Studio 2010 Lab Management features.

    ## Findings

    In order for Lab Management to successfully integrate with guest servers is used the file and print sharing ports of that machine. If they are not enabled or the ports are otherwise blocked then you will not otherwise be able to use those servers in environments. This

    In both Windows 8 and Windows Server 2012 the File and Printer Sharing ports are blocked by default and you will need to open them up for this to work.

    ## Solution for Windows 8

    You need to open the ports required for File & Print Sharing. This is roughly the same for doing the same on Windows Server 2012 through the UI.

    1.  **Start | type “Fire” | click “Settings” | press “Enter” key**
        ![image](images/image12-2-2.png "image")
        { .post-img }
        **Figure: Open the Windows Firewall Settings**
    2.  **Change Settings | check “File and Printer Sharing” | OK**
        ![image](images/image13-3-3.png "image")
        { .post-img }
        **Figure: Enable File and Printer Sharing on your Windows 8 firewall**

    ## Solution for Windows Server 2012 Core

    You need to open the ports required for File & Print Sharing.

    ```
    powershell
    netsh advfirewall firewall set rule group=”File and Printer Sharing” new enable=Yes

    ```

    **Figure: Enable File and Printer Sharing via the command line**

    ![image](images/image14-4-4.png "image")  
    { .post-img }
    **Figure: Make sure that you run this in PowerShell**

    ## Conclusion

    After enabling the File and Printer Sharing firewall rules everything is now green.

    ![image](images/image15-5-5.png "image")  
    { .post-img }
    **Figure: We can now verify the Standard Environment**
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-17-windows-server-2012-core-issue-enable-file-and-printer-sharing-for-lab-management-standard-environments\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-17-windows-server-2012-core-issue-enable-file-and-printer-sharing-for-lab-management-standard-environments
- FrontMatter:
    title: Standard Environments for Automated Deployment and Testing
    description: Discover how to automate deployment and testing with Standard Environments in Visual Studio 2012 TFS, enhancing your DevOps practices for seamless delivery.
    ResourceId: Xmo3nfcFGmv
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9308
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-17
    weight: 565
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: standard-environments-for-automated-deployment-and-testing
    aliases:
    - /resources/Xmo3nfcFGmv
    aliasesArchive:
    - /blog/standard-environments-for-automated-deployment-and-testing
    - /standard-environments-for-automated-deployment-and-testing
    - /resources/blog/standard-environments-for-automated-deployment-and-testing
    tags:
    - Software Development
    - Technical Excellence
    - Technical Mastery
    - Operational Practices
    - Engineering Practices
    - Install and Configuration
    - System Configuration
    - Continuous Integration
    - Release Management
    - Application Lifecycle Management
    - Automated Testing
    - Continuous Delivery
    - Test Automation
    - Product Delivery
    - Internal Developer Platform
    categories:
    - DevOps
    - Engineering Excellence
    preview: nakedalm-experts-visual-studio-alm-17-17.png
  BodyContent: |
    Standard Environments in Visual Studio 2012 Team Foundation Server make it possible to have an automated deployment of your software to a development or QA environment. You can then have a bunch of automated tests run in those environments, collecting data all the while.

    In TFS 2010 this feature was called “Physical Environments” which is a little confusing as it just means non-Lab Management environment. It provided the ability to run tests, but you had to manually deploy which kind of sucked. What use is it unless I can do continuous delivery to it. So in Visual Studio 2012 Team Foundation Server the product team changed this to “Standard Environments” and allow you not only to monitor test execution, but also to do deployments. Better yet they also made it a snip to get existing servers up to speed…

    ![image](images/image16-2-2.png "image")  
    { .post-img }
    **Figure: Standard Environments in Visual Studio 2012 Team Foundation Server**

    The Application Lifecycle Management (ALM) community is constantly telling everyone that you should deploy in the same way to production as you do to development and testing but what we really mean is to use the same deployment mechanism, not necessarily delivery engine. As we may have different delivery engines we need to impose some standards.

    We need to come up with some sort of standard interface for our Software Configuration Management (SCM) & DevOps teams to consume so that they can always have our deployments do the same thing with the same scripts. This allows us to promote the same **unit of work** from development through testing and then to production. Fortunately this interface already exists for .NET shared packages and many developers already use it; Its called Nuget.

    Now while we call the searching of public packages and delivery of those components inside of Visual Studio Nuget it is really just something called “Nuget Package Manager for Visual Studio”. This package manager is just one implementation (granted the first) of Nuget and there are also a few others; Chocolatey and Octopus Deploy spring to mind as good other ones.

    ![image](images/image17-3-3.png "image")  
    { .post-img }
    **Figure: Nuget explained**

    So now we have a consistent packaging mechanism we need to have a deployment pipeline to service development and testing environments. This is where the “Standard Environments” comes in. It would be awesome if we could use the additional features of “System Centre Virtual Machine Manager (SVCMM)” that would give us built in snapshots and templating, unfortunately many  customers use VM Ware or other products that don’t yet work with Visual Studio 2012 Lab Management.

    In order to setup Standard Environments we need to do a couple of things:

    1. **DONE - Create your Standard Environment**
    2. **DONE - Deploy to your Standard Environment**

    ## Create your Standard Environment

    A Standard Environment is just a group of computers that you have defined as part of an environment to be monitored. These servers can be Physical or Virtual and they will have the Lab agent deployed automatically and configured to collect results from your testing.

    ![image](images/image18-5-5.png "image")  
    { .post-img }
    **Figure: Create new environments in the Lab Centre**

    If you were not previously aware you can open Microsoft Tests Manager and click the “Test Centre” title and switch over the green “Lab Centre”. The lab centre is where you manage all of your settings controllers and environments. If you are using SCVMM then you can manage your virtual environments and library's. Remember that environments are there so that we can manage ‘more than one’ machine at once. While you can do that yourself, it is a lot easier if it is done for you.

    ![image](images/image19-6-6.png "image")  
    { .post-img }
    **Figure: Give your new environment some meta data**

    You do get to set a little bit of Meta data and you can set title and you can add tags. If you have multiple client scenarios you may want to tag your environments so that you can keep track of them. You may need to have at least one environment per configuration and probably multiple so that you can have multiple testers working at the same time.

    I find that al lot of organisations are resistant to creating an environment for each tester, but if you don’t then what one tester is doing can colour another. Remember if you are using the Intellitrace, Test Impact Analysis or Code Coverage data collectors then you MUST have only one tester in that environment. If you have limited resources for environments then you could use one environment to have all of your testers testing and another to verify the results.

    ![image](images/image20-7-7.png "image")  
    { .post-img }
    **Figure: Add each machine to your environment**

    I am not sure if there is a hard limit to the number of machines that you can have in any single environment but I know that in Lab Management 2010 did have a soft limit of 5. This limit was based on performance issues and my understanding was it applied to SCVMM environment's. Some experimentation may be required if you have very large environments, but if this case I only have there machines.

    For each machine you need to tag with a role. This role can be used to specify scripts and to refer to the machines during a workflow.

    ![image](images/image21-8-8.png "image")  
    { .post-img }
    **Figure: Add an administrator account**

    An account needs to be added that is in the Administrators group of each of the machines but can be different per environment. This account will be used to connect to and configure those machines including installing the agents and configuring the data collection.

    ![image](images/image22-9-9.png "image")  
    { .post-img }
    **Figure: Select the client for CodedUI test execution**

    If you are wanting to run Coded UI tests and especially if you want to run them across multiple clients to speed up your tests then you need to select the machines to run the UI testing from. This will then configure those machines agents to run in interactive mode and they will log themselves in to run the tests. You can use a different account to do the login, but here I am just using the same domainTfLab account that I am using to configure and access them.

    [![image[15]](images/image15_thumb-1-1.png "image[15]")](http://blog.hinshelwood.com/files/2013/03/image151.png)  
    { .post-img }
    **Figure: Unable to verify that machines are accessible**

    If you are unable to verify the machines are access able then try the following:

    - [Windows Server 2012 Core Issue: Enable File and Printer Sharing for Lab Management Standard Environments](http://blog.hinshelwood.com/windows-server-2012-core-issue-enable-file-and-printer-sharing-for-lab-management-standard-environments/ "http://blog.hinshelwood.com/windows-server-2012-core-issue-enable-file-and-printer-sharing-for-lab-management-standard-environments/")

    This should fix the machines so that you can move forward.

    [![image[18]](images/image18_thumb-4-4.png "image[18]")](http://blog.hinshelwood.com/files/2013/03/image181.png)  
    { .post-img }
    **Figure: We can now verify the Standard Environment**

    As is usual with Team Foundation Server there are a bunch of verification checks that are performed before it ever tries to actually do the work. But once the checks are complete, which hopefully minimises any chance of errors.

    ![image](images/image23-10-10.png "image")  
    { .post-img }
    **Figure: Auto-configuration of your machines**

    After the validation and you select finish Lab Manager will go off and configure all of your machines. This includes installing the lab agent and configuring it to talk to your Team Foundation Server and indeed setting up the interactive UI test runner.

    ![image](images/image24-11-11.png "image")  
    { .post-img }
    **Figure: Fully configured environments**

    This environment is now ready.

    ## Deploy to your Standard Environment

    Now that I have somewhere for my application to go, I need an application to go there. As I have not got all of the way through this on my servers I will just show one way that you can use this new Standard Environment.

    ![image](images/image25-12-12.png "image")  
    { .post-img }
    **Figure: Selecting the LabDefaultTemplate**

    If you have been creating custom build workflows you will know that that XAML file controls the options that are available here and the Lab XAML changes things up quite drastically. There is really only one option of consequence and that is the “Lab Process Settings”. I am not sure why this is a pop out wizard rather than a set of options to pick, but it is likely because so many of the options depend on each other.

    ![image](images/image26-13-13.png "image")  
    { .post-img }
    **Figure: Select an Environment**

    First we need to select the environment that we just created. Don’t get exited by the ‘snapshot’ option as this will only be available if your environment is hosted in a Lab Management integrated System Centre Virtual Machine Manager (SCVMM) host.

    ![image](images/image27-14-14.png "image")  
    { .post-img }
    **Figure: Select the build you want to call**

    We have bunch of options here. We can use a build or a drop folder; If we pick build we can also select wither to take the latest, a specific or to execute a new one first. I would note that if you select “Queue a new build” you will have to have a controller available that has more than one agent available.

    ![image](images/image28-15-15.png "image")  
    { .post-img }
    **Figure: Select your deployment scripts**

    It really is that simple to do a deployment. You pick the role or tag and select a script to un on that machine. That script can come from source control and it can be a simple bat file or a PowerShell. This can take your Nuget package that is the output from your build and execute it on the server. Personally I would stick all of my installs in here to so that I don’t need to do any separate configuration. The ultimate goal is configuration as code and that also means for the dependant applications that need to be installed on our servers. You could make a bunch of Chocolatey calls in the PowerShell to get your server setup and configured then run any deployment actions that you need.

    ![image](images/image29-16-16.png "image")  
    { .post-img }
    **Figure: My build fails, yours does not have to**

    I need to spend a bunch of time creating the PowerShell scripts that I need to do my deployments. But I think from this you can get the idea.

    ## Conclusion

    So, not only can I now deploy my code, but I can have this happen automatically and have my existing regression UI automation run as part of it. Now, I do not want to do that for every checking, or maybe I do, but I may want to run a nightly build and full regression. Or if I have thousands of automation then maybe I have a permanently  rolling build that runs to the side of my core work and validates my full regression. I then only have to delve in when there is a failure.

    In combination with some other mechanism to deploy to our pre-production and production environments we now have the makings of a standard deployment pipeline that obfuses the complexity of individual application deployment from SCM and DevOps teams while leaving the developers with the capability and versatility to deploy how they like.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-17-standard-environments-for-automated-deployment-and-testing\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-17-standard-environments-for-automated-deployment-and-testing
- FrontMatter:
    title: 'Windows 8 Issue: Unable to connect to the internet with Hyper-V domain joined guest running on WiFi'
    description: Struggling with internet connectivity on Hyper-V guests in Windows 8? Discover solutions to fix Wi-Fi issues and optimize your network setup effectively!
    ResourceId: OPPj3aAz3P6
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9281
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-15
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: windows-8-issue-unable-to-connect-to-the-internet-with-hyper-v-domain-joined-guest-running-on-wifi
    aliases:
    - /resources/OPPj3aAz3P6
    aliasesArchive:
    - /blog/windows-8-issue-unable-to-connect-to-the-internet-with-hyper-v-domain-joined-guest-running-on-wifi
    - /windows-8-issue-unable-to-connect-to-the-internet-with-hyper-v-domain-joined-guest-running-on-wifi
    - /windows-8-issue--unable-to-connect-to-the-internet-with-hyper-v-domain-joined-guest-running-on-wifi
    - /blog/windows-8-issue--unable-to-connect-to-the-internet-with-hyper-v-domain-joined-guest-running-on-wifi
    - /resources/blog/windows-8-issue-unable-to-connect-to-the-internet-with-hyper-v-domain-joined-guest-running-on-wifi
    tags:
    - Windows
    - Troubleshooting
    - System Configuration
    categories:
    - Uncategorized
    preview: puzzle-issue-problem-128-link-5-5.png
  BodyContent: |
    I have recently created my own local domain and now I am unable to connect to the internet with Hyper-V domain joined guest running. It gets weirder as it only affects me when I am on a Wi-Fi connection.

    ```
    route PRINT

    ```

    **Figure: Querying the routes**

    Now while this is complete gibberish to me I can use it to try and figure stuff out.

    ![image](images/image7-2-2.png "image")  
    { .post-img }
    **Figure: Standard Routes**

    This is very annoying as I use WiFi extensively..

    ## Applies to

    - Windows 8
    - Hyper-V

    ## Findings

    I have not really figured out what the exact problem is or why it used to work and does not now I have a domain controller as a guest. I have checked the routing table both with those computers off and on and there are no changes.

    ![image](images/image8-3-3.png "image")  
    { .post-img }
    **Figure: Networking Setup in Windows 8 for Hyper-V**

    However it worked just fine when I was cabled in so it looked like some difference between the way the Hyper-V handles cable vs WiFi.

    Doing a little testing I can be on WiFi with no VM’s running and everything works… now when I turn on any of my VM’s the internet stops working…but not right away….what!

    If I do a little network refresh…

    ```
    ipconfig /release
    ipconfig /renew

    ```

    **Figure: Refresh your network settings**

    …Then I see the changes immediately. So I spent an hour or so both on WiFi and on Cable spinning computers up and down and refreshing the network. This is a Wireless issue!

    ![image](images/image9-4-4.png "image")  
    { .post-img }
    **Figure: Now that looks a little complicated**

    After a bunch of research it looks like cabled connections are just wired strait through. However WiFi connections are the weird one and they require the “Network Bridge”. Now if we look at the properties for the network bridge it looks like there is a bunch of stuff not configured…

    ## Solution

    The solution is to make sure that all of the features for your Network Bridge are configured.

    ![image](images/image10-1-1.png "image")  
    { .post-img }
    **Figure: Default Network Bridge**

    Now I want all of those things when I am on a corporate network, so I just ticked all the boxes and OK’ed the warning and wow… everything now works…
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-15-windows-8-issue-unable-to-connect-to-the-internet-with-hyper-v-domain-joined-guest-running-on-wifi\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-15-windows-8-issue-unable-to-connect-to-the-internet-with-hyper-v-domain-joined-guest-running-on-wifi
- FrontMatter:
    title: Chicago Visual Studio ALM User Group 27th March
    description: Join the Chicago Visual Studio ALM User Group on March 27th for insights on Kanban, Work Item Tags, and more. Don't miss out—register now!
    ResourceId: Zfdh9rvKZbG
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9275
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-12
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: chicago-visual-studio-alm-user-group-27th-march
    aliases:
    - /resources/Zfdh9rvKZbG
    aliasesArchive:
    - /blog/chicago-visual-studio-alm-user-group-27th-march
    - /chicago-visual-studio-alm-user-group-27th-march
    - /resources/blog/chicago-visual-studio-alm-user-group-27th-march
    tags: []
    categories:
    - Uncategorized
    preview: metro-UserGroup-128-2-2.png
  BodyContent: |
    It has been a while since I was at the [Visual Studio ALM User Group in Chicago](http://chicagoalmug.org/). This time I will be giving a demonstration of the new Work Item Tracking features of Visual Studio 2012 Update 2 which includes Kanban Columns & Work Item Tags as well as a peek at Teams without Areas.

    With almost 2 years since my last customer visit in Chicago I just have not been out there that much and I was sorry that I missed the Chicago ALM Summit. Fortuitously my latest customer engagement is in Chicago at the same time as the user group meets. Funny how those things work out.

    ![calmug](images/calmug-1-1.png "calmug")
    { .post-img }

    I know that as well as the awesome [Angela Dugan](http://blogs.polarissolutions.com/author/angeladugan.aspx) there will also be the infamous [Edward Thomson](http://www.edwardthomson.com/blog/) from the cross-platform team at Microsoft. Angela will be talking about her favourite things which include Microsoft Test Manager and Ed will be taking us through a journey of discovery of Git and TFS lovin.

    I want to cover three things and I only have 30 minutes so it will be tight:

    - **Kanban Columns** – Although a Kanban board and Cumulative Flow diagrams were added in Visual Studio 2012 Update 1 the product team have been busy agile beavers and added the ability to customise the columns independent of state.
    - **Work Item Tags** – As is that was not enough they have also in Visual Studio 2012 Update 2 they have added the ability to tag work items with whatever you like. Awesome feature but how will it be used?
    - **Teams without Areas** – I have blogged on the topic of [Teams without Areas](http://blog.hinshelwood.com/team-foundation-server-2012-teams-without-areas/) and here I will demonstrate the techniques required to have team separate from both Area and Iteration.

    Wow… if we can get through all of that this session then the Chicago Visual Studio ALM User Group looks to be steeped in geek goodness. So if you are in Chicago on Wednesday the 27th of March, are a geek and want a beer then head on over to the Aon Centre at 18:30…

    **Warning: Be sure to register as Aon Centre security will NOT allow individuals to access the building without being pre-registered:** **[http://chicagoalmug.org/](http://chicagoalmug.org/)**
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-12-chicago-visual-studio-alm-user-group-27th-march\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-12-chicago-visual-studio-alm-user-group-27th-march
- FrontMatter:
    title: Windows Server 2012 Core for dummies
    description: Master Windows Server 2012 Core with this beginner's guide. Learn essential command-line configurations for efficient server management and setup.
    ResourceId: qtma311iiMY
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9255
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-10
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: windows-server-2012-core-for-dummies
    aliases:
    - /resources/qtma311iiMY
    aliasesArchive:
    - /blog/windows-server-2012-core-for-dummies
    - /windows-server-2012-core-for-dummies
    - /resources/blog/windows-server-2012-core-for-dummies
    tags:
    - Windows
    - Install and Configuration
    - System Configuration
    categories:
    - Uncategorized
    preview: metro-server-instances-7-7.png
  BodyContent: |
    This is a short idiots guide to setting up Windows Server 2012 Core. Windows Server 2012 Core allows you to use less memory by getting rid of some peskie UI bits and bobs. Setting it up however is a little more challenging.

    - **Update 2013-03-18 -** After all my hard work Shad told me that this was the old-school way and why did I not use "sconfig".   
       ![18-03-2013 15-53-19](images/18-03-2013-15-53-19-1-1.png)**Figure: Arrrrr**
      { .post-img }
      It does not have all of the commands I might need, but it does have many.

    While I pride myself on having a past as a developer I did dabble in thee dark side once upon a time. My first to jobs out of university ended up with me maintaining domains and computers for the organisations that I worked for even though I would rather have not.

    ![image](images/image2-2-2.png "image")  
    { .post-img }
    **Figure: You only get a command window**

    The first issue that you run into when using Windows Server 2012 Core is the dreaded command line. Where it used to be hard to script activities in Windows, the existence of Core has made it trivial if you know the commands. Now if you like the command line you may never install another version of windows again… but if like me you like… you know… Windows… then you can use another server or you can install the admin tools on Windows 8 or Windows 7.

    So to get this running there are a bunch of activities that can only be achieved through the command line:

    1. **DONE - Enable Remote Desktop for Windows Server 2012 Core**
    2. **DONE - Registering Windows on Windows Server 2012 Core**
    3. **DONE - Remotely managing Windows Server 2012 Core**
    4. **DONE - Updating Windows Server 2012 Core**
    5. **DONE - Renaming your Windows Server 2012 Core**
    6. **DONE - Set network details for your Windows Server 2012 Core**
    7. **DONE - Opening Firewall ports on Windows Server 2012 Core**
    8. **DONE - Domain join your Windows Server 2012 Core**

    I may add to this list, but this was all I needed to setup and configure separate Domain Controller, Web Application Server, Database Server and TFS server. All but my TFS server are currently Core servers and that only because it already existed.

    ## Enable Remote Desktop for Windows Server 2012 Core

    The first thing that I want to do with my servers is to connect remotely. While the Hyper-V console is awesome it does not support Cut & Past which frustrated me no end. Luckily it is very easy to enable remote desktop connections to your new server.

    ```
    cscript C:WindowsSystem32Scregedit.wsf /ar 0

    ```

    **Figure: Enable Remote Desktop via the command line for Windows Server 2012 Core**

    You will see as we go through that the technologies for managing your server are a little fragmented still. Its not that this cant be done with PowerShell, its that it is much harder than the script above to [Enabling Remote Desktop with PowerShell](http://blogs.technet.com/b/jamesone/archive/2009/01/31/checking-and-enabling-remote-desktop-with-powershell.aspx).

    I am sure there will be more parity in the future.

    ## Registering Windows on Windows Server 2012 Core

    This is the only way to register Server Core if you do not have an internal registration server. Indeed you need this to register Windows 8 Enterprise as well as there is no UI for it anyway.

    ```
    slmgr.vbs /ipk [your windows key]

    ```

    **Figure: Register Windows visa the command line for Windows Server 2012 Core**

    And look… a Visual Basic Script call…. awww….

    ## Remotely managing Windows Server 2012 Core

    This was the single most vexing and frustrating thing to configure. If you are setting up core within a domain then you just join the local computer to your existing domain and you can then add that server to a computer with server manager. But if you have a workgroup as you would before you created your domain controller then you are a little hosed.

    You have to tell the target core server to trust the incoming server manager connection and the server with server manager to trust the target core server. Phew…

    To do this you need to add the other side to each sides “TrustedHosts” list and to do that you need to enable PowerShell as this is our first PowerShell call.

    ```
    powershell
    Set-Item wsman:localhostClientTrustedHosts KRAKEN -Concatenate -Force

    ```

    **Figure: Adding trusted hosts via the command line for Windows Server 2012 Core**

    While the server manager ports are supposed to be available by default between both the servers I did have to turn the firewall off. It may be that I just got mixed up, but there are many other circumstances that I can think of to turn the firewall of so…

    ```
    NetSh Advfirewall set allprofiles state off

    ```

    **Figure: Disable the firewall via the command line** **for Windows Server 2012 Core**

    As well as remotely managing my servers I also want to be able to ping my servers. Call me old fashioned but a ‘ping’, which is disabled by default, has help me out many a time.. So I also want to enable that:

    ```
    netsh advfirewall firewall add rule name="All ICMP V4" dir=in action=allow protocol=icmpv4

    ```

    **Figure: Enable ping via the command line for Windows Server 2012 Core**

    While not really required it does tend to help you out when you can ping through your firewall.

    Now that you have the Trusted Hosts set and you can get through the firewall you can add your server to the management console.

    ![image](images/image3-3-3.png "image")  
    { .post-img }
    **Figure: Add your new Windows Server 2012 Core to the Server Manager**

    If you got a bunch of errors stating that the server does not exist then you need to disable the firewall. If you get a bunch of messages about “TrustedHosts” then you should make sure you have added each server to the others Trusted Host list.

    ## Updating Windows Server 2012 Core

    And what about Windows Updates? How the heck do we see or configure them. Well there are a bunch of commands for this, unfortunately I just don’t care. Or more precisely… I don’t want to have to care. I’m a 3am kinda guys and thats what I want.

    ```
    net stop wuauserv
    cscript c:WindowsSystem32SCregEdit.wsf /AU 4
    net start wuauserv
    powershell
    set-service wuauserv -startuptype "Automatic"

    ```

    **Figure: Enable Windows Update via the command line for Windows Server 2012 Core**

    There is a script that you can install for [Searching, Downloading, and Installing Updates](<http://msdn.microsoft.com/en-us/library/aa387102(VS.85).aspx>) but that is way more hassle than I want. In the past there were updates, specifically 1.1 .NET Framework updates that were installed automatically and broke some custom applications that companies had. Because of that burn they don’t like auto-updates.

    The facts though are that the only reason the applications broke were that they were poorly built and maintained. Is this the fault of the update tool? Or the Developers and support teams for not keeping up to date. Barring an emergency ‘OMG-OMG Look at that security hole’ it takes around three months for updates to get onto Windows Update. All that testing that needs done is also testing that your organisation needs to do and turning automatic updates of prevents that testing.

    How about a compromise. All non Production servers are set to Auto-Update and we Update production deliberately. When we release new versions of our software all updates currently applied in non-Production are applied to production. An easy way to keep progression and stave of disaster…

    ## Renaming your Windows Server 2012 Core

    Next you probably want to give your server a name other than than the silly default almost-guid crap that gets set.

    ![image](images/image4-4-4.png "image")  
    { .post-img }
    **Figure: The silly default name for your Windows Server 2012 Core**

    Why ‘win-fv6da60d6cs’ would ever be considered a good name for a server I do not know ![Smile](images/wlEmoticon-smile-8-8.png)
    { .post-img }

    So lets fix that now…

    ```
    netdom renamecomputer localhost /newname:Metatron /reboot

    ```

    **Figure: Rename your Windows Server 2012 Core via the Command Line**

    Whats in a name? Well my ‘metatron’ name, for my database server, is not what I would use for a company. Company servers have names that show lots of information:

    > elonmaptfsp01 = **E**urope | **Lon**don | **M**icrosoft | **Ap**plication | **T**eam **F**oundation **S**erver | **P**roduction | **01**
    >
    > elonmsqtfsp01 = **E**urope | **Lon**don | **M**icrosoft | **SQ**L | **T**eam **F**oundation **S**erver | **P**roduction | **01**

    You should be able to tell a lot by a name…

    ## Set network details for your Windows Server 2012 Core

    When you create a new server you normally need to set some network information to get things going. Because I have a datacentre in a laptop, and my DHCP configuration skills are zip I need to set a fixed IP access.

    _Note: Having 2 DHCP servers on a network if not configured properly is BAD_

    So for me… adding a fixed IP address is paramount but so is setting the DNS address on the “Private” network adapter that I use.

    ![image](images/image5-5-5.png "image")  
    { .post-img }
    **Figure: Virtual Switch Manager of your Hyper-V Host**

    I always add an “Internal Only” network so that even if I am on a plane with no network my Hyper-V Guests will still be able to talk. This is where I need the fixed IP and to set the DNS to that of the Domain Controller DNS Instance.

    ```
    netsh interface ip set address name="Ethernet" static 192.168.100.14 255.255.255.0 192.168.100.1 1
    netsh interface ipv4 add dnsserver "Ethernet" 192.168.100.1 1

    ```

    **Figure: Setting network settings for Windows Server 2012 Core via the command line**

    Now this would be us done but I actually add 3 virtual adapters to my servers. Why? Well I have to bind to either WiFi or Cable and changing it on the fly is slow. I can change it quickly on each guest, but I need to do it for each guest which is… effort. So to mitigate it I add 2 additional adapters and bind to both WiFi and Wire.

    ![image](images/image6-6-6.png "image")  
    { .post-img }
    **Figure: Settings for Hyper-V guest**

    This dies mean that it can get confusing as they are, by default, named “Ethernet”, “Ethernet 2” and “Ethernet 3”. Good luck figuring that out… So I always try to change the name of the adapter. In the UI that is actually surprisingly hard and hidden, but easy in the command line.

    ```
    netsh interface set interface name = "Ethernet" newname = "Private"
    netsh interface set interface name = "Ethernet 2" newname = "Public - WiFi"
    netsh interface set interface name = "Ethernet 3" newname = "Public - Wire"

    ```

    **Figure: Setting the Interface name for your Windows Server 2012 Core via the command line**

    Now we can communicate and we know how…

    ## Opening Firewall ports on Windows Server 2012 Core

    Remembering that we turned the firewall back on there may be some applications that we want to install that require particular ports to be opened.

    I have a couple of servers that I use as Tentacle’s of an Octopus Release pipeline and they need to be able to communicate on port 10933.

    ```
    netsh advfirewall firewall add rule name="Octopus Tentacle 10933" dir=in action=allow protocol=TCP localport=10933

    ```

    **Figure: Add a firewall rule for your Windows Server 2012 Core from the command line**

    Now we can enable all of our apps.

    ## Domain join your Windows Server 2012 Core

    Remembering to have already set a DNS server that will allow you to join the domain, you may have DHCP, we can now easily join the server to our domain.

    ```
    netdom join localhost /domain:vsalm.com /userd:vsalmadministrator /passwordd:[password]  /reboot:0

    ```

    **Figure: Join your Windows Server 2012 Core via the command line**

    After a reboot you are kinda done. I used the remote administration to do much of the complicated configuration and to add new Features and Roles to the servers. This can be done via the command line, but it is something that is easier in the UI.

    ## Conclusion

    There are many things in Windows Server 2012 Core that you have to do via the command line and many other things that are just easier in the UI. I have only really documented the things that I needed to use so that I would not forget. I did configure all of the Roles and Features directly in the Server Manager console as the UI lets me tick a bunch of boxes and leads me through a wizard. However if you are a scriptie kina dude then you can do that too.

    Good luck with your server configurations…

    _\-Do you need help deploying & configuring Team Foundation Server? Get in touch on_ [_info@nwcadence.com_](mailto:info@nwcadence.com?subject= Recommended through MrHinsh - Windows Server 2012 Core for dummies) _so that we can get started._
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-10-windows-server-2012-core-for-dummies\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-10-windows-server-2012-core-for-dummies
- FrontMatter:
    title: Guide to ChangeServerId says mostly harmless
    description: Discover the importance of ChangeServerId in TFS upgrades. Learn how to avoid GUID issues and ensure a smooth transition to your new environment.
    ResourceId: hoewU67YJfb
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9249
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-03-06
    weight: 1000
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: guide-to-changeserverid-says-mostly-harmless
    aliases:
    - /resources/hoewU67YJfb
    aliasesArchive:
    - /blog/guide-to-changeserverid-says-mostly-harmless
    - /guide-to-changeserverid-says-mostly-harmless
    - /resources/blog/guide-to-changeserverid-says-mostly-harmless
    tags:
    - Troubleshooting
    - Install and Configuration
    - System Configuration
    categories:
    - Uncategorized
  BodyContent: |
    If you are cloning your TFS collection then you have to run ChangeServerId. It is reasonably well documented for this senario but what other reasons might you have to run it.

    Well if you are upgrading your TFS server you may want to create a duplicate of your environment, run the upgrade and have a few folks connect and try things out. This is where we need to talk about GUIDs. GUIDs are used everywhere in side TFS. Your server has a GUID, your collections have GUIDs and even your Team Projects have GUIDs.

    So if you take a backup of your production environment and restore it to another for upgrade it will have the same GUIDs. But why is this important. Well, when you connect to another server with the same GUIDs your client applications that connect to TFS will automatically transfer all of your cache and workspaces to the new server. This gives your users continuity of use as they can easily transition to the new environment even if it has a new name.

    However if any users connect to your test / trial upgrade environment the same thing will happen and they could start to see some pretty strange results… you know… weird things like getting the wrong files when you do a get from source control, SharePoint sites created on the wrong servers and even errors when editing or querying work items.

    The way that you solve this is the same as for cloning your collection. You need to make a call to ChangeServerId.

    ```
    TFSConfig ChangeServerID /SQLInstance:ServerName] /DatabaseName:ConfigurationDatabaseName [/ProjectCollectionsOnly] [/ConfigDBOnly] [/usesqlalwayson]

    ```

    **Figure: ChangeServerID command**

    Now usually I would do this as soon as I stood up the new instance, but this instance was stood up by a customer that did not know about the GUID issues. They had just sent out an email to many of their users to try out and validate the new environment so unfortunately I recommended that they immediately change the server ID so that they don’t have problems later.

    Why do I say unfortunately… its all in the messages and there is one when you try to run ChangeServerID that my customer, as everyone does, breezed over this morning:

    > _The command ChangeServerId should only be run against a set of Team Foundation Server databases that have no application tiers configured. Do you want to continue with this operation? (Yes/No)_

    While this is absolutely explicit you and I likely did what they also did which was focus on the last sentence and the questions that it contains…

    Now if you do go ahead and say ‘yes’ then you will end up with a few problems.

    ![image](images/image-1-1.png "image")  
    { .post-img }
    **Figure: TF31001: Cannot connect to Team Foundation Server**

    woops, lets hope this is just a client issue and check the web access…

    ![TF50620](images/TF50620-3-3.jpg "TF50620")  
    { .post-img }
    **Figure: TF50620: The  Team Foundation identity scope does not exist**

    Oh… well a reboot will likely solve that…

    ![image](images/image1-2-2.png "image")  
    { .post-img }
    **Figure: TF30046: The instance information does not match**

    Dam..

    Checking the event log on the server reveals lost of errors of the TF30046 variety but logs on the server reveal nothing. Even checking the ChangeServerId log reveals nothing but success.

    To the rescue is Vladimir Khvostov from the product team who pointed me at the RegisterDB and the cause.

    ```
    TFSConfig RegisterDB /SQLInstance:ServerName [/usesqlalwayson]

    ```

    **Figure: Setting the server strait**

    In the bowless of the web.config for the TFS web services there lies an “applicationid” key that should be the new GUID but has not been updated. Hence the warning when running the command.

    Running RegisterDB command will update setting in the "C:Program FilesMicrosoft Team Foundation Server 11.0Application TierWeb Servicesweb.config" and allow the server to work again.

    To save time I went ahead and updated it manually and WOW everything worked again.

    **Lesson: Heed all Team Foundation warnings**
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-06-guide-to-changeserverid-says-mostly-harmless\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-03-06-guide-to-changeserverid-says-mostly-harmless
- FrontMatter:
    title: Improvements in Visual Studio ALM from the ALM Summit
    description: Discover the latest enhancements in Visual Studio ALM from the ALM Summit, including Git support, web-based test management, and Kanban improvements.
    ResourceId: E9mwcXKPJ0C
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9239
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-02-08
    weight: 665
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: improvements-in-visual-studio-alm-from-the-alm-summit
    aliases:
    - /resources/E9mwcXKPJ0C
    aliasesArchive:
    - /blog/improvements-in-visual-studio-alm-from-the-alm-summit
    - /improvements-in-visual-studio-alm-from-the-alm-summit
    - /resources/blog/improvements-in-visual-studio-alm-from-the-alm-summit
    tags:
    - Software Development
    - Application Lifecycle Management
    categories:
    - Uncategorized
    preview: nakedalm-experts-visual-studio-alm-6-6.png
  BodyContent: |
    There were many new improvements in Visual Studio ALM that were announced at this years ALM Summit event that I can only pick a few to highlight as my favourites. [Brian Harry did the keynote](http://channel9.msdn.com/Events/ALM-Summit/ALM-Summit-3/Building-an-Engineering-Organization-for-Continuous-Delivery) on the second day and almost immediately announced Visual Studio 2012.2 CTP 2  and a bunch of new features some of which were made available in TF Service ([http://tfs.visualstudio.com](http://tfs.visualstudio.com)) immediately.

    Although most of these features are available now on TF Service you will have to wait for some of them until TF Server 2012.2 RTM’s or even TF Server 201x (Dev12). So what are these fabulous features that have been made available:

    ## DVCS (Distributed Version Control System)

    Full fidelity implementation of Git to allow Visual Studio to natively support Git repositories and for you to choose to use Git as your DVCS version control of choice in TF Service. You will however need to wait until Dev12 (TF Server 201x) to see it on premises.

    - [Git init VS](http://blogs.msdn.com/b/bharry/archive/2013/01/30/git-init-vs.aspx "http://blogs.msdn.com/b/bharry/archive/2013/01/30/git-init-vs.aspx") - Brian Harry
    - [Building an Engineering Organization for Continuous Delivery (Git Announcement)](http://channel9.msdn.com/Events/ALM-Summit/ALM-Summit-3/Building-an-Engineering-Organization-for-Continuous-Delivery "http://channel9.msdn.com/Events/ALM-Summit/ALM-Summit-3/Building-an-Engineering-Organization-for-Continuous-Delivery") – MVP Summit

    ![image](images/image-1-1.png "image")  
    { .post-img }
    **Figure: Creating a Team Project with DVCS**

    NoteMy favourite way to use this is to [create a local Git repository](https://tfs.visualstudio.com/en-us/learn/code/create-code-project-vs-git) with Visual Studio but publish changes to TF Server. Unfortunate for now you need to use the command line until an option is added to the UI which should not be long at the current pace of development.

    ## Quality Enablement Improvements in Visual Studio ALM

    Did you wonder why you cant create and manage your test case infrastructure just like in Microsoft Test Manager but from the web? Well now you can not only create and manage Test Plans, Settings and Cases but you also get a web based Test Runner to allow you to run your manual tests on any platform and collate that data.

    ![image](images/image1-2-2.png "image")  
    { .post-img }
    **Figure: Test Hub in Action**

    This Test Hub in the web access makes adopting Acceptance Test Driven Development (ATDD) or just doing some functional testing trivial. Say goodbye to excel as your test recording tool and be part of the awesome tractability in Team Foundation Server.

    ![image](images/image2-3-3.png "image")  
    { .post-img }
    **Figure: Web Test Runner in Chrome**

    You can use this test runner to record your test results on any platform that can render html5 and JavaScript so the supported platform list just expanded.

    ## Kanban swim lanes

    If you have used the current incarnation of Kanban implemented in Update 1 you will know there is still an issue of having the accordion like states that Kanban likes without breaking TFS. With Update 2 for TF Server the team has added the ability to have those multiple swim lanes that allow you to model your current process without being forced to add all of your states to your process and rewrite all of your reports.

    ![](images/1777.image_5F00_thumb_5F00_5912078B.png)  
    { .post-img }
    **Figure: You can Customise the columns**

    Adding new columns is so easy as you can simply free text them up and map them to an existing state of your Backlog work items. This allows you to stack out as many states as you need to support your process.

    I am not sure yet what will happen if you add 20 columns, but hopefully you will already have gone through some of process improvement initiative and decided that having 20 states is a little… confusing…

    ## Work Item Tagging

    A Work Item Tracking tagging system that allows you not only to tag work items with any text you like, but to filter your queries by those tags. Live on TF Service and coming in TF Server 2012.2

    ![image](images/image3-4-4.png "image")  
    { .post-img }
    **Figure: Adding Tags for each of my Personas**

    This is massive as it allows me to add data to my work item without having to go an edit the work item type. In most cases we just want an extra piece of information attached to our work items so that we can filter search results and more easily find what we want. This is a good start at that and allows us to filter our backlogs and queries when we have many, or just more focus on one area.

    ## Conclusion

    There were so many new features that it is hard to pick out a clear favourite. Indeed there are three categories of wins that are available right now. First is the reduction in the requirement to customise templates that results from the introduction of tagging. Second is the addition of the web based Test Management that will bring many more teams into Team Foundation Server. But the last is perhaps the biggest from an adoption perspective as many teams want to use Git either as individuals or as small teams, but still leverage the massive benefits of the Visual Studio ALM platform.

    ![image](images/image4-5-5.png "image")  
    { .post-img }
    **Figure: Traceability in Team Foundation Server**

    We are starting to see the enablement of the traceability story for a wider audience and across more platforms.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-02-08-improvements-in-visual-studio-alm-from-the-alm-summit\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-02-08-improvements-in-visual-studio-alm-from-the-alm-summit
- FrontMatter:
    title: The TFS Automation Platform is dead, long live the TfPlugable
    description: Discover the TfPlugable, a revolutionary solution for TFS automation. Simplify deployment and management of extensions with our innovative platform!
    ResourceId: cMYx4JN2az5
    ResourceType: blog
    ResourceContentOrigin: Human
    ResourceImport: true
    ResourceImportId: 9229
    ResourceImportSource: Wordpress
    ResourceImportOriginalSource: Wordpress
    date: 2013-01-31
    weight: 690
    creator: Martin Hinshelwood
    layout: blog
    resourceTypes: blog
    slug: the-tfs-automation-platform-is-dead-long-live-the-tfplugable
    aliases:
    - /resources/cMYx4JN2az5
    aliasesArchive:
    - /blog/the-tfs-automation-platform-is-dead-long-live-the-tfplugable
    - /the-tfs-automation-platform-is-dead-long-live-the-tfplugable
    - /the-tfs-automation-platform-is-dead,-long-live-the-tfplugable
    - /blog/the-tfs-automation-platform-is-dead,-long-live-the-tfplugable
    - /the-tfs-automation-platform-is-dead--long-live-the-tfplugable
    - /blog/the-tfs-automation-platform-is-dead--long-live-the-tfplugable
    - /resources/blog/the-tfs-automation-platform-is-dead-long-live-the-tfplugable
    tags: []
    categories:
    - Uncategorized
    preview: nakedalm-logo-128-link-3-3.png
  BodyContent: |
    The TFS Automation Platform is dead, long live the TfPlugable! It has been a long time since I have talked about the [TFS Automation Platform](http://blog.hinshelwood.com/what-is-the-tfs-automation-platform/) that I had almost forgotten about it myself. It was almost two years ago that I spoke to [Willy](http://blogs.msdn.com/b/willy-peter_schaub/) about an ALM Rangers project to build a solution to dynamically deploy plug-ins for TFS, kind of like Nuget for TFS Extensions.

    When we first attempted to get this off the ground way back in 2011 we had a [team of rock star Rangers](http://blogs.msdn.com/b/willy-peter_schaub/archive/2011/02/20/new-rangers-project-tfs-iteration-automation.aspx) that ended up having no bandwidth for yet another project and it faded and died after a few sprints. I was sad, but what can you do…

    ## The Problem

    However recently I have seen more and more customers wanting their TFS servers to have custom automation as part of their deployment. There are quite a few things that come out of the box but there are still many things that could be done. From Admin tasks to simple rollup or email alerts for your entire organisation there are a plethora of extensions for Team Foundation Server that would be useful but are currently hidden away in the back of your TFS cupboards and never see the light of day.

    I would like to do for Team Foundation Server what NuGet has done for distributing and popularising shared assemblies. We need a store for Team Foundation Server where we can pick and choose what extensions we want. Now this already exists for Visual Studio in the [Visual Studio Gallery](http://visualstudiogallery.msdn.microsoft.com/) but there is nothing for Team Foundation Server. I can’t find Check-In Policies for TFS and it is hard to install them, although there is a little love from the Power Tools. I can’t find background operations for TFS… oh I can search for them and find them on blogs, Codeplex or GitHub… but I want the same thing that [NuGet](http://nuget.org/) or [Chocolatey](http://chocolatey.org/) provides.

    It is easy to create to create extensions for Team Foundation Server, but it is hard to deploy and manage them. Here are the key integration points that we will be looking at:

    1. **TF Job** – These jobs can be schedules or one off and run within the context of the TFS Server Itself. They are a compiled DLL that has to be deployed to a particular folder on the TF Server in order to be loaded and registered with TFS.
    2. **TF Event Sink** – Events are fired on the TF Server as a result of Work Item, Build, Source Code changes and implement the ISubscriber interface. Again they need to have the containing DLL dropped into the correct folder on the TF Server.
    3. **Custom Controls** – Sometimes you want to extend the UI of  work items capability to display data and this requires both server side and client side components to be deployed.
    4. **Check-in Policy** – These policies are evaluated at check-in both on the Client and on a Build Server as part of a Gated Check-in. They need to be registered in the system register to be executed but have no special folder.
    5. **Soap Events** – These are like TF Event Sinks but they are more disconnected from TFS. They do need to be registered with TFS, but it is a SOAP registration rather than integral to the server itself. With the introduction of TF Event Sinks there is little need for this, but if you want to have events from TFS 2008 or TFS 2010 then it may be a viable solution for backward compatibility.

    With our Team Foundation Server more commonly being managed by infrastructure teams there is less access to those servers to install and update those extensions. In essence they are very rarely productionised. While it is a fantastic thing to have what amounts to better supported server we still need to be able to add these extensions.

    I want to be able to go to a webpage on my Team Foundation Server that allows me to search for and find extensions that can then be selected and installed.

    ## The Plan

    This sounds simple, but in-fact it can be fairly complex. We plan to create this delivery mechanism and create documentation on how to create packages to do all of these things… will we have everything from day-one? No way… we will be iteratively adding functionality  we get feedback on what we have delivered and changing our roadmap to incorporate that feedback.

    1.  **DONE - Create ability to publish and manage packages**
        We decided to use myget as it provides a lot of services including permissions and a web UI that we do not need to build.

            [![image](images/image_thumb-1-1.png "image")](http://blog.hinshelwood.com/files/2013/01/image.png)

        { .post-img }
        **Figure: Using MyGet to provide hosted NuGet-as-a-service**

    2.  **DONE - Create ability to search for and install packages**
        We have already added some features to the application and it will already allow installs of packages and pass the information required for deployment to the packages.

            [![image](images/image_thumb1-2-2.png "image")](http://blog.hinshelwood.com/files/2013/01/image1.png)

        { .post-img }
        **Figure: Search for Team Foundation Server extensions**

    3.  **Create ability to customise configuration**
    4.  **Create ability to create custom configurations**

    We plan on having the first release soon with #1 & #2 above and include everything that you can install server side. As Extension creators and Extension users express a need for additional features we will prioritise them and include those requests over time. This will be a single install for your TFS server that makes all of the available extensions just a click away.

    ## The Team

    I have a couple of folks helping me on this little project and we are always looking for others that can help add value.

    - **![](images/tuppers50-headshot-150x150.jpg)   
      { .post-img }
      James Tupper**, ALM Consultant & ALM Champ
    - **![](images/mug-shot-andrew-clear.png)  
      { .post-img }
      Andrew Clear**, ALM Developer

    I am open for others to join and you would only need to contribute around 2 hours a week to participate.
  FilePath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-01-31-the-tfs-automation-platform-is-dead-long-live-the-tfplugable\index.md
  FolderPath: C:\Users\MartinHinshelwoodNKD\source\repos\NKDAgility.com\site\content\resources\blog\2013\2013-01-31-the-tfs-automation-platform-is-dead-long-live-the-tfplugable

