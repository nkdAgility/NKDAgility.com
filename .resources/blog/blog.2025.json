[
  {
    "FrontMatter": {
      "title": "Estimating Better in an Overloaded System Is a Poor Man’s Strategy",
      "short_title": "Why Limiting WIP Beats Better Estimation",
      "description": "High work in progress (WIP) causes delays and unpredictability; improving estimates won’t help. Limiting WIP and focusing on flow is key to reliable delivery.",
      "date": "2025-09-08T09:00:00Z",
      "weight": 235.0,
      "ResourceId": "9asj2UApmVM",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "estimating-better-in-an-overloaded-system-is-a-poor-man-s-strategy",
      "aliases": [
        "/resources/9asj2UApmVM"
      ],
      "concepts": [
        "Practice"
      ],
      "categories": [
        "Product Development",
        "Kanban",
        "Engineering Excellence"
      ],
      "tags": [
        "Flow Efficiency",
        "Software Development",
        "Team Performance",
        "Operational Practices",
        "Pragmatic Thinking",
        "Cycle Time",
        "Organisational Physics",
        "Value Delivery",
        "Continuous Improvement",
        "Metrics and Learning",
        "Lean Principles",
        "Social Technologies",
        "Project Management",
        "Lean Thinking",
        "Product Delivery"
      ],
      "Watermarks": {
        "description": "2025-06-18T18:22:38Z",
        "short_title": "2025-07-07T16:43:05Z"
      }
    },
    "BodyContent": "Just a regular reminder that predictability and the accuracy of any estimate deteriorate rapidly as you increase the amount of Work in Progress (WIP) in the system. And yet, most teams still try to compensate for unpredictability by estimating better, rather than addressing the actual problem: the system is overloaded and cannot flow.\n\nThis isn’t a theoretical issue. It’s not about mindset. It’s a systemic constraint. The more you load a delivery system, the slower and more unpredictable it becomes. The more you try to force progress by starting new work, the less likely it is that anything will finish.\n\nAt a certain point, no estimate matters because wait time is dominating lead time.\n\n## Estimation and flow are not interchangeable\n\nIt’s tempting to believe that delivery problems are caused by poor estimation. If only the team were better at sizing or forecasting, things would be more predictable. But the underlying assumption here is flawed: it assumes the issue lies with how the team understands the work, not with how the system behaves under load.\n\nA team may estimate that a task will take two days of effort. That estimate might be reasonable, given what they know. But if that task sits in a review queue, or is waiting on test, or is delayed due to someone being pulled onto another “high priority” initiative, then that two-day effort turns into a ten-day cycle time. The estimate wasn’t wrong. It was irrelevant.\n\nIn a system where most of the time is spent waiting, refining the accuracy of the effort estimate achieves very little. It’s a distraction from the core issue, which is that the system is too congested to behave predictably.\n\n## Little’s Law doesn’t care about your process\n\nThe relationship between WIP, throughput, and cycle time is not arbitrary. It’s defined by **[Little’s Law](https://en.wikipedia.org/wiki/Little%27s_law)**:\n\n> WIP = Throughput × Cycle Time\n\nThis relationship always holds, but it depends on a key assumption: that throughput is reasonably stable. And this is where many teams fall over.\n\nIn most software teams, throughput **does** fluctuate — sometimes significantly. That variability comes from inconsistent work item sizes, unclear requirements, frequent interruptions, blockers, technical debt, lack of test automation, and reactive priorities.\n\nUnless a team is managing WIP aggressively, working in collaboration, and applying consistent flow policies, the idea of “stable throughput” is optimistic at best and misleading at worst. This is exactly why [Scrum]({{< ref \"/resources/guides/scrum-guide\" >}}), [Kanban]({{< ref \"/resources/guides/kanban-guide\" >}}), and other flow-based systems place so much emphasis on visualising work and limiting WIP: to stabilise throughput _so_ you can get the benefits of predictability.\n\nSo yes, [Little’s Law](https://en.wikipedia.org/wiki/Little%27s_law) is always valid. But applying it usefully requires more than a theoretical understanding. It requires operational discipline. It requires systems that dampen variability rather than amplify it.\n\nIn fact, multiple industry studies and real-world examples have consistently validated this behaviour. One case study by [Troy Magennis](https://focusedobjective.com) describes a team that introduced WIP limits and began swarming on blocked work. As a result, their 85th percentile cycle time dropped from 35 days to 14 days, even after halving the team size. Meanwhile, their throughput increased from 1.07 to 1.41 stories per day (Magennis, T., _Impact of WIP Limits on Throughput and Predictability_, 2016).\n\nAnother example comes from Ultimate Software, documented in _[Making Work Visible](https://itrevolution.com/products/making-work-visible)_[ by Dominica DeGrandis](https://itrevolution.com/products/making-work-visible), where a payroll team implemented WIP limits lower than the number of developers to force collaboration. This change led to a 69% reduction in story cycle time and a 79% reduction in average queue wait time. Their conclusion was simple: controlling WIP shortened how long work spent in the system and dramatically improved predictability.\n\nThe more work you start without finishing, the longer everything takes to get done. That delay introduces variability, and that variability is what destroys the trustworthiness of your plans.\n\nMost teams don’t lose predictability because the work is hard. They lose predictability because everything is in progress, and very little is actually flowing.\n\n## You don’t need to measure to see the damage\n\nYou don’t need metrics dashboards to identify when WIP is too high. You can see it in the way work moves ,  or doesn’t.\n\nIf you reach the middle of a sprint and everything is “in progress” but nothing has been finished, that’s a signal. If developers are working on individual items and handing them off downstream to test or review, you’re operating a batch-and-queue system, and your flow efficiency is likely sitting around 5–15%.\n\nThat means 85–95% of the total time a work item spends in the system is just waiting. And yet we still treat the active effort as the part worth optimising.\n\nThis is why “estimating better” doesn’t help. Your estimates cover the 5–15%. The problem lives in the 85–95%.\n\n## Collaboration is the early warning system\n\nIn my experience, if a team isn’t working together, in pairs, mobs, or focused swarms, WIP is already too high. The more localised the work, the more parallelisation. The more parallelisation, the more queues. And the more queues, the longer and more variable the cycle time.\n\nSolo work in a collaborative delivery system isn’t faster. It’s fragmented. And it usually results in a board full of items “almost done” by the time you hit the sprint review.\n\nThere’s a reason experinced teams limit WIP to fewer items than there are people. It forces collaboration. It surfaces blockers. It reduces context switching. And it creates the conditions where delivery actually becomes predictable.\n\n## Multitasking is just unmanaged WIP\n\nIt’s easy to hide WIP inside individual calendars. A developer working on four items in parallel is managing four invisible queues. They’ll tell you they’re “almost done” with all of them, but none of them are finished.\n\nEvery switch between tasks adds cognitive load ([Mark et al., 2005, UC Irvine](https://www.ics.uci.edu/~gmark/chi08-mark.pdf)). Studies have shown that with five parallel items, you lose up to 75% of productive time to context switching alone (Weinberg, G., _Quality Software Management: Systems Thinking_, 1992; DeMarco, T. & Lister, T., _Peopleware_, 1999).\n\nWe don’t account for this in planning. We assume that “utilised” means “productive.” It doesn’t. It means slow, error-prone, and unpredictable.\n\nSo even if each individual item is small and well-estimated, the system is still under strain. And that strain manifests as delay.\n\n## The fix isn’t effort. It’s flow.\n\nI’ve worked with teams that improved throughput and predictability without changing how they estimated, or increasing capacity, or working longer hours. They simply reduced WIP and focused on finishing.\n\nAnother example comes from a workshop documented by Julia Wester and Daniel Vacanti, where a team reduced their average cycle time by 55% over four sprints by combining visible WIP limits with service level expectations. There was no change to the work, the people, or the tooling. The only thing that changed was the system of work: work was finished before starting more, blockers were made visible, and delivery became more even. This kind of operational clarity consistently outperforms speculative estimation.\n\nThey didn’t do more work. They just stopped pretending that all the started work was progress.\n\nThe result? Less stress. Fewer surprises. And a forecast that didn’t fall apart after day two.\n\n## If you want predictability, stop flooding the system\n\nYou don’t get predictability from planning harder.\n\nYou get it from flow. You get it when work finishes at a consistent rate. You get it when the system is stable enough that estimates are actually meaningful.\n\nIf you’re struggling with predictability, don’t start with estimation. Start with WIP. Look at how many items are currently in progress. Look at how long they’ve been sitting. Look at how many are waiting on something else to move first.\n\nThen ask: what would happen if we cut our WIP in half?\n\nWhat would we have to do differently to actually finish things instead of constantly starting new ones?\n\nThat’s where predictability begins, not in a planning session, but in the shape and health of the system itself.\n\n---\n\n## References\n\n- Wester, J. & Vacanti, D. (2019). _Actionable Agile Metrics for Predictability_. Leanpub. [https://www.actionableagile.com/book](https://www.actionableagile.com/book)\n- Magennis, T. (2016). _Impact of WIP Limits on Throughput and Predictability_. Focused Objective. [https://focusedobjective.com](https://focusedobjective.com)\n- Mark, G., Gonzalez, V. M., & Harris, J. (2005). _No Task Left Behind? Examining the Nature of Fragmented Work_. UC Irvine, CHI Conference. [https://www.ics.uci.edu/\\~gmark/chi08-mark.pdf](https://www.ics.uci.edu/~gmark/chi08-mark.pdf)\n- Weinberg, G. (1992). _Quality Software Management: Systems Thinking_. Dorset House Publishing. [https://www.dorsethouse.com/books/qsmvol1.html](https://www.dorsethouse.com/books/qsmvol1.html)\n- DeMarco, T. & Lister, T. (1999). _Peopleware: Productive Projects and Teams_. Dorset House Publishing. [https://www.dorsethouse.com/books/peopleware.html](https://www.dorsethouse.com/books/peopleware.html)\n- Magennis, T. (2016). _Impact of WIP Limits on Throughput and Predictability_. [https://focusedobjective.com](https://focusedobjective.com)\n- DeGrandis, D. (2017). _Making Work Visible: Exposing Time Theft to Optimize Work & Flow_. IT Revolution Press. [https://itrevolution.com/products/making-work-visible](https://itrevolution.com/products/making-work-visible)\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-09-08-estimating-better-in-an-overloaded-system-is-a-poor-man-s-strategy\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-09-08-estimating-better-in-an-overloaded-system-is-a-poor-man-s-strategy",
    "ReferencePath": "resources/blog/2025/2025-09-08-estimating-better-in-an-overloaded-system-is-a-poor-man-s-strategy"
  },
  {
    "FrontMatter": {
      "title": "Are We Still Pretending Coding Was the Bottleneck?",
      "short_title": "Coding Was Never the Software Bottleneck",
      "description": "AI exposes that coding was never the main bottleneck in software delivery; real constraints are in system flow, team practices, and organisational culture, not code writing.",
      "date": "2025-09-01T09:00:00Z",
      "weight": 100.0,
      "ResourceId": "IO5EHjiHhTf",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "are-we-still-pretending-coding-was-the-bottleneck",
      "aliases": [
        "/resources/IO5EHjiHhTf"
      ],
      "concepts": [
        "Principle"
      ],
      "categories": [
        "DevOps",
        "Product Development",
        "Engineering Excellence"
      ],
      "tags": [
        "Software Development",
        "Pragmatic Thinking",
        "Value Delivery",
        "Agentic Engineering",
        "Operational Practices",
        "Sociotechnical Systems",
        "Organisational Agility",
        "Organisational Physics",
        "Product Delivery",
        "Social Technologies",
        "Team Performance",
        "Flow Efficiency",
        "Technical Excellence",
        "Systems Thinking",
        "Continuous Improvement"
      ],
      "Watermarks": {
        "description": "2025-06-06T15:13:01Z",
        "short_title": "2025-07-07T16:43:06Z"
      }
    },
    "BodyContent": "AI has changed a lot of things in software development. But if you're shocked that it can write code, you’ve probably misunderstood where the real constraints are.\n\nLet’s be clear: **coding was never the bottleneck**.\n\nIf you're still organising your system of work like it is—managing capacity by developer headcount, measuring velocity in story points, handing off tickets from BA to Dev to QA—then AI isn’t going to save you. It’s going to expose you.\n\n## The First Way of DevOps Was Always the Warning\n\nThe First Way of DevOps is **Systems Thinking**. It’s the relentless focus on flow, from idea to delivery. Not just within development, but across the entire value stream.\n\nSo why is everyone panicking about code-writing agents?\n\nBecause most organisations never understood the First Way in the first place. They thought DevOps was about pipelines, YAML files, and infrastructure automation.\n\nThey forgot it was about fixing the system.\n\nAI isn’t breaking your delivery model. It’s just revealing how broken it already was.\n\n## If You Map Your Value Stream, the Bottleneck Isn't Where You Think\n\nDo the work. Map your system. What you’ll likely find is this:\n\n- Work sits in queues waiting for “clarification”\n- Teams are blocked by signoffs, dependencies, or overburdened specialists\n- Test feedback takes hours, days, or never comes at all\n- Quality is gated by QA teams, not engineered into the product\n- Your best developers are busy merging branches, not solving problems\n\nIn that mess, how is code ever the constraint?\n\n## AI Hallucination? Or Garbage In?\n\nYes, AI sometimes generates code that doesn’t compile or misbehaves. But let’s not act like human-written code is immune to those flaws.\n\nGarbage in, garbage out. If your acceptance criteria are vague, your architecture is a mess, and your quality is outsourced to downstream testers, you’re giving AI the same bad inputs that led you here in the first place.\n\nYou don’t fix that by blaming the tool. You fix that by adopting **disciplined engineering practices**:\n\n- **Test-First** development so intent is explicit\n- **Observability** built in from the start\n- **Definition of Done** that includes operational readiness\n- **Autonomous teams** accountable for outcomes, not output\n\nThe problem isn’t the LLM. The problem is the system it landed in.\n\n## QA Is Not a Team. It’s a System Responsibility.\n\nIf you still have a separate QA team running tests after “dev is done,” you are perpetuating one of the core dysfunctions that made DevOps necessary.\n\nQuality is not something you inspect in later. It’s something you **build in** from the start—with design, pairing, automation, and feedback.\n\nAI won’t fix this. But it will make it more obvious.\n\n## So How Do You Test AI-Generated Code?\n\nThe same way you should already be testing human-typed code:\n\n- Write the test before the code\n- Make quality part of the Definition of Done\n- Deploy frequently, observe outcomes, adapt fast\n\nAI doesn’t change that. It just **removes the excuse** that “we didn’t have time.”\n\n## If You're Still Blaming the Tool, You're Not Owning the System\n\nAI isn’t the enemy. Your culture is. Your delivery model is. Your lack of flow is.\n\nIf your teams can’t ship working software reliably today, AI isn’t going to help.\n\nBut if you’ve invested in autonomy, flow, and observability—if you’ve taken the First Way of DevOps seriously—then AI is a force multiplier.\n\nThe bottleneck was never the code. It was the way you worked.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-09-01-are-we-still-pretending-coding-was-the-bottleneck\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-09-01-are-we-still-pretending-coding-was-the-bottleneck",
    "ReferencePath": "resources/blog/2025/2025-09-01-are-we-still-pretending-coding-was-the-bottleneck"
  },
  {
    "FrontMatter": {
      "title": "Should You Use One Project to Rule Them All in Azure DevOps?",
      "short_title": "One Project vs Multiple in Azure DevOps",
      "description": "Explores when to use a single Azure DevOps project versus multiple projects, detailing impacts on flow, visibility, governance, and team collaboration at scale.",
      "date": "2025-08-25T09:00:00Z",
      "weight": 80.0,
      "ResourceId": "k-kqjqSgdGx",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "should-you-use-one-project-to-rule-them-all-in-azure-devops",
      "aliases": [
        "/resources/k-kqjqSgdGx"
      ],
      "concepts": [
        "Tool"
      ],
      "categories": [
        "DevOps",
        "Product Development",
        "Engineering Excellence"
      ],
      "tags": [
        "Azure DevOps",
        "Project Management",
        "Software Development",
        "Operational Practices",
        "Pragmatic Thinking",
        "Value Delivery",
        "Product Delivery",
        "Agile Planning Tools",
        "Application Lifecycle Management",
        "Scaling",
        "Large Scale Agility",
        "Agile Planning",
        "Agile Strategy",
        "Organisational Agility",
        "Team Performance"
      ],
      "Watermarks": {
        "description": "2025-06-06T12:34:49Z",
        "short_title": "2025-07-07T16:43:07Z"
      }
    },
    "BodyContent": "**Most organisations still believe that managing multiple projects means a better organisation. It doesn’t. It could just be hiding your problems or even creating them.**\n\nIf you’re still using multiple team projects in Azure DevOps to represent every application, every team, or every product, you may be paying the price in fragmentation, lost observability, and poor flow. That might have made sense in TFS 2005, but it's a liability in 2025.\n\nThe real path to high-performing teams? **One Project to rule them all**. One Azure DevOps Project, multiple teams, focused goals, observable flow. Scaled, not scattered.\n\nI have been advocating for [One Team Project to rule them all]({{< resource-ref \"8AfjJ-2eCEV\" >}}) almost from the beginning with [Project of Projects with team Foundation Server 2010]({{< resource-ref \"qiY3IH2aMYV\" >}})  and my stance has not changed, although the Azure DevOps product has a over the years.\n\n## TL;DR;&#x20;\n\nThe \"many teams and projects\" model in Azure DevOps is Microsoft’s own recommended setup—and one they use internally. It can make life easier for portfolio management and cross-team collaboration. But it comes with a price: increased complexity in setup, configuration, and ongoing maintenance. You’re trading operational simplicity for structural flexibility.\n\n> \"One project to rule them all \\[Teams] and in \\[Azure DevOps] bind them\"\n> \\- Martin Hinshelwood, 2010\n\n## When should you have multiple Projects in Azure DevOps?\n\nMicrosoft [clearly advises that projects are there to support multiple business units](https://learn.microsoft.com/en-us/azure/devops/organizations/projects/about-projects?view=azure-devops) and gives the following reasons for creating multiple projects:\n\n- Support custom work tracking processes for specific business units within your organisation\n- Support entirely separate business units that have their own administrative policies and administrators\n\nI removed three reasons they give from this list, as they are generally irrelevant for most organisations. The first was the permission boundary, which I will handle below; another was for testing customisations, and the last was for a separate public OSS project.\n\nNowhere does Microsoft, as the creator of Azure DevOps, advocate for a Project per project, initiative, or effort within your organisation.\n\n## Why Multiple Organisations and Projects Break Down at Scale\n\nIn most organisations, we aim to create cross-functional teams capable of delivering across a portfolio, at least within a defined funding stream or budgetary unit. As organisations grow, they typically segment into multiple funding streams, but decision-making around where and how to apply funding remains centralised within each unit.\n\nAzure DevOps’ organisational and project boundaries can hinder this flexibility.\n\n#### Multi-Organisation Boundaries\n\n- **P\\&L Boundary**: Separate organisations represent separate billing scopes; licensing, builds, storage.\n- **Query Boundary**: You cannot query across organisations inside the same tenant. To get a full view, you're forced into third-party tooling like Power BI.\n- **Linking Boundary**: While you can link work items across organisations (e.g., \"Consumes From\", \"Produces For\", \"Remote Related\"), these links are largely superficial. They aren't usable in Delivery Plans, Backlogs, or Boards.\n\n#### Multi-Project Boundaries\n\n- **Query Boundary**: While you can technically query across projects, you can't create a unified backlog. Planning becomes fragmented and requires external tools like Portfolio++ to stitch things together.\n- **Boards**: You cannot create a board that visualises work across multiple projects. That’s a hard platform limitation.\n- **Team Focus**: When individuals belong to multiple projects, their focus splinters. Backlogs fragment. Priorities conflict. The result? Increased wait time, context switching, and delivery delays.\n- **Security**: Permissions, policies, and groups must be duplicated and managed separately across projects. That’s more overhead and more risk.\n- **Shared Assets**: Test cases, source, pipelines, environments—these are far harder to reuse or coordinate across projects.\n\nEvery additional Organisation and Project adds friction that Azure DevOps is not designed to resolve. These aren’t flexible abstractions; they are hard boundaries and are by design.\n\n&#x20;None of these constraints provides anything that a single project and a sane Area Path strategy couldn’t already achieve, with less overhead and more coherence.\n\n## Should you have many projects?\n\nHere is a summary of the three options:\n\n- **One project, many teams** - If your teams are aligned, your backlog is coherent, and you're operating within a single organisation, then one project is the sweet spot. You get unified governance, consistent processes, and minimal admin overhead. Each team can tailor their boards and iterations while still feeding into a shared backlog and reporting structure. Visibility is baked in—if someone wants to see what's happening, they can. Coordination is simpler, reuse is natural, and roll-up metrics just work. Most importantly, it reduces cognitive and operational overhead, letting teams focus on delivery, not bureaucracy.\n- **One organisation, many projects, and teams** - This model is useful when you're juggling different processes, delivery cadences, or security needs. You trade a bit of simplicity for flexibility. Each project has its own process templates, permissions, and settings, which makes sense if the work is fundamentally different, but it adds friction. Cross-team visibility suffers, reuse gets clumsy, and roll-up reporting becomes harder. You're coordinating across silos, not within a system. If you're using this model, you’ve likely optimised for isolation over collaboration. That might be intentional, but it comes at a cost.\n- **Many organisations** - Only use this if you need ironclad isolation—think separate business units, external contracts, or compliance constraints. This is the most expensive model in terms of overhead, administration, and collaboration. There’s no natural visibility across orgs, no shared queries or boards, and zero cross-org reporting. Everything has to be duplicated or integrated manually. That might be acceptable if you’re supporting legacy TFS structures or strict multitenancy, but it kills flow. If you’re working across orgs and still need to coordinate, you’re solving a problem your tooling should have prevented.\n\nI have always advocated for larger projects and use the following rule of thumb:\n\n> If you have money, people, work, or products that interact in any meaningful way, then they should really be in a single Project.\n\nLet’s not pretend this is theoretical. Microsoft’s own Developer Division (DevDiv) utilises a single Azure DevOps project to manage source code, builds, releases, test cases, and work items for over 2,000 engineers. For the Windows team at Microsoft, it's more like 15,000 people in one Project.\n\nIf that’s not proof this scales, what is?\n\n## The Strategy: One Project. Many Teams. Clear Constraints.\n\nA modern Azure DevOps project is designed to scale horizontally using **Teams**, and **Area Paths** and not by creating new team projects. This means that you need to deliberately design your strategy to avoid it becoming a total midden.\n\nInside Azure DevOps, while teams are a flat list, they are linked to Area paths, a hierarchy, to determine which work items are included in the teams view, and thus their backlogs and boards.\n\nHere’s how it works.\n\n> [!WARNING]\n> This is going to get confusing since \"Team\" can mean \"team of people\" or the Azure DevOps construct of \"Team\". Im going to try and explicetly say \"Azure DevOps Team\" to refer to the construct and \"team\" to refer to a group of people. These people could be a \"portfolio team\", \"feature team\", or \"delivery team\".\n\n### 1. **Use Area Paths to Represent Departments and Products**\n\nYour Area Path hierarchy is the backbone of visibility, governance, and scale. Treat it as a map of how your products are delivered—not how your org chart looks. It should reflect the product structure and value streams, not departmental politics.\n\nCreate a distinct leaf node for every delivery team. This gives you fine-grained control for permissions, test plan isolation, dashboard targeting, and scoped visibility. Intermediate levels should reflect coherent product or platform groupings, enabling roll-up views without breaking team autonomy.\n\n```\nMyProject\n ├── Product A\n │    ├── Team 1\n │    └── Team 2\n ├── Product B\n │    ├── Team X\n │    └── Team Y\n └── Platform\n      └── Shared Services Team\n```\n\nIf your hierarchy matches your architecture and delivery teams, you unlock real traceability. If it mirrors your reporting lines, you’ll spend your time fighting visibility gaps and access problems.\n\n> [!TIP]\n> Use Area Paths deliberately. They are your primary tool for scoping permissions, isolating test plans, assigning build policies, and targeting dashboards. Keep them stable. Don’t reorganise on a whim.\n\n### 2. Define Azure DevOps Teams with Clear Area Path Ownership\n\nEach Azure DevOps Team is a lens into a defined slice of the Area Path hierarchy. That lens determines what work shows up on its backlog, board, and delivery plans. Clear, non-overlapping ownership is essential if you want visibility without duplication, focus without conflict.\n\nThe key? Design the Area Path hierarchy with intent, then map each team to a specific leaf node. Use the “include sub-areas” option carefully. Avoid overlap. One work item, one team board.\n\n- Want a unified **Platform view**? Create an Azure DevOps Team at the higher-level node and include all sub-areas.\n- Need a **delivery team focus**? Map them to their own leaf node and exclude others.\n- Building a **Portfolio Kanban**? Use higher-level Areas with Epics and Features only—leave Backlog Items to delivery teams.\n\n> [!TIP]\n> A work item should never appear on two boards. If it does, your setup will confuse stakeholders and erode trust.\n\nHere’s a common, pragmatic split:\n\n- **Feature team Boards**: Configure to show Backlog Items only.\n- **Portfolio Boards**: Configure to show Epics and Features only, with “include sub-areas” on.\n\nThis setup enables delivery teams to focus on tactical work, while leadership tracks strategic progress—all in the same project, without duplication.\n\n### 3. **Use Iteration Paths for Cadence, Not Structure**\n\nKeep Iteration Paths consistent across teams where possible. This enables consolidated reporting and facilitates shared understanding of delivery cycles.\n\n> [!WARNING]\n> When teams have different cadences within the same funding structure, it can cause friction and delays.&#x20;\n\nWhen Team A says that the work will be done by Sprint 23, what does that mean? If Team B is on a different candidate, then this could be their Sprint 45, or the Shared Platform Teams Sprint 3.  A balance of autonomy and alignment is important when lots of folks are working together in the same value stream.\n\n> [!TIP]\n> Choose a cadence for review and delivery that aligns with the business needs, stakeholder engagement cadence, and the effective planning horizon. Regardless of the delivery team's chosen process, everyone inspects and adapts at least on that cadence.\n\nIf you must deviate (e.g. teams with different Sprint lengths), isolate only the differing branches.\n\n### 4. **Secure by Area, Not by Project**\n\nOne of the most common justifications for multiple team projects is “security.” But Azure DevOps already supports:\n\n- **Granular permissions on Area Paths**\n- **Repos permissions**\n- **Pipeline-level permissioning**\n- **Environment and Library security for deployments**\n\nYou can grant fine-grained access control to individual teams, stakeholders, or systems without fragmenting your project into unmanageable silos.\n\n> [!TIP]\n> Use Azure DevOps Groups that contain Enta ID groups to maintain flexability and clarity\n\n## What About Reporting?\n\nIf you're using one Azure DevOps project with clearly defined Area Paths and Teams, reporting becomes dramatically simpler, more powerful, and more honest.\n\nEverything you need is in one place: Work Items, Repos, Pipelines, Releases, Test Plans. That means dashboards, boards, analytics views, and Delivery Plans just work—with no duct tape, no spreadsheet exports, no cross-project hacks.\n\n- Use **Dashboards** for high-level visibility tailored to stakeholders.\n- Use **Delivery Plans** for planning across multiple teams and value streams.\n- Use **Portfolio Backlogs** to track progress across Features, Epics, and Initiatives without duplicating work.\n- Use **Analytics Views** and **Power BI** to correlate flow, throughput, and cycle times across teams, products, and time.\n\nAnd when you need more:\n\n- **Portfolio++** provides rich roadmap and status visualisations that work across queries, teams, and even projects.\n- **ActionableAgile** brings deep flow metrics—cycle time scatterplots, throughput charts, WIP ageing—directly into your Azure DevOps instance.\n\n> [!TIP]\n> Reporting doesn’t just inform—it aligns. A unified project gives you shared truth. Every extra project boundary erodes that.\n\n## Final Word: Optimise for Flow, Not Structure\n\nAzure DevOps isn’t just tooling; it reflects how your organisation thinks about delivery. If you design for control, you’ll get silos. If you design for flow, you’ll get visibility, alignment, and adaptability. Its an intrinsic part of your systems of work.\n\nEvery new project boundary introduces delay, friction, and duplication. Every extra organisational boundary kills collaboration and wrecks observability. You don’t need more buckets. You need better boundaries inside one.\n\nDesign your system of work to reflect how you deliver value, not how your teams report. Use one project. Use Area Paths and Teams to model structure and scale. Secure it properly. Report from it meaningfully. And let your delivery system evolve with clarity, not chaos.\n\n**Don’t build around exceptions. Build for flow.**\n\nOne Project. Many teams. Clear constraints. Value, continuously delivered.\n\n### Definitions\n\nIt's clear that everyone refers to things within Azure DevOps differently, and naming is not Microsoft's strong suit. Here is what I mean when I use terminology in this post:\n\n- **Tennant -** Not really within Azure DevOps, but intrinsically linked is the Microsoft Entra ID tenant that provides the security with Users and Groups.\n- **Organisation** - The big bucket of stuff and the almost absolute boundary for Azure DevOps. For argument's sake, it's a \"database\" with unique IDs and clear boundaries. Also known as \"Collection\" in Team Foundation Server (TFS).\n- **Process** - The definition of the types and workflows of those types as well as the available backlog levels. Previously known as \"Process Template\".\n- **Project** - The first level bucket after Organisation that provides a security and feature boundary. Used to be called \"Team Project\".\n- **Value Board** - visualisation of the flow of value at a particular backlog level. This is just called \"Board\" in Azure DevOps, but I wanted to make my distinction clearer.\n- **Task Board** - visualisation of tasks within value represented as value pinned to the left, and sub-tasks flow across the board.\n\n## References\n\n- [About projects and scaling your organization - Azure DevOps | Microsoft Learn](https://learn.microsoft.com/en-us/azure/devops/organizations/projects/about-projects?view=azure-devops)\n- [Scaling Agile to large teams - Azure DevOps | Microsoft Learn](https://learn.microsoft.com/en-us/devops/plan/scaling-agile)\n- [Plan your organizational structure - Azure DevOps | Microsoft Learn](https://learn.microsoft.com/en-us/azure/devops/user-guide/plan-your-azure-devops-org-structure?view=azure-devops#how-many-projects-do-you-need)\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-08-25-should-you-use-one-project-to-rule-them-all-in-azure-devops\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-08-25-should-you-use-one-project-to-rule-them-all-in-azure-devops",
    "ReferencePath": "resources/blog/2025/2025-08-25-should-you-use-one-project-to-rule-them-all-in-azure-devops"
  },
  {
    "FrontMatter": {
      "title": "Getting Started with Objectives & Key Results",
      "short_title": "Getting Started with Objectives & Key Results",
      "description": "Learn how to successfully implement OKRs by aligning clear strategy, fostering transparency, empowering teams, focusing on outcomes, and establishing iterative execution practices.",
      "date": "2025-08-18T09:00:00Z",
      "weight": 490.0,
      "ResourceId": "bpRR4ieKvr3",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "getting-started-with-objectives-key-results",
      "aliases": [
        "/resources/bpRR4ieKvr3"
      ],
      "concepts": [
        "Strategy"
      ],
      "categories": [
        "Product Development",
        "Product Management",
        "Leadership"
      ],
      "tags": [
        "Objective Key Results",
        "Common Goals",
        "Strategic Goals",
        "Agile Strategy",
        "Organisational Agility",
        "Product Strategy",
        "Continuous Improvement",
        "Empirical Process Control",
        "Organisational Change",
        "Value Delivery",
        "Organisational Culture",
        "Pragmatic Thinking",
        "Social Technologies",
        "Metrics and Learning",
        "Enterprise Agility"
      ],
      "Watermarks": {
        "description": "2025-06-03T15:33:08Z",
        "short_title": "2025-07-07T16:43:08Z"
      },
      "mermaid": true
    },
    "BodyContent": "OKRs are not plug-and-play. They’re not a magic framework you sprinkle on top of chaos and suddenly get strategy, alignment, and velocity. They are a **discipline**. A **set of practices**. And they only work when the foundations are in place.\n\nSo what do you need?\n\n## 1. A Clear Strategy\n\nI've worked at a few customers that have tried, unsuccessfully, to implement OKR, and every time it comes down to a lack of leadership in defining and communicating clear strategies that everyone can understand.\n\n> “Is there a product charter that lays out the mission and strategic goals? Do all members of the team understand both, and are they able to see how their work contributes to both?”\n> — DIB: Detecting Agile BS\n\nStrategy should drive execution. If you don’t know where you’re trying to go over the next 1 to 5 years, OKRs won’t help. They’ll float. They’ll drift. They’ll get turned into a quarterly to-do list that looks busy but delivers nothing that matters. Worse, they can just become a work breakdown structure and a disaster waiting to happen.\n\n## 2. A Culture That Embraces Transparency, Inspection, and Adaptation\n\nOKRs will fail if your organisation tries to turn plans into contracts, hide things it does not like, or resist feedback. We need to be open by default. We need to welcome inspection and are willing to adapt.\n\nChange is something to be expected and the norm rather than the exception. This is about building systems where learning is baked into the way that we do things. Agile, Scrum, and DevOps all share the same fundamental requirement for success. If you are failing at them, then OKRs will not solve any problems. You need to look in the mirror and deal with what's there first.\n\nOKRs surface misalignment; they are as much like a mirror as Scrum is. They expose a vague strategy and an incoherent execution. But they only help if people feel safe to inspect and adapt. Without that culture, OKRs become fear-driven, and the outcomes become distorted.\n\n## 3. Team Agency\n\nOKRs only work if the people doing the work have the **agency** to shape how they deliver outcomes. If you’re still managing with command-and-control, resource allocation, individual performance metrics, centralised plans, and siloed functions—admit it. You don’t want agility. You want a Gantt chart and a work breakdown structure. You’ll never unlock the creativity and accountability that OKRs demand.\n\n> \"Are teams empowered to change the requirements based on user feedback?\"\n> \"Are teams empowered to change their process based on what they learn?\"\n> — DIB: Detecting Agile BS\n\nOKRs work best when teams self-manage against shared constraints. This requires clarity on purpose, context for decision-making, and boundaries that support autonomy rather than inhibit it.\n\n## 4. A Belief That Outcomes Matter More Than Output\n\nOKRs are fundamentally about **outcomes**. Not effort. Not headcount. Not feature delivery. If your leaders still reward activity over impact, OKRs will feel performative and punitive.\n\nYou have to believe that **measurable, meaningful change** is the point. Everything else is just activity.\n\nShifting to an outcome mindset means asking better questions:\n\n- What behaviour are we trying to change?\n- What evidence will show we’re making progress?\n- How can we empower teams to find better ways to achieve the outcomes?\n\nWithout this mindset, OKRs will get gamed, ignored, or weaponised.\n\n## The OKR Structure\n\nOKRs exist to translate strategy into action. That’s it.\n\n- **Objectives** clarify where you’re going.\n- **Key Results** define what success looks like.\n- **Execution** is how you actually move toward it.\n\nA simple, powerful format:\n**“I will \\[Objective] as measured by \\[this set of Key Results].”**\n\nThis structure gives you clarity, focus, and alignment. And when used well, it drives the shift from output to outcome.\n\nToo often, organisations obsess over the Objective and treat the Key Results as a laundry list. That’s a mistake. It’s the Key Results that create leverage. They force clarity. They reveal intent. They make progress inspectable.\n\n### Why Do We Need Objectives?\n\nObjectives provide direction in the chaos and reconnect execution to strategy. Without them, you’re just busy. And busy doesn’t mean valuable. We just have output.\n\nThe purpose of objectives is to:\n\n- It forces you to focus. Limit the number. Ruthlessly.\n- Connect directly to your strategic goals.\n- Give teams something meaningful to rally around.\n- Shift the conversation from “what are we doing?” to “why does it matter?”\n\nThe objectives help us resolve the goals from Scrum or Evidence-based management and can create the intent from intent-based leadership. They make the strategy visible and the contribution clear.\n\nA well-written objective is outcome-oriented and time-bound. Not vague. Not incremental. And never written as “continue doing X.”\n\n### Why Do We Need Key Results?\n\nKey Results aren’t just metrics. They’re commitments.\n\nThey:\n\n- Push teams to define **what success looks like**\n- Enable autonomy by giving teams room to decide **how** to achieve it\n- Anchor discussions in data, not opinions\n- Help leaders focus on enablement, not interference\n\nKey Results aren’t there to punish failure. They’re there to surface learning. If you hit 100% of your Key Results every time, your goals were too easy.\n\nThat’s not success. That’s sandbagging.\n\n### Execution Isn’t Optional\n\nOKRs aren’t a quarterly workshop. They live and die in the execution. If you’re not inspecting progress weekly or biweekly, they will drift. Strategic priorities will get lost in the noise of delivery.\n\nYou need a cadence. A rhythm. A system for:\n\n- Reviewing progress\n- Re-aligning focus\n- Adapting based on learning\n\nAdditionally, reassess your OKRs at least every quarter. But don’t wait until the end to find out if they mattered. The feedback loop is the heartbeat of OKRs. Without it, they become theatre. With it, they become a mechanism for continuous adaptation.\n\n## OKRs are iterative and outcomes incremental\n\nYou won’t get it right the first time. Or the second. Or the third. You’ll write vague Objectives. You’ll write vanity Key Results. You’ll set goals that are either too big or too small.\n\nThat’s fine.\n\nOKRs are a **practice**. You refine them over time. The point isn’t perfection. The point is progress. Use a retrospective on your OKRs and refactor your goals. Treat them as living artefacts. That’s how you get better.\n\n{{< mermaid width=\"400px\" >}}\nflowchart TD\nVMV[\"Vision, Mission, Values\\n(5 to 20 years)\"]\nSTR[\"Strategies\\n(1 to 5 years)\"]\nOBJ[\"Objectives\\n(Quarterly to Yearly)\"]\nKR[\"Key Results\\n(Quarterly to Yearly)\"]\nACT[\"Activities (Execution)\\n(Day to Day)\"]\nMEA[\"Measure\\n(Day to Day)\"]\nLEA[\"Learn\\n(Weekly to Quarterly)\"]\n\n    VMV --> STR\n    STR --> OBJ\n    OBJ --> KR\n    KR --> ACT\n    ACT --> MEA\n    MEA --> LEA\n    LEA --> STR\n\n    classDef yellow fill:#f9c74f,stroke:#333,stroke-width:1px;\n    classDef green fill:#90be6d,stroke:#333,stroke-width:1px;\n    classDef blue fill:#43aa8b,stroke:#333,stroke-width:1px;\n    class OBJ yellow\n    class KR green\n    class ACT,MEA,LEA blue\n\n{{< /mermaid >}}\n\nThis is what OKRs make possible: a living connection from strategy to execution, and back again. This is the cadence that drives organisational agility. This is why OKRs matter.\n\nIf you're struggling to make OKRs stick, don't blame the tool. Inspect your system. Look at your strategy. Look at your culture. Look at your cadence.\n\nBecause you can’t shortcut clarity. You can only create the conditions for it to emerge.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-08-18-getting-strted-with-okr\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-08-18-getting-strted-with-okr",
    "ReferencePath": "resources/blog/2025/2025-08-18-getting-strted-with-okr"
  },
  {
    "FrontMatter": {
      "title": "Is Agile Really Just a Mindset?",
      "short_title": "Agile as a Delivery Discipline, Not Mindset",
      "description": "Explores Agile as a disciplined system of delivery, emphasizing engineering excellence, CI/CD, observability, and system design over mindset or behaviour alone.",
      "date": "2025-08-11T09:00:00Z",
      "weight": 60.0,
      "contributors": [
        {
          "name": "Rikard Skelander",
          "external": "https://www.linkedin.com/in/rikardskelander/"
        }
      ],
      "ResourceId": "ABbVdMBZ5fI",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "is-agile-really-just-a-mindset",
      "aliases": [
        "/resources/ABbVdMBZ5fI"
      ],
      "concepts": [
        "Capability"
      ],
      "categories": [
        "Engineering Excellence",
        "Product Development",
        "Technical Leadership"
      ],
      "tags": [
        "Product Delivery",
        "Value Delivery",
        "Software Development",
        "Operational Practices",
        "Technical Mastery",
        "Pragmatic Thinking",
        "Team Performance",
        "Engineering Practices",
        "Technical Excellence",
        "Market Adaptability",
        "Agile Transformation",
        "Sociotechnical Systems",
        "Frequent Releases",
        "Organisational Agility",
        "Working Software"
      ],
      "Watermarks": {
        "description": "2025-05-30T15:27:52Z",
        "short_title": "2025-07-07T16:43:10Z"
      },
      "creator": "Martin Hinshelwood"
    },
    "BodyContent": "Let’s get one thing straight: **Agile is not a mindset.** And it’s certainly not just about behaviour. That lazy framing dilutes the discipline, ignores the engineering reality, and gives cover to incompetence.\n\nAgile for software development is a **delivery discipline grounded in technical leadership, empirical control, and engineering excellence**. If your so-called “Agile transformation” doesn’t touch your code, your infrastructure, your deployment pipelines, or your product strategy, then you’re not Agile, you’re just busy.\n\n## Agile Isn’t a Mindset. It’s a System of Work.\n\nThe term “Agile mindset” has become a smoke screen for vague, feel-good language that conveniently ignores the hard parts: architecture, observability, checkability, and releasability. A mindset doesn’t ship working software. A system does.\n\nAgile is a **strategy for managing complexity**. It draws on an **empirical ethos** to deal with uncertainty. While Agile principles support this ethos through practices like continuous delivery, frequent reflection, and embracing change, they stop short of formalising it. Agile leaves room for interpretation, which is both its power and its weakness.\n\nInstead of prescription, Agile encourages conditions that make learning and adaptation possible:\n\n- Deliver working software frequently.\n- Reflect regularly on how to become more effective.\n- Embrace change—even late in development.\n\nThis isn’t methodology. It’s operational discipline.\n\n## Behaviour Is Necessary, but Not Sufficient\n\nYes, agility requires certain behaviours: collaboration, openness to change, and continuous learning. But those behaviours are not the whole picture. They’re the byproducts of **well-designed systems**, not the system itself.\n\nIf you want teams to behave “agile,” you need to:\n\n- Give them working CI/CD pipelines.\n- Define a clear and realistic shared quality standard.\n- Stop flooding them with WIP and start managing flow.\n- Align work to meaningful goals with clear delivery expectations.\n- Enable them to ship to production regularly and reliably.\n\n**Without engineering and system design, Agile behaviours collapse under pressure.**\n\n## Engineering Practices Are the Backbone of Agility\n\nAgile without engineering is theatre. You might have sticky notes and daily standups, but if you can’t deliver reliable, high-quality software frequently, you're not Agile.\n\nHere’s what engineering excellence looks like in Agile:\n\n- **Continuous Integration & Deployment (CI/CD)**: Small, safe, frequent releases.\n- **Automated Checking**: Fast, repeatable validation that gives developers confidence.\n- **Infrastructure as Code**: Reproducible environments with version control.\n- **Telemetry and Observability**: Insight into live systems for fast feedback and debugging.\n- **Design for Replaceability**: Modular, cohesive systems you can change without fear.\n\nThese are not “nice-to-haves.” They are foundational. If your teams can’t ship to production at regular, sustainable intervals, you’re not Agile—you’re just going through the motions.\n\n## Stop Outsourcing Agile to Coaches Who Don’t Code\n\nA big part of the problem is that we’ve allowed Agile to be colonised by people with no engineering background. They talk about collaboration, but not architecture. They push for psychological safety, but ignore version control hygiene. They love retrospectives but can’t read a cycle time chart.\n\nThis isn’t a personal attack. It’s a **call for accountability**.\n\nIf you're coaching Agile teams and you don’t understand modern engineering practices—DevOps, CI/CD, telemetry, checkability, you’re not equipped to lead agility in software.\n\nAgile is not a therapy session. It’s not a motivational poster. It is a **system of delivery** designed to maximise value under conditions of uncertainty. And if we want to keep calling it that, we’d better start treating it with the rigour it deserves.\n\n## \"A bad system will beat a good person every time.\"\n\nDeming’s insight isn’t a philosophical quip—it’s a brutal truth. In Agile environments, we often celebrate the heroics of individuals, when we should be interrogating the design of the system. Good people trapped in bad systems burn out, give up, or conform.\n\nThis is where **Larman’s Law** comes in: _“Organisations are implicitly optimised to avoid changing the status quo middle-management and specialist roles, power structures and political boundaries.”_ It explains why many Agile initiatives fail. Not because people resist Agile—but because the system resists accountability.\n\nAgile invites change, but organisations repel it. Instead of redesigning systems of work, they repurpose Agile into just another management fad. Sticky notes go up. Certifications get handed out. But the constraints, silos, and dysfunction remain untouched.\n\nIf your structure still depends on project gates, command hierarchies, and stage approvals, you haven’t adopted Agile. You’ve institutionalised waste.\n\n**Systems produce outcomes. Not individuals.**\n\nWant to see agility? Look at the architecture. Look at how teams form, flow, and deliver. Look at what the system makes _easy_ and what it makes _hard_. If it’s easier to follow process than to deliver value, your system is broken—no matter how agile your people are.\n\n## Finally\n\nLet’s kill the myth:\n\n- Agile is **not a mindset**. It is a discipline.\n- Agile is **not only about behaviour**. It’s about delivery.\n- Agile is **not a feeling**. It’s a feedback-driven engineering strategy.\n\n**Agile is the deliberate design of systems that enable autonomy, accountability, and continuous delivery of value.**\n\nIf you’re not delivering, you’re not Agile. Period.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-08-11-is-agile-really-just-a-mindset\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-08-11-is-agile-really-just-a-mindset",
    "ReferencePath": "resources/blog/2025/2025-08-11-is-agile-really-just-a-mindset"
  },
  {
    "FrontMatter": {
      "title": "Telling People What to Do Is Not Leadership. It’s a Failure of System Design.",
      "short_title": "Leadership Is System Design, Not Command",
      "description": "Explores why real leadership means designing systems that enable team autonomy, flow, and accountability—rather than relying on command-and-control management.",
      "date": "2025-08-04T09:00:00Z",
      "weight": 30.0,
      "contributors": [
        {
          "name": "Brett Maytom",
          "external": "https://www.linkedin.com/in/scrum-trainer/"
        },
        {
          "name": "Alex Brown",
          "external": "https://www.linkedin.com/in/alexbrown/"
        },
        {
          "name": "Alessandro Recca",
          "external": "https://www.linkedin.com/in/alessandro-recca-b9974a21a/"
        }
      ],
      "ResourceId": "W_KrTupmowf",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "telling-people-what-to-do-is-not-leadership-it-s-a-failure-of-system-design",
      "aliases": [
        "/resources/blog/telling-people-what-to-do-is-not-leadership.-it-s-a-failure-of-system-design.",
        "/resources/W_KrTupmowf"
      ],
      "aliasesArchive": [
        "/resources/blog/telling-people-what-to-do-is-not-leadership.-it-s-a-failure-of-system-design."
      ],
      "concepts": [
        "Principle"
      ],
      "categories": [
        "Product Development",
        "Engineering Excellence",
        "Leadership"
      ],
      "tags": [
        "Agentic Engineering",
        "Lean Principles",
        "Operational Practices",
        "Self Organisation",
        "Software Development",
        "Team Performance",
        "Agile Planning",
        "Agile Product Management",
        "Empirical Process Control",
        "Organisational Agility",
        "Pragmatic Thinking",
        "Product Delivery",
        "Agile Leadership",
        "Agile Strategy",
        "Agile Transformation"
      ],
      "Watermarks": {
        "description": "2025-05-19T07:28:14Z",
        "short_title": "2025-07-07T16:43:11Z"
      },
      "creator": "Martin Hinshelwood"
    },
    "BodyContent": "If your organisation still measures leadership by how many decisions a manager makes, you are not leading. You are leaking value.\n\nThere is a stubborn, Taylorist holdover in many companies—the belief that work gets done when someone is told exactly what to do. The assumption is that certainty comes from control, clarity comes from instruction, and delivery comes from compliance.\n\nIt doesn’t.\n\nIn complex systems, command-and-control is not just ineffective—it’s a bottleneck. The moment you start “assigning tasks,” you’ve already failed to design a system that enables flow, autonomy, and accountability.\n\n## You Don’t Need to Tell People What to Do in a Well-Designed System\n\nIn organisations grounded in empirical process control, leadership isn’t about orchestrating every move. It’s about creating the conditions where teams can inspect, adapt, and deliver value continuously.\n\nModern management is not about allocating tasks. It’s about removing the need for anyone to allocate tasks in the first place.\n\nWhen teams are working against clear goals, with shared understanding, visibility of work-in-progress, and constraints that enable—not restrict—decision-making, they don’t need instructions. They need clarity, context, and trust.\n\nGreat systems aren’t static. They evolve through structured feedback loops—Sprint Reviews, Retrospectives, operational telemetry, and small experiments. Inspection and adaptation are what make systems empirical, not just idealistic.\n\n## Taylorism Is for Factories. You Run a Cognitive Organisation.\n\nIf you’re still managing by job title, project plans, and hour-counting, you’re not running a professional organisation. You’re running a factory LARP. The playbook you’re using was written for physical labour and linear processes. Not software. Not services. Not strategy.\n\nAnd yet, I still see it everywhere:\n\n- Product Managers dictating solutions instead of problems.\n- “Team leads” reviewing every commit instead of enabling continuous integration.\n- Managers handing out tasks like Halloween sweets and then wondering why delivery is unpredictable.\n\nYou don’t need more control. You need a better system.\n\n## Leadership Is Creating Systems That Don’t Need You\n\nReal leadership isn’t about your presence. It’s about what happens in your absence.\n\nThis is the ethos behind Scrum, Kanban, and DevOps:\n\n- **Scrum** gives you a social technology for solving complex problems adaptively.\n- **Kanban** gives you observability of the value stream and how work flows—or doesn’t.\n- **DevOps** ensures the loop from idea to value is short, safe, and inspectable.\n\nTogether, they form a coherent strategy for managing systems of work without resorting to micromanagement. When teams understand their constraints, have the tools to respond to change, and are accountable for outcomes, not just activity, they no longer need to be told what to do.\n\nSpeed is not the goal, but it is a critical capability. In a competitive environment, reducing time-to-market isn’t just about efficiency—it’s how organisations learn faster, respond sooner, and stay ahead of disruption. For a deeper dive into why frequent delivery is a competitive advantage, read [There Is No Place Like Production]({{< ref \"/resources/blog/2020/2020-12-28-there-is-no-place-like-production\" >}}).\n\n## Telling People What to Do is an Expensive Workaround\n\nEvery time you assign a task manually, you’re compensating for a failure upstream:\n\n- Lack of a clear Product Goal.\n- Incomplete or incoherent Backlog.\n- Pushing work into the system until it overloads\n- No service-level expectations.\n- No WIP limits.\n- No autonomy in the team.\n\nYou’re treating the symptom instead of fixing the system.\n\nAnd let’s be honest—if you have to tell people what to do, why did you hire professionals?\n\n## Design the System. Get Out of the Way.\n\nIf your team is waiting for instructions, your system has no intelligence. If you’re managing to utilisation, your system has no flow. If your engineers are busy but not delivering, your system has no value.\n\nStop focusing on the people. Start focusing on the system.\n\nScrum is not about rituals. DevOps is not about pipelines. These are practices that expose the health of your system. And if your system requires constant intervention, it’s not a system. It’s a mess.\n\nSo stop telling people what to do. Instead, design a system where people know what to do—and have the freedom, clarity, and support to do it. Here are 10 things that you can do to augment your system:\n\n### 1. **Establish Intermediate & Tactical Goals**\n\nWithout goals, people default to following orders or invent their own. Goals create the shared context necessary for autonomous decision-making and are the foundation for meaningful self-management.\n\n- **Action:** Define a clear Intermediate Goal (Product Goal) that articulates a compelling direction over multiple deliveries, and Tactical Goals (Sprint Goals) for each delivery that anchor short-term decisions in purpose.\n\n- **How**: Use Sprint Planning to make the Sprint Goal explicit and transparent. Ensure the Product Goal is visible in the content and context of the Product Backlog and re-validated during each Sprint Review. Use our [Sprint Planning Recipe]({{< ref \"/resources/recipes/sprint-planning-recipe\" >}}) to get started and then adapt it as needed. Write Sprint Goals as meaningful, outcome-focused objectives that can be met incrementally. If every Sprint ends with \"we worked on some tickets,\" then your Product Goal is either missing, or worse, meaningless.\n\n* **Why**: Without shared goals, teams wait for direction. With them, they can negotiate scope, prioritise wisely, and confidently navigate complexity. For more depth read: [The Goal – Eliyahu M. Goldratt & Jeff Cox](https://a.co/d/aZwT7jy), [Measure What Matters – John Doerr](https://a.co/d/jbqOFcX), [Evidence-based Management Guide]({{< ref \"/resources/guides/evidence-based-management-guide\" >}})\n\nToo often, the [Product Backlog]({{< ref \"/tags/product-backlog\" >}}) becomes a list of features instead of a narrative arc that advances a meaningful goal. When you write backlog items without a Product Goal, you are setting the team up to deliver outputs instead of outcomes.\n\nProduct Goals are not aspirational fluff. They are intermediate strategic goals that define value in a complex system. When absent, the result is drift. When present, they unlock focus, flow, and accountability.\n\n### 2. **Enable Self-Management with Constraints**\n\nAgency without boundaries is chaos. But command-and-control masquerading as clarity is just as destructive. Real autonomy comes from deliberate constraints that define how freedom is expressed, not whether it exists.\n\n- **Action**: Clarify and operationalise constraints through an explicit Definition of Workflow, and clear organisational boundaries of responsibility and accountability.\n- **How**: Codify these boundaries collaboratively with the team; it's their workflow. Then, create a Definition of Workflow that defines the way that work flows through their system. Don't worry about every edge case; create based on the common case of work. This DoW forms part of your Use Working Agreements that express how the team will self-manage within organisational expectations.\n- **Why**: Teams can’t be accountable for outcomes if they’re not authorised to choose how they deliver. But without boundaries, chaos replaces clarity. Autonomy is not abdication—it’s engineered through deliberate, negotiated constraints.\n\nProfessionalism is rooted in clear, shared expectations, delivered through disapline. A team that understands how work flows, where decisions are made, and what quality signals readiness at each stage doesn't need micromanagement—they already operate within a system that tells them what excellence looks like.\n\n### 3. **Stop Misusing Estimation, Start Right-Sizing**\n\nTelling people what to build, in what order, and how long it should take kills creativity and accountability. It fragments ownership and encourages compliance over curiosity. Worse, it masks the real problem: your system doesn't support flow, so you fall back to control.\n\n- **Action**: Move away from abstract estimation rituals and fixed task assignments. Instead, introduce right-sizing practices—splitting work based on historical flow metrics like cycle time and throughput and Scatter Plot analysis.\n- **How**: As a team, regularly review a scatter plot of your cycle times and investigate outliers to deepen your understanding of what 'small enough' looks like. Use that insight to reduce batch sizes where possible and provide stakeholder clarity where constraints exist. Visualise blocked or ageing work daily to keep flow visible, and use backlog refinement to slice work for predictability, not precision.&#x20;\n- **Why**: The issue isn't estimation itself—it's turning estimation into something it was never meant to be. Right-sizing is still estimation, just done in a simpler and more honest way. When teams right-size work to match their flow and capacity, they ship more consistently, adapt faster, and own their commitments.\n\nTraditional estimation is often misused as a proxy for distrust or certainty in uncertain domains. When you right-size instead—grounding delivery in data and observability—you shift from permission-based planning to capability-based planning. That's not just more efficient. It's fundamentally more respectful of the people doing the work.\n\n### 4. **Introduce Pull Systems with WIP Limits**\n\nIntroducing a work-limited pull system is key to [understanding capacity and planning for a successful delivery]({{< nkdref \"/resources/blog/2025/2025-07-21-rethinking-capacity-planning\" >}}). Push systems undermine accountability, responsibility, and ownership by enforcing direction from above. When teams have work pushed onto them without control or influence over the timing or readiness, their sense of ownership evaporates. This loss of autonomy directly stifles self-organisation and self-management, leaving teams disempowered and reactive.\n\nPush systems flood teams, forcing them into reactive firefighting and constant context-switching. The focus becomes merely \"showing progress\" rather than genuinely delivering value. This model not only overwhelms teams but also actively erodes their ability to take responsibility for outcomes, as decisions are stripped away from those who do the work.\n\nIn contrast, pull systems enhance accountability and ownership by starting with readiness. Teams pull work into their systems only when they have the capacity, when tasks are right-sized, and when the system is genuinely ready to support the flow of work.\n\n- **Action**: Implement explicit WIP limits and establish pull-based workflows at strategic, product, and team levels. Start with clear team-level WIP limits and a robust Definition of Workflow to outline readiness. Expand this discipline to portfolio and category levels, ensuring system-level flow is protected.\n- **How**: Regularly inspect cumulative flow diagrams, throughput run charts, and ageing WIP. Use these insights to identify bottlenecks and overloaded stages. Rising ageing WIP is your signal that the system has shifted back to push dynamics.\n- **Why**: Genuine ownership and accountability flourish when teams have autonomy over their workflow, responding to actual system conditions rather than artificial deadlines. This approach enhances predictability, reduces burnout, and creates sustainable delivery. Deadlines are met naturally as work is continuously delivered, not forced through the system.\n\nWIP limits are not about control—they are about providing meaningful feedback. They indicate when your system reaches capacity, signaling the team to focus and prioritise effectively. Pull-based systems are essential for sustainable, predictable value delivery. If your teams constantly feel overwhelmed and lack autonomy, it’s time to recognise this as a systemic issue: your organisation is pushing rather than enabling.\n\n### 5. **Use evidence-based management practices**\n\nMeasuring hours worked or tasks completed tells you nothing about whether the work mattered. Effort is not value. Activity is not improvement. Velocity is not progress.\n\n- **Action**: Replace effort-based reporting with outcome-oriented metrics. Use the four key dimensions of Evidence-Based Management, [Time to Market (TTM)]({{< ref \"/tags/time-to-market\" >}}), Current Value (CV), [Ability to Innovate (A2I)]({{< ref \"/tags/ability-to-innovate\" >}}), and Unrealised Value (UV), to inspect delivery capability and guide improvement.\n- **How**: Start simple. Use your existing delivery tools (like Azure DevOps or Jira) to extract basic data—Cycle Time, Throughput, and Lead Time. These give you data for Time to Market (TTM). For Current Value (CV), talk to customer support, review NPS data, or run basic satisfaction surveys. To identify Unrealised Value (UV), review abandoned roadmap items, market research, or competitor offerings. For Ability to Innovate (A2I), look at how often your work is blocked, how long code sits before being merged, and how frequently you ship. Use this data in Sprint Reviews and Retrospectives to track system health, not individual effort. Bring these insights into planning conversations to anchor decisions in reality, not assumptions.\n- **Why**: Teams that understand the outcomes of their work—how long it takes, how it impacts customers, what’s left unrealised, and where they’re blocked—are far more likely to own both the delivery and the improvement. If you want teams to care about the product, show them how it performs. Without evidence, we fall back to opinion, status, and hierarchy. With evidence, we can act with purpose.\n\nEvidence-Based Management [replaces arbitrary judgement with actionable data]({{< ref \"/resources/blog/2020/2020-12-30-evidence-based-management-gathering-metrics\" >}}). It doesn’t just measure outcomes—it enables accountability for them.\n\n### 6. **Deploy Frequently to Production**\n\nNothing signals trust like letting teams ship. But more than that, frequent delivery to production is the fastest path to feedback, accountability, and customer impact.\n\n- **Action**: Enable teams to release a usable, production-grade increment every Sprint, including the first. This doesn’t mean a perfect product—it means a valuable step forward, hardened enough to be used.\n- **How**: Establish CI/CD pipelines with automated quality gates (unit tests, integration checks, security scanning). Use feature toggles, dark launches, and audience-based rollout to mitigate risk. Set a working agreement that “done” means releasable. If it’s not going to production, it’s not done.\n- **Why**: When teams ship regularly, feedback cycles shorten, risk is reduced, and decision latency collapses. They see real impact and adapt quickly. You stop debating hypotheticals and start responding to evidence. Most importantly, you stop managing perception and start managing product.\n\nThere’s [no place like production]({{< ref \"/resources/blog/2020/2020-12-28-there-is-no-place-like-production\" >}}). Everything else is theatre.\n\n### 7. **Invest in Professional Scrum Masters & Product Owners**\n\nMost Scrum Masters and Product Owners are either appointed without preparation or promoted into the role without development. The result? They don’t coach, guide, or lead—they coordinate. And when those roles fail to create clarity and enable delivery, managers step in to fill the vacuum with control.\n\n- **Action**: Hire or develop Scrum Masters and Product Owners who demonstrate competence across three domains: technical fluency, business acumen, and organisational change leadership.\n- **How**: Provide structured learning journeys that combine high quality training with hands-on mentorship from experienced practitioners. Assess candidates or internal staff on their ability to enable delivery systems, not just facilitate meetings or write stories. Require evidence of contribution to system improvement, cross-team alignment, and customer impact.\n- **Why**: Competent SMs and POs anchor the Scrum Team in purpose and delivery. The Scrum Master builds capability, encourages flow, and fosters empiricism, and modern engineering practices. The [Product Owner sets the tone for product leadership]({{< ref \"/resources/blog/2021/2021-05-17-hiring-a-professional-product-owner\" >}}) and modern product development practices. When these roles function well, the team no longer needs daily direction from management—because the system is aligned, and delivery is deliberate.\n\nScrum Masters are not passive facilitators. They are system stewards—accountable for enabling transparency, optimising flow, and coaching both teams and managers to operate within an empirical system. If they’re not improving the system, they’re part of the dysfunction. If you want to understand what separates a competent Scrum Master from a glorified coordinator, read [Why Most Scrum Masters Are Failing—and What They Should Know]({{< ref \"/resources/blog/2024/2024-09-05-the-incompetent-scrum-master-why-most-are-failing-and-what-they-should-know\" >}}).\n\nThe problem isn’t Scrum. The problem is that [we keep filling these roles with people who aren’t ready]({{< ref \"/resources/blog/2024/2024-09-05-the-incompetent-scrum-master-why-most-are-failing-and-what-they-should-know\" >}}) or worse never will be. Raise the bar, or get out of the way.\n\n### 8. **Collapse Siloed Structures**\n\nSeparate roles create handoffs, and [handoffs create dependency]({{< ref \"/resources/blog/2025/2025-07-07-stop-building-silos-start-building-systems\" >}}). Dependency creates delay. Delay kills flow.\n\n- **Action**: Form cross-functional, preferably longer-lived teams with full accountability for discovery, delivery, and validation.\n- **How**: Restructure teams so they include the skills necessary to take work from idea to production: business analysis, UX, engineering, QA, and operations. Co-locate (physically or virtually) these disciplines inside a single team and ensure they share the same Sprint cadence, goals, and delivery responsibility. Use the Definition of Workflow to clarify interaction points and shared responsibilities within the team and eliminate those outside it. Audit each department and reassign specialists to teams where they can contribute continuously, not sporadically.\n- **Why**: You can’t ask for autonomy while forcing work through stage-gated departments. Real teams don't wait for someone else to finish—they swarm. They co-create. They ship. When you eliminate silos, you eliminate the excuses that justify command-and-control. What’s left is a team that owns its outcomes.\n\nStructure should follow flow, not function. Organise around value creation, not roles. That’s how you collapse the gap between intent and impact.\n\n### 9. **Use Sprint Reviews for Stakeholder Alignment**\n\n[Sprint Reviews]({{< ref \"/tags/sprint-review\" >}}) aren’t demos. They’re not a PowerPoint parade or a status update. They are working sessions with stakeholders—strategic checkpoints to make decisions based on what we’ve learned.\n\n- **Action**: Use Sprint Reviews to inspect the working increment, review delivery data (T2M, CV), gather market feedback, and adapt the Product Backlog collaboratively with stakeholders present.\n- **How**: Set the expectation that each Sprint Review includes real stakeholders, not just internal roles. Open with a restatement of the Product Goal and the Sprint Goal. Show working software, not slides. Invite feedback that informs priority and scope decisions. Use evidence—customer feedback, analytics, cycle time charts—to frame the discussion. End with a shared agreement on what’s next and update the Product Backlog live.\n- **Why**: Involving stakeholders early and often surfaces assumptions, shortens feedback loops, and reduces the need for managers to chase status. It shifts product delivery from projection to inspection. When everyone sees the same data and the same increment, there’s no room for spin. There’s just the truth—and the next step.\n\n### 10. **Teach Managers to Serve Systems, Not Direct People**\n\nManagers clinging to authority are a bottleneck. They inject delay, decision paralysis, and unnecessary oversight. If you're telling people what to do every day, you're not leading—you're throttling flow.\n\n- **Action**: Shift managers away from individual oversight and toward system stewardship. Equip them to visualise flow, reduce friction, and amplify team autonomy.\n- **How**: Train managers to read and act on delivery metrics—cycle time scatterplots, cumulative flow, WIP ageing. Introduce them to the constraints that enable team performance: WIP limits, service-level expectations, clear definitions of workflow. Encourage regular system health checks—where are delays? What blockers repeat? Where are policies implicit when they should be explicit? In retrospectives, ask managers not \"who failed?\" but \"what failed in the system?\"\n- **Why**: You don’t scale impact by managing more people. You scale it by creating an environment where people don’t need to be managed. When managers see themselves as designers of flow rather than allocators of effort, the entire system becomes more resilient, more responsive, and more humane.\n\nThis isn’t about [abdicating control]({{< ref \"/resources/blog/2025/2025-06-30-human-and-ai-agency-in-adaptive-systems\" >}}). It’s about relocating it into the system where it belongs.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-08-04-telling-people-what-to-do-is-not-leadership-its-a-failure-of-system-design\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-08-04-telling-people-what-to-do-is-not-leadership-its-a-failure-of-system-design",
    "ReferencePath": "resources/blog/2025/2025-08-04-telling-people-what-to-do-is-not-leadership-its-a-failure-of-system-design"
  },
  {
    "FrontMatter": {
      "title": "The Definition of Done is a Commitment to Quality",
      "short_title": "Definition of Done as Commitment to Quality",
      "description": "Defines the Definition of Done in Scrum as a clear, shared standard for quality, ensuring increments are releasable, transparent, and continuously improved by the team.",
      "date": "2025-07-28T09:00:00Z",
      "weight": 145.0,
      "ResourceId": "TwYNSm1pZOS",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "the-definition-of-done-is-a-commitment-to-quality",
      "aliases": [
        "/resources/TwYNSm1pZOS"
      ],
      "concepts": [
        "Artifact"
      ],
      "categories": [
        "Scrum",
        "Product Development",
        "Engineering Excellence"
      ],
      "tags": [
        "Definition of Done",
        "Software Development",
        "Pragmatic Thinking",
        "Empirical Process Control",
        "Product Delivery",
        "Agile Frameworks",
        "Agile Product Management",
        "Engineering Practices",
        "Operational Practices",
        "Competence",
        "Professional Scrum",
        "Value Delivery",
        "Transparency",
        "Working Software",
        "Increment"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:48:53Z",
        "short_title": "2025-07-07T16:43:12Z"
      },
      "creator": "Martin Hinshelwood"
    },
    "BodyContent": "Every Scrum Team must explicitly define what “Done” means. Without it, you are not doing Scrum. Let’s be clear: if your product increment cannot be shipped, tested, and validated at least every 30 days, you’re missing the point. Scrum is a social technology for adaptive solutions, and the Definition of Done (DoD) is the core commitment to quality that enables reliable, transparent, and releasable increments.\n\n## How Does the Agile Manifesto Relate?\n\nWhile the Definition of Done is specific to Scrum, its essence connects directly to the values and principles of the Agile Manifesto. The manifesto doesn’t define a DoD explicitly, but it demands **working software as the primary measure of progress** and calls for **continuous attention to technical excellence and good design**. These principles implicitly require teams to set and meet clear standards of completeness and quality.\n\nIn Agile, “Done” is characterised not by formal documents or bureaucratic sign-offs but by **tangible, working outcomes**. The focus is on delivering increments of value that are potentially shippable, ensuring continuous feedback, and maintaining sustainable pace. This spirit is what Scrum formalises with its Definition of Done: an explicit, transparent commitment to what quality means, grounded in Agile’s broader ethos of delivering working software and embracing change.\n\n## Why Define Done?\n\nThe Definition of Done is not optional. It is the shared understanding that tells everyone — Developers, Product Owner, stakeholders — what quality bar each increment must meet to be considered usable, releasable, and valuable. Without it, you deliver chaos disguised as agility.\n\nIf your organisation has no defined standards, your team must create its own. But let’s be blunt: if you have multiple teams on one product, they must align on a shared Definition of Done. No excuses, no fragmentation. Without this alignment, you jeopardise integration, delivery, and the product’s reputation.\n\n> “The Definition of Done creates transparency by providing everyone a shared understanding of what work was completed as part of the Increment. If a Product Backlog item does not meet the Definition of Done, it cannot be released or even presented at the Sprint Review.”\n> — Scrum Guide 2020\n\n## Done Means Releasable\n\nDone is not about user stories, requirements, or business value. It is about whether the increment is in a state that the Product Owner can say, “Yes, let’s ship it.” No hidden work, no deferred testing, no “we’ll fix it later.”\n\nA robust Definition of Done ensures:\n\n- Transparency on what’s been completed.\n- Predictability in delivery.\n- Shared accountability for quality.\n- Protection of the product’s and organisation’s reputation.\n\n## Start with a Seed, Grow It Over Time\n\nYour DoD does not need to be perfect on day one, but you do need to start. Run a facilitated DoD workshop. Involve the Scrum Team, relevant stakeholders, and anyone representing critical gates like security, architecture, UX, and compliance. Define what “Done” looks like across four layers:\n\n1. **Organisational DoD** – minimum standards to protect reputation and compliance.\n2. **Practice DoD** – engineering or discipline-specific standards (e.g., security, performance).\n3. **Customer DoD** – any client-specific requirements.\n4. **Team DoD** – additional agreements the team needs to deliver quality.\n\nWithout this clarity, you’re not managing risk; you’re just rolling dice.\n\n## Characteristics of a Strong Definition of Done\n\n- **Short, measurable checklist** — automate verification wherever possible.\n- **Mirrors shippable** — the Product Owner should have the option to ship at the Sprint Review (if not doing continuous delivery).\n- **No further work required** — if additional work is needed, you weren’t Done.\n\nThis is not subjective. “Approved by the Product Owner” is not a DoD item. The DoD is an objective, verifiable standard.\n\n## Examples of DoD Items\n\nHere’s what good engineering practices might embed:\n\n- Code passes automated quality checks (e.g., SonarQube) with no new critical issues.\n- Unit, integration, and acceptance tests are automated and pass.\n- Security scans run in CI/CD pipelines and show no high-severity vulnerabilities.\n- Documentation is updated and linked to the increment.\n- Code reviews or pair/mob programming sessions completed.\n- Automated deployment pipelines confirm repeatable, error-free delivery.\n\n## Continuous Reflection and Improvement\n\nYour DoD is not static. You must review and improve it continuously — at least every Sprint Retrospective. When you uncover new failure points, you integrate them into your DoD.\n\nIf your increment no longer meets the quality bar, stop Sprinting. Fix the foundation first — that’s called a **Scrumble**. It’s a deliberate pause to repair quality, not a failure. Once resolved, your DoD should evolve to prevent recurrence.\n\n## Practical Steps\n\n1. **Run a DoD Workshop** — include Developers, Product Owner, stakeholders, and relevant experts.\n2. **Document and Share** — make the DoD visible, accessible, and owned by the team.\n3. **Automate** — reduce human error by automating checks wherever feasible.\n4. **Review Regularly** — build DoD reviews into retrospectives.\n\n## Final Word\n\nThe Definition of Done is not bureaucracy. It’s the backbone of your Scrum implementation. Without it, you don’t have empirical process control; you have chaos. Without it, you can’t deliver continuous value; you deliver continuous risk.\n\nProfessional Scrum Teams are accountable for quality. Own it. Define it. Evolve it.\n\n> Always ask: “Would you be happy to release this increment to production and support it? You are on call tonight.” If the answer is no, it’s not Done.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-07-28-the-definition-of-done-is-a-commitment-to-quality\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-07-28-the-definition-of-done-is-a-commitment-to-quality",
    "ReferencePath": "resources/blog/2025/2025-07-28-the-definition-of-done-is-a-commitment-to-quality"
  },
  {
    "FrontMatter": {
      "title": "Rethinking Capacity Planning",
      "short_title": "Rethinking Capacity Planning",
      "description": "Explores how effective capacity planning shifts focus from individual hours to system-level flow, using Lean and Agile principles to improve predictability and value delivery.",
      "date": "2025-07-21T09:00:00Z",
      "weight": 245.0,
      "contributors": [
        {
          "name": "Nigel Thurlow",
          "external": "https://www.linkedin.com/in/nigelthurlow/"
        },
        {
          "name": "Alex Brown",
          "external": "https://www.linkedin.com/in/alexbrown/"
        }
      ],
      "ResourceId": "AhxlPTOD1yy",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "rethinking-capacity-planning",
      "aliases": [
        "/resources/AhxlPTOD1yy"
      ],
      "concepts": [
        "Principle"
      ],
      "categories": [
        "Lean",
        "Product Development",
        "Leadership"
      ],
      "tags": [
        "Flow Efficiency",
        "Lean Principles",
        "Lean Thinking",
        "Operational Practices",
        "Continuous Improvement",
        "Lean Product Development",
        "Organisational Physics",
        "Pragmatic Thinking",
        "Throughput",
        "Value Delivery",
        "Agile Strategy",
        "Portfolio Management",
        "Product Delivery",
        "Systems Thinking",
        "Team Performance"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:48:54Z",
        "short_title": "2025-07-07T16:43:13Z"
      },
      "creator": "Martin Hinshelwood"
    },
    "BodyContent": "Capacity planning is not about filling calendars or counting resource hours. It is about flow, system constraints, and predictability. And importantly, what we are talking about here applies even within environments of strict budgets, immovable deadlines, and rigorous accountabilities. Lean approaches do not discard discipline; they reframe how we achieve predictability, accountability, and sustainable delivery by focusing on the system, not just the parts. These ideas align directly with the Scrum ethos of empirical process control and the Kanban strategy of observing and managing work-in-progress limits to enhance value delivery.\n\nToo many organisations frame capacity as “how many hours does each person have?” or “how many tasks can we assign this sprint?” They fall into the trap of breaking complex, systemic work into artificial personal quotas, focusing on individual loading rates instead of collective flow. This leads to managers obsessing over how ‘utilised’ each person is, mistaking busyness for progress. Teams become overloaded with microtasks, pulled into multitasking, and lose sight of flow efficiency and value creation. This mindset traps them in local optimisations, overload, and multitasking chaos. Everyone looks busy, but value delivery crumbles. Deadlines slip, work piles up, and predictability collapses.\n\nWe need to shift from individual task-level tracking and micromanagement to managing the system of work.\n\n## Three Levels of Capacity Planning: Strategic, Category, Team\n\nEffective capacity planning happens at three distinct but connected levels: portfolio (strategic), category (product or business unit), and team (execution). Each level has its own constraints, its own levers, and its own accountabilities. If you blur these levels, you end up with local optimisations, overloaded systems, and unpredictable delivery. If you handle them deliberately, you enable scalable, reliable flow across the entire organisation. This post lays out what matters at each level, where most organisations fail, and how to focus on the right system levers to improve predictability and value delivery.\n\n### Portfolio Level (Strategic)\n\nAt the portfolio level, individual capacity is irrelevant. Portfolio-level delivery is not the sum of people’s hours or team headcounts. It is about the system’s ability to progress and complete major initiatives across the organisation.\n\nTraditional project management has well-established strengths — especially in controlling scope, budget, and schedule — but repeatedly makes the same flawed assumptions when applied to complex, system-wide delivery. To connect better, we should acknowledge where traditional methods excel and then explain why they hit limits at scale or in domains like software engineering, where variability and complexity cannot be fully controlled. It assumes that if you know how many people you have and how many hours they can work, you can calculate how many projects you can run. It treats capacity as a static sum of people, ignoring system dynamics like waiting times, handoffs, coordination overhead, and priority collisions. It assumes that by assigning people to projects and filling calendars, you maximise delivery. In reality, you simply increase work in progress, dilute focus, and create organisational thrashing.\n\nFlow-based, lean thinking demands a different focus. The real constraint at portfolio level is not team speed. It is how many initiatives the organisation can meaningfully progress in parallel before bottlenecks, cross-team dependencies, or funding constraints stall progress. This speaks directly to Lean’s core emphasis on optimising the system as a whole, not optimising local team measures. As Deming stressed, managing parts in isolation leads to suboptimisation — the real improvement comes when leadership steps back and improves the flow and constraints at the system level. It is about how efficiently the system moves work across teams, products, and functions, independent of how busy individuals are.\n\nTracking individual capacity at portfolio level leads to local optimisation and wastes effort. Managing portfolio-level WIP, cross-team flow, and initiative-level progress gives you real, actionable capacity insight. Trying to map individual team throughput directly to portfolio delivery without addressing cross-initiative coordination, system WIP limits, or systemic blockers is a guaranteed failure.\n\nSpecifically, leaders fall into the trap of believing:\n\n- That if every team improves throughput, the portfolio improves – false.\n- That we can just sum team metrics to get total portfolio capacity – false.\n- That we can ignore portfolio-level WIP and still forecast accurately – false.\n\nThe shift required is from “how many hours can we extract from people” to “how much value can the system deliver, predictably, given its real constraints.” This is why traditional project management fails at scale. It looks down at tasks and people when it should be looking up at systems and flow.\n\n### Category Level (Product / Business Unit)\n\nAt the category level, the biggest mistake is assuming you can simply roll up individual team flow metrics to understand category capacity, without managing cross-team dependencies, shared bottlenecks, or category-level WIP.\n\nWhy is this wrong?\n\nTeams within a category rarely operate in isolation. They share architectures, platforms, specialists, and decision-makers. Even if each team shows good local flow, the category’s overall delivery can be blocked by cross-team dependencies, shared capacity limits (such as UX, security, or operations), or coordination overhead (like release alignment or integration cycles).\n\nTraditional thinking assumes category performance equals the sum of teams’ performance. In reality, category performance is governed by the speed of the slowest shared bottleneck and the organisation’s ability to coordinate across flows.\n\nWhat needs to shift:\n\n- Apply category-level WIP limits on how many initiatives or epics are in play across all teams.\n- Focus on improving cross-team flow and dependency management, not just local team throughput.\n- Measure flow across the value stream, not within isolated team swimlanes.\n\nThe mistake is failing to treat the category as an interconnected system. Local team improvements mean little if the category’s delivery is constrained by systemic coordination, shared services, or unmanaged WIP.\n\n### Team Level (Execution)\n\nThe core mistake at the team level when moving to flow metrics is assuming that flow metrics like throughput or cycle time are just “better tracking” of individual performance, rather than system-level indicators of work preparation, flow, and blockers.\n\nWhy is this wrong?\n\nTraditional teams apply flow metrics to individuals, asking: “How many tasks did you finish?” or “What’s your personal throughput or cycle time?” This creates local pressure, gaming, and false signals because flow metrics were never designed to evaluate individuals. They measure how well the team system moves work end-to-end.\n\nTeams also often skip the upstream preparation work, thinking that flow metrics alone will fix predictability, without addressing key conditions:\n\n- Right-sizing work\n- Defining clear pull-ready conditions\n- Setting and respecting WIP limits\n\nWhat needs to shift:\n\n- Treat flow metrics as team-level health signals, not personal performance measures.\n- Focus on improving system conditions — work size, WIP, and dependencies — to improve flow, not squeezing people for more.\n- Use metrics to guide improvement conversations, not to monitor or punish individuals.\n\nThe mistake is misapplying flow metrics as individual productivity tools instead of using them to improve team system flow. Without addressing preparation, WIP, and collaboration, adding flow metrics just creates new reporting noise.\n\n## What needs to change\n\nThe shift from individual capacity thinking to system-level flow demands disciplined, pragmatic changes across the organisation. This is not a matter of adding a few charts or running reports — it’s a change in ethos. It is about treating capacity as an emergent system property, not a mechanical sum of parts.\n\n### Focus on Throughput, Lead Time, and Efficiency\n\nRather than fixating on individual or team utilisation, shift your measurement to system-level flow. Pay attention to:\n\n- The number of items completed per sprint or delivery cycle (noting this assumes work items are similarly sized; otherwise, throughput comparisons can be misleading).\n- The average lead time from work start to completion, helping reveal system bottlenecks and delays.\n- Process cycle efficiency (PCE): the proportion of time work actively moves versus all non–value-adding activities (not just waiting), exposing inefficiencies across the system. This includes unnecessary committees, bureaucratic processes, and other activities that exist only to service themselves rather than delivering value.\n\nThe goal is not to ask, “Who can take on more?” but to ask, “What does our system reliably deliver, and how can we improve flow without overburdening people or teams?”\n\n### Stop Misusing Estimation, Start Right-Sizing\n\nStop wasting time trying to predict perfect effort estimates.\n\nInstead, apply the Lean principle of reducing variability and batch size, using queuing theory to improve system flow. But be clear: software engineering lives in the complex domain, not the clear or complicated domain where variability can simply be engineered away. We cannot eliminate variability entirely, but we can reduce unnecessary variability by defining a clear definition of workflow, supported by approaches like One Engineering System (1ES) and platform engineering. These strategies help standardise and stabilise the environment, tools, and pipelines — leaving only the unavoidable, context-driven variability that belongs to the real problem space.\n\nTo right-size effectively:\n\n- Break work into small, similarly sized, meaningful slices that fit smoothly through your system.\n- Focus on cutting work to a shape the system can absorb predictably — not wasting time on abstract story points or inflated complexity debates.\n- Use historical throughput and cycle time data to calibrate what 'small enough' looks like in practice, not in theory.\n- Make right-sizing part of your working agreements and backlog preparation, ensuring teams only pull work that meets clear, shared readiness standards.\n\nThe issue isn't estimation itself—it's turning estimation into something it was never meant to be. Right-sizing is still estimation, just done in a simpler and more honest way. This is not about squeezing people harder; it is about designing a steady, sustainable system where predictability is built directly into the shape and handling of the work.\n\n### Apply WIP Limits and Enforce Pull\n\nStop treating WIP limits as a mechanical cap or a reportable metric. They are a deliberate, disciplined strategy to protect system flow and predictability. Set clear limits on how many initiatives, epics, or stories are in play — not on how many tasks an individual can juggle. Once the system reaches its limit, stop adding work. Enforce pull: nothing new enters until capacity is truly available. Multitasking is toxic; kill it without hesitation. This is not about pushing people harder; it’s about designing the system so work flows cleanly and teams can focus, finish, and deliver predictably.\n\n### Forecast With Empirical Data\n\nStop pretending forecasts are about precision. Forecasting is about understanding what the system consistently delivers and using that to set realistic expectations, with the important caveat that this relies on the assumption of a relatively stable system, as Lean approaches depend on system stability for predictability. This also means recognising how system constraints align with legal mandates, statutory requirements, and interdepartmental dependencies — especially in public sector or regulated environments where external obligations shape the boundaries of what can be delivered and when. If your teams typically deliver 6–8 items per sprint, then forecast 6–8 — no sandbagging, no overpromising, no wishful thinking. Use past variance to shape your delivery ranges and confidence levels. Forecasting is not about heroic assumptions; it is about respecting the boundaries of what your system can actually achieve. Teach leadership that predictability comes from protecting system health, not demanding unrealistic outputs or pushing teams beyond sustainable limits.\n\n### Monitor Flow Health Holistically\n\nFlow health is not just a dashboard; it is the living pulse of your system. Go beyond counting throughput and look deeper:\n\n- Rising cycle or lead times — these are your early-warning signals of hidden bottlenecks creeping into the system (and, as noted earlier, low PCE includes more than just waiting — it also covers other forms of systemic waste and non–value-adding activities).\n- Aging WIP — when work lingers without progress, it is a red flag that something is stalled or blocked.\n- Low PCE — when too much time is spent waiting instead of progressing, it signals waste accumulating across the system.\n\nThese are not vanity metrics. They reveal how your system is truly performing, regardless of how full calendars look or how busy people appear. Build regular inspection of these health indicators into your operating rhythm. Use them not for blame or micromanagement, but as fuel for system-wide conversations: Where is flow breaking down? What needs to change? Where can we intervene to unblock, simplify, or improve?\n\nHealthy flow is not a side effect; it is a deliberate, ongoing outcome you must design, monitor, and continuously tune.\n\nThe change is not cosmetic — it’s a fundamental rethink of how you approach planning, forecasting, and delivering across all levels of the organisation.\n\n### The Role of Leadership\n\nLeadership is not about control or oversight; it is about creating the conditions where teams and systems can thrive. Lean leadership models humility, removes systemic obstacles, and relentlessly focuses on delivering customer value, not just improving internal measures. Leaders must step back from the temptation to manage individuals and instead take accountability for enabling the system of work. That means:\n\n- Enabling true autonomy at the team level, giving teams the space to own their work and delivery, without micromanagement.\n- Actively protecting WIP limits and pull discipline across the system, even when external pressures or senior stakeholders demand more.\n- Investing in backlog refinement, right-sizing, and preparation so that teams pull only well-shaped, high-value work — and have the capacity to deliver it predictably.\n- Focusing measurement on system health — time-to-market (TTM), process cycle efficiency (PCE), throughput, and lead time — not individual utilisation, heroics, or busyness.\n\nLeaders are accountable for creating an environment where flow is deliberate, predictable, and sustainable. This is not about pushing people to work harder; it is about tuning the system so teams can focus, collaborate, and deliver value without unnecessary friction or disruption. True leadership means enabling the system, not extracting from the people.\n\n## Reframing the Conversation\n\nLean capacity planning reshapes how we think about delivery, focus, predictability, and most critically, continuous learning and relentless improvement — the true core of Lean thinking.\n\nStop asking, “How many tasks or hours can we assign?” Start asking, “How much value can the system deliver, at what lead time, and with what efficiency?”\n\nIf you’re not measuring system health indicators like PCE or TTM, you are flying blind.\n\nThis is not about making teams go faster. It is about creating smarter, healthier flow. Get the fundamentals right, and you unlock sustainable, reliable delivery that serves both your customers and your organisation.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-07-21-rethinking-capacity-planning\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-07-21-rethinking-capacity-planning",
    "ReferencePath": "resources/blog/2025/2025-07-21-rethinking-capacity-planning"
  },
  {
    "FrontMatter": {
      "title": "Why Topic Branches Drive High-Quality Delivery",
      "short_title": "Why Topic Branches Improve Software Quality",
      "description": "Explains how short-lived topic branches in source control improve software quality, enable modularity, speed up integration, and support agile, continuous delivery practices.",
      "date": "2025-07-14T09:00:00Z",
      "weight": 115.0,
      "ResourceId": "O_VlmDj7n3V",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "why-topic-branches-drive-high-quality-delivery",
      "aliases": [
        "/resources/O_VlmDj7n3V"
      ],
      "concepts": [
        "Tenet"
      ],
      "categories": [
        "Engineering Excellence",
        "Technical Leadership",
        "Product Development"
      ],
      "tags": [
        "Software Development",
        "Modern Source Control",
        "Operational Practices",
        "Engineering Practices",
        "Product Delivery",
        "Continuous Delivery",
        "Deployment Frequency",
        "Pragmatic Thinking",
        "Team Collaboration",
        "Team Performance",
        "Flow Efficiency",
        "Frequent Releases",
        "GitHub",
        "Market Adaptability",
        "Technical Excellence"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:48:56Z",
        "short_title": "2025-07-07T16:43:16Z"
      }
    },
    "BodyContent": "In modern [software development]({{< ref \"/tags/software-development\" >}}) the idea of the topic branch is an essecial one. It is your gatekeeper to preventing Conway's Law and an engineering structure that mirrors your organisational boundaries. Frequent integration through topic branches helps break down silos, encouraging cross-[team collaboration]({{< ref \"/tags/team-collaboration\" >}}) and reducing the tendency for the software architecture to reflect the organisation's communication paths.\n\nA topic branch is a short-lived, focused branch in your source control repository that isolates a **single unit of developer work**. This is not a month-long feature branch. This is not \"we'll merge it someday\" work. A topic branch is something you **code, test, and integrate in a few hours or, at most, a couple of days**.\n\nThe moment your topic branch stretches beyond a few days, take it as a warning:\n\n- Integration will get harder.\n- Merge conflicts will multiply.\n- Your risk of defects or unintended behaviours will spike.\n- Reviewing and validating costs more\n\nIf you let a branch sit for too long, you are building up **integration debt** that will bite you later. Topic branches, and thinking about them as just that, topics, is an essential practice in modern software engineering.\n\n## The Strategic importance of Topic Branches\n\nWe want to consistently emphasised the importance of technical practices that enable flow, adaptability, and resilience in software teams. Whether addressing trunk-based development, [continuous delivery]({{< ref \"/tags/continuous-delivery\" >}}), or [engineering excellence]({{< ref \"/categories/engineering-excellence\" >}}), the message remains the same: discipline in the small enables success in the large. Topic branches fit directly into this pattern. They are not just a coder habit; they are a deliberate tool that reinforces modularity, integration, and continuous feedback, all cornerstones of modern software delivery.\n\nFrom a **technical [leadership]({{< ref \"/categories/leadership\" >}})** perspective, topic branches are pivotal because they enable:\n\n- Modularity — you isolate changes to a narrow scope.\n- Continuous delivery — you keep the mainline ready for release.\n- Clear code reviews — you limit pull requests to atomic, understandable units.\n- Collaborative accountability — the team shares responsibility for integrating small changes frequently.\n- **Support for agile development practices** — you align technical work with the team’s tactical Sprint Goals and Product Goals.\n\nWithout topic branches, you create a fragile system of work. Without topic branches, you make integration harder. Without topic branches, you **slow down your delivery pipeline** and increase the chance of failure.\n\n### Practical Patterns for Tactical Implementation of Topic Branches\n\nBuilding on the strategic importance we need actionable patterns that technical leaders and teams can apply. It is not enough to understand why topic branches matter; you need pragmatic, grounded approaches that translate strategy into engineering practice. For most teams and most projects, **GitHub Flow** (the branching model, not the cloud tool) is the most effective model. It is a trunk-based model with minimal overhead and complexity. GitHub Flow treats the main branch as the production-ready line and uses small, short-lived topic branches for all work.\n\n![GitHub Flow diagram](images/branchstrategy-trunkbased.png)\n\nYou branch off `main`, do your small unit of work, push frequently, and merge back as soon as possible — ideally the same day, or next day at the latest. Your branch is:\n\n- Focused on a single task or issue.\n- Continuously tested (locally and via CI).\n- Reintegrated quickly to avoid drift.\n- Reinforces context disapline\n\nIf you have a larger application with more engineers and the need to make changes in the production line, then Microsoft’s Release Flow, which is almost identical to \"Github Flow\" with the addition of a versioned release branch. One could say that  Release Flow inherits and extends Github Flow.\n\n![Release Flow diagram](images/branchstrategy-releaseflow.png)\n\nCompare this to the traditional **Git Flow** approach that models less mature braching stratagies, which adds layers of feature, develop, release, and hotfix branches. While Git Flow can still be useful in some legacy or non-continuous delivery setups, it introduces far more overhead and complexity. It reflects a strategy from the pre-CD world.\n\n![Git Flow diagram](images/branchstrategy-old-school.png)\n\nGitflow Flow, and its derivatives, simplifies this: fewer long-lived branches, fewer merge headaches, more emphasis on **incremental delivery**.\n\n## Leading change through Branching Stratagy\n\nIf you are leading a team, the presence or absence of disciplined topic branching tells you a lot.\n\n- Short-lived topic branches = a team practising modularity, integration, continuous feedback, and accountability.\n- Long-lived feature branches = a team accumulating integration risk, delaying delivery, and likely violating agile principles.\n\nYou need to push the team to keep branches small, focused, and short-lived. Review your branching strategy regularly. Make sure it supports, not undermines, your goals of flow, agility, and quality. And above all make sure its clear what each branch is for and how it should be used.\n\nIf your team is struggling with long-lived branches, get serious:\n\n- Introduce trunk-based development practices with GitHub Flow or Release Flow.\n- Enforce limits on branch lifespan.\n- Tighten your CI/CD loops.\n- Teach your team the cost of integration delay.\n\nRemember: your branching strategy is not just a technical choice. It is a critical enabler of continuous [value delivery]({{< ref \"/tags/value-delivery\" >}}).\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-07-14-why-topic-branches-drive-high-quality-delivery\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-07-14-why-topic-branches-drive-high-quality-delivery",
    "ReferencePath": "resources/blog/2025/2025-07-14-why-topic-branches-drive-high-quality-delivery"
  },
  {
    "FrontMatter": {
      "title": "Stop Building Silos. Start Building Systems",
      "short_title": "Stop Building Silos, Start Building Systems",
      "description": "Explains how fragmented automation and tool silos harm software delivery, and advocates for unified engineering systems and platform engineering to enable reliable, scalable DevOps.",
      "date": "2025-07-07T09:00:00Z",
      "weight": 50.0,
      "ResourceId": "zLhc3UKUWOj",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "stop-building-silos-start-building-systems",
      "aliases": [
        "/resources/zLhc3UKUWOj",
        "/resources/blog/stop-building-silos.-start-building-systems"
      ],
      "aliasesArchive": [
        "/stop-building-silos--start-building-systems",
        "/blog/stop-building-silos--start-building-systems",
        "/resources/blog/stop-building-silos.-start-building-systems"
      ],
      "concepts": [
        "Ethos"
      ],
      "categories": [
        "Engineering Excellence",
        "DevOps",
        "Technical Leadership"
      ],
      "tags": [
        "Pragmatic Thinking",
        "Technical Mastery",
        "Operational Practices",
        "One Engineering System",
        "Platform Engineering",
        "Continuous Delivery",
        "Social Technologies",
        "Transparency",
        "Internal Developer Platform",
        "Technical Excellence",
        "Product Delivery",
        "Software Development",
        "Engineering Practices",
        "Value Delivery",
        "Azure Pipelines"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:48:58Z",
        "short_title": "2025-07-07T16:43:18Z"
      }
    },
    "BodyContent": "You can’t deliver quality at speed when your automation is duct-taped together. If your pipelines are stitched across multiple systems, your deployments depend on human rituals, and your tests run in the shadows, you don’t have a delivery system—you have a liability.\n\nIf your automation strategy looks something like this:\n\n- Manual SQL deployments from someone’s laptop\n- Azure Pipelines building unversioned assemblies\n- Manual deployment to dev and test environments\n- TeamCity rebuilding new unversioned assemblies\n- Octopus Deploy is deploying from Team City to staging and production\n- Selenium tests running on a black-box scripted node that only one person monitors\n\nYou’re not building a product. You’re building chaos. You’re not [scaling]({{< ref \"/tags/scaling\" >}}) a team. You’re scaling dysfunction.\n\n## Fragmentation Is Not an Engineering Strategy\n\nWhen every team uses a different deployment tool, stores secrets in a personal vault, and runs tests on unmonitored boxes, you’ve created a system that _no one_ understands and _no one_ can change safely.\n\nThis isn’t flexibility. It’s fragility.\n\nFragmentation leads to duplication of effort, inconsistent results, increased cognitive load, and slower delivery. You waste time debugging pipeline differences instead of building product value. And every deviation from a shared system adds risk to quality, security, and compliance.\n\n[Engineering excellence]({{< ref \"/categories/engineering-excellence\" >}}) comes from enabling consistency where it matters—creating common foundations that support autonomy without sacrificing reliability. It comes from designing systems that are observable, changeable, and resilient—systems that empower teams through clarity, not confusion.\n\nThis kind of fragmentation also violates the core ethos of [DevOps]({{< ref \"/categories/devops\" >}}): [continuous delivery]({{< ref \"/tags/continuous-delivery\" >}}) of value through the union of people, processes, and products. If your toolchain is stitched together by tribal knowledge and Slack messages, you’re not enabling flow. You’re creating friction.\n\n## DevOps Is Not Tooling. It's Feedback, Flow, and Learning\n\nDevOps isn’t a toolkit war. It’s the discipline of enabling feedback, flow, and [continuous learning]({{< ref \"/tags/continuous-learning\" >}}) across the entire product lifecycle.\n\n- It’s about **amplifying feedback loops**—build, test, and release systems that surface issues early and often.\n- It’s about **enabling flow**—removing friction between commit and customer, reducing handoffs and rework.\n- It’s about **fostering learning**—capturing telemetry, responding to incidents, and improving from every iteration.\n\nDevOps without visibility is cargo cult. DevOps across disconnected systems is just automation theatre. And DevOps without learning is just [technical debt]({{< ref \"/tags/technical-debt\" >}}) in fast-forward.\n\n## Building One Engineering System (1ES) through Platform Engineering\n\nIf DevOps is the ethos, then **[Platform Engineering]({{< ref \"/tags/platform-engineering\" >}})** is the strategy, and **[One Engineering System]({{< ref \"/tags/one-engineering-system\" >}}) (1ES)** is the execution model.\n\nPlatform Engineering is not just infrastructure automation. It's a practice grounded in DevOps principles that aims to improve every development team's time-to-value, compliance, cost control, and security through **improved developer experiences** and **governed self-service**. It's both a mindset shift and a system of reusable tools and services.\n\nPlatform Engineering teams build and evolve **Internal Developer Platforms (IDPs)**—paved paths that reduce cognitive load, eliminate manual gates, and guide teams safely toward production.\n\nThese platforms:\n\n- Help developers be self-sufficient (e.g. starter kits, templates, IDE integrations)\n- Encapsulate patterns into reusable services\n- Automate security and compliance checks\n- Streamline operations and infrastructure management\n\n1ES, pioneered at Microsoft, embodies this by unifying:\n\n- **[Azure Pipelines]({{< ref \"/tags/azure-pipelines\" >}})** for end-to-end CI/CD\n- **[Azure Repos]({{< ref \"/tags/azure-repos\" >}})**, **Boards**, and **Artifacts** as a single source of truth\n- **Infrastructure as Code**, **Policy as Code**, and integrated telemetry\n\nThe result: a secure, observable, scalable system where guardrails are built in and teams can move fast _without creating risk_.\n\nNo handoffs. No tool silos. No black-box deploys. One path from idea to production that every team and every skillset contributes to.\n\nYou may be thinking that \"this breaks self-management\" and the agency of the teams. But self-management in Agile doesn’t mean chaos. [Scrum]({{< ref \"/categories/scrum\" >}}) Teams don’t self-manage in a vacuum—they operate within the boundaries defined by the organisation. Self-management means giving teams the autonomy to solve problems within a clearly defined system of constraints. That system of constraints—your engineering boundaries, your compliance requirements, your platform capabilities—is your Platform Engineering strategy, and your 1ES is your implementation of that strategy. It defines what good looks like. Those boundaries must be engineered and not left to tribal knowledge. If you want consistent results, define the edges and let the teams operate freely _within_ them.\n\n## Consolidate. Standardise. Enable.\n\nIf you want scale, you must design for it. That means:\n\n- One build system.\n- One deployment path.\n- One way of managing secrets, tests, telemetry, and deployments.\n\n**Azure Pipelines** is capable of it all. With templates, approvals, gates, agents, deployment groups, and environment strategies, everything you need to build a 1ES-style delivery platform is already there. Yes, there are other tools, but if you are already rooted in the Microsoft stack, then these purpose-built tools fit like a glove.\n\nStop spreading your delivery process across half a dozen tools with no visibility. Pick a platform. Make it great. And let your teams focus on product, not plumbing.\n\n**Engineering excellence isn’t about choosing the coolest tools.**\\\nIt’s about building a system of work that enables every team to deliver safely, sustainably, and continuously.\n\n**Stop optimising for familiarity. Start optimising for flow.**\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-07-07-stop-building-silos-start-building-systems\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-07-07-stop-building-silos-start-building-systems",
    "ReferencePath": "resources/blog/2025/2025-07-07-stop-building-silos-start-building-systems"
  },
  {
    "FrontMatter": {
      "title": "Human and AI Agency in Adaptive Systems: Strategy Before Optimisation",
      "short_title": "Human vs AI Agency in Adaptive Systems",
      "description": "Explores the distinct roles of human and AI agency in adaptive systems, emphasising human-led strategy and accountability versus AI-driven tactical optimisation.",
      "date": "2025-06-30T09:00:00Z",
      "weight": 570.0,
      "ResourceId": "ffJaR9AaTl7",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "human-and-ai-agency-in-adaptive-systems-strategy-before-optimisation",
      "aliases": [
        "/resources/ffJaR9AaTl7"
      ],
      "aliasesArchive": [
        "/human-and-ai-agency-in-adaptive-systems--strategy-before-optimisation",
        "/blog/human-and-ai-agency-in-adaptive-systems--strategy-before-optimisation"
      ],
      "concepts": [
        "Ethos"
      ],
      "categories": [
        "Leadership"
      ],
      "tags": [
        "Agentic Agility",
        "Sociotechnical Systems",
        "Organisational Physics",
        "Sensemaking",
        "Strategic Goals",
        "Complexity Thinking",
        "Agentic Engineering",
        "Systems Thinking",
        "Pragmatic Thinking",
        "Decision Making"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:48:59Z",
        "short_title": "2025-07-07T16:43:20Z"
      },
      "mermaid": true
    },
    "BodyContent": "Human agency is not optional in adaptive systems. It is not something to \"blend\" with AI or to automate away. It is the only thing that defines strategy, sets purpose, and drives meaningful adaptation. AI has a role, but that role is tactical optimisation within boundaries defined by humans.\n\nTreating these two forms of agency as equivalent is not just careless; it is dangerous. It leads to brittle systems that optimise yesterday’s decisions while failing to recognise when the game has changed.\n\nWhen we talk about **human agency**, we are speaking about **strategic intent** — the setting of direction, the framing of purpose, the shaping of hypotheses, and the stewardship of ethical, political, and systemic choices that no model or algorithm can or should automate. **AI agency**, by contrast, is about **tactical optimisation** — rapid [experimentation]({{< ref \"/tags/experimentation\" >}}) within bounded parameters, local improvements, efficiency gains, and the relentless pursuit of better tactics without changing the fundamental strategic frame.\n\nPut simply: AI optimises inside a system. Humans adapt and redefine the system.\n\n## Mapping Agency to Adaptive Systems\n\nIn professional practice, I map **human agency** and **AI agency** to different layers of decision-making:\n\n| Layer              | Human Agency (Strategic Intent)         | AI Agency (Tactical Optimisation)            |\n| :----------------- | :-------------------------------------- | :------------------------------------------- |\n| **Purpose**        | Define “why” and “for whom”             | Operate within a defined purpose             |\n| **Adaptation**     | Reframe goals, pivot strategies         | Optimise existing goals and operations       |\n| **Sense-making**   | Interpret signals, detect weak patterns | Surface patterns, recommend actions          |\n| **Accountability** | Own outcomes and systemic impact        | Deliver within parameters; no accountability |\n\nThe strategic layer demands human discernment because it must constantly negotiate ethical trade-offs, respond to uncertainty, and reset direction as new information emerges. Tactical layers benefit from AI’s raw speed, capacity for pattern recognition, and ability to handle enormous volumes of data. There is synergy, but it is not a partnership of equals. Humans govern; AI serves.\n\n{{< mermaid width=\"400px\" >}}\nflowchart TD\nA([Decision Point]) --> B{Is strategy or purpose changing?}\nB -- Yes --> H[/\"Human Agency\"/]\nB -- No --> C{Is ethical or political judgement required?}\nC -- Yes --> H\nC -- No --> D{Is the problem fully bounded and optimisable?}\nD -- Yes --> AI([\"AI Agency\"])\nD -- No --> H\n\nstyle H fill:#f9f,stroke:#333,stroke-width:2px\nstyle AI fill:#bbf,stroke:#333,stroke-width:2px\n\n{{< /mermaid >}}\n\n## The Risks of Overdelegating Adaptation\n\nOrganisations that overdelegate adaptive work to AI systems are not buying efficiency; they are actively sabotaging their future relevance. The risks are not hypothetical; they are immediate and compounding:\n\n### 1. Collapse of Strategic Sensing\n\nAdaptive systems are grounded in weak signal detection, hypothesis-driven exploration, and the willingness to be wrong and change course. AI, by its nature, is trained on existing data distributions and past patterns. It cannot, on its own, identify when the landscape has fundamentally shifted. Blindly optimising yesterday’s patterns only accelerates strategic obsolescence.\n\n### 2. Fragility under Complexity\n\nAI systems operate well under known constraints but become brittle in the face of novel complexity. When the operating environment changes outside the model's training range — as it inevitably will — organisations that have outsourced strategic sensing and adaptation will fail catastrophically and rapidly, long before any dashboard or model warns them.\n\n### 3. Erosion of Human Accountability\n\nWhen critical adaptive work is offloaded to AI, responsibility becomes diluted. Who is accountable for outcomes? Who owns ethical consequences? If decision-making collapses into model outputs without human interrogation, the result is not augmented intelligence; it is abdicated [leadership]({{< ref \"/categories/leadership\" >}}).\n\n## A Pragmatic Approach to Human-AI Collaboration\n\nTo work responsibly with AI in adaptive systems, organisations must operationalise clear agency boundaries:\n\n- **Humans are accountable for strategic direction, purpose setting, and system definition.**\n- **AI is responsible for tactical optimisations within clear, human-defined parameters.**\n- **Human intervention is mandatory at all escalation points where adaptation is required.**\n\nThis boundary is not a theoretical construct; it should be a live operational discipline embedded into system design, governance practices, and escalation frameworks.\n\n**Optimisation without adaptation is a recipe for irrelevance.**  \n**Adaptation without optimisation is a recipe for chaos.**  \n**Only through disciplined agency boundaries can we achieve resilient, continuously evolving systems.**\n\n# Final Thought\n\nIn the rush to automate, organisations must resist the seductive but dangerous myth that AI can replace human agency in complex adaptive environments. **AI optimises, but it does not adapt. It cannot perceive new purpose. It cannot lead. It cannot be held accountable.**\n\nStrategic intent, adaptive reframing, and ethical stewardship remain irrevocably human domains.\n\nThose who forget this are not merely inefficient.  \nThey are obsolete in the making.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-06-30-human-and-ai-agency-in-adaptive-systems\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-06-30-human-and-ai-agency-in-adaptive-systems",
    "ReferencePath": "resources/blog/2025/2025-06-30-human-and-ai-agency-in-adaptive-systems"
  },
  {
    "FrontMatter": {
      "title": "Stop Writing Business Logic in Stored Procedures",
      "short_title": "Stop Writing Business Logic in Stored Procedures",
      "description": "Explains why business logic should not be written in stored procedures, highlighting testability, maintainability, scalability, and strategies for gradual code refactoring.",
      "date": "2025-06-23T09:00:00Z",
      "weight": 240.0,
      "ResourceId": "utAzlIGxj7O",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "stop-writing-business-logic-in-stored-procedures",
      "aliases": [
        "/resources/utAzlIGxj7O"
      ],
      "aliasesArchive": [
        "/stop-writing-business-logic-in-stored-procedures",
        "/blog/stop-writing-business-logic-in-stored-procedures"
      ],
      "concepts": [],
      "categories": [
        "Engineering Excellence"
      ],
      "tags": [
        "Technical Mastery",
        "Engineering Practices",
        "Software Development",
        "Technical Excellence",
        "Technical Debt"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:00Z",
        "short_title": "2025-07-07T16:43:23Z"
      }
    },
    "BodyContent": "Over the years, I've encountered many companies that have maintained their business logic in stored procedures, but the practice of doing so has died out, for good reasons ill hilight below. However, many codebases have been around for 10+ years, and may still have large amounts of business logic in them.\n\nIf you’re still writing business logic in SQL Stored Procedures, it’s time to stop. If you still have code that stores business login in  SQL Stored Procedures its time to refactor!\n\nI’m not saying rewrite everything at once. That would be ridiculous. It’s a massive cost with no direct stakeholder value. What I _am_ saying is this:\n\n> From this point forward, stop creating new business logic in stored procedures.\n>\n> And when you _must_ change one, refactor that logic out into testable, mockable, maintainable code.\n\nThis is not about doing everything at once!\n\nTake inspiration from the Azure [DevOps]({{< ref \"/categories/devops\" >}}) team. When they decided to eliminate their suite of brittle, long-running system tests, they didn’t try to replace them in a single sprint. It took them four years of consistent work, in three-week sprints, to fully remove and replace those tests with something better. One step at a time. That’s what change looks like.\n\nBreak the cycle of adding more mess to the mess. Every stored procedure you don't write is a future bug you won't have to debug in production. Every time you choose code over SQL for business logic, you're reclaiming control of your system.\n\n## Stored Procedures are the wrong place for Business Logic\n\nLet’s be clear: this isn’t an abstract architectural debate. The reasons stored procedures are a bad place for business logic are grounded in hard-learned lessons from real teams, real outages, and real maintenance headaches. If you're serious about [engineering excellence]({{< ref \"/categories/engineering-excellence\" >}}), you need to treat stored procedures as a legacy constraint, not a strategic tool.\n\n1. **They can’t be tested properly** - You need a full database instance with seed data. You need to run a slow test harness. There’s no mocking, no fast feedback, no isolation. If it can’t be unit tested, it can’t be trusted. Long-running system tests do not tell you if the code works, only that the long-running system tests that you created work.\n2. **They don’t participate in CI/CD** - Stored procedures are almost always deployed manually or via fragile SQL scripts. While it can be automated by things like Redgate, it's often still brittle, breaks reproducibility, and blocks automated pipelines.\n3. **They aren’t version-controlled like real code** - While you can have them under source control, they are \"copied\" into source control..**.** either by Readgate or manually by a developer. Manual tasks are risky! Remember the Knight Capital Group!\n4. **They tightly couple your logic to the database** - That kills portability and locks you into a specific database engine. It also makes testing, debugging, and observability painful. There have been attempts in the past to create \"Unit Tests\" for stored procedures, but they have largely been abandoned in favour of just getting our logic out of that scenario.\n5. **They don’t scale** - Stored procedures run on the most expensive, least scalable part of your infrastructure: the database server. Business logic belongs in services that can scale out.\n6. **They violate the separation of concerns** - Your database should store and retrieve data. Your application should handle logic. Stored procedures blur that line and create a big ball of mud.\n7. **They’re hard to reason about** - No dependency injection. No composition. No mocking. No telemetry. No proper logging. Just deeply procedural code with limited tooling support. If you have to rely on a debugger to see if your code works, you are doing it wrong.\n\nBefore you write the next line of business logic in a stored procedure, ask yourself: is this something I want to debug at 2am with no tests, no telemetry, and no rollback plan?\n\nThat’s the reality of stored procedures. They make every part of your engineering practice harder. Get the logic out. Put it where it belongs—alongside the rest of your tested, observable, maintainable code.\n\n## The strategy: don’t rip, refactor\n\nYou don’t need permission to start this. You don’t need a project. You just need a commitment to modern engineering discipline:\n\n- When you build new features, do it in application code, not SQL.\n- When you touch an existing stored procedure, _refactor it_. Move the logic into testable code.\n- Leave a thin wrapper if necessary, but relocate the behaviour.\n\nThis is a _pay-as-you-go_ modernisation strategy. It lets you progressively reduce [technical debt]({{< ref \"/tags/technical-debt\" >}}) without halting delivery.\n\n## The benefits are compounding.\n\nEvery time you refactor, you:\n\n- Increase the ability to create unit tests\n- Improve maintainability\n- Enable faster feedback loops\n- Reduce runtime costs\n- Shrink the surface area for bugs\n- Move toward [continuous delivery]({{< ref \"/tags/continuous-delivery\" >}})\n\nNo single change flips the system. But every change you make is a step away from the fragile procedural past and toward a sustainable engineering future.\n\n## The outcome?\n\nThis isn’t about dogma. It’s about discipline. Modern [software development]({{< ref \"/tags/software-development\" >}}) demands testability, traceability, observability, and scalability. Stored procedures give you none of that.\n\nIf you're maintaining logic in stored procedures, you're fighting your tooling, your pipeline, and your team. Stop doing that.\n\nStart small. Move incrementally. Raise the bar.\n\nModern software is built in code, not SQL.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-06-23-stop-writing-business-logic-in-stored-procedures\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-06-23-stop-writing-business-logic-in-stored-procedures",
    "ReferencePath": "resources/blog/2025/2025-06-23-stop-writing-business-logic-in-stored-procedures"
  },
  {
    "FrontMatter": {
      "title": "How Lack of Agency is Killing Your DevOps Initiatives",
      "short_title": "Lack of Developer Agency in DevOps",
      "description": "Explores how lacking developer control over production, telemetry, and deployments undermines DevOps, leading to fragile automation and failed continuous delivery.",
      "date": "2025-06-16T09:00:00Z",
      "weight": 285.0,
      "ResourceId": "AgIU1SK-3pE",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "how-lack-of-agency-is-killing-your-devops-initiatives",
      "aliases": [
        "/resources/AgIU1SK-3pE"
      ],
      "aliasesArchive": [
        "/how-lack-of-agency-is-killing-your-devops-initiatives",
        "/blog/how-lack-of-agency-is-killing-your-devops-initiatives"
      ],
      "concepts": [
        "Ethos"
      ],
      "categories": [
        "DevOps",
        "Engineering Excellence",
        "Product Development"
      ],
      "tags": [
        "Agentic Agility",
        "Technical Mastery",
        "Social Technologies",
        "Agentic Engineering",
        "Pragmatic Thinking",
        "Software Development",
        "Operational Practices",
        "Value Delivery",
        "Self Organisation",
        "Team Motivation",
        "Technical Excellence"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:01Z",
        "short_title": "2025-07-07T16:43:27Z"
      }
    },
    "BodyContent": "[DevOps]({{< ref \"/categories/devops\" >}}) is not automation. It is not pipelines. It is not \"shifting left\" while locking decision-making into ancient [release management]({{< ref \"/tags/release-management\" >}}) bureaucracies.  \n**DevOps is agency.** It is the union of people, process, and products to enable continuous delivery of value to our end users.\n\nIf your developers do not have operational agency—control over environments, deployments, telemetry, and remediation—you are not doing DevOps.  \nYou are automating fragility.\n\n## There Is No Place Like Production\n\nWe have already established that [production is the only place real feedback happens]({{< ref \"/resources/blog/2020/2020-12-28-there-is-no-place-like-production\" >}}). UAT, staging, demo environments—none of these reveal how real users behave, where real bottlenecks emerge, or where real pain points lie.  \nReal outcomes, real telemetry, and real consequences only happen in production.\n\nIf developers do not have operational authority over production, they are blindfolded. They can build, but they cannot learn. They can deploy, but they cannot observe. They can script, but they cannot improve.\n\n**Without production feedback, [Continuous Delivery]({{< ref \"/tags/continuous-delivery\" >}}) collapses into Continuous Guessing.**\n\n## Automation without Agency is Fragile\n\nMost so-called \"DevOps transformations\" fail because they stop at tooling. They build beautiful pipelines that developers cannot influence. They deploy artifacts that developers cannot monitor.  \nAnd when something goes wrong? They are forced to raise a ticket to an ops team who barely understands the context of the change.\n\nThis is organisational malpractice.\n\nAutomation is not enough.  \nPipelines must be _developer-controlled_.  \nEnvironments must be _developer-managed_.  \nTelemetry must be _developer-owned_.\n\nIf your developers are second-class citizens in your own delivery ecosystem, you are manufacturing helplessness at scale.\n\n## Operational Agency Is Non-Negotiable\n\nTrue DevOps demands that developers have operational agency, including:\n\n- **Deploy to production anytime** – without raising a ticket, without scheduling a \"release train,\" without begging for a window.\n- **Own telemetry** – define, collect, and act on usage, performance, and error data directly from production.\n- **Roll back or forward** – respond to incidents with speed and autonomy, without waiting on a change advisory board.\n- **Observe and adapt** – monitor real user behaviour and adapt deployments and [product strategy]({{< ref \"/tags/product-strategy\" >}}) based on live signals.\n\nThis level of ownership must also be reflected in your [Definition of Done]({{< ref \"/resources/blog/2025/2025-03-17-your-evolving-definition-of-done\" >}}), ensuring that telemetry and operational readiness are part of what it means for work to be complete.\n\nAgency without feedback is noise.  \nFeedback without agency is paralysis.  \n**You must have both.**\n\n## DevOps Without Operational Agency Is Dead on Arrival\n\nEvery time you separate developers from operational decision-making, you break the feedback loop. You turn \"continuous\" delivery into ceremonial delivery.  \nYou [destroy agility]({{< ref \"/resources/blog/2021/2021-04-19-stop-normalizing-unprofessional-behaviour-in-the-name-of-agility\" >}}). You disempower your people. You institutionalise blame instead of learning.\n\nIf you want real DevOps, you must give developers real control.\n\nYes, this requires real trust.  \nYes, this demands real engineering maturity.  \nYes, this will expose the weaknesses you have been hiding behind process theatre.\n\nBut the alternative is worse: a hollow shell of DevOps, where the only thing \"continuous\" is your excuses for why it still takes six months to learn whether your features work.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-06-16-how-lack-of-agency-is-killing-your-devops-initatives\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-06-16-how-lack-of-agency-is-killing-your-devops-initatives",
    "ReferencePath": "resources/blog/2025/2025-06-16-how-lack-of-agency-is-killing-your-devops-initatives"
  },
  {
    "FrontMatter": {
      "title": "Resilience is Part of the Product, Not an Afterthought",
      "short_title": "Resilience as a Core Product Feature",
      "description": "Resilience must be designed into products from the start, not added later. Build systems to detect, contain, and recover from failures, making resilience a core feature.",
      "date": "2025-06-09T09:00:00Z",
      "weight": 150.0,
      "ResourceId": "EtzHUfsWjsD",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "resilience-is-part-of-the-product-not-an-afterthought",
      "aliases": [
        "/resources/EtzHUfsWjsD"
      ],
      "aliasesArchive": [
        "/resilience-is-part-of-the-product--not-an-afterthought",
        "/blog/resilience-is-part-of-the-product--not-an-afterthought"
      ],
      "concepts": [],
      "categories": [
        "Engineering Excellence",
        "Product Development",
        "DevOps"
      ],
      "tags": [
        "Technical Mastery",
        "Pragmatic Thinking",
        "Site Reliability Engineering",
        "Technical Excellence",
        "Operational Practices",
        "Software Development",
        "Engineering Practices"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:03Z",
        "short_title": "2025-07-07T16:43:37Z"
      }
    },
    "BodyContent": "Resilience is not a nice-to-have. It is not a department. It is not something you bolt on later if you get around to it. Resilience is part of the product. If you are serious about delivering value, you design resilience deliberately from day one. Any other approach is just gambling with your business, and is adding to your [technical debt]({{< ref \"/tags/technical-debt\" >}}).\n\nReal resilience is not about having good people with pagers. It is not about heroes. Heroes emerge when systems lack resilience. They hoard work, avoid [transparency]({{< ref \"/tags/transparency\" >}}), and justify cutting corners by claiming they are \"doing whatever it takes.\" In reality, they introduce silent risks, undermine teamwork, and erode quality standards.\n\nIf your resilience depends on a hero, you are not resilient. You are vulnerable and you just have not been exposed yet.\n\n## Resilience is a Core Feature\n\nResilience must be treated like any other core feature. It must be designed, built, and continuously improved. It must be part of your product definition, your architecture, and your engineering culture. It must be owned by the same people who build the product. At Microsoft, the Azure [DevOps]({{< ref \"/categories/devops\" >}}) engineering teams did exactly that, they built resilience which was engineered into every layer of their system — not handed off to a separate Ops team, not left to wishful thinking. Engineers owned their live site experience end-to-end form _ideation_ to _validation_ and all of the _design_, _build_, _test_, _release_ and _run_ in between.\n\nIncidents were expected, contained, and learned from, not blamed on individuals. They did not hope for resilience. They built it.\n\nIf they did have an incident, they would own it, not just fix the problem and sweep it under the rug.\n\n## Build for Containment, Not Perfection\n\nEvery serious product needs resilience capabilities: telemetry, rapid roll-forward, observability, and risk containment.\n\nWithout telemetry, you cannot see what is happening. Without rapid roll-forward, you cannot respond fast enough. Without observability, you cannot understand why things are happening. Without risk containment, small failures turn into major outages.  \nIf you have to shut down your entire platform to fix one feature, you have already failed.\n\nMicrosoft’s teams built telemetry into everything. They measured customer experience directly — failed or slow user minutes — not just server uptime. They tuned alerts to detect real-world impact. They used safe deployment rings with deliberate bake times to catch problems early. They separated deployment from exposure using feature flags, and stopped cascading failures with circuit breakers and throttling.\n\nFailures were not exceptional. Failures were normal.  \nResilience was not improvised. It was engineered.\n\n## Treat Resilience as a First-Class Investment\n\nResilience is not free, but the cost of neglecting it is far higher. Downtime kills customer trust. Outages cost revenue. Slow recovery wrecks morale. Ignoring resilience is gambling with your business.\n\nTreat resilience like a feature. Design it. Engineer it. Continuously improve it. Put it in your [Definition of Done]({{< ref \"/tags/definition-of-done\" >}}). Make it part of every code review, every architecture discussion, every release decision. If you are not actively designing for resilience, you are designing for fragility whether you mean to or not.\n\nBuild for failure. Measure resilience empirically. Improve relentlessly.\n\n## Pragmatic Steps to Build Resilience\n\nYou do not need permission to start. You do not need to fix everything at once. You just need to move with intent:\n\n- Instrument everything. If you cannot measure it, you cannot manage it.\n- Make every change reversible or overridable. Progressive delivery, feature flags, and automated deployments are minimum standards.\n- Build for isolation. Cells, circuit breakers, and throttling prevent one failure from taking down the system.\n- Treat incidents as system signals, not team failures. Every incident is feedback for your product and your organisation.\n\n## Failure is Inevitable. Your Response is Optional.\n\nYou will never eliminate failure. That is not the goal.  \nThe goal is to ensure that failures are small, contained, quickly detected, and rapidly recovered without compromising your product or your business.\n\nIf you want resilience, build it deliberately. Make it part of your product. Treat it with the same seriousness as security, scalability, and usability. Anything less is just gambling that the next crisis will not be the one that takes you down.\n\n**Resilience is not heroism. Resilience is system design.**  \nOwn it as you would any other critical feature. Because it is one.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-06-09-resilience-is-part-of-the-product-not-an-afterthought\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-06-09-resilience-is-part-of-the-product-not-an-afterthought",
    "ReferencePath": "resources/blog/2025/2025-06-09-resilience-is-part-of-the-product-not-an-afterthought"
  },
  {
    "FrontMatter": {
      "title": "The Missing Lever in Agile Transformations",
      "short_title": "The Missing Lever in Agile Transformations",
      "description": "Most agile transformations fail by neglecting agency—empowering people and systems to adapt—making true agility possible through autonomy, evidence, and continuous learning.",
      "date": "2025-06-02T09:00:00Z",
      "weight": 345.0,
      "ResourceId": "RevK05qtZD7",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "the-missing-lever-in-agile-transformations",
      "aliases": [
        "/resources/RevK05qtZD7"
      ],
      "aliasesArchive": [
        "/the-missing-lever-in-agile-transformations",
        "/blog/the-missing-lever-in-agile-transformations"
      ],
      "concepts": [
        "Ethos"
      ],
      "categories": [
        "Product Development",
        "Technical Leadership",
        "Leadership"
      ],
      "tags": [
        "Agentic Agility",
        "Agile Strategy",
        "Organisational Change",
        "Social Technologies",
        "Organisational Agility",
        "Team Motivation",
        "Change Management",
        "Agile Transformation",
        "Agile Philosophy",
        "Business Agility",
        "Organisational Culture",
        "Strategic Goals",
        "Agentic Engineering",
        "Enterprise Agility",
        "Pragmatic Thinking"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:04Z",
        "short_title": "2025-07-07T16:43:46Z"
      }
    },
    "BodyContent": "Most agile transformations fail not because they get the ceremonies wrong, but because they misunderstand the real point: **cultivating agency** in people and systems.\n\nYou can install all the stand-ups, backlogs, retrospectives, and planning sessions you want. Without genuine agency, you're not transforming. You're decorating.\n\n**[Agentic Agility]({{< ref \"/tags/agentic-agility\" >}})** is the bridge between _doing Agile_ and _being agile_. It reconnects the mechanical adoption of frameworks with the deeper need for autonomy, purpose, and empirical adaptability. Without agency, agility remains performative theatre. With agency, it becomes adaptive strength.\n\n## Hollow Transformations vs. Human and System Agency\n\nMost transformations stall because they focus on ceremonial compliance:\n\n- Stand-ups happen daily\n- Stories are \"written\"\n- Retrospectives are \"held\"\n- Boards are \"managed\"\n\nMeanwhile, decision latency remains high, impediments are tolerated, and delivery remains brittle. The system stays paralysed by learned helplessness.\n\nTransformation is about a shift in **beliefs and constraints**, not just behaviours:\n\n- Individuals must believe they can shape outcomes.\n- Teams must be enabled to change how they work.\n- Organisations must evolve policies, structures, and practices that block responsiveness.\n\nThis is the ethos behind Agentic Agility: fostering **human agency** (the ability to act with intention) and **system agency** (the capacity for the system itself to adapt).\n\nWhen we focus transformation efforts solely on compliance and ceremony, we institutionalise fragility. When we focus on agency, we unleash resilience.\n\n## Agentic Agility and Evidence-Based Management\n\nYou cannot manage what you cannot measure. You cannot empower what you cannot observe.\n\nThis is why I have consistently pointed to [Evidence-Based Management (EBM)]({{< ref \"/resources/guides/evidence-based-management-guide\" >}})as a cornerstone for real change. EBM gives organisations the tools to:\n\n- **Measure actual outcomes**, not outputs.\n- **Challenge assumptions** with data, not dogma.\n- **Adapt strategies** based on evidence, not inertia.\n\nWithout an evidence-based feedback loop, agency collapses into chaos or bureaucratic decay. EBM operationalises Agentic Agility by aligning action with impact.\n\nTransformations without agency are short-lived.\nTransformations without evidence are blind.\nTransformations with neither are inevitable failures.\n\n## Real Agility is Agentic Agility\n\nAgentic Agility reframes transformation away from ceremonies and towards capacity:\n\n- Capacity for individuals to act intentionally.\n- Capacity for teams to shape their working systems.\n- Capacity for organisations to evolve dynamically in response to reality.\n\nThe next evolution of agility will not be led by those who install more frameworks. It will be led by those who build organisations capable of thinking, learning, and acting for themselves.\n\n**Agentic Agility is not an option. It is the missing lever for real change.**\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-06-02-the-missing-lever-in-agile-transformations\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-06-02-the-missing-lever-in-agile-transformations",
    "ReferencePath": "resources/blog/2025/2025-06-02-the-missing-lever-in-agile-transformations"
  },
  {
    "FrontMatter": {
      "title": "How to Build for Business Resilience and Continuity",
      "short_title": "How to Build for Business Resilience",
      "description": "Learn key strategies for building business resilience and continuity, including observability, system decoupling, routine deployments, team empowerment, and rapid recovery.",
      "date": "2025-05-26T09:00:00Z",
      "weight": 165.0,
      "ResourceId": "VThLnxVapgJ",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "how-to-build-for-business-resilience-and-continuity",
      "aliases": [
        "/resources/VThLnxVapgJ"
      ],
      "aliasesArchive": [
        "/how-to-build-for-business-resilience-and-continuity",
        "/blog/how-to-build-for-business-resilience-and-continuity"
      ],
      "concepts": [
        "Ethos"
      ],
      "categories": [
        "DevOps",
        "Engineering Excellence",
        "Product Development"
      ],
      "tags": [
        "Site Reliability Engineering",
        "Market Adaptability",
        "Operational Practices",
        "Pragmatic Thinking",
        "Evidence Based Management",
        "Technical Excellence",
        "Software Development",
        "Technical Mastery",
        "Continuous Delivery"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:05Z",
        "short_title": "2025-07-07T16:43:58Z"
      }
    },
    "BodyContent": "Business resilience is not an accident. It is the deliberate outcome of intelligent systems design, pragmatic decision-making, and organisational discipline. If you want resilience, you must build for it—**upfront, consistently, and aggressively**.\n\nHere is a pragmatic checklist for engineering true business resilience and continuity:\n\n## Observability and Telemetry First\n\nYou cannot manage what you cannot see. You cannot fix what you cannot detect.\n\n- **Embed telemetry at every level**: application, infrastructure, business processes.\n- **Define service level objectives (SLOs)** for your critical systems and actually measure against them.\n- **Monitor leading indicators**, not just trailing failures.\n- **Establish a live site culture**, not a \"we’ll find out when customers call\" culture.\n\nIf your systems are invisible until they explode, you are not resilient; you are negligent.\n\n## Decouple Systems Aggressively\n\nCoupling is a time bomb. When one piece falls, everything else falls with it.\n\n- **Bounded contexts** are non-negotiable. Embrace them.\n- **No logic in the data tier.** Databases store data, not behaviour. If your business rules are locked in SQL, you are one outage away from a complete operational collapse.\n- **Avoid shared databases**. Duplicate data if necessary. Loose coupling beats data purity.\n- **Prefer asynchronous messaging**. Synchronous systems are brittle under load and fail catastrophically.\n\nResilience comes from isolation. Systems must fail independently, not cascade like dominoes.\n\n### When the User Profile Service takes out the entire system\n\nFor a long time I have worked with the Azure [DevOps]({{< ref \"/categories/devops\" >}}) teams at Microsoft as an strategic customer and MVP and I have witnessed this lesson firsthand. One of the major outages of [Azure DevOps]({{< ref \"/tags/azure-devops\" >}}) was triggered by something that, at first glance, seemed trivial: the Profile Service. When the Profile Service went down, developers could no longer commit code, and product owners could not update backlog items. Why? Because the system could not resolve your friendly name from your authenticated ID.\n\nThe service was so tightly coupled into critical user flows that its failure crippled the entire platform.\n\nIn response, the teams created \"live site incident\" repair work and moved the Profile Service behind a **circuit breaker**. If the Profile Service went down again, it would degrade gracefully, not drag down the entire experience.\n\nAs an anecdotal aside, a few months later another unrelated service failed, and—unsurprisingly—it also took down large parts of the system. That was the final straw. The teams went on a full-scale mission to introduce the **circuit breaker pattern** across **every service**, making sure no single point of failure could collapse the platform again.\n\nDecoupling and graceful degradation are not academic exercises. They are mandatory if you value continuity.\n\n## Treat Deployments as Routine, Not Special\n\nEvery deployment is a practice run for disaster recovery. If deployment is a risky, complex, orchestrated event, you have already failed.\n\n- **Implement [Continuous Delivery]({{< ref \"/tags/continuous-delivery\" >}}) (CD)** so that deployments happen safely, frequently, and predictably.\n- **Use feature toggles** to separate code deployment from feature release.\n- **Automate rollbacks**. A failed deployment should not require heroics.\n\nIf your organisation fears deployment day, it is structurally fragile.\n\n## Empower Teams to Act Without Hierarchy Paralysis\n\nIn a crisis, the last thing you want is a command-and-control bottleneck. Empowerment is a precondition to survival.\n\n- **Pre-delegate authority** for critical systems response.\n- **Train teams** on incident management procedures, disaster recovery, and failover operations.\n- **Decentralise decision-making** to the people closest to the work.\n\nIn crisis, minutes matter. Top-down control costs lives and revenue.\n\n## Assume Everything Will Fail; Design to Recover Fast\n\nHope is not a strategy. Failure is inevitable. Recovery speed determines survival.\n\n- **Chaos engineering** is not optional; it is responsible practice.\n- **Design for graceful degradation**. Partial failure is better than total failure.\n- **Practice recovery drills**. Don't just have a DR plan; rehearse it until it is boring.\n\nIf you are not recovering faster than your competitors, you are losing.\n\n## DevOps, [Site Reliability Engineering]({{< ref \"/tags/site-reliability-engineering\" >}}), and Evidence-Based Management\n\nBusiness resilience is **DevOps in action**: the union of people, process, and products to enable continuous delivery of value to end users. Resilient systems emerge from the daily discipline of CI/CD, Infrastructure as Code (IaC), and monitoring as first-class citizens.\n\nIt is **Site Reliability Engineering (SRE)** lived, not aspirational. SRE teaches us that availability, latency, performance, efficiency, [change management]({{< ref \"/tags/change-management\" >}}), monitoring, and emergency response are all product features—just as important as the user-facing ones.\n\nIt is **Evidence-Based Management (EBM)** made real. Metrics like Mean Time to Recovery (MTTR), [Deployment Frequency]({{< ref \"/tags/deployment-frequency\" >}}), and [Customer Satisfaction]({{< ref \"/tags/customer-satisfaction\" >}}) are not vanity measures; they are survival metrics. They inform whether your investment in resilience is paying off or just theatre.\n\nResilience is not a project. It is an ethos. You must architect it into your systems, invest in it continuously, and operationalise it ruthlessly.\n\nOtherwise, you are gambling with your business and calling it strategy.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-05-26-how-to-build-for-business-resilience-and-continuity\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-05-26-how-to-build-for-business-resilience-and-continuity",
    "ReferencePath": "resources/blog/2025/2025-05-26-how-to-build-for-business-resilience-and-continuity"
  },
  {
    "FrontMatter": {
      "title": "Robots and AI Are Not Taking Our Jobs They Are Giving Us Our Dignity Back",
      "short_title": "How Robots and AI Restore Human Dignity",
      "description": "Explores how robots and AI automate repetitive work, challenging outdated job structures and enabling humans to focus on creativity, problem-solving, and meaningful tasks.",
      "date": "2025-05-19T09:00:00Z",
      "weight": 645.0,
      "ResourceId": "F0yVBj8Tx8H",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "robots-and-ai-are-not-taking-our-jobs-they-are-giving-us-our-dignity-back",
      "aliases": [
        "/resources/F0yVBj8Tx8H"
      ],
      "aliasesArchive": [
        "/robots-and-ai-are-not-taking-our-jobs-they-are-giving-us-our-dignity-back",
        "/blog/robots-and-ai-are-not-taking-our-jobs-they-are-giving-us-our-dignity-back"
      ],
      "concepts": [
        "Philosophy"
      ],
      "categories": [
        "Uncategorized"
      ],
      "tags": [
        "Organisational Agility"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:06Z",
        "short_title": "2025-07-07T16:44:06Z"
      }
    },
    "BodyContent": "The future is not about humans fighting to keep soul-crushing work. It is about letting go of the roles we invented to dehumanise ourselves.\n\nWe created jobs like scanning groceries, cleaning toilets, packing boxes, and driving taxis not because they were noble pursuits, but because we needed to systematise output. We shaped them at the height of industrialisation under the false assumption that most people were incapable of thinking critically or creatively. That assumption was, and remains, wrong.\n\nHumans harnessed fire, developed tools, built cities, and explored space. Yet we still have people herded into checkout lanes scanning barcodes for £10 an hour because we have convinced ourselves that’s all they can do. This is not dignity. It is systemic failure.\n\n**Robots** started the change by replacing physical repetition. **AI** is accelerating it by replacing cognitive repetition. Neither are threats to humanity. They are threats to the systems that tried to industrialise it.\n\n## Scientific Management: A Philosophy of Subjugation\n\nFrederick Taylor’s Scientific Management—better known as Taylorism—was never about human potential. It was about control and compliance. It engineered mediocrity, not mastery.\n\n- **Task and Bonus Systems**: Set quotas just above sustainable capacity. Underpay unless \"targets\" are hit. Replace pride in craftsmanship with fear of poverty.\n- **Departments and Specialisation**: Teach people one sliver of a process. Reduce communication. Stifle systemic understanding. \"Efficient,\" yes. Humane, absolutely not.\n\n- **Job Titles as Status Symbols**: Create hierarchies not based on contribution or value, but on titles and politics. Reward political manipulation over problem-solving.\n\nThese patterns are not relics of history. They are alive and well in most organisations today. Hierarchies still prioritise power over outcomes. Standardisation still trumps collaboration. Fear still motivates more than trust.\n\nWe industrialised people because it made them easier to control. Now, automation and AI are finally taking those shackles off.\n\n## The Knowledge Age Demands Heads That Count\n\nIn a knowledge economy, compliance is worthless. We do not need more human robots performing repeatable tasks. We need humans solving problems, thinking critically, and delivering outcomes.\n\nThe organisations that thrive are the ones that realise this. They pay people enough that food and shelter are no longer their motivators (re Daniel Pink). They create environments where autonomy, mastery, and purpose are what drive performance—not carrot-and-stick bonus schemes.\n\nIf your workforce needs extrinsic rewards to perform, you have already failed them.\n\n## If You Are Still Paying Bonuses, You Are Still in the Industrial Age\n\nOrganisations still running bonus schemes, still obsessed with job titles, and still measuring success by output rather than outcome are clinging desperately to an age that is already automated away.\n\nYou are not preparing for the future. You are delaying your own obsolescence.\n\nThe simple truth:\n\n**Change your company, or change your company.**\n\nThe knowledge age is here. It is not waiting for your permission.\n\n## AI: The Next Step Towards Restoring Humanity at Work\n\nAI is not replacing humans. It is replacing the work that never deserved a human in the first place.\n\nWriting repetitive reports. Copying data between systems. Processing endless low-value approvals. AI is the natural continuation of automation, taking rote cognitive tasks off our plates the same way robots took rote physical tasks out of our hands.\n\nThis is not a threat. It is a liberation.\n\nEvery time AI replaces another mechanical task, it creates space for something better: creativity, strategy, empathy, innovation.\n\nIt gives us the opportunity to do work that demands distinctly human qualities—qualities that no machine can replicate.\n\nIf your organisation sees AI as a threat to its workforce, it is a sign you have industrialised your people. If you see AI as a tool for elevating humanity, you are building for the future.\n\nRobots freed our hands. AI is freeing our minds.\n\nThe only real question is: **Are you ready to stop treating people like machines?**\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-05-19-robots-and-ai-are-not-taking-our-jobs\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-05-19-robots-and-ai-are-not-taking-our-jobs",
    "ReferencePath": "resources/blog/2025/2025-05-19-robots-and-ai-are-not-taking-our-jobs"
  },
  {
    "FrontMatter": {
      "title": "Fragile by Design: The Cost of Pretending to Be Resilient",
      "short_title": "Fragile by Design: The Cost of Fake Resilience",
      "subtitle": "You don't rise to the level of your continuity plan. You fall to the level of your last real test.",
      "description": "Explores how poor engineering, shallow product thinking, and organisational denial lead to fragile systems, stressing that true resilience requires rigorous, real-world testing.",
      "date": "2025-05-12T09:00:00Z",
      "weight": 165.0,
      "ResourceId": "LGGuvRq4g7p",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "hybrid",
      "slug": "fragile-by-design-the-cost-of-pretending-to-be-resilient",
      "aliases": [
        "/resources/LGGuvRq4g7p"
      ],
      "aliasesArchive": [
        "/fragile-by-design--the-cost-of-pretending-to-be-resilient",
        "/blog/fragile-by-design--the-cost-of-pretending-to-be-resilient"
      ],
      "concepts": [],
      "categories": [
        "Engineering Excellence",
        "Product Development",
        "Technical Leadership"
      ],
      "tags": [
        "Technical Mastery",
        "Pragmatic Thinking",
        "Engineering Practices",
        "Site Reliability Engineering"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:09Z",
        "short_title": "2025-07-07T16:44:17Z"
      }
    },
    "BodyContent": "Most systems are not resilient. They are fragile by design—propped up by a fantasy of \"continuity\" that vanishes the moment real pressure hits.\n\nSpain’s national blackout. Portugal’s cascading failures. Oracle’s hospital cloud outage. Heathrow’s catastrophic shutdown. These were not accidents. They were not rare, unpredictable events. They were the inevitable consequences of bad engineering, shallow product thinking, and organisational self-delusion.\n\nResilience is not a checkbox. It is not a compliance exercise. It is not a hope and a prayer filed away in a disaster recovery plan. Resilience is hard. It is costly. It must be engineered, tested, and verified under real-world conditions—or it does not exist.\n\n## Bad Engineering\n\nReal resilience assumes things will fail. Networks will fail. Authentication systems will fail. People will make mistakes. If your architecture does not _assume failure_ at every level, you are not resilient; you are brittle.\n\nSpain’s energy grid collapsed because it was optimised for efficiency, not survivability. No dynamic rerouting. No true load isolation. No meaningful observability. Their system was designed for perfect operating conditions that do not exist outside PowerPoint decks.\n\nOracle’s outage was even worse. Critical healthcare systems went offline because Oracle’s cloud infrastructure had no effective multi-region failover. Their architecture did not degrade gracefully; it fell over completely. That is not resilience. That is negligence at scale.\n\n## Bad Product and Continuity Thinking\n\nResilience is a **product capability**. If your product cannot survive failure, it is not a product. It is a liability.\n\nSpain, Portugal, Oracle—all treated continuity as an afterthought. As long as the lights were on today, everything was declared fine. Until it was not.\n\nReal product [leadership]({{< ref \"/categories/leadership\" >}}) demands harder questions: _When—not if—this part fails, how will our system recover? How will our customers experience it? How fast can we restore service? How much risk are we carrying—and is that risk acceptable?_\n\nIf those questions are not part of your roadmap, your architecture, and your operational strategy, you are not building resilience. You are building a house of cards.\n\n## Organisational Blindness\n\nThe real failure sits higher up the chain. Leadership failed to create a culture that prioritised operational survivability over operational fantasy.\n\nI have lived through this firsthand. At Merrill Lynch, I participated in two major disaster recovery exercises. Both were declared “successful.” Both were complete failures.\n\nNot a single system restored was actually usable. Systems were technically “back online”—but functionally, nothing worked. And the root cause was obvious: Active Directory, the system everything depended on for authentication, was never successfully recovered. Without it, every other \"restored\" system was dead weight.\n\nIronically, my application was successfully restored. We assumed it would have been usable—_if_ Active Directory had been available. But we never found out. Two years running, the same critical dependency remained broken, and nobody was willing to call it what it was: systemic failure hidden behind fake success metrics.\n\nHeathrow Airport offers another textbook case of organisational blindness disguised as resilience. When a fire broke out at one of their substations, they publicly blamed the disruption on their third-party power supplier. What they failed to mention was critical: Heathrow receives power from _three independent substations_, any one of which can fully power the airport alone.\n\nThe real problem was not the power supply it was a fluctuation in the power supply. It was Heathrow’s own disaster recovery system, designed to “protect” infrastructure by shutting everything down that detected that fluctuation and activated.  \nThe result? Heathrow’s entire IT backbone collapsed. It took the rest of the day to get basic systems running again—and much longer to recover from the cascading operational chaos.\n\nInstead of owning the internal failure, leadership pointed fingers outward. It is the same story everywhere: an unwillingness to face the reality that their own fake resilience made the disaster worse.\n\n## Real Resilience: Iterating Over the Pain\n\nNot every story ends in failure. There are organisations that do it right—and the difference is discipline.\n\nTake Rackspace. During catastrophic floods in London, when almost every other datacentre in the city failed, Rackspace’s facility stayed operational. Their backup generators worked exactly as expected. While others blamed suppliers and scrambled for excuses, Rackspace quietly kept their customers online.\n\nWhen asked why their systems worked when everyone else’s failed, the CEO simply held up a key.\n\nIt was the key to the power room.\n\nEvery month, without fail, he would walk down, unlock the main breaker, and physically pull it—shutting off external power. Not in theory. Not in a simulation. A real, full transfer to emergency backup power under real-world conditions.\n\nBecause of that brutal discipline, they did not hope their disaster recovery systems would work. They _knew_. They had tested it, again and again, under real conditions. They iterated over the pain.\n\nAnd that is the lesson:  \nIf something is hard, you must do it _more often_, not less.  \nIf failure is painful, you must _lean into it_, not avoid it.\n\nOnly by living through controlled, intentional failures—early, often, and brutally—can you build true resilience.\n\nYou cannot wait until it matters. You cannot prepare only on paper. You must _earn_ resilience by testing your systems, exposing your weaknesses, and getting punched in the face repeatedly until you are strong enough to survive the real thing.\n\n## Resilience Is Built, Not Bought\n\nYou cannot buy resilience from a vendor. You cannot inherit it automatically because you deployed to \"the cloud.\" You cannot declare yourself resilient by writing it into your incident response plan.\n\nReal resilience is built. It is designed in. It is iterated over. It is relentlessly tested. It is painful, slow, and expensive. But the alternative—the fragility we saw in Spain, Portugal, Oracle, and Heathrow—is far more costly.\n\nIf you are not engineering for failure, you are engineering for collapse.\n\nFragility is not an accident. It is a design choice.  \nPretending otherwise only guarantees you will learn the hard way.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-05-12-fragile-by-design-the-cost-of-pretending-to-be-resilient\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-05-12-fragile-by-design-the-cost-of-pretending-to-be-resilient",
    "ReferencePath": "resources/blog/2025/2025-05-12-fragile-by-design-the-cost-of-pretending-to-be-resilient"
  },
  {
    "FrontMatter": {
      "title": "The Role of Agency in Scrum: Why Self-Management Without Agency is a Lie",
      "short_title": "The Role of Agency in Scrum",
      "description": "Explains why true Scrum requires real team agency, not just self-management in name, and how lacking agency leads to ineffective, ritualistic Agile practices.",
      "date": "2025-05-01T09:00:00Z",
      "weight": 200.0,
      "ResourceId": "uwJYNXG7yIu",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "the-role-of-agency-in-scrum-why-self-management-without-agency-is-a-lie",
      "aliases": [
        "/resources/uwJYNXG7yIu"
      ],
      "aliasesArchive": [
        "/the-role-of-agency-in-scrum-why-self-management-without-agency-is-a-lie",
        "/blog/the-role-of-agency-in-scrum--why-self-management-without-agency-is-a-lie",
        "/the-role-of-agency-in-scrum--why-self-management-without-agency-is-a-lie"
      ],
      "concepts": [
        "Ethos"
      ],
      "categories": [
        "Scrum",
        "Product Development",
        "Technical Leadership"
      ],
      "tags": [
        "Social Technologies",
        "Professional Scrum",
        "Agentic Agility",
        "Agile Frameworks",
        "Agile Transformation",
        "Self Organisation",
        "Team Motivation",
        "Agile Product Management",
        "Team Performance",
        "Scrum Master",
        "Agile Philosophy",
        "Scrum Team",
        "Software Development",
        "Pragmatic Thinking",
        "Agile Values and Principles"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:11Z",
        "short_title": "2025-07-07T16:44:33Z"
      }
    },
    "BodyContent": "[Scrum]({{< ref \"/categories/scrum\" >}}) is often misunderstood as a set of ceremonies or a lightweight [project management]({{< ref \"/tags/project-management\" >}}) method. It is neither. Scrum is a social technology built around the ethos of Agile, enabling teams to deliver adaptive solutions in complex environments. At its core lies a fundamental, non-negotiable requirement: self-management.\n\nBut self-management is not simply a label you apply to teams. It demands something deeper and harder: real agency.\n\nWithout agency, Scrum collapses into shallow ritual. Without agency, accountability is performative, not real.  \nWithout agency, you are not doing Scrum. You are enacting a fragile imitation of agility.\n\n## Scrum _Is_ Agile — and Agile Demands Self-Management\n\nAgile and Scrum are often conflated or treated as separate. Let us be clear: True Scrum is Agile. Scrum operationalises Agile principles with discipline, [transparency]({{< ref \"/tags/transparency\" >}}), and empiricism. It creates a bounded environment where teams can thrive.\n\nThe Agile Manifesto (2001) made it clear:\n\n> _The best architectures, requirements, and designs emerge from self-organizing teams._\n\nSelf-organisation was never about anarchy. It was about **teams owning how they deliver value**. Agile assumes teams will figure out the best way to achieve goals — not be told exactly what to do.\n\nScrum sharpened this requirement in the 2020 Scrum Guide:\n\n> _Scrum Teams are cross-functional and self-managing, meaning they internally decide who does what, when, and how._\n\nSelf-management is not a bonus feature. It is the foundation. Without it, Scrum is impossible.\n\n## Agency: The Prerequisite for Accountability\n\nAgency is the power to make decisions and act toward outcomes you are accountable for. It is inseparable from accountability itself. Without agency, accountability is a façade — a mechanism for assigning blame rather than empowering success.\n\nScrum defines clear accountabilities:\n\n- **[Product Owner]({{< ref \"/tags/product-owner\" >}})**: Maximising value.\n- **Developers**: Delivering a usable [Increment]({{< ref \"/tags/increment\" >}}) every Sprint.\n- **[Scrum Master]({{< ref \"/tags/scrum-master\" >}})**: Enabling the [Scrum Team]({{< ref \"/tags/scrum-team\" >}})’s effectiveness.\n\nThese accountabilities **assume** that those who hold them [have real authority to act]({{< ref \"/resources/blog/2025/2025-03-12-balance-of-leadership-and-control-in-scrum\" >}}).\n\nWhen organisations strip away decision-making power but leave accountability in place, they are not enabling agility. They are constructing a system of learned helplessness.\n\n## The Myth of \"Self-Managing\" Teams\n\nMany organisations today claim to embrace \"self-managing teams\" but operate in ways that directly undermine them:\n\n- Sprint Goals are dictated, not created.\n- Work is assigned to individuals by managers.\n- Technical decisions are second-guessed by external authorities.\n\nThis is not self-management. This is hierarchical command-and-control wrapped in daily standups and sticky notes.\n\nIf your team cannot decide _how_ to achieve the Sprint Goal, they are not self-managing. They are being managed under a different name.\n\n## Weak Scrum Masters Enable Weak Scrum\n\nScrum Masters are **accountable for the effectiveness of the Scrum Team**. Yet in practice, [many are limited to scheduling events and taking notes]({{< ref \"/resources/blog/2024/2024-09-05-the-incompetent-scrum-master-why-most-are-failing-and-what-they-should-know\" >}}), with no real authority to challenge systemic dysfunction.\n\nA Scrum Master without agency is not fulfilling their accountability. They are facilitating ceremony without enabling change.\n\nScrum Masters must:\n\n- **Teach** [leadership]({{< ref \"/categories/leadership\" >}}) and teams what true self-management entails.\n- **Coach** teams to take ownership of their processes and outcomes.\n- **Mentor** individuals to step into accountability with courage.\n- **Facilitate** organisational evolution, not just event logistics.\n\nIf you are a Scrum Master and [you cannot do these things because of organisational resistance]({{< ref \"/resources/blog/2025/2025-03-12-great-scrum-masters-need-technical-business-and-organisational-mastery\" >}}), you must raise it visibly. Otherwise, you are complicit in the degradation of Scrum.\n\n## Why Weak Implementations Collapse\n\nWhen organisations adopt the **appearance** of Scrum without enabling the **conditions** for Scrum, dysfunction inevitably follows:\n\n- Daily Scrums become status reporting.\n- Sprint Reviews become formalities with no real inspection.\n- Retrospectives become meaningless because the team lacks the power to change anything.\n\nScrum without agency becomes a theatre production. A ritualistic reenactment of agility, without any of the outcomes.\n\nWhen organisations complain that \"[Scrum doesn’t work]({{< ref \"/resources/blog/2021/2021-04-19-stop-normalizing-unprofessional-behaviour-in-the-name-of-agility\" >}}),\" the reality is usually simpler: **they refused to enable it to work**, and they [ignore the evidence of their own dysfunction]({{< ref \"/resources/blog/2024/2024-04-17-you-cant-stop-the-signal-but-you-can-ignore-it\" >}}).\n\n## The Path Forward: Fight for Agency\n\nIf you are serious about creating real, resilient agility:\n\n- **Scrum Masters** must coach, teach, mentor, and cause real change — not just facilitate ceremonies.\n- **Product Owners** must demand the authority to own the backlog and drive [product strategy]({{< ref \"/tags/product-strategy\" >}}).\n- **Developers** must guard their right to decide how to build and deliver working product Increments.\n\nAnd leadership must understand: if you want the results Scrum promises, you must create the environment Scrum requires.\n\nSelf-management is not optional. Agency is not optional. Without them, you have nothing.\n\n## Conclusion\n\nScrum depends on self-management, and self-management depends on agency. Remove agency, and you remove the heart of Scrum. All that remains is empty ceremony, a hollow simulation of Agile values.\n\nIf you truly want the benefits of Scrum — adaptability, resilience, continuous [value delivery]({{< ref \"/tags/value-delivery\" >}}) — you must be willing to do the hard work of granting real agency to those accountable for outcomes.\n\n**Scrum without agency is not Scrum. It is theatre.**\n\nChoose what you want to build.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-05-01-the-role-of-agency-in-scrum-why-self-management-without-agency-is-a-lie\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-05-01-the-role-of-agency-in-scrum-why-self-management-without-agency-is-a-lie",
    "ReferencePath": "resources/blog/2025/2025-05-01-the-role-of-agency-in-scrum-why-self-management-without-agency-is-a-lie"
  },
  {
    "FrontMatter": {
      "title": "Your Evolving Definition of Done",
      "short_title": "Your Evolving Definition of Done",
      "description": "Explains how the Definition of Done evolves in Scrum, aligning team practices with organisational standards to ensure consistent quality, compliance, and business value delivery.",
      "date": "2025-03-31T09:00:00",
      "weight": 100.0,
      "ResourceId": "5wIEg7lD_Xd",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "your-evolving-definition-of-done",
      "aliases": [
        "/resources/5wIEg7lD_Xd"
      ],
      "aliasesArchive": [
        "/your-evolving-definition-of-done",
        "/blog/your-evolving-definition-of-done"
      ],
      "layout": "blog",
      "concepts": [
        "Strategy"
      ],
      "categories": [
        "Product Development",
        "Engineering Excellence",
        "Product Management"
      ],
      "tags": [
        "Definition of Done",
        "Operational Practices",
        "Agile Frameworks",
        "Software Development",
        "Continuous Improvement",
        "Technical Mastery",
        "Market Adaptability",
        "Agile Product Management",
        "Professional Scrum",
        "Shift Left Strategy",
        "Value Delivery",
        "Common Goals",
        "Technical Excellence",
        "Engineering Practices",
        "Product Delivery"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:17Z",
        "short_title": "2025-07-07T16:45:08Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog"
    },
    "BodyContent": "The [Definition of Done (DoD)]({{< ref \"/tags/definition-of-done\" >}}) is not a static artefact; it evolves over time as a [Scrum Team]({{< ref \"/tags/scrum-team\" >}}) gains experience and capability. While the [Scrum Guide]({{< ref \"/resources/guides/scrum-guide\" >}}) acknowledges that teams may refine their DoD to improve product quality, there’s an often overlooked piece: Organisations should also provide an organisational Definition of Done that reflects their needs. This organisational perspective ensures that [Scrum]({{< ref \"/categories/scrum\" >}}) Teams build on a solid foundation, aligning technical execution with [strategic goals]({{< ref \"/tags/strategic-goals\" >}}).\n\nThe [Definition of Done (DoD) is an objective, measurable standard of quality]({{< ref \"/resources/blog/2025/2025-01-03-definition-of-done-objective-vs-subjective\" >}})—not a negotiable target. Keep it clear, enforceable, and automated to ensure every [Increment]({{< ref \"/tags/increment\" >}}) meets professional expectations.\n\n## Definition of Done - The Organisational quotient\n\nFor a product to deliver real value, its quality criteria must align with organisational and market expectations. It should meet a minimum quality standard that ensures usability while safeguarding the organisation, its employees, and its users. Any failure to do so could damage the organisation’s reputation and trust in the product.\n\nThis means organisations should define a business DoD that may include:\n\n- Regulatory compliance\n- Market readiness (e.g., beta testing completion, go-to-market strategies)\n- Customer experience and feedback incorporation\n- Financial viability assessment\n- Alignment with broader company objectives\n\nWithout this business-level perspective, teams risk optimising for technical completeness while missing the broader [value delivery]({{< ref \"/tags/value-delivery\" >}}) picture. The result of many iterations of the organisational definition of done for a product might look like:\n\n> Live an in production\n>\n> gathering telemetry\n>\n> supporting or diminishing\n>\n> the starting hypothesis\n\nThis short sentence packs a lot into it, and it's a commercial product definition of \"done\" for a team I have collaborated closely with for over 17 years.\n\n1. \"Live an in production\" - done here mean that it is in the hands of real users\n\n2. \"gathering telemetry\" - done here mean that the Developers must add code that collects relevant information from usage, performance, and such...\n\n3. \"supporting or diminishing the starting hypothesis\" - Done here means that the team must define success metrics before building a feature or capability, ensuring that the collected data provides clear evidence of whether the intended outcomes are being achieved.\n\nNone of these elements define the \"why\" or \"what\" of what we're building—those are captured in the backlogs. Instead, they establish the minimum quality standard required for work to be considered done.\n\n## Definition of Done - Translating Organisational Standards into Team Practice\n\nWhile Scrum Teams are self-managing, that doesn’t mean they can do whatever they want. They operate within a structured environment, within a [balance of leadership and control]({{< ref \"/resources/blog/2025/2025-03-12-balance-of-leadership-and-control-in-scrum\" >}}) that upholds both autonomy and accountability. Scrum isn’t anarchy; it’s a [social technology]({{< ref \"/tags/social-technologies\" >}}) that enables self-management within clear constraints—Scrum events, commitments, and organisational expectations.\n\nEach Scrum Team must interpret the organisational Definition of Done within their context, shaping an engineering-level DoD that aligns with it. While examples can guide them, it's the team’s responsibility to determine what Done means within organisational constraints.\n\nIn addition to supporting the organisational definition of done, a robust DoD ensures that work meets a consistent level of quality before it is considered complete. This includes [engineering practices]({{< ref \"/tags/engineering-practices\" >}}), preferably within the bounds of a [shift-left strategy]({{< ref \"/tags/shift-left-strategy\" >}}), such as:\n\n- **Writing Unit and Integration Tests** – with a preference for shifting testing earlier by adopting Test-Driven Development (TDD) and automated integration testing, ensuring issues are caught before coding progresses too far—and preferably making tests a prerequisite for writing new code.\n\n- **Performing Code Reviews** – Rather than manual code reviews create automate code quality checks using static analysis and enforce good practices before manual reviews, allowing developers to focus on deeper logic and architectural concerns—and preferably integrating peer reviews into the development workflow, such as pair or mob programming.\n\n- **Adhering to Security and Compliance Requirements** – try embeding security scanning into [CI/CD pipelines]({{< ref \"/tags/continuous-delivery\" >}}) with automated dependency checks and policy enforcement, catching vulnerabilities before they reach production—and preferably treating security as code, ensuring it evolves alongside development.\n\n- **Maintaining Updated Documentation** – Automate as much of your documentation updates as possible using tools that generate API references and architecture diagrams directly from code, keeping documentation relevant and accurate—and preferably making documentation a non-negotiable part of the Definition of Done (DoD).\n\n- **Ensuring Deployments are Automated and Repeatable** – Implement Infrastructure as Code (IaC) and continuous deployment pipelines to guarantee consistent, error-free releases—and preferably shifting validation left with feature flags, automated rollback strategies, and deployment previews.\n\nEach aspect contributes to quality, reducing the likelihood of defects and [technical debt]({{< ref \"/tags/technical-debt\" >}}). However, quality isn’t just a technical concern—it is an economic and strategic one.\n\n## The Evolution of Done Over Time\n\nNew teams often start with a weak DoD that doesn’t yet guarantee releasability. A brownfield product with legacy constraints may have a DoD that initially excludes automation, testing, or [continuous deployment]({{< ref \"/tags/deployment-frequency\" >}}) due to existing technical debt. Over time, through Sprint Retrospectives and deliberate improvements, the DoD should:\n\n1. Start at a minimal viable level (e.g., basic testing, peer reviews).\n2. Expand to include [automated testing]({{< ref \"/tags/automated-testing\" >}}), security checks, and CI/CD.\n3. Reach a state where every increment is truly releasable.\n\nAn experienced Scrum Team should aim for a DoD that ensures shippability at the end of every Sprint. Anything less introduces unnecessary risk and delays value realisation.\n\n#### Common Misconceptions\n\n1. **Can the DoD Change Per Sprint?**\\\n   Yes, but only to **increase quality**. The Sprint Retrospective is the right place to discuss DoD improvements, not reductions. However, if an issue arises, address it immediately—don’t wait for the Retrospective.\n\n2. **Can the DoD Be Lowered to Deliver More Features?**\n\n   No. Quality is a long-term investment, not a short-term lever to pull for speed. A Scrum Team has no authority to cut quality—that's a financial and risk decision made at the highest level. This authority rarely sits with project managers or middle management. If someone asks you to lower quality, tell them to get it in writing from the financial director.\n\n3. **Can We Have Different DoDs Per Backlog Item?**\n\n   No. The DoD is a universal standard applied to all work, ensuring consistency in quality. Acceptance Criteria define specific conditions for a backlog item, but these conditions do not belong in the DoD.\n\n4. **Should the DoD Be Fluid and Change Every Sprint?**\n\n   No. A fluctuating DoD signals dysfunction unless it’s always improving. Constant changes undermine [transparency]({{< ref \"/tags/transparency\" >}}) and disrupt planning. Evolution should be deliberate, incremental, and focused on raising quality—not shifting goalposts.\n\n## DoD as a Strategic Lever\n\nA strong DoD isn’t just about engineering—it’s about protecting revenue, managing risk, and ensuring predictable delivery. Weak DoD practices lead to costly rework, delayed releases, and customer dissatisfaction. By embedding security, compliance, and quality checks into the development cycle, organisations reduce their exposure to financial and reputational risks. Teams that consistently meet a well-defined DoD can deliver with greater confidence, improving [forecasting]({{< ref \"/tags/forecasting\" >}}) and market responsiveness.\n\nA strong DoD reduces rework, increases predictability, and aligns technical work with business value. As organisations evolve, so should their quality expectations. This continuous refinement is not just a technical necessity—it’s a competitive advantage.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-03-17-your-evolving-definition-of-done\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-03-17-your-evolving-definition-of-done",
    "ReferencePath": "resources/blog/2025/2025-03-17-your-evolving-definition-of-done"
  },
  {
    "FrontMatter": {
      "title": "Great Scrum Masters Need Technical, Business, and Organisational Mastery",
      "short_title": "Scrum Mastery: Technical, Business, Organisational",
      "description": "Scrum Masters are most effective when they combine leadership skills with technical, business, and organisational mastery to support teams, Product Owners, and change.",
      "date": "2025-03-24T09:00:00",
      "weight": 175.0,
      "contributors": [
        {
          "name": "Henrik Berglund",
          "external": "https://www.linkedin.com/in/henrikber/"
        }
      ],
      "ResourceId": "dQjKsWR5qfn",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "great-scrum-masters-need-technical-business-and-organisational-mastery",
      "aliases": [
        "/resources/dQjKsWR5qfn"
      ],
      "aliasesArchive": [
        "/great-scrum-masters-need-technical-business-and-organisational-mastery",
        "/blog/great-scrum-masters-need-technical-business-and-organisational-mastery",
        "/great-scrum-masters-need-technical--business--and-organisational-mastery",
        "/blog/great-scrum-masters-need-technical--business--and-organisational-mastery"
      ],
      "layout": "blog",
      "concepts": [
        "Framework"
      ],
      "categories": [
        "Scrum",
        "Leadership",
        "Product Management"
      ],
      "tags": [
        "Professional Scrum",
        "Scrum Team",
        "Scrum Master",
        "Agile Frameworks",
        "Agile Transformation",
        "Engineering Practices",
        "Software Development",
        "Competence",
        "Pragmatic Thinking",
        "Team Performance",
        "Product Delivery",
        "Organisational Agility",
        "Value Delivery",
        "Operational Practices",
        "Market Adaptability"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:18Z",
        "short_title": "2025-07-07T16:45:15Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog"
    },
    "BodyContent": "[Scrum Masters]({{< ref \"/tags/scrum-master\" >}}) don’t need to be subject-matter experts in the way traditional management once required. We’re no longer in an era where managers direct unskilled labour; modern teams are intelligent, capable, and cross-functional. The [Scrum]({{< ref \"/categories/scrum\" >}}) Master’s responsibility is not to do the work, but to enable others to do it better. They are leaders.\n\n[Leadership]({{< ref \"/categories/leadership\" >}}) requires a different kind of expertise—expertise in change, collaboration, [coaching]({{< ref \"/tags/coaching\" >}}), facilitation, conflict navigation, communication, team development, [personal]({{< ref \"/tags/personal\" >}}) growth, and a [ballance of leadership with control]({{< ref \"/resources/blog/2025/2025-03-12-balance-of-leadership-and-control-in-scrum\" >}}). These are non-negotiable.\n\nBut these skills alone are not enough; we should recognise that for leaders to be successful, domain-specific mastery matters too. A Scrum Master who understands the _technical, business, and organisational_ context their team operates in can better remove impediments, facilitate learning, and support adaptation.\n\nThis idea doesn’t replace the core leadership capabilities. It **builds on them**.\n\nFor a Scrum Master to be an effective _Teacher, Mentor, Coach, and Facilitator_, they require a deep understanding, or mastery, of the team's work, the business they operate in, and the organisation they are navigating.\n\nMastery in this context means knowledge and understanding of the philosophies, methods, practices, and techniques relevant to the domain in which the team operates. If a team is developing medical devices, the Scrum Master should understand that field's regulatory and quality requirements. If they are working in industrial design, they need familiarity with prototyping, material constraints, and production processes. If they are developing software, they should understand [software development]({{< ref \"/tags/software-development\" >}}) practices, including [Continuous Delivery]({{< ref \"/tags/continuous-delivery\" >}}), [Test First]({{< ref \"/tags/test-first-development\" >}}), and [DevOps]({{< ref \"/categories/devops\" >}}) principles.\n\nWithout this domain knowledge, how can they effectively help the team deliver value?\n\nThere are three key areas of mastery that make a Scrum Master truly effective: **[Technical Mastery]({{< ref \"/tags/technical-mastery\" >}}), Business Mastery, and Organisational Evolutionary Mastery.**\n\n## Three Masteries of an effective Scrum Master\n\nMany individuals take on the Scrum Master role without fully developing the expertise needed in even one of these masteries, let alone all three. This gap in [competence]({{< ref \"/tags/competence\" >}}) can hinder the [Scrum Team]({{< ref \"/tags/scrum-team\" >}})’s ability to navigate challenges effectively and maximise their potential. They often fall into the assumption of the knowledge fallacy trap because they don't have the skills, knowledge, or experience to identify the deficiency in or corruption of a key practice or capability for the Scrum Team to be effective.\n\nWhile it is not mandatory to have all of these masteries to the same depth, depending on the size of the organisation and others working in the same field, a great Scrum Master possesses these three critical masteries that enable them to serve the Scrum Team, the [Product Owner]({{< ref \"/tags/product-owner\" >}}), and the organisation effectively.\n\n### 1. Technical Mastery\n\nOne of the core capabilities of any team is their ability to deliver a valuable, usable product. For a Scrum Master to coach them on creating that value, they need to understand what effective looks like in the context. If they are working with a hardware team, they should understand product engineering and manufacturing constraints. If they are in finance, they should understand financial modelling and compliance.\n\nThe key is domain-specific technical mastery that allows them to facilitate discussions, remove impediments, and guide the team towards better practices. If they are working with software teams they should be able to teach and coach the team members in the technical practices for software, for example:\n\n- **Coach the Developers in SOLID principles** – ensuring that the team adheres to fundamental object-oriented design principles to create maintainable and scalable software.\n- **Facilitate the adoption of Static Analysis & Linting** – Encouraging automated code quality checks to catch defects early and enforce coding standards.\n- **Mentor the team in Pair Programming** – Promoting collaborative coding to enhance knowledge sharing, reduce defects, and improve overall code quality.\n- **Instill Test-Driven Development (TDD) practices** – Guiding the team to write tests before code, ensuring robust, verifiable, and high-quality software.\n- **Enable [Continuous Integration]({{< ref \"/tags/continuous-integration\" >}}) and Deployment (CI/CD)** – Driving automation and frequent delivery to accelerate feedback loops and improve release reliability.\n- **Advocate for Cloud and DevOps principles** – Teaching the team how to leverage cloud-native architectures, Infrastructure as Code (IaC), and automated operations.\n- **Ensure Clean Code and Refactoring discipline** – Encouraging best practices that result in readable, maintainable, and scalable codebases while reducing [technical debt]({{< ref \"/tags/technical-debt\" >}}).\n\nIn other contexts, like designing hardware, creating movies, or creating financial accounts, they would need to teach and coach the technical practices that make sense for those contexts. These skills help the Scrum Master serve the Scrum Team and increase their effectiveness.\n\n> The Scrum Master serves the Scrum Team in several ways, including:\n>\n> - Coaching the team members in self-management and cross-functionality;\n> - Helping the Scrum Team focus on creating high-value Increments that meet the [Definition of Done]({{< ref \"/tags/definition-of-done\" >}});\n> - Causing the removal of impediments to the Scrum Team’s progress; and,\n> - Ensuring that all Scrum events take place and are positive, productive, and kept within the timebox.\n>\n>   — [The Scrum Master, Scrum Guide]({{< ref \"/resources/guides/scrum-guide\" >}})\n\nWithout technical mastery within the relevant domain, guiding a Scrum Team towards high-value [product delivery]({{< ref \"/tags/product-delivery\" >}}) is challenging.\n\n### 2. Business Mastery\n\nThe Product Owner is a key position that sets the tone for product leadership and defines success within the organisation. For them to be successful, they must implement modern [product management]({{< ref \"/categories/product-management\" >}}) practices and have a value-driven mindset. The Product Owner should be accountable for and have the authority to maximise the value of the product and the effectiveness of the [Product Backlog]({{< ref \"/tags/product-backlog\" >}}). Not every person who takes on the accountability of the Product Owner role will already possess these skills or even be aware that they should. Developing expertise in modern product management practices and value-driven decision-making is an ongoing journey. Since an effective Scrum Team requires an effective Product Owner, it falls within the accountability of the Scrum Master to teach, coach, and mentor the Product Owner as needed. This requires that they understand the business context of the Scrum Team and its product as well as the product management processes, techniques, and practices that a Product Owner might use to maximise the value of the Scrum Team's work.\n\nThis includes that the Product Owner is able to:\n\n- **Leverage customer insights and market research** – The Scrum Master helps the PO incorporate data-driven insights from customer feedback, competitive analysis, and market trends to inform Product Backlog decisions.\n- **Articulate the strategic vision of the product** – The Scrum Master should coach the PO on clearly defining and communicating the long-term vision of the product to stakeholders and the Scrum Team.\n- **Actively manage stakeholders, their desires, expectations, and outcomes** – The Scrum Master mentors the PO in engaging with stakeholders effectively, ensuring alignment without compromising product integrity.\n- **Developing and explicitly communicating intermediate [strategic goals]({{< ref \"/tags/strategic-goals\" >}})** – The Scrum Master supports the PO in setting achievable, incremental objectives that drive value and guide the Scrum Team.\n- **Ensuring that the Product Backlog is transparent, visible, and understood** – The Scrum Master teaches the PO how to refine, prioritise, and maintain a clear, actionable Product Backlog.\n- **Using evidence-based management techniques to optimise outcomes and value delivered** – The Scrum Master coaches the PO on leveraging data, metrics, and [experimentation]({{< ref \"/tags/experimentation\" >}}) to make informed product decisions.\n- **Work with Developers daily to clarify and renegotiate the Scope of the Sprint** – The Scrum Master facilitates collaboration between the PO and Developers to ensure continuous alignment and adaptability.\n\n> Scrum Master Service to the Product Owner\n>\n> - Ensuring that goals, scope, and product domain are understood by the Scrum Team.\n> - Helping the Scrum Team understand the need for clear and concise Product Backlog items.\n> - Ensuring the Product Owner knows how to arrange the Product Backlog to maximize value.\n>\n> — [The Scrum Master, Scrum Guide]({{< ref \"/resources/guides/scrum-guide\" >}})\n\nWithout business mastery, a Scrum Master cannot effectively support the Product Owner or ensure the team's alignment with business goals.\n\n### 3. Organisational Evolutionary Mastery\n\nMost organisations operate within traditional hierarchical structures that prioritise control and predictability, which often conflict with the adaptability and empirical approach that Scrum fosters. Scrum enables teams to embrace change, iterate quickly, and focus on delivering value in an environment of uncertainty. To bridge this gap, Scrum Masters must actively guide organisations towards a more dynamic, self-organising model that supports agility and responsiveness to market shifts. Many Agile transformations fail due to a lack of understanding of how organisations truly function and evolve, making this mastery critical for any Scrum Master seeking lasting impact.\n\nKey aspects include:\n\n- **Navigate organisational structure and politics** – Helping teams and leadership understand and adapt to the organisation's hierarchy, decision-making processes, and political dynamics to remove impediments.\n- **Apply [change management]({{< ref \"/tags/change-management\" >}}) principles** – Facilitating sustainable change by addressing resistance, fostering adoption, and ensuring alignment with Agile values.\n- **Engage stakeholders effectively** – Ensuring that decision-makers, sponsors, and key influencers understand Agile principles and support the Scrum Team’s ability to deliver value.\n- **Lead Agile and [Lean]({{< ref \"/categories/lean\" >}}) transformations** – Driving [organisational agility]({{< ref \"/tags/organisational-agility\" >}}) by educating leadership, coaching teams, and embedding [Lean thinking]({{< ref \"/tags/lean-thinking\" >}}) into strategic planning and execution.\n- **Influence leadership to remove systemic impediments** – Advocating for structural and cultural changes that enable agility and improve [value delivery]({{< ref \"/tags/value-delivery\" >}}) across the organisation.\n- **Foster a culture of [continuous learning]({{< ref \"/tags/continuous-learning\" >}}) and adaptation** – Encouraging a mindset of experimentation, feedback, and iterative improvement at all levels of the organisation.\n\n> Scrum Master Service to the Organisation:\n>\n> - Leading and coaching the organisation in its Scrum adoption.\n> - Planning Scrum implementations within the organisation.\n> - Helping employees and stakeholders understand Scrum and empirical [product development]({{< ref \"/categories/product-development\" >}}).\n> - Causing change that increases the productivity of the Scrum Team.\n>\n> — [The Scrum Master, Scrum Guide]({{< ref \"/resources/guides/scrum-guide\" >}})\n\nWithout organisational mastery, a Scrum Master will struggle to drive lasting, meaningful change within the organisation.\n\n## Conclusion: Can a Scrum Master Be Effective Without These Skills?\n\nWhile the entire Scrum Team is accountable for delivery, the Scrum Master ensures the conditions for success by addressing systemic issues and empowering the team to work efficiently. They do not execute the work themselves but are responsible for enabling outcomes—ensuring that the Scrum framework is effectively applied, fostering collaboration, and removing impediments that hinder progress.\n\nA Scrum Master’s role is not passive; they actively influence the team’s ability to deliver by facilitating strategy, ensuring alignment with business goals, and advocating for [organisational change]({{< ref \"/tags/organisational-change\" >}}) where necessary. Without technical, business, and organisational mastery, they risk being ineffective in guiding the team towards high-value delivery.\n\nWhile a Scrum Master can function without deep technical knowledge, they will be far more effective if they understand the _technical, business, and organisational_ context they operate in. Mastery in these three areas allows them to serve their teams better, drive value, and enable true agility within the organisation.\n\n**Scrum Masters don’t need to be coders, but if their team is developing software, they should have mastery in software development as well as whatever domain is relevant to the industry their team operates in.** The [Scrum Master is is not a juniors or entry level]({{< ref \"/resources/blog/2025/2025-02-17-no-such-thing-as-a-junior-scrum-master\" >}}) activity. They should be experienced professionals with a deep understanding of the three masteries.\n\nWhile there are no absolute right answers, some answers are better than others. Scrum Masters should continuously seek to deepen their knowledge in all three mastery areas to best serve their teams and organisations.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-03-12-great-scrum-masters-need-technical-business-and-organisational-mastery\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-03-12-great-scrum-masters-need-technical-business-and-organisational-mastery",
    "ReferencePath": "resources/blog/2025/2025-03-12-great-scrum-masters-need-technical-business-and-organisational-mastery"
  },
  {
    "FrontMatter": {
      "title": "Balance of Leadership and Control in Scrum",
      "short_title": "Leadership vs. Control in Scrum Teams",
      "description": "Explores how Scrum Masters and Product Owners balance leadership, authority, and team autonomy to ensure accountability, effective self-management, and organisational alignment.",
      "date": "2025-03-17T09:00:00",
      "weight": 405.0,
      "contributors": null,
      "ResourceId": "UH6M7ujV-kB",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "balance-of-leadership-and-control-in-scrum",
      "aliases": [
        "/resources/UH6M7ujV-kB"
      ],
      "aliasesArchive": [
        "/balance-of-leadership-and-control-in-scrum",
        "/blog/balance-of-leadership-and-control-in-scrum"
      ],
      "layout": "blog",
      "concepts": [
        "Accountability"
      ],
      "categories": [
        "Leadership",
        "Scrum",
        "Product Management"
      ],
      "tags": [
        "Agile Frameworks",
        "Professional Scrum",
        "Agile Product Management",
        "Software Development",
        "Scrum Master",
        "Agile Leadership",
        "Pragmatic Thinking",
        "Team Performance",
        "Agile Transformation",
        "Team Motivation"
      ],
      "platform_signals": [
        {
          "platform": "Scrumorg",
          "post_url": "https://www.scrum.org/resources/blog/balance-leadership-and-control-scrum",
          "post_date": "2025-07-15T09:00:00Z",
          "post_type": "crosspost"
        }
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:19Z",
        "short_title": "2025-07-07T16:45:23Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog"
    },
    "BodyContent": "[Scrum]({{< ref \"/categories/scrum\" >}}) is built on self-management, yet accountability cannot exist without authority. If Scrum Masters and Product Owners are held responsible for outcomes, how much control should they have? Too much, and teams lose autonomy. Too little, and they become ineffective. This article explores the nuanced balance of [leadership]({{< ref \"/categories/leadership\" >}}), authority, and control in Scrum—how influence must be complemented by decisive action to enable true agility.\n\n**Can One Be Held Accountable for What One Has No Control Over?**\n\n> **TL;DR;** - Accountability without authority is a contradiction. If Scrum Masters and Product Owners are expected to deliver results, they must have the authority to remove impediments, challenge dysfunction, and enforce alignment where necessary. Influence is critical, but influence alone is often not enough. True leadership means balancing empowerment with decisive action, ensuring teams are both autonomous and accountable. Without the authority to act when needed, accountability becomes an empty expectation.\n\n## Leadership, Authority, and Accountability\n\nProduct Owners and Scrum Masters balance leadership, authority, and control by providing clear intent, fostering initiative, and reinforcing accountability. They guide rather than micromanage, ensuring the team understands the vision and goals, has the autonomy to execute, and remains accountable for outcomes. When intervention is needed, they step in decisively while preserving the team’s ownership of their responsibilities.\n\nProduct Owners and Scrum Masters lead through influence but must assert authority when needed—Product Owners to maximise product value, and Scrum Masters to enable the effectiveness of the [Scrum Team]({{< ref \"/tags/scrum-team\" >}}). Effective leadership balances autonomy and alignment, ensuring teams self-manage while staying accountable to commitments and organisational goals.\n\n### Context Dictates Authority\n\nThe authority wielded by the [Product Owner]({{< ref \"/tags/product-owner\" >}}) is more widely recognised and acknowledged, so why not the [Scrum Master]({{< ref \"/tags/scrum-master\" >}})?\n\nThe Scrum Master is accountable for the Scrum Team's effectiveness. This accountability demands both leadership and, within the right context, a degree of authority. While some argue that a Scrum Master should have no direct authority, this ignores the reality that influence alone is often insufficient to drive change in certain organisational contexts.\n\nThe argument against Scrum Masters having authority is often based on a misunderstanding of self-management. According to the Scrum Guide, self-managing teams decide who does what, when, and how. However, this autonomy is bounded by Scrum events, commitments, and organisational needs. The key is the freedom to decide how to deliver value—without ignoring accountability, strategy, or constraints.\n\nIn practice, the level of authority a Scrum Master should exercise depends on the organisational landscape. In a command-heavy environment, excessive control leads to blind obedience, stifling self-management. Conversely, a leadership-heavy approach without structure creates chaos. The Scrum Master must navigate this balance, adapting to the constraints of the organisation while continuously working to remove impediments to the team's effectiveness. The organisational constraints being the very things that may be  reducing the effectiveness of the Scrum Team.\n\n### The Duality of Leadership and Control\n\nLeadership in a Scrum environment is about guiding the team toward [continuous improvement]({{< ref \"/tags/continuous-improvement\" >}}). However, leadership without some degree of control is often ineffective. Control, in this context, does not mean command and dictate—it means ensuring that the Scrum framework is upheld, that organisational impediments are actively removed, and that the team operates within its defined constraints.\n\nSome argue that the best Scrum Masters might be managers, while others argue that a Scrum Master should not have authority. Both perspectives have merit but must be contextualised.\n\n- The idea that a Scrum Master can be a manager works in an organisation where a manager understands and embodies servant leadership. When a manager removes impediments, provides clarity, and champions agility without imposing control, they function effectively as a Scrum Master.\n- The notion that a Scrum Master should not have authority assumes an ideal state where influence is enough. However, in many organisations, without a minimum level of authority—such as the ability to hold the team accountable for Scrum adoption or to challenge organisational constraints—Scrum Masters struggle to fulfil their accountability.\n\n### Practical Considerations\n\nScrum Masters must master the art of situational leadership. Some teams require a hands-off coach, while others benefit from more direct guidance. A Scrum Master should have the authority to:\n\n- Enforce Scrum framework adherence when teams attempt to dilute its effectiveness.\n- Challenge anti-patterns that hinder agility.\n- Influence and escalate organisational impediments effectively.\n- Ensure that the team continuously inspects, adapts, and improves.\n\n### Conclusion\n\nAccountability without authority is a flawed concept. The Scrum Master, and the Product Owner, must operate within the context of their organisation, leveraging both influence and, where necessary, the authority to drive meaningful change. The key is not about wielding power but about ensuring the team is empowered while working within the system they are part of, always striving to evolve that system toward greater agility.\n\n#### References:\n\n- [Why Does a Scrum Master Not Have Authority?](https://www.growingscrummasters.com/deploy-improve-scrum/why-does-a-scrum-master-not-have-authority/)\n- [Your Next Scrum Master Should Be Your Manager](https://www.scrum.org/resources/blog/your-next-scrum-master-should-be-your-manager)\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-03-12-balance-of-leadership-and-control-in-scrum\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-03-12-balance-of-leadership-and-control-in-scrum",
    "ReferencePath": "resources/blog/2025/2025-03-12-balance-of-leadership-and-control-in-scrum"
  },
  {
    "FrontMatter": {
      "title": "Why Measuring Individual Cycle Time is Killing Your Flow (And What to Do Instead)",
      "short_title": "Why Individual Cycle Time Hurts Kanban Flow",
      "description": "Measuring individual cycle time in Kanban misleads teams, hides real bottlenecks, and harms flow. Focus on system-wide metrics like PCE, WIP, and throughput instead.",
      "date": "2025-03-03T09:00:00",
      "weight": 245.0,
      "contributors": [
        {
          "name": "Nigel Thurlow",
          "external": "https://www.linkedin.com/in/nigelthurlow/"
        }
      ],
      "ResourceId": "KHEPBWiFDKJ",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "why-measuring-individual-cycle-time-is-killing-your-flow-and-what-to-do-instead",
      "aliases": [
        "/resources/KHEPBWiFDKJ",
        "/resources/blog/why-measuring-individual-cycle-time-is-killing-your-flow-and-what-to-do-instead"
      ],
      "aliasesArchive": [
        "/measuring-individual-cycle-time-is-killing-your-flow",
        "/blog/measuring-individual-cycle-time-is-killing-your-flow",
        "/why-measuring-individual-cycle-time-is-killing-your-flow-(and-what-to-do-instead)",
        "/blog/why-measuring-individual-cycle-time-is-killing-your-flow-(and-what-to-do-instead)",
        "/resources/blog/why-measuring-individual-cycle-time-is-killing-your-flow-and-what-to-do-instead"
      ],
      "layout": "blog",
      "concepts": [
        "Principle"
      ],
      "categories": [
        "Product Development",
        "Kanban",
        "Lean"
      ],
      "tags": [
        "Operational Practices",
        "Software Development",
        "Lean Principles",
        "Pragmatic Thinking",
        "Flow Efficiency",
        "Project Management",
        "Systems Thinking",
        "Metrics and Learning",
        "Cycle Time",
        "Lean Thinking",
        "Organisational Physics",
        "Value Delivery",
        "Value Stream Management",
        "Continuous Improvement",
        "Market Adaptability"
      ],
      "platform_signals": [
        {
          "platform": "Scrumorg",
          "post_url": "https://www.scrum.org/resources/blog/why-measuring-individual-cycle-time-killing-your-flow-and-what-do-instead",
          "post_date": "2025-07-08T09:00:00Z",
          "post_type": "crosspost"
        },
        {
          "platform": "ProKanban",
          "post_url": "https://www.prokanban.org/blog/why-measuring-individual-cycle-time-is-killing-your-flow-and-what-to-do-instead",
          "post_date": "2025-05-22T09:00:00Z",
          "post_type": "crosspost"
        }
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:20Z",
        "short_title": "2025-07-07T16:45:40Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog"
    },
    "BodyContent": "Looking at [cycle time]({{< ref \"/tags/cycle-time\" >}}) for an individual is a fundamental misunderstanding of how flow works in a system—unless the individual is the system. And here is why!\n\n## Process Cycle Efficiency (PCE) Drives Flow, Not Individual Productivity\n\n[Kanban]({{< ref \"/categories/kanban\" >}}) isn’t about individual productivity; it’s about optimising the flow of work through a system. When you measure an individual’s cycle time, you ignore the real bottlenecks—queues, dependencies, and wait times that slow everything down. A person might complete tasks quickly, but if those tasks get stuck waiting for reviews, approvals, or other handoffs, the overall system remains inefficient. If you want faster delivery, fix the system, not the people.\n\nAs Nigel Thurlow puts it: _\"You never measure a person, ever. You only ever measure a process. You improve the system, never the people within it. If you're measuring an individual person to try and blame them, then you're ignoring what's wrong with the process that's causing it.\"_\n\n## Encourages Local Optimisation Over System Improvement\n\nMeasuring individual cycle time leads to bad incentives. If someone is judged on how fast they complete their own tasks, they’ll prioritise speed over impact. This can lead to:\n\n- Focusing on tasks that make them look efficient rather than what benefits the team.\n- Taking on work too early, creating unnecessary work in progress (WIP).\n- Cherry-picking simple tasks to appear fast rather than tackling what actually moves the system forward.\n\nKanban is about improving the whole workflow. Look at Process Cycle Efficiency (PCE) and [Throughput]({{< ref \"/tags/throughput\" >}}) together—one improves the other.\n\n## Ignores Work in Progress (WIP) and Blockers\n\nA fast-moving individual doesn’t mean fast-moving work. If the system is overloaded with WIP, nothing gets delivered faster. Work often gets stuck in queues, waiting for handoffs, or blocked by dependencies. Measuring individual cycle time won’t tell you where the real problems are.\n\nInstead, track:\n\n- **Total WIP**—to ensure the system isn’t overloaded.\n- **Time in queue vs. time in progress**—to identify bottlenecks.\n- **Blocked work items**—to find systemic delays.\n\n## Misrepresents Collaboration and Dependencies\n\nKnowledge work isn’t assembly-line work. It requires handoffs, reviews, and collaboration. Measuring an individual’s cycle time isolates their part of the work but ignores the time it spends waiting on others. Worse, it discourages teamwork—if people are penalised for long cycle times, they’ll avoid collaborating because it slows them down.\n\nOptimise for flow across the system, not just individual speed.\n\n## Creates Unintended Behaviour\n\nIf people are measured by their [personal]({{< ref \"/tags/personal\" >}}) cycle time, they may:\n\n- **Rush work**, sacrificing quality to look fast.\n- **Avoid complex or high-value tasks**, because they take longer.\n- **Hoard work**, keeping tasks they know they can finish quickly rather than distributing work across the team.\n\nNone of this improves system flow. It just distorts behaviour.\n\n## What Should You Measure Instead?\n\n> At the end of the day, the Kanban Method (as opposed to kanban) is designed to improve flow (basically Process Cycle Efficiency) by improving throughput (units per unit time) by removing constraints (which includes bottlenecks) in the system. Make the system more effective by making it more efficient. - Nigel Thurlow\n\nIf you want to improve flow, focus on:\n\n- **customer [lead time]({{< ref \"/tags/lead-time\" >}}) ([time to market]({{< ref \"/tags/time-to-market\" >}}))** - the total time from when work is requested to when it is delivered to the customer.\n- **Work in progress (WIP) limits** - to reduce bottlenecks and improve flow.\n- **Process Cycle Efficiency (PCE)** - the ratio of active work time to non value added time.\n- **Bottlenecks and blockers** - to identify systemic constraints.\n- **Throughput** - the rate at which something is produced or delivered..\n\n## Bottom Line\n\nKanban is about improving the system, not monitoring individuals. Measuring individual cycle time distracts from real systemic inefficiencies and leads to bad behaviours. Instead, optimise for end-to-end flow and make sure work moves smoothly across the whole system.\n\nAs Thurlow emphasises: _\"If there are training or skill gaps, that’s a system problem, not a person problem. Someone failed the person by not providing the right training, support, or experience.\"_ This reinforces why the focus should always be on fixing the system, not blaming individuals.\n\n### Want to improve your Kanban flow?\n\nIf you need help setting up meaningful Kanban metrics, let’s talk. We can identify the right measurements to improve your system without falling into the trap of individual cycle time metrics.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-03-03-measuring-individual-cycle-time-is-killing-your-flow\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-03-03-measuring-individual-cycle-time-is-killing-your-flow",
    "ReferencePath": "resources/blog/2025/2025-03-03-measuring-individual-cycle-time-is-killing-your-flow"
  },
  {
    "FrontMatter": {
      "title": "Stop Hiding Behind Complexity and Start Delivering Continuously",
      "short_title": "Continuous Delivery for Complex Software",
      "description": "Continuous delivery is achievable for any software, regardless of complexity. Success depends on investment in automation, quality, and process improvement—not technical barriers.",
      "date": "2025-02-24T09:00:00",
      "weight": 155.0,
      "contributors": [
        {
          "name": "John McFadyen",
          "external": "https://www.linkedin.com/in/johnmcfadyen/"
        },
        {
          "name": "Rich Visotcky",
          "external": "https://www.linkedin.com/in/richvisotcky/"
        }
      ],
      "ResourceId": "7hEAycZIn8w",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "stop-hiding-behind-complexity-and-start-delivering-continuously",
      "aliases": [
        "/resources/7hEAycZIn8w"
      ],
      "aliasesArchive": [
        "/stop-hiding-behind-complexity-deliver-continuously",
        "/blog/stop-hiding-behind-complexity-deliver-continuously",
        "/stop-hiding-behind-complexity-and-start-delivering-continuously",
        "/blog/stop-hiding-behind-complexity-and-start-delivering-continuously"
      ],
      "layout": "blog",
      "concepts": [
        "Practice"
      ],
      "categories": [
        "DevOps",
        "Engineering Excellence",
        "Product Development"
      ],
      "tags": [
        "Continuous Delivery",
        "Software Development",
        "Technical Mastery",
        "Operational Practices",
        "Market Adaptability",
        "Product Delivery",
        "Evidence Based Management",
        "Deployment Frequency",
        "Metrics and Learning",
        "Organisational Agility",
        "Technical Excellence",
        "Frequent Releases",
        "Azure DevOps",
        "Business Agility",
        "Release Management"
      ],
      "platform_signals": [
        {
          "platform": "Scrumorg",
          "post_url": "https://www.scrum.org/resources/blog/stop-hiding-behind-complexity-and-start-delivering-continuously",
          "post_date": "2025-07-01T09:00:00Z",
          "post_type": "crosspost"
        }
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:30Z",
        "short_title": "2025-07-07T17:46:10Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog",
      "preview": "2025-02-24-stop-hiding-behind-complexity-deliver-continuously.jpg"
    },
    "BodyContent": "Every organisation says their software is 'too complex' for [continuous delivery]({{< ref \"/tags/continuous-delivery\" >}}). That's nonsense. Complexity is an excuse, not a blocker. [Azure DevOps]({{< ref \"/tags/azure-devops\" >}}), Starbucks, and countless others proved it wrong. The only real obstacle is the resistance to invest in fixing what’s broken. Complexity is an excuse, not a blocker. Microsoft proved it. Starbucks proved it. You can too; if you’re willing to put in the time, effort, and money.\n\nContinuous delivery is not a pipe dream. If the organisation is willing to invest, it’s achievable for every software product, regardless of complexity or legacy constraints. And that's the challenge.\n\nThe organisation must be willing to invest significant time and effort in enabling it. Microsoft's Azure [DevOps]({{< ref \"/categories/devops\" >}}) team exemplifies this. They transitioned from shipping new features every two years to delivering value every three weeks, increasing their annual feature delivery from 25 to nearly 300 at their peak.\n\nThis evolution was not the result of a silver bullet but a deliberate effort to modernise architecture, eliminate [technical debt]({{< ref \"/tags/technical-debt\" >}}), automate relentlessly, and embed a culture of [continuous improvement]({{< ref \"/tags/continuous-improvement\" >}}). It is an ongoing evolution that has paid dividends for every year of effort invested. They delivered 58 features at the end of the first year of investment, rising to over 250 features after four years, later stabilising at just over 300. This is the power of continuous delivery.\n\n### TLDR\n\nEvery software system, no matter how complex or archaic, can be updated, tested, and deployed continuously—without delays, bottlenecks, or manual interventions. This is the core of Continuous Delivery (CD): software always in a deployable state, ready for frequent, reliable releases.\n\n## What is holding you back?\n\nMany teams believe they cannot achieve continuous delivery and instead claim:\n\n- Their product is too big and complex\n- Their teams lack the skills\n- It’s not possible in their regulated industry\n\nEvery single one of these justifications is illegitimate and reflects either the team's unwillingness to learn or the [leadership]({{< ref \"/categories/leadership\" >}})'s unwillingness to invest. These are excuses, not realities.\n\n**In reality, systemic and continuous underinvestment in quality, scalable, and supportable products is to blame.**\n\nThis failure is not driven by the engineers or managers doing the work, but they have enabled it. The cause lies squarely in the business, even if they did not consciously make it.\n\n> \"If you put people under pressure to deliver, they will increasingly and systemically decrease quality to meet whatever ridiculous deadlines you give them.\"\n\nThe result is unchecked technical debt, high bug rates in production, significant rework, and unmet expectations.\n\nThis is not a terminal condition but a challenge to manage and overcome. The key lies in intentionality. Without tackling the root causes of complexity for new capabilities, slow releases, and frequent production issues, process changes will fail to deliver meaningful results.\n\n### The Evolution of the Developer Division at Microsoft\n\nLike every other company that has built software at scale, Microsoft fell into the usual traps of long release cycles, single-pass coding, and poor testing quality. For the Developer Division—responsible for Visual Studio, Team Foundation Server, and other software engineering tools—this resulted in a two-year release cycle, a four-year customer feedback loop, and fixing 75,000 bugs to get Visual Studio 2010 out the door.\n\nMarket forces pushed them to evolve. They could no longer meet the demands of an increasingly dynamic market, and a four-year response time to customer needs was unsustainable. While laggards might remain, it's the early adopters who drive new business and shape emerging markets. Failing to keep them engaged signals a decline that, if left unchecked, can be fatal—but recovery is possible with decisive action.\n\nAzure DevOps emerged as the result of decisive action by Microsoft's Developer Division, triggered by an urgent need to break free from their two-year release cycle and four-year customer feedback loop. They didn't inherit perfection—they faced legacy code, fragmented processes, and a monolithic release cycle. Their transformation began with small, incremental changes, but success required deeper, systemic shifts:\n\n- **Automate Everything**: This cannot be emphasised enough. Automate every possible task. If something cannot be automated today, create a plan to rework the architecture until it can be. From testing and deployments to upgrades, certificates, passwords, and environments—automation should be the default, not the exception.\n\n- **Trunk-Based Development**: The cognitive load and resulting complexity from supporting multiple versions of your product significantly increases complexity and risk. Long-running branches, especially when promoting by branch, slow the delivery of [working software]({{< ref \"/tags/working-software\" >}}) to real users. Adopting [Trunk-Based Development practices]({{< ref \"/resources/blog/2025/2025-02-06-stop-promoting-branches\" >}}) eliminates this risk by ensuring that all code integrates continuously into a single shared branch.\n\n- **Feature Flags**: To maximise both quality and value, it's essential to [test new capabilities in production]({{< ref \"/resources/blog/2025/2025-02-06-testing-in-production-maximises-quality-and-value\" >}}) while gradually exposing them to users, reducing risk. This approach shortens feedback loops and enables swift adaptation to emerging market opportunities. Since we can't predict which features will deliver the most value, we validate hypotheses by running small experiments with real data. Effective use of feature flags is crucial for these experiments, ensuring safe, controlled releases that drive continuous improvement.\n\n- **Shift-Left**: Shift from testing quality at the end (QA, Staging, UAT) to embedding it throughout the development process. Use hypothesis-driven practices and unit tests at every stage to ensure high quality from the start. Discovering a security vulnerability in staging often means the flaw is deeply embedded, leaving no time or budget for proper fixes—only quick patches that hackers easily exploit. Instead, conduct security tests, code reviews, and performance checks continuously, as close to code creation as possible.\n\n- **Iterate Over Pain**: If a task is hard or error-prone, you should do it more often. Any activity, like releasing, that feels difficult or frequently leads to errors deserves focused attention. Repeated practice exposes weak points, allowing you to refine the process and reduce risk. Avoiding the pain only ensures it remains a persistent threat.\n\n## What can we learn?\n\nIf you want to be able to adapt to market opportunities or surprises, then you need to be able to shift quickly. This means that any software system, regardless of its complexity, architecture, or purpose, should be updated, tested, and deployed in a continuous flow without delays, bottlenecks, or manual interventions. This is the ethos of Continuous Delivery (CD), where software is always in a deployable state, enabling frequent and reliable releases.\n\nIn the world of modern software engineering its no longer an optional thing. It's a business demand.  Too many business opportunities have been missed because we are too slow to deliver and too slow to turn feedback into usable working products on a short enough timeline.\n\nHow short your timeline needs to be is a question for your business... what is your effective planning horizon. For Starbucks PoS its 48h; for [Windows]({{< ref \"/tags/windows\" >}}), its \\~120h, for Facebook its just a few minutes.\n\n## Measuring your velocity\n\nVelocity isn't just about how much work gets done—it's about how fast you move from idea to outcome. It’s about closing feedback loops quickly, enabling continuous improvement, and delivering valuable increments faster.\n\nIn 2018, Buck Hodges from Microsoft's Azure DevOps/Team Foundation Server team introduced four key metrics to evaluate and enhance the [software development]({{< ref \"/tags/software-development\" >}}) and deployment process:\n\n- **Time to Build:** This metric measures the duration from code commit to the completion of a successful local build on a developer's workstation. It reflects the amount of time a developer needs to wait to know if their code compiles.\n\n- **Time to Self-Test:** This refers to the time taken to execute automated tests after a build locally. A shorter Time to Self-Test reflects fast tests and enables quicker feedback on code quality. Efficient self-testing cycles catch defects early, reduce rework, and maintain code integrity.\n\n- **Time to Deploy:** This metric tracks the time required to deploy a build to a production environment. Shorter deployment times increase velocity by enabling rapid feedback and [value delivery]({{< ref \"/tags/value-delivery\" >}}). Minimising the Time to Deploy is crucial for rapidly delivering features and fixes to end users. [Continuous integration]({{< ref \"/tags/continuous-integration\" >}}) and delivery (CI/CD) pipelines are essential for optimising this metric.\n\n- **Time to Learn:** This encompasses the period from deployment to collecting and analysing user feedback or telemetry data. Reducing Time to Learn ensures teams quickly understand user interactions and make informed decisions for future development. Faster learning cycles mean teams adapt quickly, prioritise effectively, and avoid wasting time on low-value features.\n\nThese metrics represent stages in the flow of work from ideation to outcome. They are not the only metrics or stages, but they represent and expose significant bottlenecks in this case—and they are 100% within the control of engineering. Engineering did not require any outside approval to measure and optimise these stages. Accountability for improvement lies squarely within the team.\n\nBy monitoring and optimising these metrics, development teams can achieve a more streamlined and responsive DevOps workflow, leading to faster delivery of high-quality software. However, these metrics are focused on the work of engineers building the product, and there may be other things in the application lifecycle that may have a bigger impact on you and your teams.\n\nIt's crucial to take a holistic view of metrics, and the [Evidence-Based Management (EBM) guide]({{< ref \"/resources/guides/evidence-based-management-guide\" >}}) is a great starting point. It offers example metrics that can either be adopted directly or adapted to fit your context. When choosing metrics, focus on the four Key Value Areas (KVAs) defined by EBM:\n\n1. **[Current Value]({{< ref \"/tags/current-value\" >}}) (CV):** Measures the value delivered to customers or stakeholders today, reflecting satisfaction and success based on the current product.\n2. **Unrealized Value (UV):** Identifies potential future value by highlighting gaps between what customers have and what they need or desire.\n3. **[Ability to Innovate]({{< ref \"/tags/ability-to-innovate\" >}}) (A2I):** Assesses how effectively the organisation can deliver new capabilities, features, or products without being constrained by technical debt, process bottlenecks, or organisational drag.\n4. **[Time to Market]({{< ref \"/tags/time-to-market\" >}}) (T2M):** Evaluates the speed at which ideas, features, or fixes move from concept to production, directly impacting responsiveness to market demands and customer needs.\n\nThese four areas provide a balanced view, ensuring you don’t just measure output but focus on the outcomes that drive business success and [customer satisfaction]({{< ref \"/tags/customer-satisfaction\" >}}).\n\n## The Path Forward\n\nUltimately, when deployments are automated, code is well-tested, and processes are streamlined, teams can respond faster to customer needs, market changes, and business opportunities. Azure DevOps’ and Windows evolutions proved that the barrier to continuous delivery is not technical complexity but organisational will.\n\nNo matter where you start, the path to continuous delivery is through addressing the complexity that is slowing you down head-on. Prioritise automation, enforce code quality and relentlessly improve your processes. The result is not just faster releases but better software, happier teams, and more satisfied customers.\n\nIf Azure DevOps can do it with their scale and complexity, so can you.\n\nThe only question is whether you're willing to do what Azure DevOps, Starbucks, and countless others have done: stop hiding behind complexity, and start delivering continuously.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-24-stop-hiding-behind-complexity-deliver-continuously\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-24-stop-hiding-behind-complexity-deliver-continuously",
    "ReferencePath": "resources/blog/2025/2025-02-24-stop-hiding-behind-complexity-deliver-continuously"
  },
  {
    "FrontMatter": {
      "title": "There Is No Such Thing as a \"Junior\" Scrum Master",
      "short_title": "No Such Thing as a Junior Scrum Master",
      "description": "Argues that the Scrum Master role requires proven mastery and real-world experience, not entry-level skills or certifications, and should be earned within the team, not assigned.",
      "date": "2025-02-17T09:00:00",
      "weight": 135.0,
      "contributors": [
        {
          "name": "Dave (\"Dungeon\" Dave) Smith",
          "external": "https://www.linkedin.com/in/dungeon-dave-smith/"
        }
      ],
      "ResourceId": "f2RQh2UCwqB",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "there-is-no-such-thing-as-a-junior-scrum-master",
      "aliases": [
        "/resources/f2RQh2UCwqB"
      ],
      "aliasesArchive": [
        "/no-such-thing-as-a-junior-scrum-master",
        "/blog/no-such-thing-as-a-junior-scrum-master",
        "/there-is-no-such-thing-as-a--junior--scrum-master",
        "/blog/there-is-no-such-thing-as-a--junior--scrum-master"
      ],
      "layout": "blog",
      "concepts": [
        "Accountability"
      ],
      "categories": [
        "Leadership",
        "Technical Leadership",
        "Scrum"
      ],
      "tags": [
        "Competence",
        "Pragmatic Thinking",
        "Software Development",
        "Agile Frameworks",
        "Scrum Master",
        "Professional Scrum",
        "Organisational Agility",
        "Agile Leadership",
        "Team Performance",
        "Technical Excellence",
        "Team Collaboration",
        "Product Delivery"
      ],
      "platform_signals": [
        {
          "platform": "Scrumorg",
          "post_url": "https://www.scrum.org/resources/blog/there-no-such-thing-junior-scrum-master",
          "post_date": "2025-06-24T09:00:00Z",
          "post_type": "crosspost"
        }
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:37Z",
        "short_title": "2025-07-07T17:46:27Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog",
      "preview": "2025-02-10-no-such-thing-as-a-junior-scrum-master.jpg",
      "marketing": []
    },
    "BodyContent": "Would you ever hire a **Junior CISO** or a **Junior Financial Director**? Of course not. These positions, by definition, require demonstrated mastery of their respective domains, alongside the authority and responsibility to enact meaningful change. The same should be true of a [Scrum]({{< ref \"/categories/scrum\" >}}) Master. The idea of a “junior” [Scrum Master]({{< ref \"/tags/scrum-master\" >}}) is a fallacy. The Scrum Master is not an entry-level position, nor is it something that should be handed out as a career stepping stone. A Scrum Master **should be born fully formed**, emerging from the [Scrum Team]({{< ref \"/tags/scrum-team\" >}}) as a practitioner who has already demonstrated [technical mastery]({{< ref \"/tags/technical-mastery\" >}}), business mastery, and organisational evolutionary mastery. They should be **elevated by the team, not assigned by management.**\n\n## The Myth of the Junior Scrum Master\n\nToo often, organisations treat the Scrum Master role as a checkbox on a hiring matrix, assuming that anyone can step in and “facilitate” a few events. This mindset reduces the Scrum Master to a glorified meeting scheduler rather than the steward of effectiveness that they are meant to be. The reality is this: **Scrum Masters are not made in a two-day certification course**—they are forged in the crucible of real-world experience within high-performing Scrum Teams.\n\nThis aligns with the points made in [The Incompetent Scrum Master]({{< ref \"/resources/blog/2024/2024-09-05-the-incompetent-scrum-master-why-most-are-failing-and-what-they-should-know\" >}}), which highlights that many Scrum Masters lack the depth of knowledge and experience necessary to be effective. The best Scrum Masters are not those who simply “get certified” but those who have lived and breathed Scrum within a team, demonstrating real-world [competence]({{< ref \"/tags/competence\" >}}) before stepping into the role.\n\nAdditionally, a Scrum Master **must have first-hand experience** of working within a Scrum Team. This doesn’t mean they **have to been a coder**; Scrum Teams are made up of Business Analysts, Testers, Flow Designers, and many other roles that contribute to delivering great products. But they must have seen what a cohesive team looks and feels like, and they must have experienced how a great Scrum Master and [Product Owner]({{< ref \"/tags/product-owner\" >}}) operate.\n\nThat said, I believe that a Scrum Master for a Scrum Team delivering software **should be able to code**. They should be able to understand and critique the quality of the work being done in order to understand and affect the Scrum Team's effectiveness. While they may not be writing production code daily, their ability to engage meaningfully with developers on code quality, [DevOps]({{< ref \"/categories/devops\" >}}) practices, and architectural decisions is invaluable. Without this understanding, how can they genuinely support the team in delivering high-quality software?\n\nThe best Scrum Masters:\n\n- Have worked within a Scrum Team for years, developing their craft as a Developer, Product Owner, or another key role.\n- Have demonstrated their ability not just to deliver work but to enable agility through [lean]({{< ref \"/categories/lean\" >}}) thinking, [continuous improvement]({{< ref \"/tags/continuous-improvement\" >}}), and servant [leadership]({{< ref \"/categories/leadership\" >}}).\n- Possess **technical mastery, business mastery, and organisational evolutionary mastery**—the three pillars of a truly competent Scrum Master.\n\nA person whose knowledge of Scrum is limited to a **two-day certification course** will struggle to land a real Scrum Master job; and rightly so. Just as a company wouldn’t trust its entire departmental finances to someone who just completed a “Financial Mastery in Two Days” course, they shouldn’t entrust the success of a multi-million-dollar project to someone whose entire experience is a “[Professional Scrum]({{< ref \"/tags/professional-scrum\" >}}) Mastery” online session.\n\nAdditionally, many organisations attempt to cut costs by hiring a “junior” Scrum Master at half the salary, while expecting full performance. The result? A Jira lackey and reporting serf, someone who is bullied into administrative tasks rather than empowered to drive agility. It’s the equivalent of hiring a “junior” chef at a discount and making them sweep the yard before every shift—then blaming the methodology when the food is awful.\n\n## Scrum Masters Are Chosen by the Team, Not Imposed by Management\n\nA Scrum Master should **not** be an external hire brought in to “fix” a team. Instead, they should **rise naturally from within the team**, selected by their peers who trust them to safeguard the team’s effectiveness.\n\nThis approach ensures:\n\n- The Scrum Master has credibility within the team—they have already **earned the respect** of their colleagues.\n- They understand the organisation’s constraints, culture, and history, enabling **meaningful change** without naive disruption.\n- Their selection is based on demonstrated competence, not just theoretical knowledge or a certification.\n\nIf a team does not trust or respect their Scrum Master, they won’t follow them. The Scrum Master must be someone who has already shown leadership, not someone who needs to “grow into the role.”\n\n## The Accountability of the Scrum Master Is Heavy—And It Requires Mastery\n\nScrum Masters, as all leaders, **should not lead only through authority**—they should lead through influence. That influence comes from **mastery of three key domains**:\n\n1. **Technical Mastery** – A deep understanding of [software development]({{< ref \"/tags/software-development\" >}}), DevOps, modern [engineering practices]({{< ref \"/tags/engineering-practices\" >}}), and the realities of delivering high-quality products. This doesn’t mean they have to code daily, but they must understand how technical decisions impact agility.\n2. **Business Mastery** – The ability to align Scrum Teams with the broader business strategy, ensuring that the work they facilitate delivers real, measurable value. This does not take away from the Product Owner but instead supports it.\n3. **Organisational Evolutionary Mastery** – The skill to enable systemic change, remove organisational impediments, and cultivate a culture of agility **beyond the team level**.\n\nWhile Scrum Masters should lead through influence and servant leadership, they are not powerless. The concept of intent-based leadership, where they also hold authority, can be incredibly effective. The best Scrum Masters [know when to serve and when to step up with authority](https://www.scrum.org/resources/blog/your-next-scrum-master-should-be-your-manager) to drive change. They wield the accountability of the role not just as a facilitator but as a true leader, ensuring that agility is not merely an aspiration but a reality.\n\nThis concept is further reinforced in [The Scrum Master is Accountable for Delivery]({{< ref \"/resources/blog/2025/2025-01-30-the-scrum-master-is-accountable-for-delivery\" >}}), which highlights how Scrum Masters must take ownership of delivery effectiveness and drive the team towards meaningful outcomes. Does this still sound like a junior position?\n\n## Scrum Masters Should Wield Their Accountability with Competence from Day One\n\nThe idea that a Scrum Master should “learn on the job” is dangerous. A Scrum Master **should be able to step into the role with full competency from day one**, because they have already been functioning as a de facto Scrum Master within their team before ever taking on the title.\n\nThis is not about gatekeeping—it’s about effectiveness. If a Scrum Master is learning the fundamentals while on the job, they are **not serving the team—they are hindering it**.\n\nThis is also why hiring a Scrum Master should be an intentional and rigorous process. As outlined in [Hiring a Professional Scrum Master]({{< ref \"/resources/blog/2021/2021-03-15-hiring-a-professional-scrum-master\" >}}), organisations often make the mistake of prioritising certifications over experience, failing to assess whether a candidate truly embodies the role. A Scrum Master is not someone who simply “facilitates” but someone who **actively drives effectiveness, navigates complexity, and enables [continuous delivery]({{< ref \"/tags/continuous-delivery\" >}}) of value**.\n\n## Conclusion: Scrum Masters Are Born Fully Formed\n\nA Scrum Master is not a role that should be taken lightly. It is not a career ladder step, nor is it something one can simply “train” into without prior deep experience. The best Scrum Masters **emerge naturally** from within the team, already demonstrating the mastery required before they ever assume accountability formally.\n\nThe Scrum Master role demands mastery across technical, business, and organisational domains. Anything less is inadequate and frankly does not fulfil their obligation to the Scrum Team, the Product Owner, or the business.\n\nIf you are looking for a Scrum Master, don’t look at certifications or job titles. Look at the **people who have already been leading without the title**—those who have already demonstrated their competence in making the team more effective. That’s your Scrum Master.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-17-no-such-thing-as-a-junior-scrum-master\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-17-no-such-thing-as-a-junior-scrum-master",
    "ReferencePath": "resources/blog/2025/2025-02-17-no-such-thing-as-a-junior-scrum-master"
  },
  {
    "FrontMatter": {
      "title": "Testing in Production Maximises Quality and Value",
      "short_title": "Testing in Production for Quality and Value",
      "description": "Explains how audience-based deployment and testing in production enable faster feedback, safer rollouts, and higher software quality by targeting real users and reducing risk.",
      "date": "2025-02-13T09:00:00",
      "weight": 145.0,
      "contributors": [
        {
          "name": "Benjamin Day",
          "external": "https://www.linkedin.com/in/benjaminpday/"
        },
        {
          "name": "Dave Westgarth",
          "external": "https://www.linkedin.com/in/dave-westgarth/"
        },
        {
          "name": "Vladimir Khvostov",
          "external": "https://www.linkedin.com/in/vladimirkhvostov/"
        }
      ],
      "ResourceId": "_ncZFfeCrnS",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "testing-in-production-maximises-quality-and-value",
      "aliases": [
        "/resources/_ncZFfeCrnS"
      ],
      "aliasesArchive": [
        "/testing-in-production-maximises-quality-and-value",
        "/blog/testing-in-production-maximises-quality-and-value"
      ],
      "layout": "blog",
      "concepts": [
        "Tool"
      ],
      "categories": [
        "Engineering Excellence",
        "Product Development",
        "DevOps"
      ],
      "tags": [
        "Operational Practices",
        "Market Adaptability",
        "Customer Focus",
        "Azure DevOps",
        "Technical Mastery",
        "Continuous Improvement",
        "Continuous Delivery",
        "Software Development",
        "Deployment Frequency",
        "Experimentation",
        "Technical Excellence",
        "Organisational Agility",
        "Value Delivery",
        "Deployment Strategies",
        "Frequent Releases"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:38Z",
        "short_title": "2025-07-07T17:46:34Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog",
      "preview": "2025-02-06-testing-in-production-maximises-quality-and-value.jpg",
      "marketing": []
    },
    "BodyContent": "Testing in production, is about structured, observable releases that allow for fast feedback, controlled exposure, and rapid course correction, ensuring quality without sacrificing speed.\n\nOne such paradigm shift in software delivery is audience-based deployment.\n\nGone are the days of rigid Dev-Test-Staging-Production pipelines. These [traditional environments are costly, slow, and fundamentally flawed]({{< ref \"/resources/blog/2025/2025-02-06-stop-promoting-branches\" >}}). They delay feedback loops, hinder innovation, and reinforce outdated notions of software stability.\n\nInstead, modern software engineering demands a smarter approach: deploying directly to real users in production but in a controlled, incremental manner.\n\nFor those familiar with ring-based deployment, audience-based deployment is not a new concept; it expands on it. Ring-based deployment is a proven strategy, widely used at scale by companies like Microsoft with products like [Windows]({{< ref \"/tags/windows\" >}}) and Microsoft Teams. Audience-based deployment simply extends this principle by providing even finer-grained control over who gets access to a given change based on account types, user profiles, or organisational groups. This approach allows teams, like the Azure [DevOps]({{< ref \"/categories/devops\" >}}) team, to release software to small, targeted user groups, enabling faster feedback, reduced blast radius, and progressive rollout strategies.\n\nThis approach enables:\n\n- **Faster feedback** from real-world conditions, not simulated test environments.\n- **Reduced blast radius** by limiting exposure of potentially risky changes.\n- **Progressive rollout strategies**, improving resilience and adaptability.\n\n### Retaining Context Without Environmental Branching\n\nWhile you may need to retain some environmental context for compliance or operational reasons, **your branching structure should not model it**. Creating branches that mimic Dev-Test-Staging environments is costly and counterproductive. It increases complexity, delays feedback, and reinforces silos rather than fostering [continuous delivery]({{< ref \"/tags/continuous-delivery\" >}}). Instead, focus on:\n\n- Using **feature flags** to control exposure.\n- Implementing **progressive rollouts** instead of environment-based branching.\n- Relying on **observability and monitoring** rather than artificial environments.\n\nBy shifting away from rigid environment-based branching, teams can iterate faster and detect issues in real-world scenarios without unnecessary overhead.\n\nI don't think this is easy; it's not. Teams making this shift face teething problems; adapting workflows, enhancing observability, and upskilling in DevOps and CI/CD practices. Success here isn't just technical; it's cultural. Organisations must embrace automation, foster real-time monitoring capabilities, and embed progressive delivery into their engineering ethos. It requires significant discipline and a relentless focus on the usable working product that many teams just don't have.\n\n### How Microsoft Transformed Deployment\n\nMicrosoft’s transformation to DevOps and audience-based deployment has been an industry-defining journey, starting with the Visual Studio and [Azure DevOps]({{< ref \"/tags/azure-devops\" >}}) (was Team Foundation Server) teams in the Developer Division and later extending to Windows and Office.\n\n**Key Lessons from Microsoft’s Evolution:**\n\n- **Be Customer Obsessed** – Prioritise user experience and collect telemetry to refine deployments.\n- **Iterate Over Pain** – If it's hard and painful, do it more often until it becomes just another activity.\n- **Adopt a Production-First Mindset** – Deploy as continuously as possible, with safeguards to protect end-users.\n- **Enable Team Autonomy with Enterprise Alignment** – Empower teams while ensuring strategic cohesion.\n- **Shift Left on Quality** – Detect and address issues earlier in the development cycle.\n\nThese were hard-learned lessons from the transition of Team Foundation Server from one delivery every two years to one every three weeks. This was also the catalyst for them to move their product to the cloud, ultimately leading to the Azure DevOps product we have today. There was a key realisation that closing feedback loops is much harder if you are delivering a locally installed product. Not every customer takes every release, and not every customer allows the vendor to truly understand the usage patterns.\n\nIf you want to build products that meet your customer's needs, then you need to get ahead of those needs. If you respond to customer requests, then you are too late to meet their need, and are costing them time and money while you go build what they asked for. Getting ahead of that loop, crossing the chasm, requires that you are able to engage with early adopters and collect telemetry and feedback much closer to the development cycle. Feedback on something that you shipped two years ago is largely useless if your priorities have changed since then.\n\nAudience-based deployment allows you to control which users and which accounts get access to new features. This means that you can start to engage with early adopters even within an organisation where most users are late adopters.\n\nThis connection to the users, the telemetry it provides, and the closeness of the feedback to the build that allows you to maximise the value, the ROI, of the work that you do is the business reason to move in this direction.\n\n## The Azure DevOps team revolutionised Microsoft’s approach.\n\nThe Azure DevOps team revolutionised Microsoft’s approach to deployment by pioneering a **ring-based deployment strategy** that allowed for:\n\n1. **Incremental feature releases** with real-time telemetry analysis.\n2. **Production-first mindset**, shifting quality assurance left.\n3. **Automated stops to rollouts triggered by observed failures.**\n4. **Continuous monitoring** to reduce release risk.\n\nThis strategy proved so effective that it became the foundation for deploying changes to **Windows**, an operating system with a vastly larger and more diverse user base. And more scary indeed is that Windows is an installed product that needs to support an almost infinite set of configurations.\n\n#### Windows: [Scaling]({{< ref \"/tags/scaling\" >}}) the Model to Millions\n\nWindows took inspiration from Azure DevOps' success and implemented the ring-based model at an unprecedented scale:\n\n1. **Internal to Microsoft** - Im not necessarily privy to the details of this, but there have been hints and stories told by folks on the inside. (\\~70,000 members)\n\n   1. Internal Channel - Nightly changes tested internally by a small subset of engineers.\n   2. Dogfooding Channel – Microsoft employees use new versions before external customers.\n\n2. **Windows Insider Program** - Anyone can join this just by opting in. (\\~17m members)\n\n   1. **Canary Channel** – This is for highly technical users who get builds from the dev branch every few days.\n   2. **Dev Channel** – For enthusiasts; gets builds every few weeks from the dev branch\n   3. **Beta Channel** - This is for early adopters and gets early builds every month or so from the release branch\n   4. **Release Preview** - For those looking for just an early peek but want stability. Builds every 3 months or so from the release branch about 3 months before they hit GA.\n\n3. **General Availability** - Finally, changes are staged and rolled out to everyone else (\\~900bn machines worldwide)\n\nThis approach enables them to:\n\n- **Detect failures early**, before they affect millions of users.\n- **Refine features based on telemetry and user behaviour**.\n- **Confidently scale releases** while maintaining stability.\n\nThis isn’t just DevOps done well; it’s a learning engine driving [continuous improvement]({{< ref \"/tags/continuous-improvement\" >}}) across Microsoft’s ecosystem. Today, you will find this model and variants of it on all of Microsoft's platforms.\n\nFor example, I am in the Insider group for Microsoft Teams, with my account in R3, with both R3.5 (preview) and R4 (ga) ahead of me... and yet I can be in a call with folks from any of the rings from R0 all the way to R4. We each get different features and capabilities and a different product stability level.\n\n### Why You Should Ditch the Old Way\n\nBeyond the inefficiencies of traditional environments, the old way accumulates waste—relearning, duplicated effort, and maintaining outdated processes, all drain resources. Each additional environment introduces overhead in familiarization, regression testing, and upkeep, diverting attention from work that delivers actual value. The cost isn't just financial; it's an innovation tax.\n\nMost organisations still cling to the traditional **Dev-Test-Staging-Production** model because it feels safe. But let’s be honest:\n\n- **Testing environments are never identical to production.** Data, scale, and real-world user behaviour differences mean you’re testing a mirage.\n- **Delayed feedback loops increase risk.** The longer it takes to discover issues, the harder and costlier they are to fix.\n- **It stifles innovation.** Slow, gated releases hinder rapid iteration and [experimentation]({{< ref \"/tags/experimentation\" >}}).\n\nThe alternative? **Deploying directly to your users, but smartly.**\n\n### Making the Shift: Key Strategies for Audience-Based Deployment\n\nWe first need to accept that rolling forward is the only viable option! If a team has just failed to roll forward, what makes us think they have the skills to execute the more complex task of rolling back? Rolling back is often more risky than pushing a fix forward, as it can introduce inconsistencies, data mismatches, and unexpected failures. The key is to **design rollouts to be fail-safe**, ensuring issues are detected early and addressed immediately without needing a complex rollback process.\n\n> \"I was a big proponent of the rolling forward strategy. 10+ years ago, I said that if a team screwed up a database upgrade, most likely they will not succeed with a database downgrade. Sometimes downgrade means data loss. When we do deployments, we upgrade binaries first by creating new VMs and switch traffic to them. We keep old VMs running for 3 hours, so that we can go back to an old binaries if we detect any user impacting issues. After 3 hours we deallocate VMs, but do not delete them. If we detect an issue 3+ hours after deployment, we can still start VMs and go back to previous binaries. When we start database upgrade, we delete old VMs. At this point there is no going back to an old binaries.\" -Vladimir Khvostov, Principal Software Engineer at Microsoft - Azure DevOps\n\nThe Azure DevOps team does allow for limited rollback under specific circumstances, but only for binaries, never for data.\n\nWant to embrace audience-based deployment? Here’s how:\n\n1. **Feature Flags & Toggles** – Control feature exposure dynamically without redeploying code.\n2. **Progressive Delivery** – Gradually expand releases based on telemetry and user feedback.\n3. **Real-Time Observability** – Use logging, metrics, and tracing to detect issues immediately.\n4. **Automated Rollout Halts** – Deployments should automatically pause if telemetry detects anomalies or performance degradations, ensuring issues are caught before they escalate.\n5. **User Opt-In Programs** – Encourage beta testers and early adopters to participate.\n\n### The Future of Continuous Delivery\n\nIn an interconnected world, **production is the ultimate reality check.** Audience-based deployment isn’t just an evolution of DevOps,it’s the logical next step in **delivering value faster, safer, and smarter.**\n\nThe question is, **are you ready to embrace it?**\n\nIs your team still relying on pre-production environments? What’s stopping you from adopting audience-based deployment?\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-06-testing-in-production-maximises-quality-and-value\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-06-testing-in-production-maximises-quality-and-value",
    "ReferencePath": "resources/blog/2025/2025-02-06-testing-in-production-maximises-quality-and-value"
  },
  {
    "FrontMatter": {
      "title": "Without Delivery, There Is No Value",
      "short_title": "Without Delivery, There Is No Value",
      "description": "Value in software is only realised through delivery. Frequent releases validate assumptions, reduce risk, and enable rapid feedback, adaptation, and continuous improvement.",
      "date": "2025-02-10T09:00:00",
      "weight": 180.0,
      "ResourceId": "UfdnQrxv5iF",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "without-delivery-there-is-no-value",
      "aliases": [
        "/resources/UfdnQrxv5iF"
      ],
      "aliasesArchive": [
        "/without-delivery-no-value",
        "/blog/without-delivery-no-value",
        "/without-delivery--there-is-no-value",
        "/blog/without-delivery--there-is-no-value"
      ],
      "layout": "blog",
      "concepts": [
        "Tenet"
      ],
      "categories": [
        "Product Development",
        "Engineering Excellence",
        "Scrum"
      ],
      "tags": [
        "Software Development",
        "Deployment Frequency",
        "Working Software",
        "Market Adaptability",
        "Customer Focus",
        "Operational Practices",
        "Frequent Releases",
        "Value Delivery",
        "Product Delivery",
        "Continuous Delivery",
        "Empirical Process Control",
        "Release Management",
        "Time to Market",
        "Pragmatic Thinking",
        "Increment"
      ],
      "platform_signals": [
        {
          "platform": "Scrumorg",
          "post_url": "https://www.scrum.org/resources/blog/without-delivery-there-no-value",
          "post_date": "2025-06-17T09:00:00Z",
          "post_type": "crosspost"
        }
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:40Z",
        "short_title": "2025-07-07T17:46:37Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog",
      "preview": "2025-02-10-without-delivery-no-value.jpg",
      "marketing": []
    },
    "BodyContent": "Before delivery, all ideas and strategies remain theoretical. They are assumptions - educated guesses that may or may not align with actual needs or expectations. **Delivery is the only mechanism** through which these assumptions are validated, transforming theory into tangible outcomes that can be measured, tested, and improved.\n\n> Value exists only when it is realised, and the only way to realise the value in software is to release it.\n\nNo matter how well-intentioned or carefully crafted a plan might be, until a product is delivered and used, its potential remains locked away. Each day of delay represents not only a missed opportunity to create value but also an accumulation of costs - from lost feedback to the risks of market irrelevance. Even the best directions and strategies are hypothetical until they are tested and validated through [frequent releases]({{< ref \"/tags/frequent-releases\" >}}). The **Standish Group’s CHAOS Report** has consistently shown that projects with long, waterfall-style cycles have significantly lower success rates than those with frequent iterations. Only **29% of traditional projects succeed**, while agile projects that release frequently succeed **42%-64%** of the time. The difference? Rapid, incremental validation of assumptions.\n\n> - Are teams delivering [working software]({{< ref \"/tags/working-software\" >}}) to at least some subset of real users every iteration (including the first) and gathering feedback?\n> - Is feedback from users turned into concrete work items for sprint teams on timelines shorter than one month?\n> - Are teams empowered to change the requirements based on user feedback?\n>\n> <cite>From US DOD: Detecting Agile BS</cite>\n\nThe reality is simple: **value can only be realised through delivery.** No matter how clear your direction or how promising your assumptions about value may seem, they are worth nothing until they are tested and validated through release.\n\n### **Why Frequent Releases Are Critical**\n\n[Transparency]({{< ref \"/tags/transparency\" >}}) is the cornerstone of both [Scrum]({{< ref \"/categories/scrum\" >}}) and Agile. Delivering a usable, working [increment]({{< ref \"/tags/increment\" >}}) at the end of every Sprint provides the baseline for:\n\n- **Inspection:** Stakeholders and the team can evaluate progress, functionality, and alignment with goals.\n- **Adaptation:** Course corrections based on real-world feedback rather than assumptions.\n\nWithout delivery, transparency is lost. You are left with only assumptions—untested and unproven—that create an illusion of progress while value remains unrealised. The **DORA ([DevOps]({{< ref \"/categories/devops\" >}}) Research and Assessment) metrics** highlight that teams with shorter **[Lead Time]({{< ref \"/tags/lead-time\" >}}) for Changes (LT)** are more competitive, as they can push value to users faster and adapt to market changes in real time. Companies with **longer LT** are often left struggling to keep pace with customer needs, suffering the cost of missed opportunities.\n\nEvery unreleased increment leaves value on the table. Each assumption about value—no matter how well-informed—is a risk. Agile and Scrum are designed to mitigate this risk by focusing on short feedback loops:\n\n- **Frequent releases validate value early and often.**\n- **Delayed releases magnify risks,** wasting time and resources on work that may not deliver the expected value.\n\nThe cost of [unrealised value]({{< ref \"/tags/unrealised-value\" >}}) grows exponentially the longer a product remains unvalidated. It’s not just a financial cost but an opportunity cost: the insights, iterations, and refinements that could have been gained from early feedback are lost. **Change Failure Rate (CFR), another DORA metric, consistently demonstrates that larger, infrequent releases are more prone to failure.** By releasing smaller, more frequent updates, organisations can mitigate risk and ensure smoother deployments.\n\n##### What happened with [Windows]({{< ref \"/tags/windows\" >}}) 8?\n\nFor example, I'd offer the outcome of the release of Windows 8 after 6 years of engineering and 6 years of UI/UX validations as evidence of this folly... all be it a significant one. Microsoft spent millions on the work that you would expect around validating that they were doing the right thing in labs and prototypes. It was not until the first Beta of Windows 8 that the true extent of the backlash became evident... but it was too late to do anything about it. The release of Windows 8 wiped billions off Microsoft brand loyalty and recognition, a loss that they have only recently recovered from. **Had Microsoft leveraged frequent, iterative releases and shorter feedback loops, they could have detected these issues years earlier, before they became a full-scale business risk.** Which is what the changes for Windows 10 were all about, and why we skipped Windows 9. Clear delineation of brand, and a new licence and release model that focused on frequent, iterative releases and shorter feedback loops. Windows 11 is a product delivered almost continuously to production with thousands of people getting daily builds and millions getting weekly.\n\n### **The Cost of Delayed Delivery**\n\nTo illustrate, consider a hypothetical scenario: a team works tirelessly for a year, refining their understanding of value and direction. At the end of that year, they release a product that indeed delivers value. _But at what cost?_\n\n- **Lost Value:** During that year, customers could have been engaging with early increments, providing critical feedback, and validating assumptions. Each missed iteration represents an unrealised value.\n- **Opportunity Cost:** Competitors may have released sooner, capturing [market share]({{< ref \"/tags/market-share\" >}}) and leaving the delayed team playing catch-up.\n- **The Lack of Adaptation:** With no increments released, the team had no chance to inspect, adapt, or pivot. The final product, while valuable, is a result of guesswork rather than empiricism.\n\nTeams that release infrequently also face **longer Mean Time to Restore (MTTR)**, as failures in large deployments take significantly longer to diagnose and fix. Research from DORA indicates that high-performing teams restore service **168x faster** than low-performing teams, primarily due to frequent, smaller releases that allow for quicker recovery from incidents.\n\nScrum and Agile advocate for frequent releases precisely to avoid these costs. The feedback gained from early and frequent releases is invaluable in steering the product towards maximum value with minimal waste.\n\n### **Conclusion: Delivery Turns Assumptions Into Value**\n\nThe act of delivering usable increments frequently is not just a practice; it is the foundation of everything else. **Everything before delivery is an assumption, and all non-delivered product represents a cost of delay.**\n\nEvery unreleased increment represents value left on the table. Every delay increases the cost of missed opportunities, lost feedback, and unnecessary rework. By releasing frequently, teams unlock the full potential of Agile, ensuring that value is realised early, often, and with confidence.\n\nDelivering the right thing at the right time begins with getting it into the hands of users as early and as often as possible. Anything less is just an expensive assumption.\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-10-without-delivery-there-is-no-value\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-10-without-delivery-there-is-no-value",
    "ReferencePath": "resources/blog/2025/2025-02-10-without-delivery-there-is-no-value"
  },
  {
    "FrontMatter": {
      "title": "Stop Promoting Branches",
      "short_title": "Stop Promoting Branches in Deployment",
      "description": "Explains why promoting code through multiple branches slows delivery, increases risk, and suggests GitHub Flow or Release Flow as simpler, safer alternatives for deployment.",
      "date": "2025-02-06T09:00:00",
      "weight": 160.0,
      "contributors": [
        {
          "name": "Benjamin Day",
          "external": "https://www.linkedin.com/in/benjaminpday/"
        }
      ],
      "ResourceId": "x7ra7pQCDX5",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "stop-promoting-branches",
      "aliases": [
        "/resources/x7ra7pQCDX5"
      ],
      "aliasesArchive": [
        "/stop-promoting-branches",
        "/blog/stop-promoting-branches"
      ],
      "layout": "blog",
      "concepts": [
        "Principle"
      ],
      "categories": [
        "Engineering Excellence",
        "Product Development",
        "DevOps"
      ],
      "tags": [
        "GitHub",
        "Software Development",
        "Technical Mastery",
        "Market Adaptability",
        "Continuous Delivery",
        "Operational Practices",
        "Organisational Agility",
        "Pragmatic Thinking",
        "Modern Source Control",
        "Deployment Frequency",
        "Deployment Strategies",
        "Value Delivery",
        "Release Management",
        "Flow Efficiency",
        "Engineering Practices"
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:50Z",
        "short_title": "2025-07-07T17:46:49Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog",
      "preview": "2025-02-06-stop-promoting-branches.jpg",
      "marketing": []
    },
    "BodyContent": "The traditional Dev → Test → Staging → Production model is flawed, leading to unnecessary complexity and reinforcing outdated software delivery patterns. This breakdown explains why branch promotion is a failure mode, why [GitHub]({{< ref \"/tags/github\" >}}) Flow and Release Flow are reasonable alternatives, and why Git Flow belongs in the bin.\n\n## TL;DR\n\nIf teams still promote code through a Dev → Test → Staging → Production model, they are doing it wrong. This model inevitably leads to a **branch promotion strategy**, adding friction, increasing risk, and delaying [value delivery]({{< ref \"/tags/value-delivery\" >}}).\n\n- **GitHub Flow is a simple option for [continuous delivery]({{< ref \"/tags/continuous-delivery\" >}}).**\n- **Release Flow is a good choice when production needs to exist for some time.**\n- **Git Flow? That bloated mess belongs in the past.**\n\nBranching should be a tool to support flow, not an administrative overhead that slows everything down. If a model requires multiple merges to get code into production, **it is already behind.** Reverse integration, which involves pulling changes from downstream branches back into upstream branches, is fraught with danger and should be avoided.\n\n## The Failure of the branch Promotion Model\n\nThis model was meant to provide structure and control, but in practice, it leads to teams **confusing environments with branches**.\n\nThe typical pattern looks like this:\n\n1. Code is committed to a **Dev branch**.\n2. It moves to a **Test branch** for QA.\n3. It advances to a **Staging branch** for approval.\n4. It is finally merged into **Production**.\n\nWhat started as an environment management strategy **becomes a branch promotion model**, where:\n\n- Features wait in queues instead of shipping immediately.\n- Merge conflicts create unnecessary rework.\n- Hotfixes bypass the process, breaking consistency.\n- Rollbacks require painful cherry-picking instead of simple toggles.\n- Reverse integration causes unpredictable failures and last-minute surprises.\n\nThis is a linear, gated approach that **kills agility**. Instead of focusing on **delivering value**, teams get stuck in a cycle of merging, resolving conflicts, and firefighting. Reverse integration only amplifies the chaos, introducing instability at the worst possible moments.\n\n## Branch Promotion is a Symptom of Organisational Dysfunction\n\nIf teams are **passing code between branches like a baton in a relay race**, they are reinforcing a broken process. This is just waterfall with more Git commands.\n\nInstead of treating branches as milestones, teams should focus on **[continuous integration]({{< ref \"/tags/continuous-integration\" >}}) and delivery**. That means:\n\n1. Every change merges into `main` as soon as it is ready.\n2. Deployment is decoupled from release using feature flags.\n3. Testing happens in production-like environments without blocking releases.\n4. Rollbacks are instant; simply toggle a flag instead of reverting code.\n\nReverse integration breaks this model by introducing last-minute, untested changes into upstream branches, increasing risk and eroding confidence in deployments. Instead of integrating forward with stability, teams are forced into reactive fixes that create further instability.\n\nThis eliminates the bottlenecks of branch promotion. Instead of waiting weeks for a merge to move through environments, **code is always deployable**.\n\n### Supporting Multiple Versions in Production\n\nBranch promotion models often significantly increase cognitive load as engineers may be forced to support multiple versions in production. This excessive complexity increases the chances of reverse integration, where engineers must back-port features and fixes to different production versions, introducing further instability.\n\nIn these scenarios, Developers face constant challenges in tracking which code changes apply to which versions, leading to a higher risk of errors and regressions. Maintaining multiple live versions not only complicates testing, debugging, and feature rollouts but also makes it nearly impossible to ensure consistency across environments.\n\nAn extreme version of this is branch-by-customer, where separate branches are maintained for different clients. This is one of the most unmanageable and expensive practices, requiring extensive manual effort to maintain, patch, and update. Merging changes across multiple customer-specific branches is error-prone and time-consuming, leading to unpredictable behaviour and instability. Avoid at all costs.\n\n### Git Flow\n\nGit Flow was an attempt to support many of the old branching models, but it is a bloated relic that needs to die! If teams are still using Git Flow, it is time to stop.\n\nIt introduces:\n\n- A develop branch that adds unnecessary friction as it needs to be integrated into main.\n- `release/\\*` branches that delay deployment.\n- `hotfix/\\*` branches that signal a broken process.\n\nTeams that adopt Git Flow reinvent branch promotion, creating an overcomplicated merge-heavy workflow that belongs in the past.\n\n## Mainline Branching Practices\n\nThe alternative is to use trunk or mainline development where all code is integrated continuously into the main, and there are only ever short-lived topic branches for a few developers to work together on something small.\n\nThe two main options relevant here are GitHub Flow and Release Flow.\n\n### GitHub Flow\n\nOne of the easiest to understand, implement, and do well is GitHub Flow. For most teams its the only branching model they will need as it provides that speed and simplicity that enable fast turnarounds and low cognitive load. It looks like:\n\n1. Developers work in **short-lived feature branches**.\n2. They open a **pull request** against `main`.\n3. Code is reviewed, merged, and **deployed immediately**.\n\nOne would expect the pull request to be as automated as possible within the context of modern software [engineering practices]({{< ref \"/tags/engineering-practices\" >}}):\n\n- **Automated tests** to validate every change.\n- **Continuous deployment** to eliminate hand-offs.\n- **Observability and monitoring** to detect issues early.\n\nReverse integration is **completely unnecessary** in GitHub Flow because all changes integrate forward, reducing complexity and risk.\n\n### Release Flow\n\nFor teams that need to support multiple versions in production, **Microsoft’s Release Flow** extends GitHub Flow without unnecessary complexity for the specific purpose of having a release version that you need to help until the next release is ready. Microsoft developed this because it took longer than their 3 weeks for Sprint to deploy new versions of Azure [DevOps]({{< ref \"/categories/devops\" >}}) to the thousands of databases that they used.\n\n- All work merges into `main`.\n- When a release is ready, a **version branch** (e.g., `release/1.2`) is created.\n- Fixes are always made into the main and cherry-picked into the release branches or, if necessary, implemented again.\n\nThis keeps development fast **while maintaining stability where needed**. It avoids regression by always fixing into \\`main\\`. Critically, Release Flow continues to **avoid the pitfalls of reverse integration**, ensuring that all changes move forward in a controlled, predictable manner.\n\n## Keep It Simple, Keep It Fast\n\nBranching should enable fast delivery, not slow it down.\n\n- **Want to ship continuously? Use GitHub Flow.**\n- **Need to maintain live versions? Use Release Flow.**\n\nIf teams still promote branches through environments, **it is time to rethink the strategy**. Reverse integration is a dangerous practice that adds unnecessary risk and complexity. The best branching model is the one that gets in the way the least. **Stop promoting branches. Start delivering value.**\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-06-stop-promoting-branches\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-06-stop-promoting-branches",
    "ReferencePath": "resources/blog/2025/2025-02-06-stop-promoting-branches"
  },
  {
    "FrontMatter": {
      "title": "Delivery is the only Measure of Progress in Scrum",
      "short_title": "Delivery Is the Only Measure in Scrum",
      "description": "Scrum teams must deliver working software to real users every Sprint; true progress is measured by delivery to production, not just by completing internal work.",
      "date": "2025-02-03T09:00:00",
      "weight": 175.0,
      "contributors": [
        {
          "name": "Ana Kotevska",
          "external": "https://www.linkedin.com/in/ana-kotevska-b0b9ab39/"
        }
      ],
      "ResourceId": "jBIyK6NW3ZB",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "delivery-is-the-only-measure-of-progress-in-scrum",
      "aliases": [
        "/resources/jBIyK6NW3ZB"
      ],
      "aliasesArchive": [
        "/delivery-is-the-only-measure-of-progress",
        "/blog/delivery-is-the-only-measure-of-progress",
        "/delivery-is-the-only-measure-of-progress-in-scrum",
        "/blog/delivery-is-the-only-measure-of-progress-in-scrum"
      ],
      "layout": "blog",
      "concepts": [
        "Principle"
      ],
      "categories": [
        "Product Development",
        "Scrum",
        "Engineering Excellence"
      ],
      "tags": [
        "Pragmatic Thinking",
        "Software Development",
        "Market Adaptability",
        "Operational Practices",
        "Deployment Frequency",
        "Professional Scrum",
        "Product Delivery",
        "Value Delivery",
        "Customer Focus",
        "Working Software",
        "Continuous Delivery",
        "Technical Mastery",
        "Frequent Releases",
        "Agile Product Management",
        "Technical Excellence"
      ],
      "platform_signals": [
        {
          "platform": "Scrumorg",
          "post_url": "https://www.scrum.org/resources/blog/delivery-only-measure-progress-scrum",
          "post_date": "2025-06-10T09:00:00Z",
          "post_type": "crosspost"
        }
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:51Z",
        "short_title": "2025-07-07T17:46:52Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog",
      "preview": "2025-02-03-delivery-as-the-ultimate-measure-of-progress.jpg"
    },
    "BodyContent": "As a social technology, [Scrum]({{< ref \"/categories/scrum\" >}}) has remained steadfast in its ethos for over 32 years, enabling teams to generate value through adaptive solutions to complex problems. Yet, a subtle distinction in its guidance often trips up practitioners - Scrum **explicitly** mandates a **Done [Increment]({{< ref \"/tags/increment\" >}})** but **implicitly** mandates **Delivery**. This distinction, though subtle, holds profound implications in a modern context where [DevOps]({{< ref \"/categories/devops\" >}}) has reshaped the landscape of software delivery.\n\n### TLDR;\n\nModern software [engineering practices]({{< ref \"/tags/engineering-practices\" >}}) have made it easy to ship to production and validate that your product is of a quality level that would allow it. I would expect every [Scrum Team]({{< ref \"/tags/scrum-team\" >}}) to:\n\n- deliver [working software]({{< ref \"/tags/working-software\" >}}) to at least some subset of real users every iteration, including the first\n- turn feedback from users into concrete work items on timelines shorter than one month\n- change the requirements based on user feedback\n\nAt a very minimum, I expect them to deliver their increments to production at least once per Sprint, preferably continuously.\n\n### Delivery as the Fundamental Measure of Progress\n\nScrum Teams are measured not by what they start but by what they finish, and more importantly, by what they **deliver**. A Done Increment is only as valuable as its ability to drive change and provide feedback in the hands of real users. Anything less is just inventory.\n\nIt’s time to shift the focus: delivery is not an afterthought, it is **the measure of progress**. In the 1990s, releasing software to production was a cumbersome, risky process, and the Scrum Guide was written in that world. Today, with modern DevOps capabilities, [continuous delivery]({{< ref \"/tags/continuous-delivery\" >}}) is not just possible—it is expected.\n\n> **If a Scrum Team is producing Done Increments but not delivering them, they are not actually doing Scrum—they are simply simulating progress.**\n\n### Done Is Not Enough\n\nA Done Increment, according to Scrum, meets the [Definition of Done]({{< ref \"/tags/definition-of-done\" >}}): it is properly tested, meets quality standards, and is potentially shippable. But potential is not value—realised value comes only from delivery.\n\nThe distinction between Done and Delivered is simple:\n\n- **Done means the work meets an internal quality standard.**\n- **Delivered means the work has been put into production and is creating impact.**\n\nIf an Increment remains in staging or internal QA, it does not matter how refined or polished it is—it is not delivering value.\n\n### Why This Matters\n\nThe speed of market responsiveness defines competitive advantage today. A product that remains undelivered provides no feedback, no learning, and no adaptation. Organizations that mistake Done for Delivered risk falling behind more responsive competitors who understand that speed to value is everything.\n\nA feature sitting on a shelf has the same business impact as a feature that was never built.\n\n**Delivery is what separates successful Scrum Teams from ineffective ones.**\n\n### How to Ensure Delivery Becomes the Default\n\nScrum Teams must reframe their Definition of Done to include deployment while ensuring that they [don't inadvertently compromise]({{< ref \"/resources/blog/2025/2025-01-03-definition-of-done-objective-vs-subjective\" >}}) it. Every Sprint should result in increments that go into production. Here’s how teams can bridge the gap:\n\n1. **Automate Everything**\n\n   If your release process requires manual intervention, it is a liability. CI/CD pipelines eliminate constraints and ensure every increment is delivered safely and efficiently. Don't end up like the Knight Capital Group or CrowdStrike.\n\n2. **Treat Delivery as a First-Class Citizen**\n\n   The goal of every Sprint should not be to produce an increment—it should be to deliver value. A backlog item is not complete until users are benefiting from it.\n\n3. **Inspect User Impact, Not Just Internal Quality**\n\n   Sprint Reviews should not be about demonstrating functionality in a staging environment; they should be about real user impact. What changed for the customer? What insights did we gain from their usage?\n\n4. **Break Down Barriers**\n\n   Silos between development, operations, security, and compliance must be removed. Cross-functional teams should be fully empowered to deploy without external dependencies.\n\n5. **Make Undelivered Work Visible**\n\n   Track work that is \"Done but not Delivered.\" If work is piling up, ask why. This is an issue of flow, not just completion.\n\nRemember [usable working product is how we manage risk and deliver value]({{< ref \"/resources/blog/2023/2023-07-20-how-usable-working-products-are-your-ultimate-weapon-against-risks\" >}}). If you are not delivering, you are not managing risk, and you are not delivering value.\n\n### Conclusion\n\nIn 2025, there is no reason why a Done Increment should not be delivered. The tools, practices, and knowledge exist. The only thing standing in the way is outdated ways of thinking.\n\nDelivery is no longer just an aspiration—it is the fundamental measure of progress. The ability to deliver frequently, safely, and reliably is what makes a Scrum Team truly professional.\n\nThe question is no longer \"Are we Done?\" but **\"Have we Delivered?\"**\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-03-delivery-as-the-ultimate-measure-of-progress\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-02-03-delivery-as-the-ultimate-measure-of-progress",
    "ReferencePath": "resources/blog/2025/2025-02-03-delivery-as-the-ultimate-measure-of-progress"
  },
  {
    "FrontMatter": {
      "title": "The Scrum Master is accountable for Delivery",
      "short_title": "The Scrum Master’s Accountability for Delivery",
      "description": "Explains how the Scrum Master is accountable for enabling effective product delivery, fostering team success, and ensuring each sprint produces a usable, valuable increment.",
      "date": "2025-01-30",
      "weight": 220.0,
      "contributors": [
        {
          "name": "Ryan Ripley",
          "external": "https://www.linkedin.com/in/ryanripley"
        },
        {
          "name": "Elle Anderson",
          "external": "http://www.linkedin.com/in/anderelle"
        },
        {
          "name": "Sathpal Singh",
          "external": "https://www.linkedin.com/in/sathpal/"
        },
        {
          "name": "Ralph Jocham",
          "external": "https://www.linkedin.com/in/ralphjocham/"
        }
      ],
      "ResourceId": "yMnia2DLI6q",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "the-scrum-master-is-accountable-for-delivery",
      "aliases": [
        "/resources/yMnia2DLI6q",
        "/the-scrum-master-is-accountable-for-delivery",
        "/blog/the-scrum-master-is-accountable-for-delivery"
      ],
      "aliasesArchive": [
        "/the-scrum-master-is-accountable-for-delivery",
        "/blog/the-scrum-master-is-accountable-for-delivery"
      ],
      "layout": "blog",
      "concepts": [
        "Accountability"
      ],
      "categories": [
        "Scrum",
        "Product Development",
        "Leadership"
      ],
      "tags": [
        "Software Development",
        "Agile Frameworks",
        "Professional Scrum",
        "Scrum Master",
        "Product Delivery",
        "Value Delivery",
        "Team Performance",
        "Operational Practices",
        "Empirical Process Control",
        "Agile Planning",
        "Pragmatic Thinking",
        "Working Software",
        "Increment",
        "Agile Leadership"
      ],
      "platform_signals": [
        {
          "platform": "Scrumorg",
          "post_url": "https://www.scrum.org/resources/blog/if-you-are-not-doing-test-first-then-you-are-doing-it-wrong",
          "post_date": "2025-06-03T09:00:00Z",
          "post_type": "crosspost"
        }
      ],
      "Watermarks": {
        "description": "2025-05-07T12:49:52Z",
        "short_title": "2025-07-07T17:46:52Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog",
      "preview": "2025-01-30-the-scrum-master-is-accountable-for-delivery.jpg"
    },
    "BodyContent": "Ultimately, the [Scrum]({{< ref \"/categories/scrum\" >}}) Master is accountable for the [Scrum Team]({{< ref \"/tags/scrum-team\" >}})'s success. This includes [product delivery]({{< ref \"/tags/product-delivery\" >}}), product success, Sprint outcomes, the team's ability, and ensuring the team has the resources, skills, and ethos needed to succeed. While the entire Scrum Team shares accountability for delivery, the [Scrum Master]({{< ref \"/tags/scrum-master\" >}})’s role is to create the conditions for effective delivery and [continuous improvement]({{< ref \"/tags/continuous-improvement\" >}}). Delivery is the minimum bar for effectiveness—without it, the team cannot measure or realise value. Without delivery, there is no [increment]({{< ref \"/tags/increment\" >}}), no feedback, and no way to empirically assess value. A Scrum Team that delivers without value is ineffective but still functional. A Scrum Team that fails to deliver anything cannot be considered effective under any measure.\n\n> Let the record show that I believe that, if you’re in the kind of organisation that will still fund Scrum Masters despite a long-in-the-tooth Scrum adoption, then you can bet your ass the Scrum Master is accountable for delivery. That’s because they should be facilitating the “aha” moments required of the team to address things like capacity, understanding, and level-setting with product and stakeholders when goals are just too big or infeasible.\n>\n> <cite>[Elle Anderson](http://www.linkedin.com/in/anderelle)</cite>\n\nScrum Masters should embrace their accountability for creating an environment where delivery is not just possible but inevitable. Effectiveness begins with delivery—then expands to encompass value, learning, and continuous improvement. This dual focus ensures that the Scrum Team not only meets the minimum bar but thrives well beyond it.\n\n## The Scrum Master is accountable for Delivery\n\nThe success of a Scrum Team begins with their accountability for delivering a usable, working product at the end of every sprint—including the very first one. This principle is the backbone of Scrum's empirical process, ensuring the team generates valuable feedback for continuous improvement of their product and the system. A working increment is non-negotiable; without it, there’s no way to inspect and adapt effectively or measure progress towards the team's goals. By focusing on delivery as the minimum bar for effectiveness, the Scrum Team builds a foundation that doesn’t just deliver but delivers value consistently.\n\nEffectiveness is More Than Delivery, but Delivery is a Minimum.\n\n### **The accountability of the Scrum Master for delivery**\n\nAt the heart of this framework lies the Scrum Master, who holds a pivotal accountability: enabling an environment where delivery becomes not just possible but inevitable. This accountability isn’t about executing the work but ensuring the team has the resources, strategies, and support needed to thrive.\n\nThe Scrum Master is accountable for the effectiveness of the Scrum Team, and to achieve that, they need to have a level of authority that fits the context of the Scrum Team and the organisation. Ideally, they can pursue this accountability using influence and [leadership]({{< ref \"/categories/leadership\" >}}), but in many organisations, this is impossible without an appropriate level of authority.\n\nCan a Scrum team be considered effective if they don't deliver? The Scrum Master is accountable for the team’s culture and its collective ability to effectively deliver value each and every Sprint. If they fail to fulfil that accountability through the inability of the Scrum Team to deliver value, then they should be held accountable for that failure by the business. The Scrum Guide makes it clear that the Scrum Master’s accountability for the team's effectiveness inherently ties to delivery, as the production of a usable increment every sprint is the foundational measure of a team’s success. The business holding the Scrum Master accountable for delivery in no way dilutes the collective accountability of the Scrum Team; instead, it reinforces the importance of every team member’s role in achieving this shared goal.\n\nIt's entirely likely that [your next Scrum Master will be your manager](https://www.scrum.org/resources/blog/your-next-scrum-master-should-be-your-manager).\n\n## **But what about the Scrum Team’s Shared Accountability for Delivery?**\n\nThe [Scrum Guide (2020)]({{< ref \"/resources/guides/scrum-guide\" >}}) makes it clear: the entire Scrum Team is accountable for delivering a valuable, useful increment every sprint. That said, while delivery is a collective responsibility, the role of the Scrum Master has a unique slant: they are not _players_ on the field but the _coach_. Their accountability lies in fostering an environment where effective delivery can happen consistently.\n\nUsing a football analogy, the coach is ultimately held accountable for the team’s performance. They are responsible for strategy, facilitation, and ensuring the team has the resources and focus needed to succeed. The players, however, still own the execution. In Scrum, the Scrum Master is similarly accountable for enabling outcomes—not by doing the work themselves but by ensuring that the Scrum framework is effectively applied and the team functions optimally.\n\nWhile the entire Scrum Team is accountable for delivery, the Scrum Master ensures the conditions for success by addressing systemic issues and empowering the team to work efficiently.\n\n## **Effectiveness Beyond Delivery**\n\nEffectiveness in a Scrum context spans far beyond simply delivering increments of software. However, let’s be clear: delivery is the baseline. Without delivery, the concept of effectiveness becomes moot. As I often say, “Effectiveness starts with delivery.” From there, we can layer on concepts like:\n\n1. **Delivering Meaningful Value:** Effectiveness isn’t about shipping anything and everything in the backlog. It’s about delivering increments that provide tangible value to the customer and the organisation. Efficiency doesn’t mean you’re effectively delivering meaningful and impactful things.\n\n2. **Maximising Value While Minimising Waste:** A truly effective team doesn’t just execute orders. They challenge assumptions, reduce unnecessary work, and focus on outcomes, not output. Scrum Masters facilitate this by fostering a culture of curiosity and continuous improvement.\n\n3. **Empowering Autonomous Teams:** The hallmark of an effective Scrum Master is the ability to cultivate a team that self-manages and self-optimises. This requires creating [psychological safety]({{< ref \"/tags/psychological-safety\" >}}), enabling conflict resolution, and empowering the team to make decisions.\n\n4. **Collaborating with Adjacent Teams:** Effective Scrum Masters actively work with and enable adjacent teams to align efforts, remove cross-team dependencies, and foster organisational coherence. By promoting collaboration across teams, they ensure a seamless flow of [value delivery]({{< ref \"/tags/value-delivery\" >}}) across the organisation.\n\n5. **Fulfilling Organisational Accountability:** The Scrum Master has an accountability to the organisation beyond the team. This involves educating leadership about Scrum, advocating for systemic improvements, and helping the organisation embrace new ways of working. By bridging the team and the broader organisation, Scrum Masters enhance alignment and drive strategic value.\n\n## **Why Delivery Is the Minimum Bar**\n\nHere’s the reality: without delivery, there is no effectiveness to measure. Consider the [Agile Manifesto’s]({{< ref \"/resources/guides/manifesto-for-agile-software-development\" >}}) first principle: _\"Our highest priority is to satisfy the customer through early and [continuous delivery]({{< ref \"/tags/continuous-delivery\" >}}) of valuable software.\"_ Delivery is not the _end-all-be-all_, but it is the minimum bar of [competence]({{< ref \"/tags/competence\" >}}) for a Scrum Team. A team that consistently fails to deliver usable increments cannot claim to be effective, no matter how skilled or engaged they are.\n\nAlthough from a single instance, this quote embodies the common failure of Scrum Teams to even meet this minimum bar:\n\n> The code that was done never arrived at production, nor did it come close to meeting DoD's requirements, and by most standards, we did not deliver anything.\n\nWhile the team may have contributed to organisational learning or questioned the value of a particular initiative, their inability to deliver [working software]({{< ref \"/tags/working-software\" >}}) regularly is antithetical to Scrum. Cancelled sprints or pivots in direction are valid within the framework, but they do not negate the fundamental expectation: each sprint ends with a usable increment.\n\nEffectiveness requires delivery, but delivery itself is not the sole measure of effectiveness. It is, however, the critical foundation. A football team that consistently fails to score cannot be described as effective, no matter how skilled its players may be.\n\n## **The Scrum Master’s Accountability in Delivery**\n\nThe Scrum Master is a [lean]({{< ref \"/categories/lean\" >}})-agile practitioner with [technical mastery]({{< ref \"/tags/technical-mastery\" >}}), business mastery, and organisational evolutionary mastery that can provide training, [coaching]({{< ref \"/tags/coaching\" >}}), & [mentoring]({{< ref \"/tags/mentoring\" >}}) as needed within the context of the team, the product, and the organisation. This is [not an entry-level position but represents an experienced product professional]({{< ref \"/resources/blog/2021/2021-03-15-hiring-a-professional-scrum-master\" >}}) who can enable the whole Scrum Team to take accountability for delivery by:\n\n- **Ensuring [Transparency]({{< ref \"/tags/transparency\" >}}):** Helping the team and stakeholders maintain clarity on progress, impediments, and value delivery through well-facilitated events and effective artefacts.\n- **Removing Impediments:** Proactively identifying and enabling the removal of blockers that hinder the team’s ability to deliver.\n- **Enabling [Technical Excellence]({{< ref \"/tags/technical-excellence\" >}}):** The Scrum Master should have [sufficient technical skills within the Scrum Teams' work context]({{< ref \"/resources/blog/2019/2019-09-01-are-technical-skills-required-to-be-a-scrum-master\" >}}) to advocate for and enable practices like design patterns, Test-Driven Development (TDD), [automated testing]({{< ref \"/tags/automated-testing\" >}}), and [continuous integration]({{< ref \"/tags/continuous-integration\" >}})—all of which are critical for sustainable delivery. Great Scrum Masters will also be able to teach these techniques.\n- **Facilitating Empiricism:** Supporting the team in working empirically by fostering a cadence of inspect and adapt cycles, ensuring that learning is continuously integrated into delivery.\n\nWhen delivery falters, stakeholders naturally look to the Scrum Master to understand and address the root causes. By taking ownership of systemic issues and facilitating improvements, the Scrum Master ensures the team’s consistent ability to deliver effectively.\n\nThey take accountability for delivery!\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-01-30-the-scrum-master-is-accountable-for-delivery\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-01-30-the-scrum-master-is-accountable-for-delivery",
    "ReferencePath": "resources/blog/2025/2025-01-30-the-scrum-master-is-accountable-for-delivery"
  },
  {
    "FrontMatter": {
      "title": "Why Handoffs Are Killing Your Agility",
      "short_title": "Why Handoffs Are Killing Your Agility",
      "description": "Excessive handoffs in software development create delays, reduce quality, and harm team morale. Learn how eliminating handoffs boosts agility, flow, and value delivery.",
      "date": "2025-01-13",
      "weight": 230.0,
      "ResourceId": "pDvDdIEi9sj",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "why-handoffs-are-killing-your-agility",
      "aliases": [
        "/resources/pDvDdIEi9sj",
        "/why-handoffs-are-killing-your-agility",
        "/blog/why-handoffs-are-killing-your-agility"
      ],
      "aliasesArchive": [
        "/why-handoffs-are-killing-your-agility",
        "/blog/why-handoffs-are-killing-your-agility"
      ],
      "layout": "blog",
      "concepts": [
        "Strategy"
      ],
      "categories": [
        "Product Development",
        "Lean",
        "Engineering Excellence"
      ],
      "tags": [
        "Operational Practices",
        "Pragmatic Thinking",
        "Software Development",
        "Business Agility",
        "Market Adaptability",
        "Cross Functional Teams",
        "Flow Efficiency",
        "Organisational Agility",
        "Product Delivery",
        "Team Collaboration",
        "Team Performance",
        "Technical Mastery",
        "Lean Principles",
        "Value Delivery",
        "Agile Frameworks"
      ],
      "platform_signals": [
        {
          "platform": "Scrumorg",
          "post_url": "https://www.scrum.org/resources/blog/why-handoffs-are-killing-your-agility",
          "post_date": "2025-05-19T09:00:00Z",
          "post_type": "crosspost"
        }
      ],
      "Watermarks": {
        "description": "2025-05-07T12:50:01Z",
        "short_title": "2025-07-07T17:47:02Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog",
      "preview": "2025-01-11-why-handoffs-are-killing-your-agility.jpg"
    },
    "BodyContent": "Many organisations attempt to adopt [Lean]({{< ref \"/categories/lean\" >}}) practices without fully understanding their implications in [software development]({{< ref \"/tags/software-development\" >}}). This often leads to excessive handoffs, which fragment communication and reduce agility.\n\nHere's the kicker: handoffs are _not_ Lean, Agile, or [DevOps]({{< ref \"/categories/devops\" >}}). They are an anti-pattern that introduces waste, increases [cycle time]({{< ref \"/tags/cycle-time\" >}}), and makes collaboration difficult.\n\n### TL;DR\n\nHandoffs are a silent killer in software development. They create inefficiencies, reduce quality, and destroy agility. If your organisation is still riddled with handoffs between siloed teams, you are doing it wrong. Embrace cross-functional teams, optimise for flow, and maintain organisational hygiene to ensure only the minimal set of rules and alignments needed to deliver value effectively. Together, these practices protect your ability to focus on creating value.\n\n### What Are Handoffs?\n\nHandoffs occur when one team or individual completes a task and passes it to another team for further work. Examples include:\n\n- Developers handing off features to testers.\n- Testers handing off validated features to operations.\n- Business analysts tossing requirements over the fence to developers.\n\nEach of these transitions is a point of failure, introducing delays, miscommunication, and opportunities for rework.\n\n### The Hidden Costs of Handoffs\n\nHandoffs come with a plethora of hidden costs that undermine agility and efficiency. Compounding these challenges is the build-up of organisational cruft—rules and processes that outlive their usefulness. This cruft can further slow progress and obscure [value delivery]({{< ref \"/tags/value-delivery\" >}}). Each of these costs impacts not only the immediate work but also the organisation's ability to deliver value quickly and sustainably.\n\n1. **Loss of Context**: Valuable information is lost when tasks move from one team to another. Teams waste time trying to re-establish the original intent. Moreover, the cost of context switching exacerbates this issue. When questions arise that cannot be answered immediately, team members often feel compelled to start new tasks, increasing work in progress (WIP) which in turn increases cycle time. This leads to further delays and amplifies the loss of context, making it even harder to regain clarity and focus on the original work.\n\n2. **Increased Cycle Time**: Every handoff introduces a delay, pushing your delivery timelines further out. This delay often stems from an increase in batch size as teams attempt to locally optimise for handoffs, which ironically leads to even longer cycle times. Larger batch sizes also bring significantly higher risk, as larger changes are more prone to defects and harder to integrate.\n\n3. **Reduced Quality**: Misunderstandings and lack of accountability often lead to defects and lower overall product quality. The increase in cycle time and the loss of context also contribute to growing [technical debt]({{< ref \"/tags/technical-debt\" >}}), making it much harder to identify and fix bugs in larger deployments. This, in turn, further degrades the overall quality and increases the risk of failures in production.\n\n4. **Decreased Morale**: Team members stuck in silos feel disconnected from the bigger picture, leading to frustration and burnout. This disconnect erodes their sense of **purpose**, a critical element in achieving \"autonomy, mastery, and purpose\" as described in Daniel Pink's _Drive_. Without a clear connection to the end-to-end delivery of value, team members lose motivation and struggle to see the impact of their work.\n\nTogether, these hidden costs act as multipliers, compounding each other and magnifying the negative impact on your organisation's ability to deliver high-quality software efficiently. Addressing one cost often reduces others, making it crucial to tackle these issues holistically.\n\n### Why Do Handoffs Persist?\n\nHandoffs are a symptom of functional silos. Organisations that structure themselves by discipline (e.g., separate teams for development, testing, and operations) create natural barriers to collaboration. This approach is a holdover from the \"Scientific Management Method\" developed during the Industrial Revolution when workers were mechanised to optimise for narrow, repetitive tasks rather than holistic, value-driven outcomes. Even well-meaning attempts to implement Agile often retain these silos, resulting in what I like to call \"[hybrid Agile]({{< ref \"/tags/hybrid-agile\" >}})\" — a mismatched combination of Agile practices and traditional command-and-control management. This ineffective blend perpetuates the very silos and inefficiencies that Agile aims to eliminate.\n\n## The Solution: Eliminate Handoffs\n\nEliminating handoffs requires a mix of modern [engineering practices]({{< ref \"/tags/engineering-practices\" >}}) and a commitment to automation. By automating repetitive tasks and adopting strategies like \"testing in production,\" organisations can significantly reduce the friction and delays associated with traditional handoffs. This approach enables faster feedback loops, improved quality, and a seamless delivery pipeline.\n\nTo achieve true agility, a focus on eliminating handoffs is necessary by implementing cross-functional teams and optimising flow. Here's how:\n\n1. **Create Cross-Functional Teams** - Bring together individuals with all the skills needed to deliver end-to-end value. A cross-functional team might include developers, testers, designers, and operations personnel working collaboratively towards a shared goal. No sub-teams. No silos.\n\n   > **Pro Tip:** Co-locate teams in timezones and use [collaboration tools]({{< ref \"/tags/collaboration-tools\" >}}) like Microsoft Teams or Slack to ensure seamless communication.\n\n2. **Adopt [Continuous Delivery]({{< ref \"/tags/continuous-delivery\" >}}) Practices** - Automation is a cornerstone of Continuous Delivery (CD). By integrating [automated testing]({{< ref \"/tags/automated-testing\" >}}), deployment, and monitoring into your pipeline, you ensure quality at every step while reducing manual intervention. Moving towards \"testing in production\" becomes a natural evolution of this strategy, allowing teams to gather real-world feedback quickly and address issues proactively.\n\nContinuous Delivery (CD) eliminates the need for separate testing or deployment phases. Build pipelines that automatically validate and deploy changes, ensuring quality at every step.\n\n3. **Leverage Test-First Development** - Adopt Test-Driven Development (TDD), Behaviour-Driven Development (BDD), or Acceptance Test-Driven Development (ATDD). Writing tests first ensures clarity and reduces rework, as discussed in [You are doing it wrong if you are not using test first](https://nkdagility.com/blog/you-are-doing-it-wrong-if-you-are-not-using-test-first/).\n\n4. **Minimise Work in Progress (WIP)** - Limit WIP to reduce context switching and improve focus. A lower WIP means fewer handoffs and faster delivery cycles.\n\n5. **Invest in Collaborative Refinement** - [Backlog refinement]({{< ref \"/tags/backlog-refinement\" >}}) should be a team sport. The entire [Scrum]({{< ref \"/categories/scrum\" >}}) Team — including the [Product Owner]({{< ref \"/tags/product-owner\" >}}) and Developers — must collaborate to clarify and break down work items. See more in [If your backlog is not refined then you are doing it wrong](https://nkdagility.com/blog/if-your-backlog-is-not-refined-then-you-are-doing-it-wrong/).\n\n6. **Shift Left and Own It** - All of these practices contribute to a \"shift left\" strategy, where quality, security, and deployment considerations are addressed earlier in the development lifecycle. Ultimately, the team that creates a feature should also own it in production, including gathering and acting on feedback. This end-to-end ownership fosters accountability, ensures quicker feedback loops, and allows teams to continuously improve based on real-world usage.\n\nOrganisations inevitably accumulate cruft—unnecessary rules, outdated processes, and misaligned practices. These accumulate quietly over time and, if left unchecked, undermine agility and the ability to focus on value creation. To combat this, periodic acts of organisational hygiene are essential. These involve critically assessing and removing unnecessary constraints, ensuring the organisation maintains only the minimal set of rules and alignment required to deliver value effectively. When combined with a shift-left approach and a relentless focus on flow, these practices help organisations stay lean, adaptive, and aligned with their goals.\n\nHandoffs might seem inevitable in large organisations, but they are a choice. By reorganising your teams, adopting modern engineering practices, and embracing a Lean-Agile mindset, you can minimise handoffs and unlock true agility.\n\nRemember: every handoff is an opportunity for waste. Eliminate them, and watch your teams thrive.\n\n## References\n\n1. Daniel Pink, _Drive: The Surprising Truth About What Motivates Us_\n2. The 2020 Scrum Guide - [Scrum.org](https://scrum.org/)\n3. Martin Hinshelwood, _You are doing it wrong if you are not using test first_ - [NKD Agility](https://nkdagility.com/blog/you-are-doing-it-wrong-if-you-are-not-using-test-first/)\n4. Martin Hinshelwood, _If your backlog is not refined then you are doing it wrong_ - [NKD Agility](https://nkdagility.com/blog/if-your-backlog-is-not-refined-then-you-are-doing-it-wrong/)\n5. The Agile Manifesto - [AgileManifesto.org](https://agilemanifesto.org/)\n6. Don Reinertsen, _Principles of [Product Development]({{< ref \"/categories/product-development\" >}}) Flow_\n\n**What challenges has your team faced in eliminating handoffs?** _Share your experiences and thoughts in the comments below._ Let’s start a conversation about how we can all build better, faster, and more collaborative teams!\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-01-11-why-handoffs-are-killing-your-agility\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-01-11-why-handoffs-are-killing-your-agility",
    "ReferencePath": "resources/blog/2025/2025-01-11-why-handoffs-are-killing-your-agility"
  },
  {
    "FrontMatter": {
      "title": "Definition of Done - Objective vs Subjective",
      "short_title": "Definition of Done: Objective vs Subjective",
      "description": "Explains the difference between subjective goals and the objective Definition of Done in Scrum, highlighting how clear, measurable criteria ensure consistent product quality.",
      "date": "2025-01-03",
      "weight": 180.0,
      "ResourceId": "-Z5GGUOjc-d",
      "ResourceImport": false,
      "ResourceType": "blog",
      "ResourceContentOrigin": "Hybrid",
      "slug": "definition-of-done-objective-vs-subjective",
      "aliases": [
        "/resources/-Z5GGUOjc-d",
        "/definition-of-done-objective-vs-subjective",
        "/blog/definition-of-done-objective-vs-subjective",
        "/definition-of-done---objective-vs-subjective",
        "/blog/definition-of-done---objective-vs-subjective"
      ],
      "aliasesArchive": [
        "/definition-of-done-objective-vs-subjective",
        "/blog/definition-of-done-objective-vs-subjective",
        "/definition-of-done---objective-vs-subjective",
        "/blog/definition-of-done---objective-vs-subjective"
      ],
      "layout": "blog",
      "concepts": [
        "Artifact"
      ],
      "categories": [
        "Product Development",
        "Scrum",
        "Product Management"
      ],
      "tags": [
        "Definition of Done",
        "Operational Practices",
        "Software Development",
        "Agile Planning",
        "Pragmatic Thinking",
        "Product Delivery",
        "Professional Scrum",
        "Competence",
        "Engineering Practices",
        "Value Delivery",
        "Technical Mastery",
        "Agile Frameworks",
        "Technical Excellence",
        "Team Performance",
        "Working Software"
      ],
      "platform_signals": [
        {
          "platform": "Scrumorg",
          "post_url": "https://www.scrum.org/resources/blog/definition-done-objective-vs-subjective",
          "post_date": "2025-05-27T09:00:00Z",
          "post_type": "crosspost"
        }
      ],
      "Watermarks": {
        "description": "2025-05-07T12:50:03Z",
        "short_title": "2025-07-07T17:47:03Z"
      },
      "AudioNative": true,
      "creator": "Martin Hinshelwood",
      "resourceTypes": "blog",
      "preview": "2025-01-03-definition-of-done-objective-vs-subjective.jpg"
    },
    "BodyContent": "In countless teams, there’s a recurring mix-up between “what” we’re building, “how” it aligns with business objectives, and the objective quality criteria by which it should be measured. The result? Chaos masquerading as agility. To clear the air: in [Scrum]({{< ref \"/categories/scrum\" >}}), the “what” and “how” are driven by Product and Sprint Goals. These provide directional clarity but remain inherently subjective—a north star guiding your path, not a litmus test of quality.\n\nContrast this with the [Definition of Done]({{< ref \"/tags/definition-of-done\" >}}) (DoD). The DoD is your team’s objective compass—a binary, quantifiable checklist that ensures every [Increment]({{< ref \"/tags/increment\" >}}) meets professional-grade quality. It’s non-negotiable and should be firmly rooted in your product’s brand, user expectations, and technical robustness.\n\n#### TL;DR:\n\nDon’t confuse subjective goals with objective quality. In Scrum, the Definition of Done (DoD) is a crucial, measurable bar of quality, not a negotiable outcome. Keep it clear, objective, and automated wherever possible to ensure that every Increment meets professional standards.\n\n### Product and Sprint Goals: Subjective by Design\n\nGoals in Scrum are aspirational, meant to challenge teams and align efforts towards strategic outcomes. The Product Goal represents a long-term objective, while the Sprint Goal offers a short-term milestone. Together, they guide the team like a compass through the wilderness., helping maintain direction even through surprise obstacles and side quests. However, achieving these goals isn’t always guaranteed. Progress is iterative, incremental, and constantly adapting to new insights - a bit like chasing a moving target.\n\n### Definition of Done: The Objective Measure\n\nUnlike goals, the Definition of Done is a steadfast benchmark for quality. It defines the bare minimum for an Increment to be considered complete. Without it, teams risk releasing poorly constructed, subpar products that erode user trust and damage the brand. A solid DoD ensures consistent quality across all deliverables, instilling confidence in both internal teams and end users.\n\n### Establishing a Solid Definition of Done\n\nThere is a key message in the Scrum Guide that is often overlooked that plays a critical role in establishing the DoD.\n\n> If the Definition of Done for an increment is part of the standards of the organization, all Scrum Teams must follow it as a minimum. If it is not an organizational standard, the [Scrum Team]({{< ref \"/tags/scrum-team\" >}}) must create a Definition of Done appropriate for the product. - Scrum Guide 2020\n\nFor me this suggests that there should be some kind of Organizational or Product DoD. I think of this as comming from the business. This is driven by the business and should reflect the businesses intent for quality in the product. That might be the minimum level of quality required by the business to protect their brand, their customers, and their employees.\n\nAn example of a Organizational or Product DoD for a team working on a cloud product might be:\n\n> “Live and in production, gathering telemetry that supports or diminishes the starting hypothesis.”\n\nThis sets a clear bar for delivery while supporting empirical learning and iterative improvement. It stays clear of the technical detail and jargon of an individual teams DoD and focuses on its objective and purpose for the product. It implies much, from ideation to delivery while minimizing imposition on the teams. It creates alignment of intent while maintaining autonomy of implementation. It recognizes that every team needs a unique DoD that is relevant for their context.\n\nEach team working on a product would then be responsible for creating a DoD that is appropriate for their context within that product.\n\nThis is the seed that will grow into each teams unique quality bar that reflects this DoD. A robust reflection should be:\n\n1. **Objective and Measurable**: Avoid vague criteria and instead focus on things that you can measure.\n2. **Comprehensive**: What are all the things that need to be true for a production deployment of your product to be deployed to production?\n3. **Living Document**: The teams DoD as needed to reflect evolving standards, technologies, and stakeholder expectations of the product as it grows.\n\n### Common Pitfalls\n\nDespite its critical importance, the DoD is often misunderstood, undervalued, or even undermined. Teams frequently:\n\n- **Blur Subjective and Objective**: Adding criteria like “approved by the [Product Owner]({{< ref \"/tags/product-owner\" >}})”, which shifts focus from quality to stakeholder satisfaction. Any \"approved by ... person or department\" should be strictly avoided.\n- **Overlook Automation**: Relying on manual checks leads to inconsistencies and slower feedback loops.\n- **Treat the DoD as a Maximum**: Viewing it as a ceiling instead of a floor hampers innovation and improvement.\n\n### Practices for Defining Done\n\nTo maintain focus on quality, consider the following practices:\n\n1. **Automate Everything:** Automated tests and CI/CD pipelines should validate DoD compliance as part of the development process. If you have things that cant be automated right now, plan the work to change the product to enable those activities to be automated.\n2. **Review Regularly**: Incorporate DoD reviews in retrospectives to ensure its relevance and alignment with current product and organizational needs. Keep a list of \"things that need to be true to deploy to production that we cant do yet\", and regularly move these to Done.\n3. **Train Teams**: Ensure every team member understands the DoD and its importance in delivering professional-grade Increments.\n4. **Separate Quality from Approval**: Keep subjective approval processes distinct from the DoD to avoid undermining its objectivity.\n\n### Conclusion: The Quality of Done\n\nIn Scrum, the Definition of Done is your minimum bar for quality. It’s the safeguard against [technical debt]({{< ref \"/tags/technical-debt\" >}}), the foundation for stakeholder trust, and the cornerstone of professional-grade delivery. By keeping your DoD objective, measurable, and focused on quality, you empower your team to build products that meet—and often exceed—user expectations. Remember, the DoD is a minimum bar, not a maximum aspiration. Raise it periodically and watch your product’s quality soar.\n\n**What’s Your Take?**\n\nWe’d love to hear your thoughts! How does your team define and enforce the Definition of Done? Have you faced challenges distinguishing subjective goals from objective quality measures? Share your experiences and insights in the comments below!\n",
    "FilePath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-01-03-definition-of-done-objective-vs-subjective\\index.md",
    "FolderPath": "C:\\Users\\MartinHinshelwoodNKD\\source\\repos\\NKDAgility.com\\site\\content\\resources\\blog\\2025\\2025-01-03-definition-of-done-objective-vs-subjective",
    "ReferencePath": "resources/blog/2025/2025-01-03-definition-of-done-objective-vs-subjective"
  }
]
