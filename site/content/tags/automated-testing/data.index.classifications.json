{
  "Tool": {
    "category": "Tool",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 82.0,
    "ai_mentions": 15,
    "ai_alignment": 32,
    "ai_depth": 30,
    "non_ai_confidence": 30,
    "final_score": 82.0,
    "reasoning": "The content discusses Automated Testing as a practice that utilises tools to enhance software quality and reliability. It explicitly mentions the role of automation tools in executing tests, which aligns with the category's focus on tools that facilitate workflows and improve team collaboration. The discussion on integrating automated tests into the development pipeline and its impact on Agile and DevOps principles demonstrates a strong conceptual alignment with the category. Additionally, the content provides a detailed exploration of how Automated Testing supports continuous improvement and organisational agility, indicating a significant depth of discussion on the topic.",
    "level": "Primary",
    "reasoning_summary": "This content is a great fit for the category, as it thoroughly explores how automated testing tools streamline workflows and boost team collaboration. By highlighting integration with development pipelines and connections to Agile and DevOps, it clearly demonstrates the value of automation in supporting continuous improvement and organisational agility. The discussion is both detailed and directly relevant to the category’s focus."
  },
  "Accountability": {
    "category": "Accountability",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 12.0,
    "ai_mentions": 10.0,
    "ai_alignment": 5.0,
    "ai_depth": 2.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily focuses on Automated Testing and its benefits for software quality and delivery. While it touches on themes of organisational agility and team collaboration, it does not explicitly discuss accountability or outcome ownership, which are central to the category. The mention of Agile and DevOps principles is too vague to establish a strong connection to accountability as a structural construct in work systems.",
    "level": "Ignored"
  },
  "Framework": {
    "category": "Framework",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 32.0,
    "ai_mentions": 15.0,
    "ai_alignment": 25.0,
    "ai_depth": 40.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses Automated Testing, which is a practice that supports Agile and DevOps principles but does not focus on frameworks themselves. While it mentions concepts like continuous improvement and collaboration, it lacks a direct discussion of specific frameworks or their implementation strategies, which are essential for the Framework category.",
    "level": "Ignored"
  },
  "Values": {
    "category": "Value",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 42.0,
    "ai_mentions": 12,
    "ai_alignment": 30,
    "ai_depth": 25,
    "non_ai_confidence": 50,
    "final_score": 42.0,
    "reasoning": "The content discusses the importance of Automated Testing in delivering value predictably and sustainably, which aligns with the concept of values guiding behaviour and decision-making. However, the primary focus is on the technical aspects and benefits of Automated Testing rather than a deep exploration of underlying values. While it mentions Agile and DevOps principles, it does not delve into the philosophical foundations or core values that influence team dynamics and organisational behaviour.",
    "level": "Tertiary"
  },
  "Tenet": {
    "category": "Tenet",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 62.0,
    "ai_mentions": 12,
    "ai_alignment": 25,
    "ai_depth": 25,
    "non_ai_confidence": 0,
    "final_score": 62.0,
    "reasoning": "The content discusses Automated Testing in detail, highlighting its role in enhancing software quality and reliability, which aligns with Agile and DevOps principles. It mentions continuous improvement and collaboration, which are core tenets of these methodologies. However, it does not explicitly define actionable tenets or guiding rules, leading to a moderate confidence score.",
    "level": "Secondary"
  },
  "Method": {
    "category": "Method",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 62.0,
    "ai_mentions": 12,
    "ai_alignment": 28,
    "ai_depth": 22,
    "non_ai_confidence": 0,
    "final_score": 62.0,
    "reasoning": "The content discusses Automated Testing as a systematic practice that enhances software quality and reliability, which aligns with the structured procedures of methods in Agile and DevOps. It mentions the integration of automated tests into the development pipeline, reflecting a procedural approach. However, the focus is more on the practice itself rather than a detailed exploration of specific methods like Scrum or Kanban, leading to a moderate confidence score.",
    "level": "Secondary"
  },
  "Strategy": {
    "category": "Strategy",
    "calculated_at": "2025-04-09T16:27:21",
    "ai_confidence": 32.0,
    "ai_mentions": 5,
    "ai_alignment": 15,
    "ai_depth": 12,
    "non_ai_confidence": 30,
    "final_score": 32.0,
    "reasoning": "The content discusses Automated Testing primarily as a technical practice rather than a strategic approach. While it touches on themes of organisational agility and alignment with Agile and DevOps principles, it lacks a direct focus on high-level strategic planning or decision-making. The mention of a 'shift-left strategy' is the closest reference to strategy, but it is not explored in depth or tied back to overarching organisational goals. Overall, the content is more operational in nature, focusing on implementation rather than strategic alignment.",
    "level": "Ignored"
  },
  "Practice": {
    "category": "Practice",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 87.0,
    "ai_mentions": 18,
    "ai_alignment": 36,
    "ai_depth": 34,
    "non_ai_confidence": 50,
    "final_score": 87.0,
    "reasoning": "The content explicitly discusses Automated Testing as a critical practice, aligning closely with the category of Practice. It details how this practice enhances software quality, reduces manual effort, and accelerates delivery, which are all actionable techniques that improve team performance. The depth of discussion is significant, covering the benefits of integrating automated tests into the development pipeline and its role in fostering a culture of continuous improvement. The content also touches on Agile and DevOps principles, reinforcing its relevance to the Practice category.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the Practice category, as it thoroughly explores Automated Testing as a hands-on approach to improving software development. It highlights practical benefits like boosting quality and speeding up delivery, and connects these techniques to broader Agile and DevOps methodologies, making it highly relevant for teams seeking actionable ways to enhance their workflows."
  },
  "Philosophy": {
    "category": "Philosophy",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 32.0,
    "ai_mentions": 15.0,
    "ai_alignment": 25.0,
    "ai_depth": 40.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content primarily focuses on the practice of Automated Testing, discussing its technical aspects and benefits rather than exploring the philosophical underpinnings of Agile or DevOps. While it briefly touches on concepts like organisational agility and continuous improvement, these are secondary to the main topic of testing practices. The discussion lacks a deep exploration of the foundational beliefs that shape methodologies, which is essential for a strong alignment with the Philosophy category.",
    "level": "Ignored"
  },
  "Observability": {
    "category": "Observability",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 12.0,
    "ai_mentions": 10.0,
    "ai_alignment": 5.0,
    "ai_depth": 2.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily focuses on Automated Testing, discussing its benefits for software quality and delivery. While it touches on Agile and DevOps principles, it does not explicitly address observability or its key topics such as metrics, logs, or traces. The discussion lacks depth in relation to observability, making it a secondary theme rather than a primary focus.",
    "level": "Ignored"
  },
  "Capability": {
    "category": "Capability",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 78.0,
    "ai_mentions": 15,
    "ai_alignment": 32,
    "ai_depth": 28,
    "non_ai_confidence": 0,
    "final_score": 78.0,
    "reasoning": "The content discusses Automated Testing as a critical practice that enhances software quality and reliability, which aligns with the concept of capabilities in delivering value predictably and sustainably. It mentions the importance of embedding testing into the development workflow, fostering a culture of continuous improvement, and supporting Agile and DevOps principles. However, while it touches on the systemic nature of this practice, it primarily focuses on the technical aspects and benefits of Automated Testing rather than a broader discussion on capabilities as enduring competencies.",
    "level": "Secondary",
    "reasoning_summary": "This content is well-suited to the category as it highlights how Automated Testing supports consistent value delivery and aligns with Agile and DevOps practices. However, its main emphasis is on the technical benefits and implementation of testing, rather than exploring capabilities as lasting organisational strengths or competencies."
  },
  "Model": {
    "category": "Model",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 32.0,
    "ai_mentions": 15.0,
    "ai_alignment": 25.0,
    "ai_depth": 40.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses Automated Testing primarily as a practice rather than a conceptual model. While it touches on Agile and DevOps principles, it does not explicitly mention or analyse any specific models or frameworks relevant to the 'Model' category. The focus is more on the benefits and implementation of testing rather than on how models inform decision-making or enhance organisational agility.",
    "level": "Ignored"
  },
  "Principle": {
    "category": "Principle",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 78.0,
    "ai_mentions": 15,
    "ai_alignment": 32,
    "ai_depth": 28,
    "non_ai_confidence": 30,
    "final_score": 78.0,
    "reasoning": "The content discusses the principles of continuous improvement and value delivery in the context of Automated Testing. It explicitly mentions how this practice fosters a culture of ongoing learning and adaptation, aligning well with the core themes of the category. The depth of discussion is substantial, detailing how automated testing integrates into Agile and DevOps principles, although it does not focus on the principles themselves as a primary subject.",
    "level": "Secondary"
  },
  "Artifact": {
    "category": "Artifact",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 12.0,
    "ai_mentions": 10.0,
    "ai_alignment": 5.0,
    "ai_depth": 2.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily focuses on Automated Testing as a practice rather than discussing artifacts in Agile, Scrum, or Lean. While it touches on Agile principles, it does not explicitly mention or explore specific artifacts or their roles, purposes, or management. The discussion lacks depth regarding the structure and types of artifacts, leading to a low confidence score in alignment with the 'Artifact' category.",
    "level": "Ignored"
  },
  "Discipline": {
    "category": "Discipline",
    "calculated_at": "2025-04-10T13:21:15",
    "ai_confidence": 32.0,
    "ai_mentions": 15.0,
    "ai_alignment": 40.0,
    "ai_depth": 30.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content primarily focuses on Automated Testing, which is more about quality assurance and software development practices rather than the concept of 'Discipline' itself. While it discusses systematic approaches and continuous improvement, it does not explicitly mention discipline as a core theme. The alignment with discipline is moderate due to the emphasis on structured practices, but the depth of discussion does not delve into the principles of discipline in a broader context.",
    "level": "Ignored"
  },
  "Decision Making": {
    "resourceId": "Automated Testing",
    "category": "Decision Making",
    "calculated_at": "2025-05-06T20:57:30",
    "ai_confidence": 36.66,
    "ai_mentions": 1.1,
    "ai_alignment": 4.9,
    "ai_depth": 4.6,
    "ai_intent": 4.2,
    "ai_audience": 6.4,
    "ai_signal": 6.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses entirely on the benefits, processes, and organizational impact of Automated Testing. There are no direct mentions or explicit references to 'Decision Making' or related frameworks such as evidence-based management or structured methodologies for making organizational choices. Conceptual alignment is weak—while Automated Testing can inform decision-making indirectly by providing timely feedback, the content never discusses how evidence from tests is used to make organizational or team decisions, nor does it mention evaluation frameworks, metrics for decision support, or cognitive biases. The depth is moderate but limited to process and cultural aspects of automated testing, not on the methods for structured choice or prioritization. The intent is informative, but its purpose is not focused on decision-making or supporting informed organizational decisions. The audience (software teams, engineering managers) overlaps somewhat, but the content is not aimed at those specifically seeking to improve decision-making quality. Signal-to-noise is moderate, with focused discussion on automation but none on decision processes. No penalties were applied; the information is current and not satirical or oppositional. Overall, this is quality content about testing, but relevance to the category 'Decision Making' is only tangential.",
    "level": "Ignored"
  },
  "Collaboration Tools": {
    "resourceId": "Automated Testing",
    "category": "Collaboration Tools",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 25.13,
    "ai_mentions": 0.8,
    "ai_alignment": 3.2,
    "ai_depth": 3.7,
    "ai_intent": 4.1,
    "ai_audience": 6.8,
    "ai_signal": 5.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 25.0,
    "reasoning": "The content is focused entirely on the benefits, principles, and strategic value of Automated Testing in Agile and DevOps environments. There is no direct mention of Collaboration Tools or platforms such as Slack, Jira, or Microsoft Teams. Conceptually, the topic is adjacent to collaboration but remains focused on testing workflows rather than tools enabling team communication or task coordination. It references benefits such as enhanced collaboration among cross-functional teams and shortened feedback loops, indicating mild alignment, but never discusses the tools, platforms, or features central to the 'Collaboration Tools' category. There is some audience overlap, as Agile practitioners are a target for both topics, but the signal is modest and relevance to the classification is tangential. There are no penalties to apply since the content is current, not critical, and does not contradict the category's framing. Scores are staggered to reflect slightly higher audience and signal relevance, but very low for direct mentions, alignment, and depth.",
    "level": "Ignored"
  },
  "Business Agility": {
    "resourceId": "Automated Testing",
    "category": "Business Agility",
    "calculated_at": "2025-05-06T20:57:30",
    "ai_confidence": 62.12,
    "ai_mentions": 2.6,
    "ai_alignment": 7.7,
    "ai_depth": 7.6,
    "ai_intent": 6.8,
    "ai_audience": 6.1,
    "ai_signal": 5.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 62.0,
    "reasoning": "The content is centered on Automated Testing as a practice but only tangentially connects to Business Agility. There is one indirect reference to 'organisational agility' and brief alignment with Agile/DevOps principles, but the focus is technical enablement and quality—rather than a direct, deep exploration of business agility as a discipline. Conceptual alignment is moderate: the text describes how Automated Testing fosters adaptability and responsiveness, relating these to agility concepts. However, it does not discuss business agility frameworks, leadership, metrics, broader organizational transformation, or culture at length. Depth is above average due to explanations of strategic impacts (e.g., enabling innovation, adapting to change), but remains anchored in software/testing contexts. Intent is somewhat aligned, as the content is supportive of agility, yet it addresses practitioners interested in software quality, not the executive or organizational strategist audience typical of business agility discourse. The signal-to-noise ratio is slightly diluted because the technical discussion, while relevant, covers Agile and DevOps only to support the case for testing, not the broader agility domain. No penalties were given since the content is up-to-date and supportive. Overall, the piece loosely fits under Business Agility via its logic but should not be considered a core reference for this category.",
    "level": "Secondary"
  },
  "Organisational Agility": {
    "resourceId": "Automated Testing",
    "category": "Organisational Agility",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 77.46,
    "ai_mentions": 6.7,
    "ai_alignment": 8.3,
    "ai_depth": 7.9,
    "ai_intent": 7.8,
    "ai_audience": 7.5,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 77.0,
    "reasoning": "The content explicitly mentions organisational agility ('systemic enabler of organisational agility') and situates automated testing as a practice that enables adaptability via continuous improvement, fast feedback loops, and collaboration—concepts directly aligned with organisational agility. It references Agile and DevOps principles, and discusses not just technical benefits but organisational outcomes such as responsiveness to change and sustained delivery of customer value. The discussion goes beyond surface mentions, linking automated testing to larger agility outcomes, though most technical examples are rooted in software engineering. The audience is likely technical leaders, DevOps professionals, or agile practitioners—closely aligned with the likely audience for organisational agility content. No significant off-topic material is present, and there are no obvious outdated practices or contradictions that warrant a penalty. The confidence score is strong but does not approach perfect alignment, since the discussion orbits more around the implementation of testing than a comprehensive treatment of organisational agility frameworks or leadership strategies.",
    "level": "Secondary",
    "reasoning_summary": "This content is a strong fit for the organisational agility category. It clearly connects automated testing to agility by highlighting how it supports adaptability, rapid feedback, and collaboration—key aspects of agile organisations. While it focuses on technical practices, it effectively ties these to broader organisational outcomes, making it highly relevant for professionals interested in organisational agility."
  },
  "Backlog Refinement": {
    "resourceId": "Automated Testing",
    "category": "Backlog Refinement",
    "calculated_at": "2025-05-06T20:57:30",
    "ai_confidence": 8.6,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 0.9,
    "ai_intent": 1.4,
    "ai_audience": 2.6,
    "ai_signal": 1.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content focuses entirely on automated testing, emphasizing its importance in Agile and DevOps for software quality, early issue detection, and continuous improvement. There is no direct mention of backlog refinement or its specific practices (e.g., backlog grooming, user story clarity, prioritization). Conceptual alignment is very weak since the main concern is testing, not backlog management. The depth of discussion about backlog refinement is nearly nonexistent, and the intent is not to inform or support backlog refinement but rather quality assurance practices. Audience may overlap somewhat (Agile practitioners), but the core content is off-topic for this specific category. All points are scored extremely low except for a slightly higher audience score, as technical practitioners interested in backlog refinement might also be interested in automated testing. No penalties are applied as there is no outdated or contradictory information.",
    "level": "Ignored"
  },
  "Scrum Team": {
    "resourceId": "Automated Testing",
    "category": "Scrum Team",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 13.9,
    "ai_mentions": 0.6,
    "ai_alignment": 1.8,
    "ai_depth": 2.1,
    "ai_intent": 2.2,
    "ai_audience": 2.3,
    "ai_signal": 1.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses exclusively on Automated Testing, discussing its benefits for quality, reliability, and delivery speed. The target audience appears to be development teams and organizations seeking quality assurance, which only partially overlaps with typical Scrum Team concerns. There are no direct mentions of the Scrum Team, its structure, accountabilities, or the Scrum Guide. While Agile principles are referenced, the content remains generic and does not make explicit or substantive connections to the Scrum Team accountability, its roles, or its specific responsibilities. Some mild allusions to cross-functional teams and collaboration are present, but these are generic to software development practices and not specific to the Scrum Team as defined by Scrum. Therefore, all dimension scores are very low and varied according to indirect relevance. There are no out-of-date or counter-category references, so no penalties are applied. The low confidence score correctly reflects the near-absence of Scrum Team-specific content.",
    "level": "Ignored"
  },
  "Agile Strategy": {
    "resourceId": "Automated Testing",
    "category": "Agile Strategy",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 56.7,
    "ai_mentions": 2.9,
    "ai_alignment": 6.2,
    "ai_depth": 5.7,
    "ai_intent": 6.5,
    "ai_audience": 7.2,
    "ai_signal": 6.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 57.0,
    "reasoning": "The content primarily discusses Automated Testing—a technical practice emphasizing software quality and process acceleration. It makes nods to enabling 'organisational agility,' fostering 'continuous improvement,' and aligning with Agile and DevOps principles. The use of terms like 'delivering customer value' and highlighting adaptability/built-in feedback loops shows some conceptual alignment with Agile Strategy. However, there is only a single indirect reference to Agile (in 'aligns with principles of Agile and DevOps'), with no explicit mention of 'Agile Strategy' or core strategic topics such as vision alignment, leadership, or enterprise-scale planning. The focus is clearly on a tactical/technical level, not strategic integration or organizational vision. The depth is moderate—the systemic benefits are explained, but it doesn't provide strategic planning frameworks, leadership guidance, or case studies tied directly to Agile Strategy. Intent is supportive of Agile themes but not directly of the category's core purpose. The audience appears to be a mix of practitioners and those interested in enabling agility. Signal is reasonably strong, with most of the discussion relevant, though a portion remains technical rather than explicitly strategic. As no penalties were necessary, the final score reflects substantive but not primary relevance to the Agile Strategy category.",
    "level": "Tertiary"
  },
  "Current Value": {
    "resourceId": "Automated Testing",
    "category": "Current Value",
    "calculated_at": "2025-05-06T20:57:20",
    "ai_confidence": 45.375,
    "ai_mentions": 0.6,
    "ai_alignment": 4.2,
    "ai_depth": 4.7,
    "ai_intent": 4.0,
    "ai_audience": 7.1,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 45.0,
    "reasoning": "The content on 'Automated Testing' does not directly mention 'Current Value' or focus on Evidence-Based Management concepts. There are no explicit references to Current Value, and no metrics or indicators specifically discussed that tie automated testing outcomes to real-time value measurement for customers or the organization. However, there is moderate conceptual alignment through comments about delivering value, enhancing customer satisfaction, and enabling customer value delivery, which are tangentially relevant to Current Value but not explored in detail. The discussion mostly centers on the benefits of automated testing for workflow efficiency and quality assurance, rather than measurement, analysis, or indicators associated with Current Value. The intent is aligned with technical practitioners (DevOps, Agile teams) but not directly tailored to stakeholders interested in measuring or analyzing Current Value. The content's focus is mostly relevant, but its relation to the category is indirect and lacks substantial depth on the requested classification topic. Therefore, the confidence is appropriately low, reflecting weak, indirect overlap rather than direct or substantial content fit.",
    "level": "Tertiary"
  },
  "Scrum": {
    "resourceId": "Automated Testing",
    "category": "Scrum",
    "calculated_at": "2025-05-06T20:57:20",
    "ai_confidence": 23.9,
    "ai_mentions": 0.5,
    "ai_alignment": 2.2,
    "ai_depth": 2.4,
    "ai_intent": 2.5,
    "ai_audience": 7.6,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content explicitly discusses Automated Testing and its benefits in software development, emphasizing automation, early issue detection, and continuous improvement. There is one indirect mention of Agile and a brief reference to DevOps, but no mention of Scrum, Scrum roles, events, artifacts, or its specific principles, practices, or implementation details. The alignment with Scrum is very weak; while the culture of continuous improvement and self-organization are compatible with Scrum philosophy, the article never focuses on the Scrum framework itself or any elements unique to it. The depth is limited to general practices in automated QA and development pipelines, without exploring Scrum implementation details. The intent is primarily to inform about Automated Testing broadly within software contexts, not Scrum in particular. The audience—technical practitioners interested in software quality—somewhat overlaps with Scrum audiences but is not specifically tailored. The content is focused with little filler, but very little of the core content addresses Scrum; thus, overall confidence is low.",
    "level": "Ignored"
  },
  "Product Validation": {
    "resourceId": "Automated Testing",
    "category": "Product Validation",
    "calculated_at": "2025-05-06T20:57:20",
    "ai_confidence": 31.95,
    "ai_mentions": 0.2,
    "ai_alignment": 2.4,
    "ai_depth": 2.6,
    "ai_intent": 3.9,
    "ai_audience": 5.2,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 32.0,
    "reasoning": "The content focuses on Automated Testing as a practice to ensure software quality and reliable delivery. There is no direct mention of 'Product Validation' or its core methodologies such as user testing, prototyping, market fit assessment, or customer feedback integration. The alignment is low because Automated Testing addresses verifying software quality, not validating product ideas with real users. While some concepts like 'feedback loops' and 'delivering customer value' are nods toward continuous improvement, they are discussed in a general software delivery context, not the context of testing product-market fit or validating assumptions. The depth of discussion is moderate for Automated Testing but lacks substance in areas relevant to Product Validation. The intent is mostly quality assurance, with only tangential support to Product Validation objectives. Audience alignment is moderate, as both audiences might include product teams, but this content is aimed more at engineers than at those interested in iterative product validation with users. The signal-to-noise ratio is relatively high because the content remains focused on its subject, but the subject itself is mostly outside the product validation domain. No penalties were necessary as the content is neither outdated nor contradictory, but the confidence is low due to insufficient alignment with the Product Validation category.",
    "level": "Ignored"
  },
  "Site Reliability Engineering": {
    "resourceId": "Automated Testing",
    "category": "Site Reliability Engineering",
    "calculated_at": "2025-05-06T20:57:20",
    "ai_confidence": 32.2,
    "ai_mentions": 0.4,
    "ai_alignment": 3.6,
    "ai_depth": 3.0,
    "ai_intent": 4.3,
    "ai_audience": 6.1,
    "ai_signal": 6.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 32.0,
    "reasoning": "The content focuses exclusively on Automated Testing, discussing its benefits for software quality, rapid feedback, agility, and development pipeline stability. However, it does not directly mention or discuss Site Reliability Engineering (SRE), its principles, SLOs, incident response, automation specific to production reliability, or the unique role that SREs play. While maintaining reliability is a theme, the core conceptual alignment with SRE is only tangential; automated testing is a general development practice, not specifically tied to SRE contexts in the content presented. The depth of discussion is moderate but never goes beyond showing test automation as a feature for software quality and delivery speed, without exploring operational reliability in production, monitoring, or capacity planning. The main audience seems to be software teams interested in DevOps and Agile, but not specifically SRE practitioners. Signal-to-noise is reasonable since the content is focused and well-argued on automated testing, but its focus is not on SRE practices. No penalties were applied because the information is current and respectful of best practices. Overall, the confidence is low for fitting under SRE, justified by minimal direct and conceptual overlap, with slightly higher scores in audience fit and relevancy/signal.",
    "level": "Ignored"
  },
  "Company as a Product": {
    "resourceId": "Automated Testing",
    "category": "Company as a Product",
    "calculated_at": "2025-05-06T20:57:20",
    "ai_confidence": 36.8,
    "ai_mentions": 0.4,
    "ai_alignment": 3.3,
    "ai_depth": 3.6,
    "ai_intent": 3.7,
    "ai_audience": 5.2,
    "ai_signal": 7.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses exclusively on Automated Testing and its benefits for software delivery, quality, and team agility. While it mentions concepts like cross-functional collaboration, continuous improvement, customer value, and organisational agility, these are framed specifically in the context of software testing practices, not in the broader sense of treating the entire company as a product. There is no explicit mention of 'Company as a Product' (CaaP), nor does the discussion extend to organisational design, company-wide customer feedback integration, or comparative analysis to traditional structures. The depth is moderate as it explores testing's impact on culture and workflow, but never expands to holistic, company-level strategic transformation central to CaaP. The intent is to educate practitioners or leaders about automated testing, not about CaaP principles or implementations. The audience alignment is average, as the readers might be partially interested in organisational strategies, but the technical focus is primary. Signal-to-noise is high because the content is targeted and on-topic for automated testing. No penalties were required as the content isn't outdated, satirical, or in contradiction to CaaP, but the fit is only incidental and conceptually adjacent, not direct.",
    "level": "Ignored"
  },
  "Kanban": {
    "resourceId": "Automated Testing",
    "category": "Kanban",
    "calculated_at": "2025-05-06T20:57:23",
    "ai_confidence": 5.8,
    "ai_mentions": 0.1,
    "ai_alignment": 0.7,
    "ai_depth": 0.6,
    "ai_intent": 1.2,
    "ai_audience": 1.5,
    "ai_signal": 1.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The content is focused exclusively on Automated Testing as a practice to enhance software quality and agility. There is no direct mention or implicit reference to Kanban, its core principles, or related practices such as visualisation of work, work-in-progress limits, or flow management. The main ideas center on test automation and its benefits in Agile and DevOps environments, which, while sharing some surface-level agile principles, do not conceptually align with Kanban’s methodology or practical application. Depth and intent scores are minimal, as Kanban is not the target nor context, and the signal-to-noise ratio reflects that all content is off-topic for the Kanban category. No penalties are applied because the content is modern, neutral in tone, and not critical of Kanban. The extremely low scores reflect the near-total absence of relevance as required by strict category definition.",
    "level": "Ignored"
  },
  "Empirical Process Control": {
    "resourceId": "Automated Testing",
    "category": "Empirical Process Control",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 38.49,
    "ai_mentions": 1.2,
    "ai_alignment": 4.9,
    "ai_depth": 4.4,
    "ai_intent": 5.0,
    "ai_audience": 5.9,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content thoroughly discusses the importance and benefits of Automated Testing within software development, focusing on quality, early defect detection, feedback loops, continuous improvement, and Agile/DevOps practices. However, there are no direct mentions of 'Empirical Process Control' or explicit exploration of its core principles such as transparency, inspection, and adaptation as separate topics. The alignment is partial: while automated testing can support empirical process control in practice (e.g., through feedback loops and adaptation), the content never overtly addresses the theory, nor does it reference key figures or case studies specific to empirical process control. Audience fit is moderate, aiming at practitioners interested in Agile and DevOps, but not specifically those seeking focused exploration on empirical process control. The overall signal-to-noise ratio is decent, as the content stays technical and practical, but the focus is on testing, not on empirical control frameworks themselves. Thus, the confidence that this content strictly fits the 'Empirical Process Control' category is moderate-low, mostly based on conceptual overlap rather than direct intent or depth.",
    "level": "Ignored"
  },
  "Agile Leadership": {
    "resourceId": "Automated Testing",
    "category": "Agile Leadership",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 52.58,
    "ai_mentions": 1.4,
    "ai_alignment": 5.2,
    "ai_depth": 4.9,
    "ai_intent": 6.1,
    "ai_audience": 6.5,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 53.0,
    "reasoning": "The content focuses almost exclusively on Automated Testing as a technical practice. While it references Agile principles, continuous improvement, and organisational agility, it does not directly mention Agile Leadership or cover leadership-specific roles, cultural transformation, or empowerment strategies—the hallmark topics of the Agile Leadership category. The alignment score is moderate: there are some thematic intersections regarding empowerment and agility, but leadership aspects are only implied by phrases like 'fosters a culture' and 'empowers teams', not substantively explored. The depth score reflects the content's detail about testing within an Agile context but remains shallow on direct leadership discourse. Intent is largely about informing on the benefits of automated testing, not on guiding leaders or shaping Agile culture. The audience is likely cross-functional teams and developers, with some overlap with those interested in Agile, but not directly leaders or managers. The signal-to-noise ratio is relatively high, as the content is focused and on-topic, but not on this specific category. No penalties were applied, as the content does not undermine, satirize, or advocate outdated practices. The final confidence score reflects that while the content has touchpoints with agility and improvement, it is not significantly about Agile Leadership.",
    "level": "Tertiary"
  },
  "Digital Transformation": {
    "resourceId": "Automated Testing",
    "category": "Digital Transformation",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 72.6,
    "ai_mentions": 2.4,
    "ai_alignment": 8.1,
    "ai_depth": 7.3,
    "ai_intent": 6.9,
    "ai_audience": 7.6,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 73.0,
    "reasoning": "The content on 'Automated Testing' focuses in depth on testing as a key enabler of software quality, reliability, and organisational agility. While it never directly mentions 'Digital Transformation', many concepts are implicitly aligned—especially themes like enhancing agility, supporting continuous improvement, accelerating delivery, and integrating modern practices such as Agile and DevOps. The piece discusses the strategic value of automated testing for business agility and sustainable value delivery, aligning it conceptually with Digital Transformation. However, it does not explicitly discuss the broader strategic integration of digital technologies or reference digital transformation frameworks, and the audience is more technical (development/DevOps practitioners) than strategic (executives, transformation leaders). Depth is strong as it goes beyond surface-level mentions, but intent and alignment are slightly limited by its narrow focus on testing rather than holistic transformation. No penalties were applied, as the content is current, constructive, and does not contradict the category's framing.",
    "level": "Secondary",
    "reasoning_summary": "While the content thoroughly explores automated testing and its benefits for software quality and agility, it doesn’t directly address Digital Transformation as a broader organisational strategy. Its focus is technical, appealing mainly to practitioners, and lacks explicit discussion of digital transformation frameworks or leadership perspectives, making its fit with the category partial rather than comprehensive."
  },
  "Market Adaptability": {
    "resourceId": "Automated Testing",
    "category": "Market Adaptability",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 81.46,
    "ai_mentions": 7.5,
    "ai_alignment": 8.7,
    "ai_depth": 8.3,
    "ai_intent": 8.1,
    "ai_audience": 8.0,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 81.0,
    "reasoning": "The content on Automated Testing explicitly references concepts central to Market Adaptability, such as accelerating delivery, shortening feedback loops, supporting Agile and DevOps principles, and enabling organisational agility. While the primary focus is on automated testing, the discussion meaningfully connects this practice to adapting quickly to market changes, maintaining high throughput, and delivering continuous value—core to the category. Direct mentions of Agile, DevOps, feedback loops, customer value, and adaptability strongly align. The discussion goes significantly beyond surface features, addressing systemic enablers and strategic outcomes. The intent is highly supportive, aiming to inform an audience interested in agility and responsiveness, likely practitioners or technology leaders—directly matching the category’s audience. Some information is general to testing best practices, but the majority is focused and relevant, especially in how testing supports adaptability. No penalties are applied as the practices and framing are current and aligned with the positive, enabling tone. The confidence score is high due to deep, focused alignment but stops short of perfect due to the content’s primary lens being automated testing rather than market adaptability as a sole topic.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the Market Adaptability category. It clearly links automated testing to key adaptability themes like rapid delivery, Agile and DevOps practices, and organisational agility. The discussion goes beyond basics, showing how testing enables quick market response and continuous value, making it highly relevant for those focused on adaptability and change."
  },
  "Daily Scrum": {
    "resourceId": "Automated Testing",
    "category": "Daily Scrum",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 1.6,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.6,
    "ai_intent": 0.7,
    "ai_audience": 2.0,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content is focused exclusively on Automated Testing, its benefits, and its role in Agile and DevOps environments. There are zero direct mentions of the Daily Scrum, and no implicit references to specific Scrum events or ceremonies. Conceptual alignment is extremely low, as the main themes are quality assurance and automation, not team alignment or daily progress inspection. Depth is minimal regarding Daily Scrum (none of the key topics are discussed). The intent does not align with discussing Daily Scrum; it's instead aimed at general agile practitioners interested in testing practices. The audience is somewhat related (software teams/practitioners), but the content's signal is almost entirely off-topic for the Daily Scrum category. No penalties were deemed necessary because the content is not outdated, nor is it satirical or critical. The extremely low confidence reflects that this content should not be classified under 'Daily Scrum' by any reasonable standard.",
    "level": "Ignored"
  },
  "Value Stream Management": {
    "resourceId": "Automated Testing",
    "category": "Value Stream Management",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 28.53,
    "ai_mentions": 0.5,
    "ai_alignment": 3.2,
    "ai_depth": 2.95,
    "ai_intent": 3.85,
    "ai_audience": 6.1,
    "ai_signal": 5.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 29.0,
    "reasoning": "While the content discusses concepts related to delivering value, process automation, and organisational agility, it does not explicitly mention Value Stream Management or its core frameworks. The focus is tightly on Automated Testing as a technical and process enabler, touching on value delivery only in broad strokes. There is indirect thematic alignment through references to continuous improvement, customer value, and Agile/DevOps principles (aligning somewhat with VSM's goals), but no direct coverage of value stream mapping, waste identification, or VSM-specific metrics. The intent appears to be education about testing practices for software teams rather than providing insight or instruction on how to manage or analyse value streams. Audience alignment is moderate, as software practitioners interested in Automated Testing may overlap with those interested in VSM, but the content is not tailored for VSM leaders or strategists. Signal-to-noise is decent, as the content is focused, but its relevance to Value Stream Management is tangential and not central. No penalties applied.",
    "level": "Ignored"
  },
  "Value Stream Mapping": {
    "resourceId": "Automated Testing",
    "category": "Value Stream Mapping",
    "calculated_at": "2025-05-06T20:57:27",
    "ai_confidence": 7.39,
    "ai_mentions": 0.1,
    "ai_alignment": 1.2,
    "ai_depth": 1.5,
    "ai_intent": 1.1,
    "ai_audience": 1.8,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content does not mention Value Stream Mapping (VSM) directly, nor does it discuss any of the key VSM topics, principles, or techniques. Its focus is exclusively on Automated Testing and software quality assurance rather than on mapping, visualising, or optimising process flows. While there is a passing reference to delivering value and some indirect alignment to Lean/Agile practices, the content lacks substantive conceptual overlap with VSM. The target audience (software practitioners) may sometimes overlap with VSM audiences, but the discussion is not directed toward practitioners of process mapping or Lean improvement. The signal-to-noise ratio is slightly higher than other dimensions since the content is focused (though off-topic), and no penalties were needed as the content is not outdated, nor is it critical. Overall, the confidence that this content fits under 'Value Stream Mapping' is extremely low.",
    "level": "Ignored"
  },
  "Technical Leadership": {
    "resourceId": "Automated Testing",
    "category": "Technical Leadership",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 65.85,
    "ai_mentions": 1.9,
    "ai_alignment": 7.6,
    "ai_depth": 7.4,
    "ai_intent": 7.9,
    "ai_audience": 7.1,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 66.0,
    "reasoning": "The content focuses primarily on the benefits, strategies, and business impact of automated testing within a software development context, emphasizing agility, continuous improvement, cross-functional collaboration, and alignment with Agile and DevOps principles. While technical leadership is not explicitly mentioned, the themes strongly overlap with those discussed in technical leadership, such as enabling team productivity, fostering a culture of quality, and supporting customer-centric delivery. However, the piece does not directly discuss the role or responsibilities of technical leaders, nor does it mention practices like mentoring, facilitation of agile ceremonies, or architectural decision-making. The depth of discussion on how automated testing influences team and organizational agility adds some alignment, but the primary subject matter is automated testing rather than technical leadership per se. No penalties are applied because the content is up-to-date and aligns with modern best practices, and the tone is professional and supportive. The confidence score reflects moderate suitability due to indirect but relevant alignment.",
    "level": "Secondary"
  },
  "Lead Time": {
    "resourceId": "Automated Testing",
    "category": "Lead Time",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 20.45,
    "ai_mentions": 0.0,
    "ai_alignment": 2.2,
    "ai_depth": 2.0,
    "ai_intent": 2.4,
    "ai_audience": 7.1,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content exclusively discusses Automated Testing, emphasizing its benefits for software quality, early detection of issues, and accelerating software delivery. There is no direct mention of 'Lead Time' or its definition as an observability metric. The content does not explore techniques for measuring, tracking, or optimizing Lead Time. While a minor conceptual overlap exists—Automated Testing can reduce delivery times and thus indirectly impact Lead Time—the main focus is tooling, quality assurance, and process improvement rather than on cycle metrics or observability. The audience (technical practitioners and team leads) aligns with the category, and the writing is focused without off-topic filler. However, the lack of explicit or in-depth linkage to the core meaning of 'Lead Time' sharply limits the confidence score, resulting in very low direct mentions, alignment, and depth.",
    "level": "Ignored"
  },
  "Lean Product Development": {
    "resourceId": "Automated Testing",
    "category": "Lean Product Development",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 31.322,
    "ai_mentions": 0.2,
    "ai_alignment": 3.9,
    "ai_depth": 3.6,
    "ai_intent": 4.1,
    "ai_audience": 4.9,
    "ai_signal": 5.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 31.0,
    "reasoning": "The content centers on Automated Testing for software quality, focusing on its benefits for reliability, early issue detection, and delivery acceleration. While it references concepts like continuous improvement, feedback loops, and value delivery—which are conceptually aligned with Lean principles—the text never directly mentions Lean Product Development or discusses its distinctive frameworks, terminology, or case studies. Depth remains modest: though it touches on system-level impacts and cultural benefits, the discussion is largely confined to testing, with scant exploration of Lean waste reduction, value stream mapping, or Lean-Agile integration. Intent aligns partially, as the advice generally supports efficient product development, but the primary focus is on process efficiency rather than Lean's comprehensive product development philosophy. The target audience (software teams, possibly technical leaders) could overlap with Lean practitioners but is not specifically addressed. Signal-to-noise is moderate: some Lean-aligned references exist, but most content orbits QA and general Agile/DevOps best practices. Thus, the confidence score is low, reflecting focus on a subtopic relevant to, but not constitutive of, Lean Product Development.",
    "level": "Ignored"
  },
  "Enterprise Agility": {
    "resourceId": "Automated Testing",
    "category": "Enterprise Agility",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 61.75,
    "ai_mentions": 2.2,
    "ai_alignment": 7.1,
    "ai_depth": 6.8,
    "ai_intent": 6.9,
    "ai_audience": 6.2,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 62.0,
    "reasoning": "The content focuses primarily on Automated Testing as a practice for enhancing software quality and delivery. While it makes several references to agility ('organisational agility,' 'respond swiftly to changes,' 'aligns with principles of Agile and DevOps'), these are largely framed as benefits or tangential elements rather than as the main topic. There are brief mentions of continuous improvement, collaboration, and adaptability, directly relating to the Enterprise Agility category, but there are no deep dives into frameworks, organisational transformation, or leadership roles at scale. The discussion is more technical/team-focused, with passing connections to organisational level agility. Direct mentions of 'agility' and explicit reference to integration with Agile/DevOps only occur once or twice. The intent and audience partially align—this could be read by those interested in enterprise agility, but also fits a purely technical audience. The majority of the content remains focused on the practice of Automated Testing itself, not on scaling agility or organisation-wide transformation. Therefore, while there is conceptual alignment and some depth, the overall relevance to Enterprise Agility is moderate, but not strong. No penalties were applied, as the content is current, neutral, and does not contradict the category.",
    "level": "Secondary"
  },
  "Project Management": {
    "resourceId": "Automated Testing",
    "category": "Project Management",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 44.09,
    "ai_mentions": 1.3,
    "ai_alignment": 5.4,
    "ai_depth": 4.95,
    "ai_intent": 4.0,
    "ai_audience": 4.6,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 44.0,
    "reasoning": "The content focuses primarily on automated testing as a software engineering practice to ensure quality and reliability, outlining benefits such as early issue detection, reduced manual effort, and alignment with agile and DevOps principles. There are indirect project management connections, such as references to accelerating delivery and enabling organizational agility, but project management itself is neither directly mentioned nor used as a framing context. The content does not cover project management methodologies, key roles, project lifecycle phases, or governance topics from the category definition. The main intent is to advocate for automated testing rather than provide project management guidance. The audience is likely software engineers or quality professionals rather than project management practitioners. There is moderate signal due to some overlap in values (continuous improvement, stakeholder value), but the depth of project management discussion is shallow, with no exploration of tools or techniques specific to the category. Scores reflect secondary relevance, with the final confidence well below the threshold for strong topical alignment.",
    "level": "Tertiary"
  },
  "Sensemaking": {
    "resourceId": "Automated Testing",
    "category": "Sensemaking",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 18.648,
    "ai_mentions": 0.2,
    "ai_alignment": 1.523,
    "ai_depth": 1.805,
    "ai_intent": 0.95,
    "ai_audience": 7.124,
    "ai_signal": 8.16,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content focuses exclusively on the practices, benefits, and organizational impact of Automated Testing. There are no direct mentions or substantial discussion of sensemaking, interpreting complexity, or related frameworks (e.g., Cynefin). Conceptual alignment is minimal: while it superficially references agility, adaptation, and collaboration, these are presented strictly through the lens of software quality and testing. The discussion dives into technical practices, workflow optimization, and Agile/DevOps principles, but not how organizations interpret complexity to make sense of ambiguous environments. The content's primary intent is to inform technical and QA practitioners about the value of automated testing, not to teach or discuss sensemaking. The target audience partially overlaps (organizations, teams) but is not focused on sensemaking practitioners or strategists. Most of the content is focused, but on a different topic. Thus, the confidence is very low, with no penalties applied. The low scores for mentions, alignment, depth, and intent keep the confidence down, while audience and signal scores are modestly higher, reflecting some overlap in issues of organizational agility.",
    "level": "Ignored"
  },
  "Team Performance": {
    "resourceId": "Automated Testing",
    "category": "Team Performance",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 86.7,
    "ai_mentions": 6.7,
    "ai_alignment": 9.5,
    "ai_depth": 8.8,
    "ai_intent": 9.0,
    "ai_audience": 8.0,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 87.0,
    "reasoning": "The content centers on Automated Testing as a means to improve software quality, reliability, and delivery predictability at the team level. While 'team performance' is not named directly and explicit references to delivery metrics or system-level performance are not dominant, the entire discussion focuses on how Automated Testing strengthens team delivery, promotes sustainable throughput, and enables faster, more reliable outcomes. Strong conceptual alignment is evident, with repeated connections between automation, predictability, and continuous improvement for teams. The depth goes beyond surface-level by describing how Automated Testing enables continuous improvement, aligns with Agile/DevOps, and drives organization-wide agility. The main intent is directly relevant for teams aiming to increase delivery capabilities. The audience appears to be practitioners and leaders concerned with delivery systems. Slight deductions in mentions and signal accounts for the absence of explicit 'team performance' metrics and for a minor inclusion of broader organizational agility. No penalties are necessary as the content is current, positive, and fully supportive. Thus, the confidence reflects high, but not perfect, fit to the 'Team Performance' category.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the 'Team Performance' category, as it thoroughly explores how Automated Testing enhances team delivery, reliability, and continuous improvement. While it doesn’t explicitly mention 'team performance' metrics, its focus on improving team outcomes and delivery processes makes it highly relevant for practitioners and leaders interested in boosting team effectiveness."
  },
  "Platform Engineering": {
    "resourceId": "Automated Testing",
    "category": "Platform Engineering",
    "calculated_at": "2025-05-06T20:57:30",
    "ai_confidence": 27.42,
    "ai_mentions": 0.7,
    "ai_alignment": 3.3,
    "ai_depth": 2.7,
    "ai_intent": 2.8,
    "ai_audience": 4.1,
    "ai_signal": 2.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 27.0,
    "reasoning": "The content focuses extensively on automated testing, discussing its benefits for software quality, early issue detection, and integration in development pipelines. However, there is no direct mention or explicit reference to Platform Engineering, Internal Developer Platforms, or platform-focused self-service, automation, or standardization. The conceptual alignment is weak: while automated testing is a supporting practice within Platform Engineering, the article treats it generically, referencing DevOps and Agile but not connecting automated testing specifically to the processes, tooling, or culture of platform engineering. Depth is moderate regarding testing but sparse about platform topics. The intent is to inform about testing benefits, but the core purpose is not platform-centric. The target audience is software practitioners generally, not specifically platform engineers or their stakeholders. The majority of the content is on-topic for automated testing but off-topic for platform engineering, resulting in a low signal-to-noise ratio for this category. No penalties applied, as there is no satirical or outdated material present.",
    "level": "Ignored"
  },
  "Windows": {
    "resourceId": "Automated Testing",
    "category": "Windows",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 13.14,
    "ai_mentions": 0.05,
    "ai_alignment": 0.3,
    "ai_depth": 0.22,
    "ai_intent": 0.4,
    "ai_audience": 8.1,
    "ai_signal": 0.22,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content focuses entirely on the general concept of automated testing, its benefits, and its role in modern software development. There is no mention of Windows or the Windows operating system, nor any references to installation, configuration, troubleshooting, or management of Windows environments. The conceptual alignment is extremely low because it does not discuss or even imply Windows-specific features, tools, or challenges. The audience (software engineering/IT professionals) could overlap with Windows practitioners, but the topic is generalized, not targeting Windows users specifically. The signal-to-noise ratio, direct mentions, and depth scores are minimal because none of the content is topically relevant to Windows as defined by the category criteria. No penalties were needed, as there is no outdated or contradictory material, but the confidence is extremely low due to complete lack of topical relevance.",
    "level": "Ignored"
  },
  "Customer Feedback Loops": {
    "resourceId": "Automated Testing",
    "category": "Customer Feedback Loops",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 32.85,
    "ai_mentions": 0.6,
    "ai_alignment": 3.9,
    "ai_depth": 3.35,
    "ai_intent": 4.0,
    "ai_audience": 7.2,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content primarily focuses on the practices, benefits, and strategic importance of Automated Testing. While there are some mentions of 'feedback loops' (e.g., 'shortened feedback loops' in the context of code quality and agility), these are brief references and not elaborated as customer feedback mechanisms. Key dimensions such as Direct Mentions, Conceptual Alignment, and Depth score low, as the main ideas center on software quality and development pipeline automation rather than collecting or acting on customer feedback. The content's intent is to advocate for automated testing as a technical and organizational enabler rather than to discuss feedback loop processes for customer-driven development. The audience aligns reasonably well with practitioners and technical teams, and most of the content remains relevant and focused (signal), but little of it is directly about Customer Feedback Loops as defined. No penalties are required, as the content is current and not satirical or critical. Overall, the confidence reflects the very peripheral connection to the intended category.",
    "level": "Ignored"
  },
  "Estimation": {
    "resourceId": "Automated Testing",
    "category": "Estimation",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 8.2,
    "ai_mentions": 0.0,
    "ai_alignment": 2.1,
    "ai_depth": 1.9,
    "ai_intent": 2.2,
    "ai_audience": 2.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content exclusively discusses automated testing, software quality, and its integration with Agile and DevOps practices. There are no direct mentions of estimation, techniques, or the process of forecasting within Agile or Scrum. The content does not cover empirical data, collaborative estimation techniques, or any of the core topics specified for the Estimation category. At best, there is an indirect alignment in its reference to predictability and continuous improvement, which may relate to Agile values, but not specifically to estimation. The minimal fractional scores for alignment and depth reflect this loose association, with the majority of the content focused entirely on testing-related topics rather than estimation. The audience (Agile/technical teams) and the overall context are a modest but insufficient fit for the Estimation category. No penalties were necessary as the content is up to date and does not undermine the category; it is simply unrelated.",
    "level": "Ignored"
  },
  "Scaling": {
    "resourceId": "Automated Testing",
    "category": "Scaling",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 13.42,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 1.6,
    "ai_intent": 2.8,
    "ai_audience": 4.0,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content discusses the benefits and strategic importance of automated testing in enhancing software quality and delivery speed. While there is a general nod towards organizational agility, cross-functional teams, and continuous improvement, there are no direct mentions of scaling frameworks (SAFe, LeSS, Nexus), nor are scaling methodologies or unique scaling challenges addressed. The depth of discussion is centrally around testing as a practice within teams, not about coordination across teams or enterprise alignment at scale. The intent is to inform about automated testing, targeting practitioners—possibly overlapping with the broader audience interested in scaling—but not focused on enterprise-level coordination or scaling strategies. Signal-to-noise is moderate, as the content is relevant to quality/DevOps but only tangential to the Scaling category. No points are deducted, as the content is current and the tone is objective. Overall, confidence is low regarding this content meaningfully fitting the 'Scaling' category.",
    "level": "Ignored"
  },
  "Sprint Review": {
    "resourceId": "Automated Testing",
    "category": "Sprint Review",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 8.0,
    "ai_mentions": 0.3,
    "ai_alignment": 0.8,
    "ai_depth": 0.7,
    "ai_intent": 0.8,
    "ai_audience": 1.2,
    "ai_signal": 0.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content is solely focused on Automated Testing, discussing its value in software development, Agile, and DevOps contexts. There is no explicit mention or discussion of the 'Sprint Review,' nor any covered topic from the Sprint Review category's definition or key topics. None of the points—method, process, participant roles, feedback, or adaptation of the product backlog during a Sprint Review—are discussed or even referenced obliquely. The main ideas, while within the broader context of Agile practices, have no conceptual or practical alignment to what occurs in a Sprint Review. The intent, depth, and audience are technical and broadly targeted to practitioners, but not specifically those seeking Sprint Review insights. As such, the content has negligible direct relevance or connection to 'Sprint Review,' reflected in the very low confidence and sub-1 scores across all dimensions.",
    "level": "Ignored"
  },
  "Test Automation": {
    "resourceId": "Automated Testing",
    "category": "Test Automation",
    "calculated_at": "2025-05-06T20:57:32",
    "ai_confidence": 91.1,
    "ai_mentions": 9.8,
    "ai_alignment": 9.3,
    "ai_depth": 8.9,
    "ai_intent": 9.1,
    "ai_audience": 8.8,
    "ai_signal": 9.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 91.0,
    "reasoning": "The content explicitly centers on Automated Testing, directly using the term multiple times and reinforcing the connection to test automation concepts. Mentions are strong (9.8) with clear and repetitive use. Alignment (9.3) is very high, as the discussion precisely matches the category’s definition, describing the rationale, value, and role in Agile/DevOps. The depth is substantial (8.9): it elaborates on systematic benefits (e.g., early issue detection, reduced manual effort, shift-left strategy, CI/CD pipeline integration) and contextualizes why automation matters, though it is short on concrete technical tools/frameworks. Intent (9.1) is strongly aligned as the text is designed to inform and persuade practitioners of the necessity and organizational impact of automated testing. Audience alignment (8.8) is strong, targeting technical practitioners (teams, organizational context), though it is not deeply technical (few details on specific frameworks), slightly lowering the score. Signal-to-noise ratio (9.0) is high; all content is on-topic and purposeful, with no off-topic filler. No penalties are warranted as the content is up-to-date, supportive, and fully aligned with the category ethos.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the Automated Testing category. It clearly focuses on test automation, thoroughly explaining its benefits and relevance within Agile and DevOps contexts. The discussion is well-targeted at technical practitioners, offering valuable insights into why automated testing is essential, even though it doesn’t delve into specific tools or frameworks. Overall, it’s highly relevant and purposeful."
  },
  "Technical Excellence": {
    "resourceId": "Automated Testing",
    "category": "Technical Excellence",
    "calculated_at": "2025-05-06T20:57:27",
    "ai_confidence": 82.15,
    "ai_mentions": 5.8,
    "ai_alignment": 9.2,
    "ai_depth": 8.7,
    "ai_intent": 8.3,
    "ai_audience": 8.7,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 82.0,
    "reasoning": "The content thoroughly discusses Automated Testing as a high-level practice that increases software quality, reliability, and agility — well-aligned with Technical Excellence. While the term 'Technical Excellence' is not directly mentioned, many aligned concepts are present, such as enabling high-quality software, fostering continuous improvement, integrating with Agile and DevOps, and embedding practices into the development workflow. Depth is strong: the article goes beyond 'just use this tool/method' to address broader organizational and engineering benefits, systemic enablers, and outcomes like customer satisfaction. The intended audience is technical practitioners and leaders focused on delivery and quality. The signal is largely on-topic, though does not explicitly mention some signature practices like TDD or modular architecture, resulting in a slightly lower signal score. No outdated or negative tone is observed, so no penalties are warranted. The formula yields a high confidence score, as the content robustly supports the goals and themes of Technical Excellence.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the Technical Excellence category. It explores how Automated Testing enhances software quality, reliability, and agility, and connects these benefits to broader engineering and organisational outcomes. While it doesn’t name every signature practice, it clearly targets technical professionals and aligns with the core aims of Technical Excellence, making it highly relevant."
  },
  "Behaviour Driven Development": {
    "resourceId": "Automated Testing",
    "category": "Behaviour Driven Development",
    "calculated_at": "2025-05-06T20:57:32",
    "ai_confidence": 23.05,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.9,
    "ai_intent": 3.0,
    "ai_audience": 5.0,
    "ai_signal": 3.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "The content addresses automated testing broadly, focusing on its role in improving software quality, enabling early defect detection, supporting Agile/DevOps, and driving organizational efficiency. There are no direct references to Behaviour Driven Development (BDD), either by name or by discussing BDD-specific concepts such as user stories, acceptance criteria, stakeholder collaboration, or BDD tools like Cucumber/SpecFlow. While automated testing is compatible with BDD and sometimes used within BDD approaches, the text does not make that connection or align its themes with BDD principles specifically. Thus, the Direct Mentions score is near zero, and the Conceptual Alignment and Depth scores are low, as the content's core focus is generic test automation, not the practices, intent, or collaborative principles central to BDD. The audience is somewhat aligned (teams concerned with testing and software quality), which justifies a moderate Audience score. The Signal-to-Noise ratio is also low-to-moderate as all content is about testing, but not about BDD. No penalties are applied as the content is not outdated, critical, or satirical. Overall, the confidence score is low, appropriately reflecting that this content does not fit under the Behaviour Driven Development category.",
    "level": "Ignored"
  },
  "Mentoring": {
    "resourceId": "Automated Testing",
    "category": "Mentoring",
    "calculated_at": "2025-05-06T20:57:27",
    "ai_confidence": 8.2,
    "ai_mentions": 0.0,
    "ai_alignment": 1.2,
    "ai_depth": 0.9,
    "ai_intent": 0.6,
    "ai_audience": 2.1,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content is entirely focused on the practice, benefits, and organizational impacts of Automated Testing. There are no direct mentions of mentoring, coaching, or any relevant developmental guidance as defined for the 'Mentoring' category. Alignment and depth are extremely low, as the article does not touch on skills development, coaching techniques, leadership strategies, or supporting professional growth apart from general references to team benefits and agile principles. The intent is informative about a technical practice, not developmental coaching, and the target audience appears to be practitioners seeking to improve software quality through automation rather than those seeking guidance or mentorship. The signal-to-noise ratio is low as virtually none of the content is relevant to mentoring. No penalties were applied since the tone is neutral and the information is current, but the resulting confidence, per the weighted formula, is justifiably extremely low, reflecting an almost complete lack of fit for the 'Mentoring' category.",
    "level": "Ignored"
  },
  "Coaching": {
    "resourceId": "Automated Testing",
    "category": "Coaching",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 6.4,
    "ai_mentions": 0.2,
    "ai_alignment": 0.9,
    "ai_depth": 1.3,
    "ai_intent": 0.4,
    "ai_audience": 2.5,
    "ai_signal": 0.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The content 'Automated Testing' is entirely focused on the practice, benefits, and organizational impact of automated software testing. There are no direct mentions of coaching or coaching-related topics, nor are any terms such as 'coach', 'mentoring', 'guidance', or 'development' used. The main ideas align with continuous improvement and cross-functional collaboration, but these themes are discussed in the context of automation, not coaching. There is minor peripheral conceptual overlap with coaching in references to culture, empowerment, and Agile/DevOps collaboration, but the depth is minimal, and coaching is not an explicit or implied theme. The primary intent is informative for technical teams, not to explore coaching practices, roles, or dynamics. The signal-to-noise ratio is low from a coaching perspective, as almost none of the content is relevant to that category. No outdated or contradictory content was found, so no penalties are applied. The extremely low confidence score reflects the near-total lack of category relevance.",
    "level": "Ignored"
  },
  "Evidence Based Management": {
    "resourceId": "Automated Testing",
    "category": "Evidence Based Management",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 43.3,
    "ai_mentions": 1.2,
    "ai_alignment": 5.7,
    "ai_depth": 4.9,
    "ai_intent": 5.6,
    "ai_audience": 6.3,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "The content is focused on the topic of Automated Testing as a means to ensure software quality, reduce manual effort, and speed up delivery. Although it discusses outcomes like improved customer satisfaction, value delivery, and agility — all pertinent to some evidence-based management themes — it never explicitly mentions Evidence-Based Management (EBM), nor does it reference the core EBM topics (Current Value, Time to Market, Outcome Management, etc.) in detail. There are no direct citations of empirical data driving management decisions. Instead, the discussion is primarily about engineering practice and its organizational benefits, not the application of empirical evidence to management or decision-making in a structured EBM framework. There are brief mentions that slightly touch on value delivery and feedback loops present in EBM, aligning moderately for intent, audience, and relevance to managers and teams seeking organizational improvement. The depth remains surface level in the EBM context, and signal to noise is middling as most content is technical, not management/process focused. No penalties were applied, as the content is neither outdated nor contradicts EBM principles. However, the overall confidence is modest, reflecting that while the content is adjacent to EBM and value-focused, it does not substantially or explicitly fit the category.",
    "level": "Tertiary"
  },
  "Product Development": {
    "resourceId": "Automated Testing",
    "category": "Product Development",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 85.95,
    "ai_mentions": 5.4,
    "ai_alignment": 9.0,
    "ai_depth": 8.7,
    "ai_intent": 8.2,
    "ai_audience": 8.1,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 86.0,
    "reasoning": "The content explicitly connects Automated Testing to principles core to Product Development, such as enabling early feedback, supporting Agile and DevOps workflows, fostering continuous improvement, and facilitating cross-functional collaboration. Direct references to concepts like feedback loops, customer value, iterative improvement, and pipeline integration demonstrate strong conceptual alignment. The discussion goes beyond technical implementation, emphasizing strategic and organizational benefits—key to the category. While 'Product Development' is not named verbatim, many related terms and concepts are present, supporting a moderate 'Direct Mentions' score. The content is thorough, discussing systemic impact rather than just technical aspects, making the 'Depth' score high. The purpose clearly matches the category: it's informative and directly intended for teams concerned with developing valuable and usable products. The content targets practitioners and organizational stakeholders in product delivery, with no significant technical implementation bias or irrelevant content, justifying high scores for 'Audience' and 'Signal.' No outdated or critical tone, so no penalties applied. Weighted aggregation, after calibration, places confidence at 85.95, reflecting strong but not absolute fit given the lack of the direct category term.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the Product Development category. It thoroughly explores how Automated Testing supports key product development practices—like early feedback, Agile workflows, and continuous improvement—while highlighting both strategic and organisational benefits. Although the exact term isn’t used, the concepts and audience clearly align, making the classification highly appropriate."
  },
  "Trend Analysis": {
    "resourceId": "Automated Testing",
    "category": "Trend Analysis",
    "calculated_at": "2025-05-06T20:57:30",
    "ai_confidence": 46.98,
    "ai_mentions": 1.2,
    "ai_alignment": 5.6,
    "ai_depth": 5.8,
    "ai_intent": 6.4,
    "ai_audience": 7.7,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 47.0,
    "reasoning": "The content on 'Automated Testing' primarily focuses on the benefits, mechanics, and strategic value of automated tests in software development, particularly within Agile and DevOps contexts. While it references concepts relevant to business agility and automation's role in adaptability, it does not directly examine or analyze trends, shifts, or patterns over time in these practices. There are no explicit mentions of 'trend analysis,' emerging industry directions, analytics, or case studies examining the evolution of automated testing. The conceptual alignment and depth scores reflect some discussion on strategic impact and agility, which connects tangentially to the mindset of trend adaptation, but there is no substantial exploration of trend identification, metrics, or forward-looking analysis. The intent and audience scores are relatively strong, as this content would be of interest to practitioners and managers aligning with Agile and DevOps, and the information is largely focused. However, the low direct mentions and only partial conceptual alignment substantially reduce the overall confidence, as the core meaning of the 'Trend Analysis' category is not substantially engaged.",
    "level": "Tertiary"
  },
  "Agile Frameworks": {
    "resourceId": "Automated Testing",
    "category": "Agile Frameworks",
    "calculated_at": "2025-05-06T20:57:30",
    "ai_confidence": 37.75,
    "ai_mentions": 1.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.2,
    "ai_intent": 4.8,
    "ai_audience": 6.2,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content focuses almost exclusively on automated testing practices and their benefits for quality, speed, and organizational agility. There is a single passing mention of alignment with Agile principles, but no explicit reference to Agile frameworks themselves (Scrum, Kanban, Lean, XP, etc.) or comparison of frameworks. Depth and conceptual alignment with the 'Agile Frameworks' category is limited, as automated testing is a supportive practice rather than an exploration of framework structures, principles, or value delivery models. The intent is adjacent but not directly centered on Agile frameworks. The audience is likely technical teams or DevOps practitioners rather than specifically those studying or implementing Agile frameworks at an organizational level. Overall, only a modest portion of the text is relevant to Agile frameworks strictly as defined; therefore, the confidence score is appropriately low and penalties were not required.",
    "level": "Ignored"
  },
  "GitHub": {
    "resourceId": "Automated Testing",
    "category": "GitHub",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 9.3,
    "ai_mentions": 0.2,
    "ai_alignment": 0.6,
    "ai_depth": 0.8,
    "ai_intent": 0.5,
    "ai_audience": 2.0,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content extensively discusses automated testing as a modern software practice, but never mentions GitHub, nor does it reference any GitHub services, features, or functionalities. There are no mentions of GitHub Actions, repositories, workflows, or any GitHub-specific integration for CI/CD or version control. The alignment and depth scores are low because the content is conceptually adjacent to topics used within GitHub (like automation and CI/CD) but fails to tie these directly to GitHub. Intent, audience, and signal scores are slightly higher as the information is aimed at practitioners who often use tools like GitHub, but the overall lack of explicit or implicit connection to GitHub severely limits category fit. No penalties were applied as the content is current and neutral in tone.",
    "level": "Ignored"
  },
  "Organisational Change": {
    "resourceId": "Automated Testing",
    "category": "Organisational Change",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 41.53,
    "ai_mentions": 2.3,
    "ai_alignment": 4.6,
    "ai_depth": 4.3,
    "ai_intent": 4.8,
    "ai_audience": 4.1,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content focuses on Automated Testing as a technique to improve software quality and delivery speed. While it briefly references organisational agility and culture (e.g., fostering a culture of continuous improvement, supporting Agile and DevOps principles, systemic enabler of organisational agility), the main substance stays technical and process-focused. There are indirect links to organisational change (such as mentioning adaptability and cross-functional collaboration), but no direct discussion of change management strategies, frameworks, leadership roles in change, or overcoming resistance. The target audience is primarily technical with light nods toward business impact. Thus, the conceptual alignment and depth are moderate but not substantial; mentions are indirect and infrequent. No penalties apply as the tone is appropriate and current. The resulting confidence reflects that while there are connections, the content is tangential for the 'Organisational Change' category.",
    "level": "Tertiary"
  },
  "Frequent Releases": {
    "resourceId": "Automated Testing",
    "category": "Frequent Releases",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 74.73,
    "ai_mentions": 3.0,
    "ai_alignment": 8.2,
    "ai_depth": 7.7,
    "ai_intent": 8.3,
    "ai_audience": 8.1,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 75.0,
    "reasoning": "The content strongly discusses automated testing as a means to accelerate software delivery, enhance agility, and support continuous improvement, which conceptually aligns well with the principles behind Frequent Releases. However, there are no direct, explicit mentions of 'Frequent Releases,' continuous delivery, or associated methodologies (hence the lower score in Direct Mentions). The discussion emphasizes enablers for rapid and reliable delivery, focusing on how automated testing supports a culture of continuous improvement and responsiveness to change, tying into the core intent behind Frequent Releases. The depth of discussion goes beyond superficial references by detailing cultural and technical benefits. The intended audience—software development teams and organizational leadership focused on agility—matches that of Frequent Releases guidance. Signal-to-noise ratio remains high since all content is on-topic, but not all information directly links automated testing to release frequency. No obsolete practices or negative tone was found, so no penalties were applied. In summary, the content is highly relevant as a strategic enabler for Frequent Releases but is indirectly aligned rather than a direct treatise or guide to Frequent Releases itself.",
    "level": "Secondary",
    "reasoning_summary": "This content is highly relevant to the Frequent Releases category because it explores how automated testing enables faster, more reliable software delivery and supports a culture of continuous improvement. While it doesn’t directly mention Frequent Releases or related methodologies, its focus on agility and delivery speed makes it a strong, though indirect, fit for the category’s intent and audience."
  },
  "Modern Source Control": {
    "resourceId": "Automated Testing",
    "category": "Modern Source Control",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 8.83,
    "ai_mentions": 0.5,
    "ai_alignment": 1.9,
    "ai_depth": 1.8,
    "ai_intent": 1.3,
    "ai_audience": 1.8,
    "ai_signal": 1.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content is exclusively focused on automated testing within the context of software quality and development pipelines. There are no direct mentions of modern source control systems, version control strategies, or relevant best practices—the closest overlap is the mention of integration into the development pipeline, which might include CI/CD, a topic sometimes adjacent to source control but not central here. Alignment with 'Modern Source Control' is weak, as the principal themes, intent, and audience are more about testing and quality assurance rather than version control. The discussion is in-depth about automated testing itself, but provides no depth on any source control practices. There is minimal signal relative to the category: almost the entire content is off-topic under this classification. No penalties were required as the content is neither outdated nor oppositional. The confidence score reflects the extremely poor fit for the 'Modern Source Control' category.",
    "level": "Ignored"
  },
  "Team Motivation": {
    "resourceId": "Automated Testing",
    "category": "Team Motivation",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 22.67,
    "ai_mentions": 0.4,
    "ai_alignment": 2.1,
    "ai_depth": 2.6,
    "ai_intent": 2.3,
    "ai_audience": 7.2,
    "ai_signal": 6.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "The content focuses primarily on the technical benefits of automated testing for software teams, such as improved reliability, early defect detection, and support for agile or DevOps practices. There is little to no direct mention or explicit reference to team motivation, nor does the content meaningfully discuss psychological, social, or leadership aspects that drive engagement or high performance as outlined in the classification definition. While terms like 'empower teams' and 'foster a culture of continuous improvement' provide some slight conceptual link, these are not explored in a motivational context but rather as byproducts of strong testing practice. The discussion lacks explicit coverage of trust, collaboration, recognition, or leadership style, and does not address how these impact collective motivation. The content’s intent is to advocate for automated testing as a tool for quality and delivery, not to guide or enliven team motivation. Audience overlap is moderate, as both topics can be relevant for agile team practitioners, but the primary focus is technical process, not motivational strategies. Therefore, the overall confidence that this content is genuinely about 'Team Motivation' is quite low.",
    "level": "Ignored"
  },
  "Metrics and Learning": {
    "resourceId": "Automated Testing",
    "category": "Metrics and Learning",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 59.63,
    "ai_mentions": 2.3,
    "ai_alignment": 6.5,
    "ai_depth": 6.3,
    "ai_intent": 5.9,
    "ai_audience": 6.1,
    "ai_signal": 6.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 60.0,
    "reasoning": "The content focuses extensively on Automated Testing and its impact on software quality, agility, and delivery speed. There are indirect overlaps with 'Metrics and Learning', such as references to feedback loops, continuous improvement, and alignment with Agile/DevOps practices. However, the content does not directly discuss data-driven metrics, performance analysis, or measurement frameworks central to the category. Mentions of feedback loops and continuous improvement are somewhat in the spirit of Metrics and Learning but center on automation as the mechanism, not metrics-driven processes. The target audience (technical teams in Agile/DevOps) aligns reasonably well. The discussion goes beyond superficial remarks, providing rationale on process improvement and organizational impact, but does not provide case studies, explicit metric usage, or in-depth exploration of evidence-based practices. No penalties were applied as the content is current, relevant, and its tone is consistent with the intended use-case. Confidence is moderate: the thematic overlap is significant but indirect, falling short of direct or deep engagement with metrics collection, analysis, or learning systems.",
    "level": "Tertiary"
  },
  "Product Discovery": {
    "resourceId": "Automated Testing",
    "category": "Product Discovery",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 13.2,
    "ai_mentions": 0.0,
    "ai_alignment": 1.8,
    "ai_depth": 1.7,
    "ai_intent": 2.0,
    "ai_audience": 4.2,
    "ai_signal": 3.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content is focused exclusively on automated testing practices, which are technical implementation details concerned with code quality, reliability, and efficient software delivery. There are no direct mentions of 'Product Discovery' or explicit references to typical discovery activities (such as user research, defining features, customer interviews, or validating product ideas). The alignment is low because the main ideas largely address quality assurance and software development, not the process of identifying and defining product features based on user needs. While the content briefly touches on delivering customer value and organizational agility, it does not offer substantive discussion or depth related to methodologies or frameworks central to Product Discovery. The intended audience (technical teams or engineering managers) only partially overlaps with those interested in Product Discovery. Most of the material is off-topic according to the provided category definition, leading to a very low signal-to-noise ratio. No penalties were applied as the content is current and non-contradictory, but the low scores across dimensions accurately reflect its minimal fit to the Product Discovery category.",
    "level": "Ignored"
  },
  "Engineering Practices": {
    "resourceId": "Automated Testing",
    "category": "Engineering Practices",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 92.74,
    "ai_mentions": 9.1,
    "ai_alignment": 9.4,
    "ai_depth": 9.5,
    "ai_intent": 9.2,
    "ai_audience": 9.3,
    "ai_signal": 9.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 93.0,
    "reasoning": "The content extensively and explicitly centers on automated testing, a key Agile engineering practice. The phrase 'Automated Testing' appears repeatedly both in the title and throughout the discussion, directly naming the practice. The discussion shows strong conceptual alignment by connecting automated testing to agile principles, explaining its systemic and cultural impact on software teams, and relating it to quality, feedback loops, and adaptability—which are core to Engineering Practices. The content moves beyond a shallow treatment, delving into the integration of testing tools, shift-left testing, and organizational effects, demonstrating notable depth. The intent is clearly to inform and advocate for automated testing as a foundational engineering practice in Agile, not as a tangential idea. The audience is technical and focused on engineering teams (references to pipelines, cross-functional collaboration, development workflows). The content is focused and on-topic, with minimal filler and no irrelevant sections, resulting in a high signal-to-noise ratio. No penalties are necessary: the content is current and supportive of the category, not satirical or outdated. The high, but not perfect, scores reflect a possible slight lack of mention of specific named methodologies (TDD, CI/CD, etc.), but otherwise the fit is exceptionally strong and appropriate.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the Engineering Practices category, as it thoroughly explores automated testing within Agile frameworks. It clearly targets technical audiences, delves into practical and cultural impacts, and directly connects testing to core Agile principles. The discussion is focused, relevant, and demonstrates a deep understanding of automated testing as a foundational engineering practice."
  },
  "Organisational Culture": {
    "resourceId": "Automated Testing",
    "category": "Organisational Culture",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 54.04,
    "ai_mentions": 2.8,
    "ai_alignment": 6.6,
    "ai_depth": 5.4,
    "ai_intent": 5.7,
    "ai_audience": 7.2,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 54.0,
    "reasoning": "The content primarily focuses on the technical and process benefits of Automated Testing, such as early defect detection, reduced manual effort, and integration into CI/CD pipelines. While there are a few glancing references to fostering a 'culture of continuous improvement' and supporting 'organisational agility,' these mentions are brief and not the primary focus. There is little to no deep exploration of organisational culture itself, leadership roles, or intra-team dynamics as per the classification definition. The content's main intent is to advocate for the adoption of automated testing practices, mentioning some alignment with Agile and DevOps but not discussing cultural transformation or leadership strategies in detail. The audience appears to be technical leaders and practitioners, partially aligning with the intended audience for organisational culture discussions. The overall confidence score reflects minor conceptual alignment and indirect references, but the lack of direct and substantial cultural discussion keeps the score moderate.",
    "level": "Tertiary"
  },
  "Agile Planning": {
    "resourceId": "Automated Testing",
    "category": "Agile Planning",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 31.93,
    "ai_mentions": 2.3,
    "ai_alignment": 3.8,
    "ai_depth": 3.9,
    "ai_intent": 3.6,
    "ai_audience": 5.1,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 32.0,
    "reasoning": "The content focuses almost entirely on the principles, benefits, and implementation of Automated Testing, with only indirect reference to Agile concepts (e.g., mentions of agility, feedback loops, and adaptability). There are no explicit references to Agile Planning, its key artifacts (sprints, backlog refinement), or its planning methodologies. The content is conceptually related to agility and iterative approaches but clearly centers on testing practices, not planning. Depth is moderate as it covers multiple aspects of automated testing but not Agile Planning-specific topics. Intent is informative but mainly for those seeking to understand automated testing, not Agile planning practices. The audience alignment is somewhat generic, catering to teams interested in quality and agility but not specifically planners or Agile practitioners. Signal is high, as the content is focused with little to no off-topic or filler material. Overall, while the content touches on themes adjacent to agility, it does not deeply align with or exemplify the 'Agile Planning' category, resulting in a low to moderate confidence score.",
    "level": "Ignored"
  },
  "Organisational Psychology": {
    "resourceId": "Automated Testing",
    "category": "Organisational Psychology",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 13.35,
    "ai_mentions": 0.1,
    "ai_alignment": 1.75,
    "ai_depth": 1.35,
    "ai_intent": 2.3,
    "ai_audience": 4.1,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content is centered on Automated Testing as a software development practice, presenting benefits such as early issue detection, reduced manual effort, and delivery acceleration. There are no explicit mentions or references to Organisational Psychology concepts, terminology, or core psychological theories. While the text refers tangentially to team collaboration and organisational agility, it does so in the context of workflow and technical outcomes rather than exploring psychological principles, employee motivation, leadership, or team dynamics as defined in the Organisational Psychology category. The depth score is low because the discussion does not analyze psychological drivers, interventions, or research-based concepts—it remains technical and process-oriented. The purpose is focused on software quality and agile practices, not the psychological aspects underpinning organisational behavior. Only a small segment references team collaboration, and the audience appears to be technical professionals rather than organisational psychologists, HR practitioners, or leadership roles interested in psychological factors. No penalty is warranted, as the content is not outdated and does not contradict the category's framing, though the conceptual alignment is weak. The low confidence score reflects the minimal overlap between the evaluated content and the core meaning of Organisational Psychology.",
    "level": "Ignored"
  },
  "Personal": {
    "resourceId": "Automated Testing",
    "category": "Personal",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 10.7,
    "ai_mentions": 0.3,
    "ai_alignment": 1.7,
    "ai_depth": 1.9,
    "ai_intent": 1.1,
    "ai_audience": 2.2,
    "ai_signal": 1.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 11.0,
    "reasoning": "The content focuses entirely on Automated Testing as a foundational practice in software development, emphasizing its benefits for quality, early issue detection, reduced manual effort, and organizational agility. However, there are no explicit or implicit mentions of personal perspective, anecdotes, or individual reflections on Agile, Scrum, DevOps, or related practices. The narrative is generalized and lacks any subjective insights, stories, or personal experiences—it is descriptive rather than reflective. The audience is broad (development or technical teams) and not specifically practitioners sharing personal insights. The content is relevant and high in signal for technical or DevOps categories, but it does not align with the 'Personal' category as defined. All dimension scores are low due to a lack of personal context, with slightly higher marks for audience and depth only because organizational agility and team impacts are mentioned—still, these are described generically, not personally. The final confidence score is minimal, proportionate to the sparse alignment with the 'Personal' category.",
    "level": "Ignored"
  },
  "Self Organisation": {
    "resourceId": "Automated Testing",
    "category": "Self Organisation",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 42.65,
    "ai_mentions": 0.6,
    "ai_alignment": 4.1,
    "ai_depth": 4.3,
    "ai_intent": 5.7,
    "ai_audience": 6.2,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "The content primarily focuses on the value and practice of Automated Testing, describing how it benefits software quality, workflow efficiency, and organisational agility. While there are tangential connections to key Agile principles—such as autonomy, feedback loops, and continuous improvement—the concept of self-organisation is never explicitly mentioned or directly discussed. The alignment score reflects these indirect links, noting that automated testing can 'empower teams' and support Agile practices. However, there is no exploration of specific self-organising techniques, leadership roles, or explicit principles of autonomous team operation. The main intent is to advocate for test automation rather than to educate or discuss self-organisation. The audience could overlap with practitioners interested in self-organisation but is more likely focused on quality assurance and engineering teams more broadly. The signal remains moderate since most of the text stays relevant to its own topic, with only minor overlaps to the self-organisation category. No penalties were applied, as the piece is current, not satirical, and does not contradict the category's framing. The final confidence score appropriately reflects the content's moderate conceptual overlap but significant divergence from the self-organisation category's core definition.",
    "level": "Tertiary"
  },
  "DevOps": {
    "resourceId": "Automated Testing",
    "category": "DevOps",
    "calculated_at": "2025-05-06T20:57:22",
    "ai_confidence": 78.1,
    "ai_mentions": 4.8,
    "ai_alignment": 8.9,
    "ai_depth": 8.4,
    "ai_intent": 7.9,
    "ai_audience": 7.7,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 78.0,
    "reasoning": "The content directly mentions DevOps only once and primarily focuses on automated testing as a practice, which is highly relevant to DevOps but not exclusive to it. Conceptually, the content is strongly aligned with DevOps principles, highlighting continuous improvement, feedback loops, shifting left, and cross-team collaboration. The discussion goes moderately deep by exploring broader organizational benefits and the integration of automated testing into pipelines but remains anchored to testing rather than general DevOps philosophy. The intent is mainly to inform about automated testing, only referencing DevOps as an area it supports, rather than making DevOps the main focus. The audience skews toward practitioners interested in software quality, which aligns well but not exclusively with the DevOps community. The majority of the content is relevant and focused, with minimal off-topic material. No penalties are applied as the information is current and the tone is supportive. This results in a confidence score that reflects strong alignment and depth regarding DevOps relevance, but slightly reduced due to its focus on testing first and DevOps second.",
    "level": "Secondary",
    "reasoning_summary": "While the content centres on automated testing, it closely aligns with DevOps principles such as continuous improvement and collaboration. However, DevOps is referenced more as context than the main subject. The discussion is relevant for DevOps practitioners, but the primary focus remains on testing practices, not DevOps itself. This makes the content highly relevant, though not exclusively dedicated, to the DevOps category."
  },
  "Complexity Thinking": {
    "resourceId": "Automated Testing",
    "category": "Complexity Thinking",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 13.27,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.8,
    "ai_intent": 1.2,
    "ai_audience": 4.0,
    "ai_signal": 6.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content focuses exclusively on Automated Testing to enhance software quality, reliability, and agility, with emphases on early detection, reduced manual effort, and integration with Agile and DevOps. Nowhere does it reference or even allude to complexity thinking, complexity science, non-linear dynamics, complexity frameworks like Cynefin, emergence, or self-organisation. Its audience alignment is moderately high, as those interested in Agile/DevOps may overlap with complexity thinking, but there is no explicit targeting or discussion of complexity theory principles. The overall discussion remains on practical, process-driven approaches to testing rather than the theoretical underpinnings or management of complex adaptive systems. Thus, conceptual alignment and depth are very low. The signal-to-noise is relatively high, as the piece is focused and relevant within its own scope, but that scope is not complexity thinking. There are no penalties applied, as there are no contradictions or obsolete references; however, the content is fundamentally mismatched with the 'Complexity Thinking' category.",
    "level": "Ignored"
  },
  "Automated Testing": {
    "resourceId": "Automated Testing",
    "category": "Automated Testing",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 93.45,
    "ai_mentions": 9.6,
    "ai_alignment": 9.7,
    "ai_depth": 9.2,
    "ai_intent": 9.6,
    "ai_audience": 9.1,
    "ai_signal": 9.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 93.0,
    "reasoning": "The content is highly relevant to the 'Automated Testing' category. Direct mentions of the term 'Automated Testing' are frequent and central throughout the text. Conceptually, the discussion closely aligns with the category's focus, addressing the importance of automated testing, early defect detection, reduced manual intervention, CI/CD, and its synergy with Agile and DevOps practices. The depth of the article is substantial, moving beyond basic definitions to discuss integration with development pipelines, shift-left strategies, collaboration, and the impact on organizational agility. Intent is strongly supportive and educational, matching the category's purpose. The target audience appears to be practitioners, technical leaders, and project stakeholders in software development—a perfect fit. The content is focused, with minimal tangential discussion, and nearly all points reinforce the core topic. No outdated advice or antagonism to the category's framing is present, so no penalties are applied. Minor deductions are present in the depth and audience categories, as the discussion is broad and high-level rather than deep in technical implementation, and audience targeting is slightly more general than exclusively practitioners.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent match for the 'Automated Testing' category. It thoroughly explores automated testing’s role, benefits, and integration with modern development practices like CI/CD, Agile, and DevOps. The discussion is focused, relevant, and educational, targeting a broad technical audience. While it’s more high-level than deeply technical, it remains highly appropriate for the category’s intent and audience."
  },
  "Unrealised Value": {
    "resourceId": "Automated Testing",
    "category": "Unrealised Value",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 25.47,
    "ai_mentions": 0.4,
    "ai_alignment": 2.8,
    "ai_depth": 3.0,
    "ai_intent": 3.2,
    "ai_audience": 5.1,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 25.0,
    "reasoning": "The content focuses on Automated Testing as a practice for improving software quality, increasing delivery speed, and enabling organisational agility. While concepts like 'enabling value', 'continuous improvement', and 'organisational agility' are mentioned, these contexts do not directly address the definition, indicators, strategies, or case studies of Unrealised Value as understood in Evidence-Based Management. There are no explicit mentions of Unrealised Value or its measurement. The closest alignment is the suggestion that automation enables innovation and improvement, which are thematically adjacent but not specific to the category. The depth of discussion remains primarily technical and operational, not centered around identifying, measuring, or capturing untapped organisational value. The intent is focused on promoting testing, not unpacking latent market demand or opportunity backlogs. The signal-to-noise ratio is high in terms of relevance to software teams, but does not map closely to the target audience of strategic decision-makers concerned with Unrealised Value in EBM. Consequently, confidence in this content fitting the category is low.",
    "level": "Ignored"
  },
  "Internal Developer Platform": {
    "resourceId": "Automated Testing",
    "category": "Internal Developer Platform",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 18.42,
    "ai_mentions": 0.2,
    "ai_alignment": 1.6,
    "ai_depth": 2.4,
    "ai_intent": 2.1,
    "ai_audience": 5.3,
    "ai_signal": 3.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content is entirely focused on automated testing and its benefits for software teams. There is no direct mention of Internal Developer Platforms (IDP), nor are their core frameworks, architecture, or comparative context discussed. The alignment is minimal, as automated testing can be a component within an IDP but is not exclusive or defining to the category. Depth of discussion is limited strictly to automated testing without bridging to platform concepts. The intent is educational about testing practices, not about establishing or implementing an IDP. The primary audience aligns somewhat, since both topics might interest technical and DevOps practitioners, but the focus remains off-platform. Signal-to-noise ratio is moderate because the content remains on its subject (testing), but that subject is only tangentially relevant to IDP. Overall, the confidence is very low that this content appropriately fits the 'Internal Developer Platform' category.",
    "level": "Ignored"
  },
  "Shift Left Strategy": {
    "resourceId": "Automated Testing",
    "category": "Shift Left Strategy",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 80.27,
    "ai_mentions": 6.7,
    "ai_alignment": 8.6,
    "ai_depth": 8.1,
    "ai_intent": 8.2,
    "ai_audience": 7.5,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 80.0,
    "reasoning": "The content on 'Automated Testing' directly references the shift-left strategy, stating that automated testing 'supports a shift-left strategy, encouraging testing to occur earlier in the development cycle.' This explicit mention justifies a solid score for direct references, though the content centers primarily on automated testing itself rather than an in-depth exploration of shift-left practices as a whole. The conceptual alignment is high—the approach and examples provided (early testing, feedback loops, integration into the development pipeline) closely match core shift-left principles. In terms of depth, the text moves beyond surface-level discussion by connecting automated testing to organizational agility, workflow integration, and overall business value, but it does not extensively cover a broad range of shift-left topics such as security or compliance. The intent is strongly aligned, positioning automated testing as a shift-left enabler, and targeting practitioners and technical audiences who would benefit from such strategies. The signal-to-noise ratio is good; nearly all content is relevant, though certain sections are focused more generically on 'quality' and 'agility' rather than shift-left specifics, slightly lowering this metric. No penalties were necessary as there is no outdated information or negative framing. The final confidence score proportionately reflects a content piece that is highly relevant and supportive of the category, but whose primary focus is only one aspect (testing) of the broader shift-left strategy.",
    "level": "Secondary",
    "reasoning_summary": "This content is a strong fit for the shift-left category, as it clearly links automated testing to shift-left principles—emphasising early testing and integration into development workflows. While its main focus is on testing rather than the full spectrum of shift-left practices, the alignment and relevance are high, making it valuable for practitioners interested in adopting shift-left strategies."
  },
  "Social Technologies": {
    "resourceId": "Automated Testing",
    "category": "Social Technologies",
    "calculated_at": "2025-05-06T20:57:22",
    "ai_confidence": 70.35,
    "ai_mentions": 2.7,
    "ai_alignment": 8.2,
    "ai_depth": 7.9,
    "ai_intent": 7.5,
    "ai_audience": 8.0,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 70.0,
    "reasoning": "The content is primarily focused on 'Automated Testing', a technical practice. While it does not directly use the phrase 'Social Technologies', the description and discussion incorporate significant conceptual alignment, referencing Agile, DevOps, collaboration among teams, and fostering continuous improvement—core components of Social Technologies. There is a moderate depth in discussing how automated testing influences organisational culture and team dynamics, such as by encouraging collaboration and iterative improvement, aligning it with the social aspects of value delivery. However, the explicit emphasis remains on the technical and process benefits rather than in-depth on frameworks or methodologies that define Social Technologies. The intent supports the category by highlighting organisational agility and collaboration, and the audience seems aligned with practitioners and decision-makers in Agile/DevOps contexts. The writing is focused, relevant, and contains minimal off-topic content. No penalties were applied, as the content is up to date and does not undermine the category's principles. The confidence score reflects solid, but not direct, alignment: while the technical aspects dominate, the underlying social technology themes are notable and integrated.",
    "level": "Secondary"
  },
  "Product Delivery": {
    "resourceId": "Automated Testing",
    "category": "Product Delivery",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 84.15,
    "ai_mentions": 6.8,
    "ai_alignment": 9.2,
    "ai_depth": 8.7,
    "ai_intent": 8.3,
    "ai_audience": 8.8,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 84.0,
    "reasoning": "The content focuses on Automated Testing and explicitly links it to the acceleration and improvement of software delivery. Direct references to 'accelerate delivery', 'integrating automated tests into the development pipeline', 'shortened feedback loops', 'cross-functional teams', and alignment with Agile and DevOps all closely match the core meaning and scope of Product Delivery. There are no explicit or frequent uses of the term 'Product Delivery' itself, which results in a lower mentions score. However, the conceptual alignment and depth are strong: the discussion extends beyond tooling to strategic fit within delivery, including continuous improvement, collaboration, and customer value. Intent centres around enhancing delivery effectiveness, targeting technical teams and practitioners (good audience alignment) with minimal off-topic content (high signal-to-noise). No outdated practices or undermining tone are present, so no penalties are required. The final confidence score reflects robust relevance to Product Delivery, despite the focus on one (key) aspect of the broader process.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the Product Delivery category, as it explores how automated testing enhances and accelerates software delivery. While it doesn’t frequently use the term 'Product Delivery', its focus on integration, feedback loops, and team collaboration aligns well with the category’s core themes, making it highly relevant for technical teams aiming to improve delivery effectiveness."
  },
  "Portfolio Management": {
    "resourceId": "Automated Testing",
    "category": "Portfolio Management",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 13.45,
    "ai_mentions": 0.25,
    "ai_alignment": 1.0,
    "ai_depth": 0.65,
    "ai_intent": 1.5,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content focuses exclusively on Automated Testing within the context of software development and quality assurance. It does not directly mention or reference Portfolio Management in any capacity. There is a vague connection to organisational agility and continuous improvement, but these references remain abstract and do not pertain to managing a portfolio of projects or aligning investments and strategy as required by the Portfolio Management category. The depth of discussion is technical and operational, aimed at practitioners or teams implementing testing practices rather than strategic leadership or portfolio managers. There is minimal alignment in audience or topic focus, and almost no signal toward the core category definition. No penalties were applied as the content is current and does not contradict the category, but the overall confidence is very low due to the lack of direct and conceptual fit.",
    "level": "Ignored"
  },
  "Application Lifecycle Management": {
    "resourceId": "Automated Testing",
    "category": "Application Lifecycle Management",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 62.7,
    "ai_mentions": 2.7,
    "ai_alignment": 7.5,
    "ai_depth": 6.9,
    "ai_intent": 7.1,
    "ai_audience": 6.8,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 63.0,
    "reasoning": "The content directly focuses on Automated Testing as a practice within modern software development, discussing its value for software quality, early issue detection, continuous integration, and alignment with Agile and DevOps principles—all of which are relevant to Application Lifecycle Management (ALM). However, there are no explicit direct mentions of 'Application Lifecycle Management' or ALM-specific methodologies, tools, or the full lifecycle stages: the focus remains tightly on testing rather than the governance and management of the entire application lifespan. The depth addresses the systemic impact of automated testing, but more as a supportive practice for agility and quality, not a comprehensive examination of ALM. Intent is highly relevant and supportive, but the audience seems skewed toward technical practitioners and QA teams rather than broader ALM stakeholders. Content focus is solid but not singularly ALM—signal is somewhat diluted by general software quality themes. No penalties are applied since the content is up to date, accurate, and not critical of ALM, but the lack of full lifecycle or governance discussion reduces overall confidence, resulting in a score in the low 60s.",
    "level": "Secondary"
  },
  "Agile Product Management": {
    "resourceId": "Automated Testing",
    "category": "Agile Product Management",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 55.35,
    "ai_mentions": 2.1,
    "ai_alignment": 5.6,
    "ai_depth": 5.3,
    "ai_intent": 6.1,
    "ai_audience": 6.7,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content focuses on Automated Testing, emphasizing its role in software quality, early issue detection, delivery acceleration, and support of Agile and DevOps principles. Direct mentions of 'Agile' appear only once, and the primary subject is automated testing, which is more technical than product-management oriented. Conceptually, there is partial alignment as the discussion highlights how automated testing facilitates delivery of customer value, cross-functional team collaboration, faster feedback loops, and organizational agility—all traits valued in Agile Product Management. However, the piece does not discuss the role of Product Owners, backlog prioritization, or stakeholder engagement, nor does it dive into product vision, customer feedback loops specific to product direction, or metrics-driven product decision-making. The audience could include Agile PMs, but the focus remains on technical and quality assurance professionals. The depth is moderate, thoroughly explaining automated testing's benefits, but with only tangential relation to product management methodology. Signal-to-noise is fair, as most content is relevant to delivering value, though it's anchored in technical execution rather than strategic product management. No penalties are applied as there are no outdated practices or contradictory tones observed. Overall, confidence in classifying this content under Agile Product Management is modest, given its adjacent but not central fit.",
    "level": "Tertiary"
  },
  "Product Strategy": {
    "resourceId": "Automated Testing",
    "category": "Product Strategy",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 24.56,
    "ai_mentions": 1.2,
    "ai_alignment": 2.85,
    "ai_depth": 2.6,
    "ai_intent": 2.25,
    "ai_audience": 2.9,
    "ai_signal": 2.46,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 25.0,
    "reasoning": "The content is focused entirely on automated testing, which is a technical and process-oriented topic aimed at ensuring software quality and improving development practices. There are no direct mentions or explicit references to product strategy, nor are the methodologies, frameworks, or vision/roadmapping aspects of product strategy discussed. While the content briefly alludes to agility and alignment with customer value, these are framed within the context of test automation rather than strategic product vision or market positioning. The main intent is to advocate for testing as a practice for quality, not as an element of product strategy. The depth is moderate for testing as a topic but does not extend into relevant strategic considerations. The primary audience is technical practitioners rather than product strategists or decision-makers. The content is focused but off-topic with respect to the strict classification definition.",
    "level": "Ignored"
  },
  "Continuous Delivery": {
    "resourceId": "Automated Testing",
    "category": "Continuous Delivery",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 59.5,
    "ai_mentions": 2.0,
    "ai_alignment": 7.8,
    "ai_depth": 7.1,
    "ai_intent": 7.7,
    "ai_audience": 7.4,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 60.0,
    "reasoning": "The content explicitly discusses automated testing as a practice that accelerates delivery and improves software quality by enabling early issue detection and reducing manual work. While there are no direct mentions of 'Continuous Delivery' by name, the conceptual alignment is moderate to strong: automated testing is a core enabler of Continuous Delivery, and the piece emphasizes building quality in, rapid feedback, and integrating tests in the development pipeline—principles central to Continuous Delivery. The depth is decent since it covers technical and cultural impacts and connects automated testing to agility and innovation, but it doesn't thoroughly discuss Continuous Delivery as a discipline or explore broader CD tooling, deployment automation, or release strategies. The author’s intent is in line with improving delivery practices, and the target audience (software practitioners, those focused on quality and process) aligns moderately well with those interested in Continuous Delivery. The content remains focused (good signal-to-noise), but slightly broadens into organizational agility and customer value rather than drilling down into Continuous Delivery specifically. No penalties are applied, as the piece is current and not critical or satirical in tone. The final confidence score reflects that while 'Automated Testing' is deeply relevant to, but not wholly representative of, the Continuous Delivery category.",
    "level": "Tertiary"
  },
  "Cross Functional Teams": {
    "resourceId": "Automated Testing",
    "category": "Cross Functional Teams",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 41.85,
    "ai_mentions": 2.0,
    "ai_alignment": 4.8,
    "ai_depth": 4.4,
    "ai_intent": 5.0,
    "ai_audience": 6.5,
    "ai_signal": 6.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily focuses on Automated Testing, detailing its benefits, implementation, and impact on software quality. There is only a single indirect mention of 'cross-functional teams' in the context of collaboration enhanced by automated testing, but the piece is not explicitly about cross-functional teams. Conceptual alignment is present where the impact of Automated Testing on team collaboration is discussed, but the main ideas and depth do not directly reflect the structure, challenges, or best practices of cross-functional teams. The content's intent is general information on automated testing, with a passing alignment to the cross-functional philosophy in Agile. The audience—practitioners interested in software quality and agile practices—somewhat overlaps, hence a moderate audience score. The signal-to-noise ratio is fair as only a minor segment aligns with the specified category, while most of the content remains on automated testing itself. No penalties are applied since the content is not outdated and does not contradict the category. The final confidence score appropriately reflects the peripheral and limited relationship between the content and the cross-functional teams category.",
    "level": "Tertiary"
  },
  "Flow Efficiency": {
    "resourceId": "Automated Testing",
    "category": "Flow Efficiency",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 37.3,
    "ai_mentions": 1.2,
    "ai_alignment": 4.1,
    "ai_depth": 3.6,
    "ai_intent": 4.4,
    "ai_audience": 5.2,
    "ai_signal": 6.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on Automated Testing, emphasizing its role in improving software quality, early issue detection, delivery acceleration, and support for Agile/DevOps methods. However, there are no direct mentions or explicit discussions of 'Flow Efficiency' or its specific principles. While the ideas of accelerating delivery and increasing throughput touch on outcomes relevant to flow efficiency, the main theme is automated testing as a technical and process enabler, not the direct optimization of work throughput or the systematic management of flow. Depth is moderate—while connections to organizational agility and continuous improvement are made, key Flow Efficiency topics such as bottleneck elimination, WIP limits, or visual management tools are not addressed. The intent is somewhat adjacent but not explicitly aligned; the likely audience (software teams, DevOps practitioners) partially overlaps with those interested in flow efficiency, particularly in Agile/Lean environments, but the core focus—test automation—makes the content only tangentially relevant. There is little off-topic filler, yielding a fair signal-to-noise ratio. No penalties were applied because content is timely and tone is not contradictory.",
    "level": "Ignored"
  },
  "Remote Working": {
    "resourceId": "Automated Testing",
    "category": "Remote Working",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 6.73,
    "ai_mentions": 0.2,
    "ai_alignment": 0.8,
    "ai_depth": 0.7,
    "ai_intent": 1.1,
    "ai_audience": 2.3,
    "ai_signal": 1.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The provided content focuses on the value of Automated Testing for Agile teams, discussing aspects such as early issue detection, reduced manual effort, and support for continuous improvement. While the content is connected to Agile practices, it never addresses remote working, distributed teams, or the specific challenges of collaborating remotely in an Agile context. There are no explicit or implicit references to remote work, its tools, or ceremonies. The audience and purpose are broadly software practitioners interested in automation and quality, not specifically remote Agile teams. As a result, scores for direct mentions, conceptual alignment, depth, and signal-to-noise ratio are extremely low. The overall confidence score is very low, fitting for content that is not at all related to the evaluated category.",
    "level": "Ignored"
  },
  "Large Scale Agility": {
    "resourceId": "Automated Testing",
    "category": "Large Scale Agility",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 36.964,
    "ai_mentions": 0.9,
    "ai_alignment": 3.6,
    "ai_depth": 3.7,
    "ai_intent": 6.2,
    "ai_audience": 7.1,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content provides a thorough overview of the value, practices, and cultural impact of Automated Testing, making frequent references to Agile principles such as continuous improvement, shift-left strategies, and team collaboration. However, there are no direct mentions of 'Large Scale Agility,' nor are any frameworks for scaling agile (like SAFe, LeSS, or Nexus) or specific enterprise-level strategies discussed. While the content does connect automated testing with organisational agility and systemic enablement, the alignment and depth with the large-scale context remains mostly implicit. The target audience seems broad (teams and organisational leaders), but direct guidance for enterprise-level scaling or multi-team coordination is absent. The signal-to-noise ratio is high because all the discussion is tightly relevant to automated testing in an agile context, though not targeted at scaling. Hence, the confidence score is moderate: the content is relevant tangentially but lacks specificity or depth around Large Scale Agility.",
    "level": "Ignored"
  },
  "Product Owner": {
    "resourceId": "Automated Testing",
    "category": "Product Owner",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 11.25,
    "ai_mentions": 0.1,
    "ai_alignment": 1.8,
    "ai_depth": 1.5,
    "ai_intent": 2.0,
    "ai_audience": 4.8,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 11.0,
    "reasoning": "The content does not mention the Product Owner or discuss their accountability in any explicit way. Instead, it centers on the concept and benefits of Automated Testing, focusing on software quality, delivery speed, and team collaboration from a technical and process perspective. While it references Agile principles, these are in a general sense and not tied to the responsibilities or accountability of the Product Owner specifically. There is very limited conceptual overlap—automated testing enables value delivery, which is adjacent to a Product Owner's goals—but the article does not discuss strategic backlog prioritization, stakeholder management, or decision-making frameworks that define the Product Owner role. The audience skews slightly towards technical practitioners or cross-functional teams compared to the Product Owner's expected audience. No penalties are applied, as the content is not outdated or satirical, but the lack of direct relevance is reflected in low scores across mentions, alignment, depth, and intent.",
    "level": "Ignored"
  },
  "Transparency": {
    "resourceId": "Automated Testing",
    "category": "Transparency",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 17.575,
    "ai_mentions": 0.0,
    "ai_alignment": 2.3,
    "ai_depth": 1.7,
    "ai_intent": 2.0,
    "ai_audience": 7.4,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content provides an overview of Automated Testing, its benefits for software quality, and its alignment with Agile and DevOps, but it does not mention 'transparency' directly or focus on the key aspects of the Transparency category. There is a tangential connection where automated testing can contribute to openness (e.g., test reporting increasing visibility), but this is not explicitly discussed. No practices or tools aimed specifically at improving visibility or fostering trust through transparency are highlighted. The target audience (teams adopting Agile/DevOps) partially overlaps but is not directly focused on transparency as a core theme. The signal-to-noise ratio is reasonably high, but nearly all focus is on quality and process efficiency, not transparency. No penalties were necessary as there is no outdated information or oppositional tone. Thus, the confidence score is low and reflects minimal alignment with the Transparency classification.",
    "level": "Ignored"
  },
  "Service Level Expectation": {
    "resourceId": "Automated Testing",
    "category": "Service Level Expectation",
    "calculated_at": "2025-05-06T20:57:29",
    "ai_confidence": 5.07,
    "ai_mentions": 0.2,
    "ai_alignment": 0.6,
    "ai_depth": 0.6,
    "ai_intent": 0.6,
    "ai_audience": 1.5,
    "ai_signal": 1.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 5.0,
    "reasoning": "The content exclusively discusses Automated Testing, focusing on its role in software quality, reliability, and continuous improvement. Nowhere does it mention Service Level Expectation (SLE), nor does it reference cycle time forecasting, elapsed time ranges, or any of the key SLE concepts detailed in the classification definition. There are no direct or indirect references to SLE’s calculation, transparency, or its use in Kanban, Scrum, or Agile predictability. The audience (Agile/DevOps practitioners) partially overlaps with SLE's typical audience, but all other dimensions are minimal, as the main subject matter is orthogonal to SLE. No penalties were needed. The minuscule confidence score reflects only a faint, unintended conceptual link (general Agile practice), but no substantive alignment.",
    "level": "Ignored"
  },
  "Continuous Integration": {
    "resourceId": "Automated Testing",
    "category": "Continuous Integration",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 53.65,
    "ai_mentions": 1.15,
    "ai_alignment": 5.8,
    "ai_depth": 5.3,
    "ai_intent": 5.95,
    "ai_audience": 7.65,
    "ai_signal": 7.05,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 54.0,
    "reasoning": "The content is focused on Automated Testing, which is a key component and enabler of Continuous Integration (CI), but does not mention CI explicitly nor frame the discussion strictly in terms of CI principles or workflows. The phrase 'integrating automated tests into the development pipeline' and references to development workflows are adjacent to CI, and the content aligns well with CI-related practices such as early testing, code quality, and workflow integration. However, CI as a process, toolset, or philosophy is never directly mentioned, nor does the content explore topics unique to CI like frequent code integration, automated merges, or CI tooling. The depth and intent scores reflect the substantial treatment of automated testing, but with only indirect relevance to CI. The audience and signal scores are moderate to strong because the piece is technical and targeted to practitioners, minimally off-topic, and broadly relevant for teams that would practice CI. No penalties were applied as the content is not outdated or contrary to CI. Final confidence is moderate because, while highly relevant as a foundational practice within CI, the content doesn't anchor itself squarely in the CI domain.",
    "level": "Tertiary"
  },
  "Decision Theory": {
    "resourceId": "Automated Testing",
    "category": "Decision Theory",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 6.2,
    "ai_mentions": 0.2,
    "ai_alignment": 0.8,
    "ai_depth": 0.4,
    "ai_intent": 0.5,
    "ai_audience": 2.1,
    "ai_signal": 0.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The content is exclusively focused on the value and process of Automated Testing within software engineering contexts. There are no direct or even implicit mentions of Decision Theory, its frameworks, or associated concepts such as heuristics, probability, cognitive psychology, or behavioural economics. While the article does touch briefly on decision-enabling practices—such as empowering teams to respond to change or enhance collaboration—these do not link specifically to decision-making under uncertainty as defined in Decision Theory. The target audience is software practitioners interested in technical implementation rather than those exploring models or strategies for decision-making. The content is highly focused but offers no overlap with the conceptual or thematic elements of Decision Theory. Therefore, all scoring dimensions are just above zero to reflect marginal, general relevance (such as indirect support for making better release decisions), but these are not substantial or explicit. No penalties were necessary as the content is current and does not contradict the category.",
    "level": "Ignored"
  },
  "Definition of Ready": {
    "resourceId": "Automated Testing",
    "category": "Definition of Ready",
    "calculated_at": "2025-05-06T20:57:27",
    "ai_confidence": 3.35,
    "ai_mentions": 0.2,
    "ai_alignment": 0.6,
    "ai_depth": 0.5,
    "ai_intent": 0.8,
    "ai_audience": 2.6,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content is entirely focused on Automated Testing, discussing its benefits for software quality, continuous improvement, and Agile/DevOps integration. There are zero explicit mentions of the Definition of Ready (DoR). The conceptual alignment is minimal, as there is a tangential connection to Agile principles but none specifically to DoR or readiness criteria for backlog items. The depth is shallow with respect to the target category; all detail pertains to testing, not readiness. The content's intent is informative but not related to DoR. Audience overlap exists in that both target Agile practitioners, but with a testing (not backlog refinement) focus. Signal-to-noise is low for DoR (content is narrowly focused on testing). No penalties are applied: the content is current and presented neutrally. Confidence is very low, as the content does not address the substance or objectives of the \"Definition of Ready\" category per the classification definition.",
    "level": "Ignored"
  },
  "Artificial Intelligence": {
    "resourceId": "Automated Testing",
    "category": "Artificial Intelligence",
    "calculated_at": "2025-05-06T20:57:26",
    "ai_confidence": 21.25,
    "ai_mentions": 0.4,
    "ai_alignment": 1.6,
    "ai_depth": 1.7,
    "ai_intent": 3.1,
    "ai_audience": 7.2,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 21.0,
    "reasoning": "The content thoroughly discusses the value and implementation of Automated Testing within Agile and DevOps, emphasizing early detection of issues, acceleration of delivery, and team collaboration. However, there are no explicit mentions of Artificial Intelligence, nor is there discussion of AI-driven automation, AI-enhanced analytics, or intelligent testing frameworks. While the content is highly relevant to Agile and DevOps practitioners focused on quality assurance, it is not aligned with the category definition, which requires a clear focus on the application or impact of Artificial Intelligence within these methodologies. The main concepts and depth of discussion pertain strictly to automated processes and organizational agility, not AI. Thus, only minimal marks are awarded for conceptual alignment and depth, with higher scores for audience and signal, reflecting the overall clarity and practitioner focus. No outdated information or category-framing contradiction is present, so no penalties were applied.",
    "level": "Ignored"
  },
  "Product Management": {
    "resourceId": "Automated Testing",
    "category": "Product Management",
    "calculated_at": "2025-05-06T20:57:22",
    "ai_confidence": 37.47,
    "ai_mentions": 1.5,
    "ai_alignment": 4.7,
    "ai_depth": 4.1,
    "ai_intent": 4.2,
    "ai_audience": 4.5,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content centers on Automated Testing, a practice most commonly rooted in technical implementation rather than the strategic scope of Product Management as defined. There are some indirect allusions relevant to the category—such as aligning with Agile principles, enabling delivery of value, and fostering collaboration across cross-functional teams—but Product Management itself is never directly named or deeply discussed. The main focus is software quality and delivery efficacy. While product managers may care about automated testing from a strategic perspective (e.g., as part of delivering consistent value or ensuring product quality at scale), this content does not explore concepts like product vision, stakeholder balancing, resource allocation at a strategic level, or evidence-based product decisions. Instead, it speaks more to technical teams and practices. The brief mention of alignment with Agile and customer value offers slight overlap in audience and intent, so those scores are not at the lowest possible, but depth and direct mention remain limited. There are no outdated or critical elements. Overall, the low confidence reflects the lack of direct and substantial alignment with 'Product Management' as a strategic discipline.",
    "level": "Ignored"
  },
  "Customer Retention": {
    "resourceId": "Automated Testing",
    "category": "Customer Retention",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 71.85,
    "ai_mentions": 2.8,
    "ai_alignment": 7.9,
    "ai_depth": 7.6,
    "ai_intent": 7.5,
    "ai_audience": 8.2,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 72.0,
    "reasoning": "The content focuses primarily on automated testing as a means to ensure software quality and reliable delivery. There is only a very brief and indirect mention of customer retention: the link between maintaining quality/delivery speed and long-term customer satisfaction and retention is made in passing, not as a central theme. Alignment with the customer retention category exists conceptually because maintaining software quality can reduce customer churn and improve experience, but the article's main purpose is not explicitly about customer retention strategies or methodologies. The discussion on Agile, DevOps, and value delivery is relevant, yet always in the service of testing practices rather than engagement strategies. Few direct category mentions keep the 'mentions' score low, while audience, depth, and signal are relatively strong as the piece is focused and targets practitioners likely to care about customer outcomes indirectly. No penalties are required, as the information is current and the tone supportive.",
    "level": "Secondary",
    "reasoning_summary": "This content mainly explores automated testing to boost software quality and delivery, with only a brief nod to customer retention. While there’s an indirect link—since better quality can help keep customers—the main focus isn’t on retention strategies. The article is more about testing practices for practitioners, so it only loosely fits the customer retention category rather than addressing it directly."
  },
  "Minimum Viable Product": {
    "resourceId": "Automated Testing",
    "category": "Minimum Viable Product",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 12.71,
    "ai_mentions": 0.3,
    "ai_alignment": 1.6,
    "ai_depth": 2.4,
    "ai_intent": 1.1,
    "ai_audience": 3.0,
    "ai_signal": 2.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content is focused exclusively on Automated Testing, discussing its benefits for software quality, early defect detection, team agility, and continuous improvement. Nowhere does the text explicitly mention Minimum Viable Product or core MVP concepts such as early market validation, identifying core features, or rapid learning cycles for hypothesis testing. While there are indirect thematic overlaps—for example, delivering value quickly, aligning with Agile/DevOps, and supporting innovation—these are generic development best practices, not unique to MVP. The depth and alignment scores are very low, reflecting this disconnect, and the direct mention score is near zero. There is some minor audience overlap (targeting product teams, developers), but the overall intent, context, and substance do not serve the MVP category. Thus, confidence in this piece fitting the Minimum Viable Product category is very low.",
    "level": "Ignored"
  },
  "Beta Codex": {
    "resourceId": "Automated Testing",
    "category": "Beta Codex",
    "calculated_at": "2025-05-06T20:57:27",
    "ai_confidence": 23.32,
    "ai_mentions": 0.2,
    "ai_alignment": 2.4,
    "ai_depth": 2.7,
    "ai_intent": 2.9,
    "ai_audience": 7.0,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "There are no direct mentions of Beta Codex, its principles, or related terminology—the focus is solely on Automated Testing within a software engineering context. There are some indirect thematic overlaps: the text briefly mentions adaptive teams and organisational agility. However, these ideas are loosely connected and presented in the context of general Agile/DevOps practices, not decentralised organisational design or human-centric leadership as foundational to Beta Codex. The discussion stays technical and process-oriented rather than exploring structural, cultural, or leadership shifts towards decentralisation or human-centric frameworks. The primary audience is practitioners involved in software delivery, not those specifically interested in Beta Codex or progressive organisational design. The intent is to advocate for automated testing, not to address organisational models or compare them to the Beta Codex approach. Signal-to-noise is relatively high, as the content stays on topic for automated testing, but this topic is not relevant to the Beta Codex category. No penalties were applied, as there are no outdated practices or active contradictions, but overall confidence is very low due to minimal category fit.",
    "level": "Ignored"
  },
  "Lean Thinking": {
    "resourceId": "Automated Testing",
    "category": "Lean Thinking",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 36.785,
    "ai_mentions": 0.8,
    "ai_alignment": 4.9,
    "ai_depth": 3.7,
    "ai_intent": 5.6,
    "ai_audience": 6.4,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses exclusively on Automated Testing, discussing its benefits for software quality, faster delivery, and continuous improvement. There is no direct mention of Lean Thinking, Lean principles, or core Lean concepts such as waste elimination, value stream mapping, Kaizen, or Lean tools (e.g., 5S, Kanban). The closest conceptual overlap is fostering continuous improvement and enhancing value delivery, which can align with Lean, but the article is framed within Agile and DevOps contexts. Depth of discussion regarding Lean Thinking is shallow, as Lean is neither cited nor explored. The intent is adjacent—improving efficiency and value—but is not purpose-built for Lean practitioners. The audience aligns partly, as readers interested in process improvement might also find Lean relevant, but the direct focus is software quality engineers. The content is highly relevant to its stated topic (signal), but off-topic for Lean Thinking except by loose association. No penalties were applied as the content is current, neutral, and does not undermine Lean. Overall, the confidence score remains low due to indirect alignment and complete lack of explicit Lean references.",
    "level": "Ignored"
  },
  "Lean Startup": {
    "resourceId": "Automated Testing",
    "category": "Lean Startup",
    "calculated_at": "2025-05-06T20:57:32",
    "ai_confidence": 11.97,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.5,
    "ai_intent": 1.2,
    "ai_audience": 4.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content focuses entirely on the concept and benefits of Automated Testing for software quality and delivery. There are no direct mentions of Lean Startup, nor does the text discuss core Lean Startup principles such as MVP, the Build-Measure-Learn feedback loop, validated learning, pivots, or customer development. While the article does mention short feedback loops, agility, and continuous improvement, these are addressed from the perspective of software development and quality assurance, not entrepreneurship or Lean Startup methodology. The intent is informative for teams interested in software quality, and the audience skews toward technical practitioners rather than startup founders. There is a very weak conceptual alignment because some principles (iterative improvement, feedback) are shared, but the depth of Lean Startup discussion is minimal. Signal-to-noise is moderate, as the content is focused but lacks direct relevance to Lean Startup topics. No penalties were applied as the content is not outdated or contrary in tone, but it also does not meet the strict classification criteria.",
    "level": "Ignored"
  },
  "Agile Planning Tools": {
    "resourceId": "Automated Testing",
    "category": "Agile Planning Tools",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 12.45,
    "ai_mentions": 0.2,
    "ai_alignment": 1.8,
    "ai_depth": 2.4,
    "ai_intent": 2.1,
    "ai_audience": 3.2,
    "ai_signal": 2.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content is focused on Automated Testing as a practice within software development and Agile/DevOps contexts but does not directly discuss Agile Planning Tools themselves. There are no explicit or implicit mentions of backlog management, sprint planning, release planning, or specific tools (such as Jira or Trello) used for Agile planning. The main intent is to highlight quality assurance practices and their benefits for agility, not the tools or processes of Agile planning. While the audience aligns partially (tech and Agile-focused practitioners), the overlap is minimal and the discussion is not centered around the category. As a result, all relevance scores are low, particularly in direct mentions and conceptual alignment.",
    "level": "Ignored"
  },
  "Professional Scrum": {
    "resourceId": "Automated Testing",
    "category": "Professional Scrum",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 45.82,
    "ai_mentions": 0.2,
    "ai_alignment": 6.3,
    "ai_depth": 5.9,
    "ai_intent": 5.7,
    "ai_audience": 7.0,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 46.0,
    "reasoning": "The content provides a thorough overview of Automated Testing as a software quality practice. While the principles discussed—continuous improvement, predictability, delivery of value, and integration within development cycles—are conceptually aligned with elements of Professional Scrum (notably empiricism, technical excellence, and value delivery), the piece never references Professional Scrum, Scrum values, or specific Scrum roles or philosophy. The focus remains on general Agile, DevOps, and quality assurance approaches, not on the disciplined application or ethos of Professional Scrum. There is solid conceptual overlap but not intent: the primary purpose is to promote automated testing overall, not to explore its role as an example of Professional Scrum professionalism. Audience alignment is moderate, as both target practitioners, but the 'Professional Scrum' lens is absent. Signal-to-noise is fairly good—the article remains focused, but lacks discussion of Scrum-specific professionalism. No penalties were applied, as the piece is current and not actively contradicting Professional Scrum principles.",
    "level": "Tertiary"
  },
  "Install and Configuration": {
    "resourceId": "Automated Testing",
    "category": "Install and Configuration",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 13.97,
    "ai_mentions": 0.4,
    "ai_alignment": 1.8,
    "ai_depth": 2.1,
    "ai_intent": 2.5,
    "ai_audience": 2.5,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content discusses the strategic benefits and general importance of automated testing for software quality, agility, and delivery speed. It focuses on why automated testing matters and its effect on organizational agility, but it does not mention or provide instructions on installation, setup, or configuration of any specific tools. There are no direct references to 'Install and Configuration'; the closest relevant technical topic is the mention of integrating automated tests into pipelines, but this is explained at a high level and lacks actionable detail on how to perform any installation or configuration steps. The audience appears to be practitioners seeking to understand the value of automated testing, rather than those seeking implementation guidance. Accordingly, conceptual alignment, intent, depth, and signal-to-noise scores are low but nonzero due to minor conceptual overlap (integration, technical audience). The confidence score is well below threshold, reflecting the marginal relevance to the target category.",
    "level": "Ignored"
  },
  "Increment": {
    "resourceId": "Automated Testing",
    "category": "Increment",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 36.3,
    "ai_mentions": 0.4,
    "ai_alignment": 3.5,
    "ai_depth": 3.9,
    "ai_intent": 4.1,
    "ai_audience": 6.6,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 36.0,
    "reasoning": "The content is focused on Automated Testing as a practice that ensures software quality and supports rapid, reliable delivery. While it references Agile principles and the idea of delivering value sustainably, it does not directly mention 'Increment' or discuss the concept of delivering usable software at the end of each iteration—a key requirement for this category. There is conceptual tangential alignment in that automated testing enables increments to meet quality standards, but the main ideas and depth revolve around testing, not increment delivery itself. The audience (technical teams, Agile practitioners) somewhat overlaps, and the content remains focused, but the intent is centered on testing enablement rather than increment creation. Thus, confidence in fit with the 'Increment' category is low, and scores reflect only partial, indirect relevance.",
    "level": "Ignored"
  },
  "Product Backlog": {
    "resourceId": "Automated Testing",
    "category": "Product Backlog",
    "calculated_at": "2025-05-06T20:57:22",
    "ai_confidence": 7.3,
    "ai_mentions": 0.6,
    "ai_alignment": 1.4,
    "ai_depth": 1.7,
    "ai_intent": 1.0,
    "ai_audience": 1.1,
    "ai_signal": 1.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is exclusively focused on Automated Testing, detailing its benefits, practices, and role in Agile and DevOps contexts. There is no explicit mention or direct discussion of product backlogs, backlog refinement, product owner responsibilities, user stories, backlog tools, or how automated testing relates to backlog management. While it nods to Agile principles and continuous delivery, this serves only as contextual background rather than direct relevance. The content is aimed at software professionals but does not target roles or scenarios specific to backlog management. All dimensions score very low as there is only an extremely tenuous, implied relevance based on Agile context but no substantive connection to the Product Backlog category. The confidence score is proportionally low, accurately reflecting the negligible fit.",
    "level": "Ignored"
  },
  "Software Development": {
    "resourceId": "Automated Testing",
    "category": "Software Development",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 95.7,
    "ai_mentions": 9.7,
    "ai_alignment": 9.5,
    "ai_depth": 9.3,
    "ai_intent": 9.8,
    "ai_audience": 9.6,
    "ai_signal": 9.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 96.0,
    "reasoning": "The content directly and repeatedly discusses Automated Testing as a core practice within Software Development, explicitly referencing its role in quality assurance, early issue detection, development pipelines, and integration with Agile and DevOps principles. The main themes align strongly with the classification, focusing on methodologies, best practices, and impact on organizational agility—key elements in Software Development. The explanation is thorough, offering conceptual and procedural insights rather than superficial mentions, and is clearly intended for development practitioners. The audience is well-matched, targeting technical professionals involved in or overseeing the software development lifecycle. There is negligible off-topic filler; the focus remains consistently on automated testing in a developmental context. No penalties for outdatedness or contradictory tone are warranted, as the practices described are current and supportive of the category’s framing. Thus, the confidence score is high, closely reflecting both the directness and the depth of category alignment.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the Software Development category, as it thoroughly explores Automated Testing within the field. It addresses its significance in quality assurance, integration with Agile and DevOps, and practical methodologies, all aimed at technical professionals. The discussion is focused, current, and highly relevant, making it well-suited for those involved in the software development lifecycle."
  },
  "Hypothesis Driven Development": {
    "resourceId": "Automated Testing",
    "category": "Hypothesis Driven Development",
    "calculated_at": "2025-05-06T20:57:32",
    "ai_confidence": 18.15,
    "ai_mentions": 0.1,
    "ai_alignment": 1.2,
    "ai_depth": 1.4,
    "ai_intent": 2.0,
    "ai_audience": 5.1,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content on 'Automated Testing' does not explicitly mention Hypothesis Driven Development (HDD) or its characteristic practices (e.g., hypothesis formulation, experimentation, validated learning). While the discussion covers the benefits of automated testing with respect to quality, agility, and feedback cycles, it never references hypothesis-driven experimentation or decision-making. Conceptual alignment is low because, although both automated testing and HDD emphasize feedback and continuous improvement, testing is presented here as a general quality assurance practice, not as a means for validating explicit hypotheses related to product features or user behavior. Depth of discussion regarding HDD is minimal, focusing entirely on the periodic benefits of testing rather than on structured learning through experiments. The intent is tangential, targeting practitioners interested in software quality rather than those seeking to practice or learn about HDD. Audience overlaps partially, as both audiences may be technical practitioners, but signal-to-noise ratio is middling since the content is focused but irrelevant to the HDD category. No penalties were applied, as content does not contradict or undermine HDD, nor does it reference obsolete practices. The resulting confidence score is very low, accurately reflecting the minimal fit of this content under the Hypothesis Driven Development category.",
    "level": "Ignored"
  },
  "Evidence Based Leadership": {
    "resourceId": "Automated Testing",
    "category": "Evidence Based Leadership",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 14.63,
    "ai_mentions": 0.2,
    "ai_alignment": 1.7,
    "ai_depth": 1.3,
    "ai_intent": 1.8,
    "ai_audience": 3.2,
    "ai_signal": 2.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 15.0,
    "reasoning": "The content focuses solely on the technical practice of Automated Testing, emphasizing software quality, early issue detection, and accelerating delivery. It touches on themes like feedback loops and collaboration, which are somewhat adjacent to evidence-based decision-making, but does not explicitly mention Evidence Based Leadership, empirical leadership practices, or data-driven management. There are no references to evidence guiding leadership decisions, KPIs, or relevant frameworks. The target audience appears to be technical practitioners rather than leaders seeking to leverage evidence for organizational improvements. While some concepts such as feedback loops and organizational agility could relate tangentially to the Evidence Based Leadership category, the discussion remains centered on QA practices and technical workflows rather than on leadership intent or outcomes. Thus, the confidence score is very low.",
    "level": "Ignored"
  },
  "Working Agreements": {
    "resourceId": "Automated Testing",
    "category": "Working Agreements",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 10.35,
    "ai_mentions": 0.0,
    "ai_alignment": 1.3,
    "ai_depth": 1.5,
    "ai_intent": 2.1,
    "ai_audience": 3.0,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content exclusively discusses Automated Testing, focusing on its role in software quality, speed, and development effectiveness within Agile/DevOps contexts. Nowhere does it mention or allude to working agreements, team norms, or principles for team collaboration. The piece targets practitioners interested in technical practices for testing, not the establishment of team behavioral agreements. While there is incidental mention of collaboration and cultural improvement, these are strictly within the context of testing and quality assurance, not structured team agreements. The signal-to-noise is low for 'Working Agreements' as almost the entire content is off-topic. Scores reflect marginal alignment (mentions, conceptual ties) only through broad Agile connection, not category relevance.",
    "level": "Ignored"
  },
  "Miscellaneous": {
    "resourceId": "Automated Testing",
    "category": "Miscellaneous",
    "calculated_at": "2025-05-06T20:57:29",
    "ai_confidence": 24.04,
    "ai_mentions": 1.2,
    "ai_alignment": 2.9,
    "ai_depth": 2.8,
    "ai_intent": 2.1,
    "ai_audience": 2.3,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on Automated Testing, which is closely related to software development practices often associated with Agile and DevOps. While the piece never explicitly explores particular frameworks or named methodologies, it does directly state that automated testing 'aligns with principles of Agile and DevOps,' making this content ineligible for the Miscellaneous category by the provided definition. There are no direct mentions of 'Miscellaneous,' and the conceptual fit is weak since actionable value and alignment with established Agile/DevOps principles are overt. The depth dimension remains low because the discussion repeatedly ties back to continuous improvement and agile responses rather than surfacing as generalized or purely anecdotal. The primary intent appears to be instructional for practitioners seeking to improve technical practices, so intent and audience alignment are also quite low. The signal-to-noise ratio is low since all information is focused on technical practice, which does not correspond to the broad catch-all or tangential nature of the Miscellaneous category. No penalty adjustments are necessary; the tone and recency are appropriate. The overall confidence is appropriately low, as the content is much more specific and practice-aligned than the Miscellaneous designation allows.",
    "level": "Ignored"
  },
  "Test First Development": {
    "resourceId": "Automated Testing",
    "category": "Test First Development",
    "calculated_at": "2025-05-06T20:57:32",
    "ai_confidence": 42.65,
    "ai_mentions": 1.8,
    "ai_alignment": 5.2,
    "ai_depth": 4.3,
    "ai_intent": 5.0,
    "ai_audience": 5.5,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "The content exclusively discusses Automated Testing in the context of software quality, reliability, early feedback, and development workflow improvements. There are no explicit or implicit references to Test First Development or its foundational principles, such as defining success criteria prior to implementation, the role of acceptance criteria, manual test first practices, or practices like TDD/ATDD. While continuous integration, collaboration, and feedback loops are mentioned (slightly aligning with Test First Development values), these concepts are anchored in general automation and DevOps/Agile contexts rather than the unique discipline of Test First. The audience appears technical, matching the general direction of the category, but the messaging and emphasis remain on automation and organizational agility, not Test First Development specifically. There is some minor conceptual overlap in advocating for earlier testing and cross-functional collaboration, but the lack of depth, direct mentions, and focused alignment justify a moderate-to-low confidence score. No penalties are applied, as the information is current and not undermining Test First principles.",
    "level": "Tertiary"
  },
  "Operational Practices": {
    "resourceId": "Automated Testing",
    "category": "Operational Practices",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 91.2,
    "ai_mentions": 7.4,
    "ai_alignment": 9.6,
    "ai_depth": 8.9,
    "ai_intent": 9.3,
    "ai_audience": 8.7,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 91.0,
    "reasoning": "The content thoroughly discusses Automated Testing as an operational practice that improves software quality and delivery efficiency, core aspects of the 'Operational Practices' category. It makes repeated, explicit references to operational concepts such as process automation, workflow integration, reducing manual effort, accelerating delivery, continuous improvement, and alignment with Agile and DevOps principles. The material goes beyond surface-level discussion by exploring how automated testing supports organisational agility, collaboration, and a shift-left strategy. The audience is clearly practitioners involved in delivery and process optimization, with language tailored to technical and operational roles. The content is focused with very little off-topic material, resulting in a high signal-to-noise ratio. No aspects are outdated or actively contradictory, so no penalties were applied. Confidence is high but not absolute, as it does not deeply discuss process metrics or broader operational frameworks, thus one or two dimensions are fractionally below perfect.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the 'Operational Practices' category, as it delves into how Automated Testing enhances software quality and delivery through process automation and workflow integration. It’s tailored for technical practitioners, emphasising efficiency, collaboration, and alignment with Agile and DevOps, though it could further explore metrics or broader frameworks for a perfect match."
  },
  "Sociotechnical Systems": {
    "resourceId": "Automated Testing",
    "category": "Sociotechnical Systems",
    "calculated_at": "2025-05-06T20:57:29",
    "ai_confidence": 55.11,
    "ai_mentions": 1.2,
    "ai_alignment": 6.7,
    "ai_depth": 6.3,
    "ai_intent": 6.1,
    "ai_audience": 7.0,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content focuses primarily on Automated Testing, discussing both technical benefits and its role in supporting team practices and organisational agility. However, it does not explicitly reference 'Sociotechnical Systems' or directly discuss the interplay between technological and organisational structures as described in the classification definition. The alignment and depth scores are moderate, reflecting a partial connection—the discussion touches on team collaboration, cross-functional teams, and continuous improvement, which are relevant to sociotechnical considerations, but it lacks explicit frameworks or case studies that would demonstrate deep sociotechnical analysis. The intent is somewhat aligned, as it presents Automated Testing as a cultural and process enabler rather than just a technical tool, yet it stops short of fully exploring how social and technical systems integrate. The audience appears well-aligned, likely targeting practitioners and organisational decision-makers concerned with software delivery effectiveness. The signal score is high given the content remains focused and relevant to software delivery and organisational outcomes. No penalties were required as the content is up-to-date and not contradictory. Overall, the confidence score indicates that while the content has meaningful overlap with Sociotechnical Systems concepts, it falls short of a direct or in-depth treatment as required for a stronger classification.",
    "level": "Tertiary"
  },
  "Open Space Agile": {
    "resourceId": "Automated Testing",
    "category": "Open Space Agile",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 19.23,
    "ai_mentions": 0.1,
    "ai_alignment": 2.3,
    "ai_depth": 1.7,
    "ai_intent": 3.2,
    "ai_audience": 4.1,
    "ai_signal": 2.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is focused exclusively on Automated Testing as a practice to improve software quality, reliability, and delivery speed. There are no direct mentions or even indirect references to Open Space Technology or Open Space Agile. While the text loosely aligns with some general Agile principles (e.g., continuous improvement, collaboration, agility), it does not discuss collective participation, shared ownership, emergence, psychological safety, or any mechanisms unique to Open Space Agile. The discussion remains at the surface level regarding organizational agility and is primarily technical, targeting practitioners concerned with testing, rather than those focused on Agile transformation strategies. There is no off-topic or obsolete information, and the intent is constructive but only weakly linked to the Open Space Agile category as defined. No penalties were applied as there's no outdated or contradictory content, but the very low confidence score reflects the near-total absence of category relevance.",
    "level": "Ignored"
  },
  "Azure DevOps": {
    "resourceId": "Automated Testing",
    "category": "Azure DevOps",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 23.95,
    "ai_mentions": 0.35,
    "ai_alignment": 2.9,
    "ai_depth": 2.7,
    "ai_intent": 3.1,
    "ai_audience": 4.2,
    "ai_signal": 3.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content discusses automated testing in a general sense, focusing on its benefits for software quality, early issue detection, and alignment with Agile and DevOps principles. However, there is no mention of Azure DevOps or any of its services, tools, or capabilities. While there is conceptual overlap in that automated testing is fundamental to DevOps practices (and by extension to Azure DevOps), the text never explicitly references the Azure DevOps platform. Depth, alignment, and intent scores are modest, reflecting that while the article is relevant to DevOps practitioners (thus giving a higher audience score), it is not specifically focused on Azure DevOps itself. The signal-to-noise ratio is reduced as a significant portion of the text is generic, not focused on the Azure DevOps category definition. No penalties apply as the content is current and neutral in tone. The final confidence score is low, proportionate to the lack of direct reference and limited alignment with the explicit Azure DevOps classification.",
    "level": "Ignored"
  },
  "Definition of Done": {
    "resourceId": "Automated Testing",
    "category": "Definition of Done",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 13.8,
    "ai_mentions": 0.7,
    "ai_alignment": 1.7,
    "ai_depth": 1.4,
    "ai_intent": 2.1,
    "ai_audience": 3.5,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content thoroughly discusses Automated Testing, its impact on software quality, delivery speed, and its place in Agile/DevOps. However, it does not directly mention the Definition of Done (DoD) or criteria for completed increments. The closest alignment is that automated testing can be part of a DoD in Agile teams, but this conceptual link is not made explicit. No details are given about DoD creation, best practices, or collaborative agreement on what 'done' means. Audience and signal scores are slightly higher due to relevance to practitioners, but the overall confidence score is very low because the content does not focus on the core definition, intent, or practices surrounding the Definition of Done.",
    "level": "Ignored"
  },
  "Pragmatic Thinking": {
    "resourceId": "Automated Testing",
    "category": "Pragmatic Thinking",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 70.6,
    "ai_mentions": 1.3,
    "ai_alignment": 8.2,
    "ai_depth": 7.9,
    "ai_intent": 8.7,
    "ai_audience": 7.2,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 71.0,
    "reasoning": "The content introduces Automated Testing with a practical lens, emphasizing early issue detection, reduction of manual effort, and acceleration of software delivery—elements that align with pragmatic, experience-based problem solving in Agile and DevOps contexts. It does not directly use the term 'Pragmatic Thinking,' hence the low score for mentions. However, it repeatedly references real-world practices (shift-left, cross-functional collaboration, continuous improvement) that closely fit the conceptual scope of Pragmatic Thinking. The depth is strong as it discusses strategic and cultural implications, not just technical benefits, but it does not present concrete case studies or explicit problem-solving frameworks, so there's room for more substantial depth. The content’s intent is clearly to inform practitioners about the value of embedding practical QA strategies in Agile/DevOps pipelines, matching the category’s purpose. Audience targeting is mainly technical and practitioner-focused, which aligns well but not perfectly (e.g., less relevant for strategists or executives). The signal is high as the discussion stays relevant and concise, with minimal filler. No penalties are applied: the text is current, constructive, and does not undermine the pragmatic framing.",
    "level": "Secondary",
    "reasoning_summary": "This content fits the category well, as it highlights practical approaches to automated testing within Agile and DevOps, focusing on real-world benefits like early issue detection and efficiency. While it doesn’t explicitly mention 'Pragmatic Thinking,' its emphasis on actionable strategies and cultural impact aligns closely with the category’s intent, making it highly relevant for technical practitioners seeking practical guidance."
  },
  "Employee Engagement": {
    "resourceId": "Automated Testing",
    "category": "Employee Engagement",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 7.25,
    "ai_mentions": 0.1,
    "ai_alignment": 0.2,
    "ai_depth": 0.2,
    "ai_intent": 0.3,
    "ai_audience": 1.5,
    "ai_signal": 0.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is entirely focused on the technical aspects and process benefits of Automated Testing, such as software quality, automation tools, pipeline integration, and accelerated delivery. There are no direct or indirect mentions of employee engagement, motivation, recognition, feedback practices, or the psychological/social components that drive commitment on a team. While there is a brief nod to team collaboration and empowerment, these are contextualized strictly in terms of Agile/DevOps methodologies and workflow improvement, not workplace engagement. The intent, audience, and signal are all targeted towards technical practitioners, not towards those seeking strategies for improving motivation, satisfaction, or human-centered team dynamics. Therefore, confidence that this content fits under 'Employee Engagement' is extremely low.",
    "level": "Ignored"
  },
  "System Configuration": {
    "resourceId": "Automated Testing",
    "category": "System Configuration",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 16.15,
    "ai_mentions": 0.4,
    "ai_alignment": 1.3,
    "ai_depth": 1.1,
    "ai_intent": 2.0,
    "ai_audience": 3.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "The content focuses exclusively on Automated Testing, emphasizing its impact on software quality, early issue detection, and agile delivery. There are no direct mentions or references to system configuration, configuration management tools, or related methodologies. Conceptually, the focus remains on the practice and benefits of software testing automation—not on system setup, integration, or maintenance. Depth is limited to a broad advocacy of automated testing without touching on configuration best practices. The intent is informative for technical teams, but it does not address audiences or problems specific to system configuration. Almost all of the content is off-topic as defined by the classification, resulting in low scores across all dimensions and a proportionately low final confidence score.",
    "level": "Ignored"
  },
  "Leadership": {
    "resourceId": "Automated Testing",
    "category": "Leadership",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 21.17,
    "ai_mentions": 0.9,
    "ai_alignment": 2.4,
    "ai_depth": 2.7,
    "ai_intent": 2.1,
    "ai_audience": 7.1,
    "ai_signal": 4.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 21.0,
    "reasoning": "The content primarily focuses on the technical and process aspects of automated testing within Agile and DevOps environments. While it discusses organisational agility and continuous improvement, there are no direct mentions of leadership, leadership roles, or leadership strategies. The main ideas are only loosely aligned with leadership, mostly in the sense that automated testing contributes to the environment that leaders might want to foster. The depth is greater regarding testing practices than any theory or application of leadership, and the intent is to describe testing's value rather than guide or inform leaders. The target audience is broader (including practitioners and teams), not leadership-specific, though parts may be of interest to leaders overseeing process improvements. Most of the content's signal is related to technical or process improvement rather than leadership methodologies or frameworks. No penalties are applied, as there are no outdated or contrarian elements. Overall, the confidence score is low—the content does not meet the threshold for 'Leadership' other than a faint indirect connection.",
    "level": "Ignored"
  },
  "Throughput": {
    "resourceId": "Automated Testing",
    "category": "Throughput",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 27.9,
    "ai_mentions": 2.1,
    "ai_alignment": 3.6,
    "ai_depth": 3.3,
    "ai_intent": 2.6,
    "ai_audience": 8.3,
    "ai_signal": 5.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 28.0,
    "reasoning": "The content primarily discusses the benefits of Automated Testing in software development, focusing on quality, early detection of issues, reduced manual effort, and acceleration of delivery. The term 'throughput' is mentioned only once, near the end, and is used broadly to signal increased delivery pace, not specifically as a measurable metric or delivery health indicator. There is no detailed explanation, visualization, or analysis of throughput or its metrics; the main theme is quality assurance, not delivery metrics. The audience is practitioners and organizations interested in delivery improvements, loosely aligning with the 'Throughput' category audience, but the core of the content does not explore throughput as a metric. Intent and depth toward throughput are both very limited, with higher signal due to overall focus. No penalties were required as the content is current and tone-neutral.",
    "level": "Ignored"
  },
  "Asynchronous Development": {
    "resourceId": "Automated Testing",
    "category": "Asynchronous Development",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 12.709,
    "ai_mentions": 0.2,
    "ai_alignment": 0.7,
    "ai_depth": 0.6,
    "ai_intent": 1.0,
    "ai_audience": 7.0,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content centers on the principles, tools, and benefits of automated testing to enhance software quality—and does not mention asynchronous development, time zone collaboration, distributed teams, or associated practices. Direct mentions (0.2) are minimal, as the topic is never named or referenced. Conceptual alignment (0.7) and depth (0.6) are both very low; while some automation tools can facilitate asynchronous work, this is never discussed or implied in the content, which focuses entirely on automation for quality, not collaboration across time or space. Audience alignment (7.0) and signal (8.0) are higher since the content targets technical practitioners and stays on topic, but the topic simply does not fit the given category. Intent (1.0) reflects that the content is completely off-purpose for asynchronous development, reinforcing the low overall confidence (12.709) that this content fits the target category.",
    "level": "Ignored"
  },
  "Cell Structure Design": {
    "resourceId": "Automated Testing",
    "category": "Cell Structure Design",
    "calculated_at": "2025-05-06T20:57:27",
    "ai_confidence": 5.1,
    "ai_mentions": 0.1,
    "ai_alignment": 0.3,
    "ai_depth": 0.2,
    "ai_intent": 0.2,
    "ai_audience": 2.8,
    "ai_signal": 1.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 5.0,
    "reasoning": "The content exclusively discusses automated software testing—its value in quality, agility, and delivery—but does not mention, reference, or conceptually align with Cell Structure Design, Beta Codex, or related principles. There are no direct or indirect references to network-based organisational structures, autonomous cells, or the decentralised models defined by Cell Structure Design. The audience is general tech/IT practitioners, not those focused on org design or Beta Codex models, but there is very slight overlap in that both address complex environments. The signal-to-noise ratio is low in relation to the evaluated category, as all discussion focuses strictly on technical testing practices and agile/DevOps. There are no penalties applied as the content is current and not satirical or critical, just entirely unrelated. Therefore, the confidence score is extremely low and reflects only a bare minimum of accidental thematic overlap (agility, value delivery) but without relevance to the Cell Structure Design category.",
    "level": "Ignored"
  },
  "Azure Boards": {
    "resourceId": "Automated Testing",
    "category": "Azure Boards",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.8,
    "ai_depth": 2.3,
    "ai_intent": 2.2,
    "ai_audience": 2.5,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content exclusively focuses on the benefits, practice, and strategy of Automated Testing in software development. Nowhere does the text mention Azure Boards, nor does it discuss its work item management, planning, or boards-specific reporting features. The discussion is tool-agnostic and only generally references Agile and DevOps principles. There is minimal indirect conceptual alignment; for example, process improvement and Agile collaboration are generally relevant, but this does not address or illustrate Azure Boards' direct features or usage. The content's intent is to promote best practices in test automation rather than guide, inform, or discuss Azure Boards functionalities or its use in Agile project processes. The target audience (software developers, QA professionals) slightly overlaps with that of Azure Boards users, but there is no explicit connection. Most of the content is high signal regarding software quality, but it is off-topic for the Azure Boards category. No penalties were applied, as the tone is neutral and current. The low confidence score accurately reflects the total lack of direct or substantial relevance to the Azure Boards category.",
    "level": "Ignored"
  },
  "Liberating Structures": {
    "resourceId": "Automated Testing",
    "category": "Liberating Structures",
    "calculated_at": "2025-05-06T20:57:27",
    "ai_confidence": 2.4,
    "ai_mentions": 0.0,
    "ai_alignment": 0.9,
    "ai_depth": 1.2,
    "ai_intent": 1.4,
    "ai_audience": 4.2,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content exclusively discusses automated testing and its benefits within Agile and DevOps contexts, making no explicit or implicit mention of Liberating Structures or their facilitation techniques. There is no direct reference to practices, methods, or topics related to the Liberating Structures toolkit, nor is there any content about teamwork facilitation, engagement methods, or related facilitation outcomes. The intent and focus are entirely devoted to technical quality practices (specifically test automation), not collaborative facilitation techniques. The audience loosely overlaps with Agile practitioners, but the primary relevance is technical, not facilitative. Therefore, the confidence score is very low, reflecting that the content does not fit under the Liberating Structures category.",
    "level": "Ignored"
  },
  "Scrum Values": {
    "resourceId": "Automated Testing",
    "category": "Scrum Values",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 8.9,
    "ai_mentions": 0.7,
    "ai_alignment": 1.8,
    "ai_depth": 1.5,
    "ai_intent": 1.2,
    "ai_audience": 1.7,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content extensively discusses the importance and benefits of Automated Testing in the context of software development, Agile, and DevOps. However, it does not directly mention or focus on any of the Scrum Values, nor does it explicitly discuss Commitment, Courage, Focus, Openness, or Respect. The themes are more aligned with software quality, workflow optimization, and continuous improvement, rather than the foundational principles that underpin Scrum. While the content alludes briefly to cross-functional collaboration and customer value—which might be tangentially related to Respect or Focus—these are not explored through the lens of Scrum Values, nor are they framed as primary topics. There is a lack of direct references to Scrum or its values, and the alignment is incidental at best. Therefore, the confidence that this content fits under the 'Scrum Values' category is very low, as reflected by the low scores across all dimensions and the final calculated confidence score.",
    "level": "Ignored"
  },
  "Agile Philosophy": {
    "resourceId": "Automated Testing",
    "category": "Agile Philosophy",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 66.45,
    "ai_mentions": 3.8,
    "ai_alignment": 7.7,
    "ai_depth": 6.9,
    "ai_intent": 7.0,
    "ai_audience": 7.2,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 66.0,
    "reasoning": "The content primarily focuses on Automated Testing, emphasizing its role in software quality, early feedback, and reducing manual effort. There are indirect references that connect Automated Testing to Agile principles, such as continuous improvement, adaptability, value delivery, and empowering teams—terms that align conceptually with the Agile Philosophy. The content further notes that Automated Testing encourages a shift-left strategy, cross-functional collaboration, and supports agility at the organizational level. However, it does not explicitly discuss the Agile Manifesto, its principles, or the cultural aspects at the heart of the Agile Philosophy. Mentions of 'Agile' are indirect and primarily in the context of supporting agility; the content is still fundamentally about a practice, not the overarching philosophy. The discussion goes modestly in depth about how the practice aligns with philosophical tenets, but it does not thoroughly unpack or analyze the Agile mindset itself. No penalties are assessed as the tone is positive, current, and not critical of Agile Philosophy. The audience appears well-matched (team leads, developers, managers interested in agility), and the content is focused with minimal noise. Thus, the confidence score is moderate, reflecting partial but not primary relevance to 'Agile Philosophy.'",
    "level": "Secondary"
  },
  "Lean": {
    "resourceId": "Automated Testing",
    "category": "Lean",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 32.63,
    "ai_mentions": 1.0,
    "ai_alignment": 3.2,
    "ai_depth": 3.4,
    "ai_intent": 4.7,
    "ai_audience": 6.1,
    "ai_signal": 4.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content focuses entirely on Automated Testing as a quality assurance practice in software development. It covers benefits such as early issue detection, reduced manual effort, faster delivery, feedback loops, and integration into development pipelines. However, it does not mention 'Lean' explicitly, nor does it directly reference Lean concepts, tools (such as 5S, Kanban, JIT), or principles like eliminating waste or value stream mapping. While themes like value delivery and continuous improvement are discussed, these are presented within the context of Agile and DevOps—not as outgrowths of Lean methodology. There is some conceptual overlap with Lean's goal of continuous improvement and value creation, but the primary emphasis is not on Lean strategies or practices, and the audience is technical rather than Lean-specific. Because there is no direct mention and only peripheral conceptual alignment, confidence is low and well below the threshold for strong classification in the Lean category.",
    "level": "Ignored"
  },
  "Azure Pipelines": {
    "resourceId": "Automated Testing",
    "category": "Azure Pipelines",
    "calculated_at": "2025-05-06T20:57:32",
    "ai_confidence": 43.2,
    "ai_mentions": 0.6,
    "ai_alignment": 4.2,
    "ai_depth": 4.1,
    "ai_intent": 4.5,
    "ai_audience": 5.1,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "The content discusses Automated Testing as a practice, emphasizing its benefits for software quality, reliability, and development efficiency. However, there are no direct or explicit mentions of Azure Pipelines, nor is there any reference to specific Azure DevOps services, YAML, or pipeline configuration. Conceptually, the text mentions integrating automated tests into the development pipeline, showing some indirect alignment with CI/CD practices, but does not specify Azure or any unique Azure Pipelines feature. The discussion remains generic and is not tailored to Azure-centric principles or implementations, leading to low scores for Direct Mentions, Conceptual Alignment, and Depth. The intended audience (software practitioners) aligns somewhat, but the absence of Azure-specific details limits confidence. No penalties were necessary, as the content is not outdated or contradictory. The final score reflects the lack of direct Azure Pipelines focus despite some overlap in practice-related themes.",
    "level": "Tertiary"
  },
  "Psychological Safety": {
    "resourceId": "Automated Testing",
    "category": "Psychological Safety",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 13.0,
    "ai_mentions": 0.1,
    "ai_alignment": 1.8,
    "ai_depth": 1.4,
    "ai_intent": 1.2,
    "ai_audience": 4.0,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content is focused entirely on the technical and process advantages of Automated Testing, such as improving software quality, accelerating delivery, and promoting agility. There are no explicit mentions or discussions about psychological safety, nor are the conceptual themes directly aligned: the emphasis is on tools, processes, and outcomes relating to quality, not on creating an environment of interpersonal risk-taking or open communication. While the discussion mentions culture and collaboration, these are in the service of software delivery and continuous improvement, not the specific constructs of psychological safety. The intent does not address psychological safety as a purpose, and the signal-to-noise ratio for this category is low. No content was outdated or contradictory to the category framing, so no penalties were necessary. As such, the confidence that this content appropriately fits the 'Psychological Safety' category is extremely low.",
    "level": "Ignored"
  },
  "Technical Mastery": {
    "resourceId": "Automated Testing",
    "category": "Technical Mastery",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 91.52,
    "ai_mentions": 7.3,
    "ai_alignment": 9.5,
    "ai_depth": 9.1,
    "ai_intent": 9.0,
    "ai_audience": 8.7,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content directly and repeatedly discusses automated testing, a core practice encompassed by Technical Mastery, highlighting its role in software quality, reliability, and delivery. While the phrase 'Technical Mastery' is not expressly named, the principles and practices described—such as integration into the development pipeline, embracing Agile and DevOps principles, shift-left strategies, early detection of issues, codebase stability, and continuous improvement—fully align with the category's definition. Depth is evident from mentioning both the technical (automation tools, shift-left, CI/CD) and cultural/organizational enablers. Intent is strongly aligned as the purpose is to inform and advocate for automated testing as a best practice within engineering. The target audience seems to be technical practitioners and engineering teams, though with some secondary references to broader organizational impact. Content is focused, with minimal filler and no off-topic digressions. No penalties apply as the content is current, supportive, and wholly in line with the category goals.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the Technical Mastery category, as it thoroughly explores automated testing—a key technical practice. It covers both technical and organisational aspects, aligns with Agile and DevOps principles, and is clearly aimed at engineering professionals. The focus remains on best practices and continuous improvement, making it highly relevant and appropriate for this category."
  },
  "Common Goals": {
    "resourceId": "Automated Testing",
    "category": "Common Goals",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 38.7,
    "ai_mentions": 2.3,
    "ai_alignment": 3.5,
    "ai_depth": 3.9,
    "ai_intent": 5.0,
    "ai_audience": 8.1,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content focuses on Automated Testing and its benefits within Agile and DevOps environments—highlighting quality, continuous improvement, and alignment with rapid delivery practices. However, 'Common Goals' as a concept is neither explicitly mentioned nor centrally explored. Alignment with the category is indirect: while themes like collaboration, value delivery, and alignment to customer outcomes are touched upon, there is no discussion of strategic alignment, ownership of shared objectives, or explicit references to frameworks like OKRs or Sprint Goals. The depth of discussion about 'Common Goals' is limited; the main thrust is the technical and process-oriented aspects of Automated Testing. The intended audience (teams working in Agile/DevOps settings) is aligned, and the signal-to-noise ratio is high, as the content remains focused. Nevertheless, the lack of direct mention and limited conceptual exploration of 'Common Goals' keeps the confidence score moderate and well below a high-confidence threshold.",
    "level": "Ignored"
  },
  "Customer Satisfaction": {
    "resourceId": "Automated Testing",
    "category": "Customer Satisfaction",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 56.15,
    "ai_mentions": 3.7,
    "ai_alignment": 6.3,
    "ai_depth": 5.8,
    "ai_intent": 6.1,
    "ai_audience": 6.8,
    "ai_signal": 6.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 56.0,
    "reasoning": "The content primarily focuses on the technical and process-oriented benefits of Automated Testing: quality, reliability, early issue detection, reduced manual effort, and accelerated delivery. Customer satisfaction is mentioned explicitly only once, towards the end, with the phrase 'ultimately leading to improved customer satisfaction and retention.' There are indirect conceptual connections; improving software quality and delivery speed can contribute to customer satisfaction, but the main thrust is not a deep or explicit exploration of customer satisfaction principles, measurement, or frameworks. The content mentions Agile and DevOps principles broadly but stops short of discussing customer satisfaction as a metric, goal, or core theme. The audience is practitioners interested in automation, with some relevance for those focusing on delivering customer value, but the signal to noise ratio is only moderately high since most of the content speaks to internal process improvements, not customer-centric outcomes. No penalties apply, as the content is not outdated or dismissive of the category. Overall, the confidence reflects the presence of some alignment and references, but a clear lack of depth and direct focus.",
    "level": "Tertiary"
  },
  "Ability to Innovate": {
    "resourceId": "Automated Testing",
    "category": "Ability to Innovate",
    "calculated_at": "2025-05-06T20:57:22",
    "ai_confidence": 41.27,
    "ai_mentions": 1.8,
    "ai_alignment": 4.7,
    "ai_depth": 4.4,
    "ai_intent": 4.6,
    "ai_audience": 6.3,
    "ai_signal": 5.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 41.0,
    "reasoning": "The content focuses primarily on Automated Testing as a practice to ensure software quality, accelerate delivery, and foster continuous improvement. There are only minimal direct or explicit references to innovation—mentioning that automated testing 'empowers teams to innovate' and 'adapt,' but this is not a central or explored topic. The main ideas and themes revolve around software quality, testing efficiency, and delivery pipeline stability, which are tangential to Ability to Innovate but not directly aligned with the category's core focus as outlined in the Evidence-Based Management framework. There is mild mention of supporting innovation, but little depth is provided in terms of metrics, frameworks, learning cycles, or concrete strategies for organisational innovation. The audience seems to align with both practitioners and strategists familiar with Agile/DevOps environments, which partially matches the category's intended readership. The signal-to-noise ratio reflects that most of the content is about software testing rather than the mechanisms for systematic or measurable innovation. No penalties were needed, as the tone is positive and current. The overall confidence is therefore moderate and proportional to the limited but present connection to the Ability to Innovate category.",
    "level": "Tertiary"
  },
  "Continuous Learning": {
    "resourceId": "Automated Testing",
    "category": "Continuous Learning",
    "calculated_at": "2025-05-06T20:57:30",
    "ai_confidence": 59.2,
    "ai_mentions": 2.4,
    "ai_alignment": 6.8,
    "ai_depth": 6.6,
    "ai_intent": 5.9,
    "ai_audience": 7.7,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 59.0,
    "reasoning": "The content explicitly focuses on Automated Testing, emphasizing its impact on software quality, early issue detection, reduced manual effort, and faster delivery. The closest conceptual tie-in to Continuous Learning is the mention of 'a culture of continuous improvement' and shortened feedback loops, which are indeed aligned with some Continuous Learning principles. However, the discussion centers on quality assurance practices, automation tools, and Agile/DevOps delivery, not on learning, growth mindset, or systemic knowledge sharing. Key elements of Continuous Learning such as learning from failure, mindset development, or structured knowledge transfer are largely absent. Direct mentions of Continuous Learning or related terms are minimal (mentions=2.4). The alignment and depth scores reflect that while there are indirect connections to learning and improvement through Agile and feedback loops, these are typically considered adjacent to, not core to, Continuous Learning as defined. The target audience (audience=7.7) is practitioners in Agile/DevOps environments, which is a partial match. The signal-to-noise ratio is high, as most content is relevant though not strictly continuous learning focused. No penalties were applied as there is no outdated information or contradiction. The overall confidence thus reflects a moderate conceptual relationship but clear focus on a neighboring domain.",
    "level": "Tertiary"
  },
  "Working Software": {
    "resourceId": "Automated Testing",
    "category": "Working Software",
    "calculated_at": "2025-05-06T20:57:30",
    "ai_confidence": 49.8,
    "ai_mentions": 1.5,
    "ai_alignment": 4.8,
    "ai_depth": 4.4,
    "ai_intent": 5.0,
    "ai_audience": 6.1,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 50.0,
    "reasoning": "The content is focused on the practice and value of Automated Testing, consistently referencing its role in ensuring software quality and accelerating delivery. However, there are no direct or explicit mentions of 'Working Software' as an artifact or deliverable; mentions of delivering high-quality software are present but primarily as an outcome of automated testing practices. The conceptual alignment is moderate—the text is related to the goal of producing reliable software but does not directly discuss working software as defined in Agile or Scrum frameworks, nor does it examine increments, artifacts, or progress measured through working software. Depth is present in discussing Automated Testing's role and benefits, but the content is not deeply exploring working software as a category. Intent skews toward advocating the supporting practice (testing) rather than directly explaining or exemplifying working software as an output. The intended audience (technical practitioners and teams focused on quality and delivery) moderately overlaps with the audience for 'Working Software,' but is not perfectly aligned. The signal is relatively high as there is little off-topic filler, yet the focus is slightly shifted from direct category relevance. No penalties have been applied, as there is no evidence of obsolete practices or contradiction. Overall, confidence is limited by the indirectness of reference and only partial alignment with the 'Working Software' category.",
    "level": "Tertiary"
  },
  "Agile Product Operating Model": {
    "resourceId": "Automated Testing",
    "category": "Agile Product Operating Model",
    "calculated_at": "2025-05-06T20:57:22",
    "ai_confidence": 48.47,
    "ai_mentions": 2.7,
    "ai_alignment": 5.3,
    "ai_depth": 4.8,
    "ai_intent": 5.1,
    "ai_audience": 5.7,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 48.0,
    "reasoning": "The content focuses entirely on Automated Testing as a practice for enhancing software quality and agility. While it references concepts foundational to agile (e.g., continuous improvement, organisational agility, customer value, collaboration), it does not directly mention the Agile Product Operating Model nor explores APOM frameworks, principles, or organizational structures. Mentions of agile principles are present but general (e.g., 'aligns with principles of Agile and DevOps'); there are no direct or sustained connections to APOM-specific topics such as transitioning to a product ethos, product governance, or Evidence-Based Management. Depth of discussion is reasonable concerning testing practices, but minimal in regard to APOM itself. The audience alignment and signal-to-noise scores reflect that this content is primarily for practitioners in software quality or delivery, not specifically for leaders or stakeholders implementing APOM. No penalties were necessary as the content is neither obsolete nor critical of the APOM framing, but the overall confidence is limited due to the lack of direct connection to the Agile Product Operating Model.",
    "level": "Tertiary"
  },
  "Scrum Master": {
    "resourceId": "Automated Testing",
    "category": "Scrum Master",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 13.75,
    "ai_mentions": 0.2,
    "ai_alignment": 1.4,
    "ai_depth": 1.3,
    "ai_intent": 1.5,
    "ai_audience": 4.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content centers around the topic of Automated Testing and its benefits for software quality, delivery speed, and enabling agility. There is no explicit or implicit mention of the Scrum Master accountability, nor any discussion connected to Scrum roles, responsibilities, or system impacts specific to the Scrum Master. While the content references agile principles and team empowerment generically, these are framed in the context of testing and team workflow, not accountability or practices unique to the Scrum Master. As such, direct mentions are nearly absent, conceptual alignment is very weak, and depth regarding the category is low. Intent and signal slightly increase given the quasi-relevance to agile-minded practitioners, but the content's focus is methodical, not role/accountability based. No penalties were necessary, as there is no outdated advice or negative tone towards the category. Overall, the confidence is very low, accurately reflecting almost no meaningful fit to the 'Scrum Master' category.",
    "level": "Ignored"
  },
  "Continuous Improvement": {
    "resourceId": "Automated Testing",
    "category": "Continuous Improvement",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 79.32,
    "ai_mentions": 5.1,
    "ai_alignment": 8.2,
    "ai_depth": 7.8,
    "ai_intent": 8.0,
    "ai_audience": 8.4,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 79.0,
    "reasoning": "While the content primarily focuses on Automated Testing, it makes explicit and implicit connections to the principles of Continuous Improvement. There is a direct mention of fostering 'a culture of continuous improvement,' and the practice is framed as supporting incremental organizational agility, rapid feedback loops, and proactive, ongoing adaptation. However, Continuous Improvement is not the main topic—it is a supporting theme, reflected mostly as a benefit and cultural outcome of Automated Testing, rather than as the core subject of the piece. The discussion of feedback loops, Agile/DevOps alignment, and sustained delivery matches the category’s conceptual framework. The depth is reasonably high, with tangible links to improved processes, adaptation, and empirical learning, but does not thoroughly explore Continuous Improvement methodologies or case studies. The audience (technical and cross-functional teams) is well-matched. No penalties apply, as the content is current, positive, and supportive. Overall, the content aligns well with the category, especially as it relates to enabling factors for Continuous Improvement, justifying a high but not full confidence score.",
    "level": "Secondary",
    "reasoning_summary": "The content aligns well with the Continuous Improvement category, as it highlights how Automated Testing fosters a culture of ongoing enhancement through rapid feedback and adaptability. While Continuous Improvement isn’t the main focus, its principles are woven throughout as key benefits, making the classification appropriate for audiences interested in process optimisation and organisational agility."
  },
  "Forecasting": {
    "resourceId": "Automated Testing",
    "category": "Forecasting",
    "calculated_at": "2025-05-06T20:57:22",
    "ai_confidence": 11.95,
    "ai_mentions": 0.2,
    "ai_alignment": 1.4,
    "ai_depth": 1.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 3.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content focuses exclusively on Automated Testing as a methodology to improve software quality, reliability, accelerate delivery, and enable continuous improvement in Agile and DevOps environments. There are no direct mentions of 'Forecasting,' nor are related concepts or metrics (e.g., empirical prediction of timelines, burn-down charts, risk management, delivery forecasting, or value optimisation based on forecasted data) discussed. The closest conceptual alignment is the mention of delivering value predictably and supporting Agile principles, but this is only loosely related and does not address forecasting practices per the strict category definition. Depth and intent remain low regarding forecasting, as the main purpose is quality assurance enablement, not predictability through empirical data or metrics. The audience—software practitioners in Agile contexts—somewhat overlaps, but the content is almost entirely unrelated to the definition of forecasting within Agile/Scrum. The signal-to-noise ratio is moderately high for its topic, but relevance to 'Forecasting' is minimal. No penalties were needed as the content is not outdated or contradictory, just off-topic for this category. The very low confidence score reflects this substantial disconnect.",
    "level": "Ignored"
  },
  "Acceptance Test Driven Development": {
    "resourceId": "Automated Testing",
    "category": "Acceptance Test Driven Development",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 17.5,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 2.0,
    "ai_intent": 2.5,
    "ai_audience": 6.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content discusses the general practice and benefits of automated testing but makes no explicit or implicit mention of Acceptance Test Driven Development (ATDD). There are no direct references to acceptance criteria, collaborative approaches between stakeholders and developers, or techniques unique to ATDD. Its alignment is tangential, as some practices (e.g., shift-left, integration in agile/devops) overlap with the spirit of ATDD, but the main focus is broad automation, not acceptance-level collaboration or test definition. The depth and intent are surface-level in relation to ATDD, aiming at quality and delivery speed rather than demonstrating knowledge of ATDD methodology. The audience (software practitioners) is compatible, though not specifically attuned to ATDD. Overall, almost all content is off-topic for this category, which justifies a low confidence score and low values for most dimensions.",
    "level": "Ignored"
  },
  "Organisational Physics": {
    "resourceId": "Automated Testing",
    "category": "Organisational Physics",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 33.4,
    "ai_mentions": 0.2,
    "ai_alignment": 3.7,
    "ai_depth": 3.5,
    "ai_intent": 2.6,
    "ai_audience": 7.4,
    "ai_signal": 4.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content primarily discusses the value and implementation of Automated Testing as a software engineering practice. There are very minimal, indirect overlaps with Organisational Physics, such as mentions of systemic enablers and feedback loops. However, the focus is on software delivery and quality assurance, not on systems thinking, organisational dynamics, or the holistic examination of organisational behaviour per the category definition. Direct mentions of 'Organisational Physics' or related systems thinking are absent. Though the audience could overlap with those interested in organisational improvement, the content is technical and geared toward software practitioners, not organisational strategists or those exploring systemic interactions. The strongest conceptual alignment is the brief nod to feedback loops and agility, but these are only tangentially connected to the deeper analysis expected in Organisational Physics. No penalties were applied as the tone is appropriate and up-to-date; calibration ensures that scores are distinct and proportionate, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Entrepreneurship": {
    "resourceId": "Automated Testing",
    "category": "Entrepreneurship",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 24.06,
    "ai_mentions": 0.3,
    "ai_alignment": 2.9,
    "ai_depth": 2.6,
    "ai_intent": 2.2,
    "ai_audience": 2.8,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is entirely focused on automated testing as a practice for improving software quality and delivery. While it mentions value delivery, innovation, and organizational agility, these are framed exclusively in the context of software engineering, not entrepreneurship. There is no direct mention of 'entrepreneurship,' its themes, mindset, risk-taking, or startup ecosystem. The alignment and depth with the entrepreneurship category are minimal — any relevance is tangential at best, such as references to agility and innovation, but these do not address entrepreneurial principles or strategy. The audience is technical (software teams), not entrepreneurial practitioners or strategists, and most of the signal is off-topic for the category beyond surface-level concepts. No content is outdated or critical of entrepreneurship, so no penalties apply. The low scores across all dimensions are proportional to the lack of direct relevance to entrepreneurship.",
    "level": "Ignored"
  },
  "Strategic Goals": {
    "resourceId": "Automated Testing",
    "category": "Strategic Goals",
    "calculated_at": "2025-05-06T20:57:22",
    "ai_confidence": 57.5,
    "ai_mentions": 2.8,
    "ai_alignment": 7.1,
    "ai_depth": 6.8,
    "ai_intent": 6.3,
    "ai_audience": 6.5,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 58.0,
    "reasoning": "The content on Automated Testing does not directly mention 'Strategic Goals' or related terminology, resulting in a low Direct Mentions score. However, it aligns moderately with the category by discussing automated testing as a 'systemic enabler of organisational agility' and touches on themes like continuous improvement, agility, and supporting a competitive advantage. The alignment and depth scores are moderate, as the article frames Automated Testing as a long-term strategic practice, but it remains mostly focused on process and operational benefits rather than explicitly on strategic goal-setting, measurement, or alignment with agile frameworks at an organisational level. The intent seems aimed at influencing practitioners and leaders to adopt automated testing as a strategic approach, yet it is not the main purpose of the content. The audience is likely technical or team leads, and partially aligns with strategic decision-makers. The signal-to-noise ratio is good, as the content is mostly focused and relevant without filler, but the depth in actual strategic-goal articulation is lacking. No penalties were applied, as the tone is not outdated and does not contradict the strategic goals framing.",
    "level": "Tertiary"
  },
  "Team Collaboration": {
    "resourceId": "Automated Testing",
    "category": "Team Collaboration",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 64.49,
    "ai_mentions": 3.4,
    "ai_alignment": 6.8,
    "ai_depth": 7.3,
    "ai_intent": 6.5,
    "ai_audience": 6.9,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 64.0,
    "reasoning": "The content on 'Automated Testing' is primarily focused on the benefits of automated testing for software quality and delivery. There are several indirect connections to team collaboration, such as the mention of cross-functional teams, alignment with Agile and DevOps principles, and fostering collaboration by embedding testing early in development. However, direct, explicit discussion of Team Collaboration is minimal; the term is not named directly and only alluded to through discussions of enabling teamwork and collective practices. The conceptual alignment is moderate: the content recognizes how automated testing supports collaborative Agile/DevOps workflows, but does not delve deeply into the mechanics or techniques for enhancing team dynamics specifically. The depth of discussion is solid for automated testing, but only tangential for collaboration topics. The intent is somewhat aligned, as the focus is on team enablement in Agile/DevOps settings, without being directly supportive of Team Collaboration as the core message. The audience matches practitioners in Agile and DevOps teams, which is relevant. Signal-to-noise is high, as the content is focused, but with only partial relevance to team collaboration. No penalties were applied because the content is current, accurate, and supportive in tone.",
    "level": "Secondary"
  },
  "Hybrid Agile": {
    "resourceId": "Automated Testing",
    "category": "Hybrid Agile",
    "calculated_at": "2025-05-06T20:57:21",
    "ai_confidence": 7.7,
    "ai_mentions": 0.3,
    "ai_alignment": 1.2,
    "ai_depth": 0.9,
    "ai_intent": 0.8,
    "ai_audience": 2.4,
    "ai_signal": 1.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content focuses entirely on Automated Testing, discussing its importance for software quality, early feedback, reduced manual effort, and alignment with Agile and DevOps principles. There are no direct or indirect references to Hybrid Agile, nor does the content explore the merging of traditional and agile methodologies, their challenges, or any dysfunctions resulting from such attempts. It does not refer to command-and-control structures, accountability in agile roles, superficial adoption, or related Hybrid Agile themes. The target audience (likely practitioners interested in testing and quality assurance) only partially overlaps with the audience for critical Hybrid Agile discussions. As a result, all category-specific scoring dimensions are extremely low, with the only positive points coming from a tangential mention of 'Agile principles' and general relevance to software development themes in very broad terms.",
    "level": "Ignored"
  },
  "Revenue per Employee": {
    "resourceId": "Automated Testing",
    "category": "Revenue per Employee",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 1.8,
    "ai_mentions": 0.1,
    "ai_alignment": 0.2,
    "ai_depth": 0.3,
    "ai_intent": 0.0,
    "ai_audience": 1.0,
    "ai_signal": 0.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content focuses exclusively on Automated Testing, its benefits for software quality, reliability, team workflow, and organisational agility. There are no direct mentions, references, or discussions of 'Revenue per Employee' or any similar financial observability metrics. The main ideas are aligned with software development practices, not financial or workforce efficiency metrics. While mildly relevant to organisational efficiency, there is no metric-based analysis, trend evaluation, or conceptual alignment with the definition provided for 'Revenue per Employee.' The audience and signal overlap is minimal, as intended readers are engineers or development leaders focused on software assurance, not financial performance. No penalties were applied, as there are no obsolete references or contradictory tones; the low scores reflect near total irrelevance to the category.",
    "level": "Ignored"
  },
  "Agnostic Agile": {
    "resourceId": "Automated Testing",
    "category": "Agnostic Agile",
    "calculated_at": "2025-05-06T20:57:24",
    "ai_confidence": 31.45,
    "ai_mentions": 0.2,
    "ai_alignment": 3.3,
    "ai_depth": 3.7,
    "ai_intent": 3.9,
    "ai_audience": 5.2,
    "ai_signal": 4.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 31.0,
    "reasoning": "The content focuses exclusively on the practice of Automated Testing, its benefits, its relationship to Agile and DevOps, and how it improves quality and value delivery. While it makes high-level mention of agile principles, there are no direct references to 'Agnostic Agile' or its distinct philosophy. There is no discussion of the Agnostic Agile movement, its principles, context-driven adaptation, or ethical considerations, nor any mention of differentiating between frameworks or leaders in the movement. The content is aligned with general agile and DevOps values (such as continuous improvement, value delivery, and agility) but never links these directly or explicitly to the Agnostic Agile concept or the nuanced application of its principles. The audience (software teams, quality practitioners, agile organizations) is partially aligned, but the purpose and depth remain generic, lacking the required context for categorization as Agnostic Agile. No penalties were applied, as the content is not outdated or critical, merely insufficiently aligned. The confidence score is therefore low, reflecting multiple dimensions where substantial alignment with the Agnostic Agile category is missing.",
    "level": "Ignored"
  },
  "Engineering Excellence": {
    "resourceId": "Automated Testing",
    "category": "Engineering Excellence",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 91.84,
    "ai_mentions": 7.7,
    "ai_alignment": 9.6,
    "ai_depth": 9.2,
    "ai_intent": 9.1,
    "ai_audience": 9.8,
    "ai_signal": 9.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content provides a focused and substantial discussion of Automated Testing, describing it as a critical practice to software quality, reliability, and organizational agility—core themes of 'Engineering Excellence.' It explicitly refers to best practices (e.g., detecting issues early, reducing manual effort, enabling CI/CD, shift-left testing) and links them to broader engineering goals such as continuous improvement, Agile/DevOps alignment, and customer satisfaction. Key phrases like 'systematic execution,' 'integration into the development pipeline,' and 'quality assurance' are tightly aligned with the domain. The target audience is clearly technical practitioners and engineering teams. The depth is robust, expanding from technical implementation to business impact. The signal-to-noise ratio is extremely high, with the entire content focused on the subject. There are no references to obsolete practices or any contradictory, tangential, or critical tones. While the category phrase 'Engineering Excellence' is not directly mentioned repeatedly, the overall conceptual alignment and depth strongly compensate for this, justifying the high confidence score.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the 'Engineering Excellence' category. It thoroughly explores automated testing, linking technical best practices to broader engineering goals like quality, agility, and continuous improvement. The discussion is clear, relevant, and aimed at technical teams, with a strong focus on practical and strategic benefits—making it highly aligned with the category’s intent."
  },
  "Deployment Strategies": {
    "resourceId": "Automated Testing",
    "category": "Deployment Strategies",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 27.1,
    "ai_mentions": 0.2,
    "ai_alignment": 2.9,
    "ai_depth": 2.7,
    "ai_intent": 2.4,
    "ai_audience": 7.1,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 27.0,
    "reasoning": "The content is focused on Automated Testing, describing its benefits in software quality, rapid feedback, and integration into development pipelines. There are no direct or even indirect mentions of deployment strategies such as blue-green deployments, canary releases, feature toggles, rolling updates, or infrastructure as code. The core concepts are more aligned with quality assurance and software development practices rather than deployment methodologies. While the content targets a technical audience that may also be interested in deployment strategies, the main purpose is orthogonal, focusing on testing rather than deployment. The signal is high in relevance to its own topic (automated testing) but not to deployment strategies, as there are no concrete discussions, actionable insights, or methodologies about deployment. No outdated practices or category-contradicting tone are present. Scores are low in the most heavily weighted dimensions (mentions, alignment, depth, and intent), which appropriately yields a low confidence score for fitting in the 'Deployment Strategies' category.",
    "level": "Ignored"
  },
  "Deployment Frequency": {
    "resourceId": "Automated Testing",
    "category": "Deployment Frequency",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 42.35,
    "ai_mentions": 1.5,
    "ai_alignment": 4.7,
    "ai_depth": 5.3,
    "ai_intent": 5.0,
    "ai_audience": 8.2,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "While the content explicitly discusses Automated Testing and references some Agile and DevOps principles, it does not directly mention Deployment Frequency nor focus on the optimization of deployment intervals. There are indirect connections: automated testing does enable faster, safer deployment by reducing manual bottlenecks and supporting rapid feedback loops, which aligns partially with the category. However, core concepts like deployment interval measurement, CI/CD strategies for increasing deployment frequency, or the impact of deployment frequency are absent. Depth is moderate, but remains focused on quality, reliability, and enabling organizational agility rather than specifically optimizing deployment frequency. The audience is likely technical teams familiar with Agile/DevOps, and the content has little off-topic material. Overall, confidence is moderate due to lack of direct mention and category-specific discussion.",
    "level": "Tertiary"
  },
  "Value Delivery": {
    "resourceId": "Automated Testing",
    "category": "Value Delivery",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 85.55,
    "ai_mentions": 6.1,
    "ai_alignment": 9.2,
    "ai_depth": 8.9,
    "ai_intent": 8.6,
    "ai_audience": 7.6,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 86.0,
    "reasoning": "The content explicitly connects Automated Testing to key facets of Value Delivery by discussing its role in accelerating delivery, maintaining quality, shortening feedback loops, and supporting Agile and DevOps principles. It references both iterative delivery and customer value, directly mentioning delivery and value alignment. While the direct use of the exact phrase 'Value Delivery' is limited, explicit links are drawn between automated testing and the ability to deliver value sustainably. The depth is strong, as the discussion moves beyond superficial technical implementation to cover strategic and systemic impacts. Intent and audience are closely matched, targeting Agile/DevOps practitioners interested in continuous value delivery. Signal-to-noise ratio is good, with nearly all content tightly focused on how automated testing supports organizational agility, though a minor part is dedicated to generalized benefits. No penalties are applied, as the content is contemporary, supportive, and well-aligned with the category. Overall, a high, but not perfect, confidence score is warranted due to a slightly heavier focus on technical quality as the first theme, before fully contextualizing within value delivery practices.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the Value Delivery category. It clearly links automated testing to faster, higher-quality delivery and highlights its strategic role in Agile and DevOps environments. While it leans slightly towards technical quality at first, it effectively connects these aspects to sustainable value delivery, making it highly relevant for practitioners focused on continuous improvement."
  },
  "Market Share": {
    "resourceId": "Automated Testing",
    "category": "Market Share",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 6.5,
    "ai_mentions": 0.3,
    "ai_alignment": 1.1,
    "ai_depth": 0.9,
    "ai_intent": 1.2,
    "ai_audience": 1.9,
    "ai_signal": 1.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The content focuses entirely on the benefits, methodology, and strategic value of automated testing within software development. There is no direct mention of market share or explicit reference to strategies aimed at increasing a product's presence or competitive advantage in a market segment. The thematic focus is on quality assurance, efficiency, agility, and customer retention, none of which are tied specifically or substantially to market share concepts. No explicit or implicit analysis of competitive landscape, market positioning, or the role of such methodologies in gaining market share is present. The content is intended for practitioners and decision-makers interested in software quality and process improvement rather than those explicitly pursuing market share growth. As such, the confidence that this content fits the 'Market Share' category is extremely low, reflected in minimal scores for all evaluated dimensions. There were no penalties applied as the tone and content were not outdated or contradictory to the category’s framing.",
    "level": "Ignored"
  },
  "Systems Thinking": {
    "resourceId": "Automated Testing",
    "category": "Systems Thinking",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 38.45,
    "ai_mentions": 0.2,
    "ai_alignment": 3.2,
    "ai_depth": 3.0,
    "ai_intent": 5.8,
    "ai_audience": 8.1,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content on 'Automated Testing' does not directly mention Systems Thinking or its foundational principles. While it references concepts such as feedback loops, continuous improvement, system-wide agility, and makes passing reference to Agile and DevOps (which can have some conceptual overlap with Systems Thinking when practiced holistically), the discussion focuses overwhelmingly on the technical process, benefits, and organisational impact of automated testing rather than the interconnectedness or holistic system analysis required for genuine Systems Thinking. There are some systemic implications hinted at—such as improving organisational agility and embedding quality culture—but these are indirect and not framed using Systems Thinking language, nor do they discuss typical tools, frameworks, or mapping techniques associated with the category. The main audience (software engineers, DevOps practitioners) overlaps somewhat with the typical Systems Thinking audience, and the content is focused with little off-topic material. The overall confidence is low, reflecting that while there is minor conceptual relevance (feedback loops, systemic enablement), the content lacks direct references, depth, and purpose-fit for the strict Systems Thinking category.",
    "level": "Ignored"
  },
  "Agentic Agility": {
    "resourceId": "Automated Testing",
    "category": "Agentic Agility",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 31.756,
    "ai_mentions": 0.6,
    "ai_alignment": 4.8,
    "ai_depth": 4.3,
    "ai_intent": 3.7,
    "ai_audience": 6.5,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 32.0,
    "reasoning": "The content on 'Automated Testing' focuses primarily on the benefits, process, and outcomes of implementing automated tests within Agile and DevOps environments. While it references the enhancement of organisational agility and empowering teams to innovate and adapt (points tangentially related to agentic agility), it does not explicitly discuss agency, intentionality, or the adaptive actions—particularly the autonomy, accountability, or double-loop learning central to agentic agility. There is no direct mention of 'agentic agility' or deep discussion of agency as a concept. The main purpose is educational for practitioners aiming to improve software quality and delivery speed, which partially aligns with the expected audience but is not specifically tailored to strategic discussions of agency within Agile or DevOps. There is high signal relative to noise, but amid solid domain relevance, only incidental overlap with the agentic agility definition exists. Scores reflect minimal direct mention, partial alignment and intent, and moderate depth/signal. No penalties are applied as the content is current and does not contradict the category.",
    "level": "Ignored"
  },
  "Agile Values and Principles": {
    "resourceId": "Automated Testing",
    "category": "Agile Values and Principles",
    "calculated_at": "2025-05-06T20:57:25",
    "ai_confidence": 57.77,
    "ai_mentions": 4.3,
    "ai_alignment": 7.9,
    "ai_depth": 5.8,
    "ai_intent": 6.8,
    "ai_audience": 7.2,
    "ai_signal": 6.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 58.0,
    "reasoning": "The content on 'Automated Testing' primarily focuses on the technical and process advantages of automated testing, such as early issue detection, reduction of manual effort, and speeding up delivery. There are passing connections to Agile principles, such as mentioning continuous improvement, rapid feedback, cross-functional teams, and aligning with Agile and DevOps principles. However, direct references to foundational Agile Values or the Agile Manifesto are minimal, and there is no explicit discussion of the four core values or twelve Agile principles. The conceptual alignment is moderately strong as the text mentions customer value, responding to change, and organizational agility. Depth is limited due to the superficial exploration of Agile principles; the main exploration is of automated testing as a practice rather than how it's rooted in Agile values. Intent is practical and somewhat aligned—facilitating agility and supporting teams—but the main purpose remains centered on promoting testing, not Agile philosophy. The audience (development/technical teams) is reasonably well aligned with those interested in Agile practices but is not exclusive to Agile practitioners. Signal-to-noise ratio is reasonably high, as most content stays focused on practices relevant to agility, though much of it is indirect regarding core Agile values. No penalties were warranted as the content is current, positive, and not contradictory to Agile framing. The confidence score reflects these factors: reasonable, but not strong, fit to the strict meaning of 'Agile Values and Principles.'",
    "level": "Tertiary"
  },
  "Azure Repos": {
    "resourceId": "Automated Testing",
    "category": "Azure Repos",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 12.35,
    "ai_mentions": 0.1,
    "ai_alignment": 1.0,
    "ai_depth": 1.1,
    "ai_intent": 2.0,
    "ai_audience": 2.2,
    "ai_signal": 1.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content is exclusively focused on automated testing in a generic context. There are no direct mentions of Azure Repos, nor is there any conceptual alignment with the functionalities, integrations, or best practices specific to Azure Repos as described in the classification definition. The discussion is technical but broadly relevant to DevOps and Agile practices rather than any Azure-specific tools or source control systems. There is no depth regarding Azure Repos, and the main intent is education around automated testing in general. The target audience (software development professionals) overlaps slightly with that of Azure Repos, but not in a targeted way. The signal is overwhelmingly off-topic for the Azure Repos category.",
    "level": "Ignored"
  },
  "Technical Debt": {
    "resourceId": "Automated Testing",
    "category": "Technical Debt",
    "calculated_at": "2025-05-06T20:57:28",
    "ai_confidence": 23.95,
    "ai_mentions": 0.1,
    "ai_alignment": 2.4,
    "ai_depth": 2.7,
    "ai_intent": 2.9,
    "ai_audience": 6.4,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses exclusively on the benefits, practices, and strategic importance of automated testing in software development. There is no mention of technical debt by name or proxy, nor any substantial conceptual linkage to the identification, measurement, or remediation of technical debt. While automated testing can be used as a tool to prevent or minimize technical debt, the content does not discuss these connections. Instead, it emphasizes quality assurance, continuous improvement, Agile/DevOps alignment, and customer value—topics orthogonal to the direct management or consequences of technical debt. The audience (software practitioners interested in engineering effectiveness) overlaps somewhat with that of technical debt topics, which is why the audience score is relatively higher. However, the alignment and signal scores are low because the primary focus is not on technical debt itself, nor does the depth move beyond generic advocacy for automated testing. No penalties were applied due to irrelevant references or outdated practices.",
    "level": "Ignored"
  },
  "Test Driven Development": {
    "resourceId": "Automated Testing",
    "category": "Test Driven Development",
    "calculated_at": "2025-05-06T20:57:31",
    "ai_confidence": 41.02,
    "ai_mentions": 0.3,
    "ai_alignment": 3.65,
    "ai_depth": 3.25,
    "ai_intent": 4.6,
    "ai_audience": 8.2,
    "ai_signal": 7.55,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 41.0,
    "reasoning": "The content does not explicitly mention Test Driven Development (TDD) or describe its unique practices such as Red-Green-Refactor, writing tests before code, or common TDD tools by name. It focuses entirely on Automated Testing as a general practice, discussing its benefits in terms of software quality, early issue detection, and integration with Agile/DevOps without any direct overlap with TDD's specific methodologies. The alignment and depth scores reflect that while there are tangential relationships (e.g., 'shift-left', early testing), these are generic to automated testing and not tied to TDD. The content's intent is informational about automated testing practices, not specifically TDD, although the audience and signal scores are higher because practitioners interested in TDD are also likely to be the target audience. No penalties were needed since there is no outdated information or actively critical tone. Overall, the confidence score is proportionally low, as the content does not fit well within the strict boundaries of the TDD category, instead aligning more with general automated testing topics.",
    "level": "Tertiary"
  }
}