{
  "Kanban": {
    "resourceId": "oRStCAqLAY4",
    "category": "Kanban",
    "calculated_at": "2025-05-07T12:48:06",
    "ai_confidence": 13.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.0,
    "ai_depth": 1.8,
    "ai_intent": 2.0,
    "ai_audience": 2.5,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. Kanban is mentioned only once, in a list of example categories alongside others like Scrum and Technical Leadership, with no further discussion or elaboration. There is no exploration of Kanban principles, practices, or its methodology. The main focus is on classification architecture, AI integration, and editorial workflow, not on Kanban as a process or framework. The audience is technical (blog owners, developers, automation enthusiasts), but not specifically Kanban practitioners. The signal-to-noise ratio for Kanban is very low, as nearly all content is unrelated to Kanban. No penalties were applied, as the content is not outdated or critical of Kanban, but the fit is extremely weak and almost entirely incidental.",
    "level": "Ignored"
  },
  "DevOps": {
    "resourceId": "oRStCAqLAY4",
    "category": "DevOps",
    "calculated_at": "2025-05-07T12:48:11",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.2,
    "ai_audience": 4.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "Direct mentions of DevOps are minimal: the term appears only once, in a biographical aside, and is not a focus of the content. The main themes revolve around automating blog post classification using generative AI and PowerShell, with a strong emphasis on human oversight, auditability, and technical implementation. While some concepts—such as automation, traceability, and blending human and machine roles—are tangentially related to DevOps principles (e.g., automation, accountability, continuous improvement), the content does not explicitly discuss DevOps as a philosophy, its cultural shifts, or its core practices. The depth of discussion is substantial regarding AI-driven content management, but not in relation to DevOps. The intent is to inform about a technical solution for content tagging, not to explore or advocate for DevOps. The audience is technical (developers, site maintainers), which partially overlaps with DevOps practitioners, but the focus is not on DevOps-specific challenges or strategies. The signal-to-noise ratio is moderate: the content is focused, but not on DevOps. No penalties were applied, as the content is current and not critical of DevOps. Overall, the confidence score is low, reflecting that while there are some conceptual overlaps (automation, accountability), the content does not fit well under the DevOps category.",
    "level": "Tertiary"
  },
  "Product Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Management",
    "calculated_at": "2025-05-07T12:48:25",
    "ai_confidence": 38.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.2,
    "ai_audience": 5.0,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content is a technical case study on automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site. Direct mentions of 'Product Management' or its frameworks are absent, and the terminology is focused on content management, automation, and technical implementation. Conceptual alignment is limited: while there are some tangential overlaps (e.g., strategic alignment of automation with editorial standards, traceability, and human oversight), the main themes are not about product management methodologies, stakeholder balancing, or business strategy. The depth of discussion is substantial, but it is technical and operational, not strategic or product-focused. The intent is to inform about a technical solution for content classification, not to guide or educate on product management practices. The audience is primarily technical practitioners (developers, site maintainers), not product managers or strategists. The signal-to-noise ratio is moderate: the content is focused, but its relevance to product management is low. No penalties were applied, as the content is current and not satirical or critical of the category. Overall, the confidence score is low, reflecting that while there are some faint echoes of product management principles (such as process improvement and traceability), the content does not directly or deeply engage with the core concerns of the Product Management category.",
    "level": "Ignored"
  },
  "Scrum": {
    "resourceId": "oRStCAqLAY4",
    "category": "Scrum",
    "calculated_at": "2025-05-07T12:48:30",
    "ai_confidence": 23.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.3,
    "ai_depth": 2.0,
    "ai_intent": 2.5,
    "ai_audience": 3.1,
    "ai_signal": 2.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. Scrum is mentioned only in passing as part of the author's career background and as an example of a category label, but there is no substantive discussion of Scrum principles, roles, events, or practices. The main focus is on automation, AI-human collaboration, and technical architecture for content management, not on Scrum as a framework or methodology. The audience is technical practitioners interested in automation and content management, not specifically Scrum practitioners. The signal-to-noise ratio for Scrum is low, as nearly all content is off-topic for the Scrum category. No penalties were applied, as the content is not outdated or critical of Scrum, but the overall fit is weak, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Product Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Development",
    "calculated_at": "2025-05-07T12:48:40",
    "ai_confidence": 54.7,
    "ai_mentions": 2.2,
    "ai_alignment": 5.8,
    "ai_depth": 6.1,
    "ai_intent": 5.5,
    "ai_audience": 6.0,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content is a detailed technical case study of using generative AI and PowerShell to automate and improve tagging and categorisation for a personal blog using Hugo. While it demonstrates iterative improvement, automation, and the integration of human oversight with AI, its primary focus is on content management, technical scripting, and classification architecture rather than on product development methodologies or practices. There are indirect references to concepts like continuous improvement, traceability, and risk mitigation (e.g., audit trails, penalty logic), but these are applied to content classification rather than to the delivery of valuable products in a business context. The term 'Product Development' is mentioned only as an example of a category, not as a subject of discussion. The depth of discussion is strong regarding technical implementation and process, but it does not explore product development principles, customer feedback loops, or cross-functional team dynamics. The intent is to inform technical practitioners about automating editorial workflows, not to guide or reflect on product development strategy or lifecycle. The audience is technical (blog owners, developers, automation enthusiasts), which partially overlaps with product development practitioners but is not a direct match. The content is focused and relevant to its stated purpose, with little off-topic material, but the signal-to-noise ratio for product development specifically is moderate. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score reflects that while there are some conceptual overlaps (automation, improvement, traceability), the content does not directly or deeply address product development as defined.",
    "level": "Tertiary"
  },
  "Leadership": {
    "resourceId": "oRStCAqLAY4",
    "category": "Leadership",
    "calculated_at": "2025-05-07T12:48:45",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 3.5,
    "ai_intent": 3.9,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a technical case study on automating blog post tagging and categorisation using generative AI and PowerShell scripts. Direct mentions of 'leadership' are minimal, with only a passing reference to 'Technical Leadership' as an example category. The main focus is on technical architecture, automation, and editorial workflow, not on leadership practices, strategies, or frameworks. Conceptual alignment is weak: while the author discusses human oversight, accountability, and the distinction between AI agency and human decision-making, these are framed in the context of content management and responsible automation, not organisational or team leadership. The depth of discussion around leadership is shallow; the content does not explore leadership models, team dynamics, or cultural change. The intent is to inform technical practitioners about automating classification, not to guide or inspire leaders. The audience is primarily technical (blog owners, developers, automation enthusiasts), not leaders or executives. The signal-to-noise ratio is moderate, as the content is focused but not on the leadership category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence that this content fits under 'Leadership' is low, as it does not directly or substantially address leadership topics as defined.",
    "level": "Ignored"
  },
  "Lean": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lean",
    "calculated_at": "2025-05-07T12:48:57",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.5,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripting to automate and improve the tagging and categorisation of blog posts in Hugo. There are no direct mentions of Lean, Lean Thinking, or any Lean methodologies, tools, or principles. The conceptual alignment is very weak: while the content discusses process improvement and efficiency, it does so in the context of content management automation, not in the context of Lean's value creation, waste reduction, or continuous improvement as defined by the Toyota Production System. The depth of discussion is substantial regarding technical implementation, but not in relation to Lean concepts. The intent is to inform about AI-driven classification and human oversight, not to educate or discuss Lean practices. The audience is technical (developers, content managers), which could overlap with Lean practitioners, but the content is not tailored to those interested in Lean methodologies. The signal-to-noise ratio is low for the Lean category, as the content is focused on automation and AI, not Lean. No penalties were applied as the content is not outdated or satirical, but the overall confidence is very low due to the lack of relevance to Lean.",
    "level": "Ignored"
  },
  "Engineering Excellence": {
    "resourceId": "oRStCAqLAY4",
    "category": "Engineering Excellence",
    "calculated_at": "2025-05-07T12:48:51",
    "ai_confidence": 77.7,
    "ai_mentions": 3.7,
    "ai_alignment": 8.6,
    "ai_depth": 7.9,
    "ai_intent": 7.8,
    "ai_audience": 8.2,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 78.0,
    "reasoning": "The content provides a detailed technical account of using generative AI and PowerShell scripting to automate and improve the tagging and categorisation of blog posts in Hugo. While 'Engineering Excellence' is not directly named, the post demonstrates strong conceptual alignment with the category through its focus on automation, traceability, auditability, and the blending of AI with human oversight—key aspects of high-quality engineering practices. The discussion covers technical architecture, data information architecture, and the implementation of validation and penalty logic to ensure quality and explainability, all of which are hallmarks of engineering excellence. The depth is substantial, with clear examples of scripts, data structures, and process flows, though the primary focus is on content management rather than core software development practices like CI/CD or code review. The intent is to inform and guide practitioners on building robust, transparent, and scalable systems, which fits the category's audience. The signal-to-noise ratio is high, with minimal digression and a strong focus on technical process improvement. However, the content is more about applying engineering rigour to content management than about advancing software engineering standards per se, which slightly lowers the direct mention and depth scores. No penalties were applied, as the content is current, constructive, and aligns with the ethos of engineering excellence.",
    "level": "Secondary",
    "reasoning_summary": "This content aligns well with the 'Engineering Excellence' category, as it showcases how automation, traceability, and AI-driven processes can elevate content management. While it doesn’t focus on traditional software engineering topics, its emphasis on robust, auditable systems and clear technical guidance demonstrates the principles of engineering excellence in a practical, content-focused context."
  },
  "Technical Leadership": {
    "resourceId": "oRStCAqLAY4",
    "category": "Technical Leadership",
    "calculated_at": "2025-05-07T12:48:18",
    "ai_confidence": 41.7,
    "ai_mentions": 2.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.0,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content is a detailed technical case study on automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo site. While it references the category 'Technical Leadership' as an example of a category in the taxonomy, there are no direct or repeated discussions of technical leadership principles, servant leadership, agile team guidance, or related best practices. The main focus is on the technical architecture, scripting, and process automation for content management, not on leading development teams or fostering agile practices. The conceptual alignment is limited: the content does touch on strategy, accountability, and human oversight, which are tangentially relevant to technical leadership, but these are framed in the context of content management rather than team or organisational leadership. The depth of discussion is high for automation and AI integration, but shallow for technical leadership topics. The intent is to inform about a technical solution for classification, not to guide or mentor technical leaders. The audience is primarily technical practitioners interested in automation, scripting, and AI, not specifically technical leaders or agile coaches. The signal-to-noise ratio is moderate, as the content is focused but not on the core category. No penalties were applied, as the content is current and not contradictory. Overall, the content only weakly fits the 'Technical Leadership' category, resulting in a low-to-moderate confidence score.",
    "level": "Tertiary"
  },
  "Agile Strategy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Strategy",
    "calculated_at": "2025-05-07T12:49:03",
    "ai_confidence": 36.7,
    "ai_mentions": 0.6,
    "ai_alignment": 3.2,
    "ai_depth": 3.5,
    "ai_intent": 2.8,
    "ai_audience": 4.1,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. While it discusses strategy in the context of technical architecture, automation, and editorial control, it does not directly address Agile Strategy as defined. There are no explicit mentions of Agile methodologies, principles, or strategic alignment with Agile. The main focus is on technical implementation, data architecture, and the blend of AI and human oversight for content management. The closest conceptual overlap is the mention of 'strategy' in the sense of technical or editorial strategy, but not organisational or Agile strategy. The depth of discussion is strong for technical automation and process improvement, but not for Agile Strategy topics such as organisational vision, continuous value delivery, or leadership in Agile contexts. The intended audience appears to be technical practitioners or site owners, not Agile strategists or executives. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence score is low, reflecting that the content does not fit well under the Agile Strategy category.",
    "level": "Ignored"
  },
  "Lean Startup": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lean Startup",
    "calculated_at": "2025-05-07T12:49:08",
    "ai_confidence": 18.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 6.2,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of Lean Startup, nor are Lean Startup concepts (such as MVPs, Build-Measure-Learn, validated learning, or rapid experimentation for business model validation) discussed. The main focus is on content management, automation, and human-AI collaboration for editorial control, not on startup innovation or iterative business learning. While the content does discuss iterative improvement and feedback loops, these are in the context of technical system refinement, not the Lean Startup methodology. The audience is technical practitioners interested in automation and AI for content management, which only partially overlaps with Lean Startup's typical audience. The signal-to-noise ratio is moderate, as the content is focused but not relevant to Lean Startup. Overall, the content does not fit the Lean Startup category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Backlog Refinement": {
    "resourceId": "oRStCAqLAY4",
    "category": "Backlog Refinement",
    "calculated_at": "2025-05-07T12:49:12",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 1.8,
    "ai_intent": 2.0,
    "ai_audience": 4.2,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and scripting to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of backlog refinement, nor are there references to Agile, Scrum, or related practices. The main themes revolve around content management, taxonomy, automation, and human-AI collaboration for editorial control. While the author briefly mentions a background in Scrum and process consulting, this is only in the context of personal history and does not connect to backlog refinement concepts, techniques, or practices. The depth of discussion is substantial regarding classification systems and technical implementation, but none of this is relevant to backlog refinement as defined. The intent is to inform about AI-driven content classification, not to discuss or support backlog refinement. The audience is technical and process-oriented, which partially overlaps with Agile practitioners, but the content is not targeted at those interested in backlog refinement. The signal-to-noise ratio is low for this category, as nearly all content is off-topic. No penalties were applied, as the content is not outdated or critical of backlog refinement; it is simply unrelated.",
    "level": "Ignored"
  },
  "Product Backlog": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Backlog",
    "calculated_at": "2025-05-07T12:49:18",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.5,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve tagging and categorisation of blog posts in Hugo. There is no direct mention of the Product Backlog, nor is there any discussion of Agile, Scrum, backlog refinement, prioritisation, or related practices. The main themes are technical automation, content management, and classification systems for a personal blog, which are conceptually unrelated to the Product Backlog as defined. The depth of discussion is substantial, but entirely off-topic for this category. The intent is to inform about technical solutions for content classification, not backlog management. The audience is technical, which partially overlaps with Agile practitioners, but the subject matter is not relevant to Product Backlog management. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is not outdated or critical of the Product Backlog. Overall, the confidence that this content fits under 'Product Backlog' is extremely low.",
    "level": "Ignored"
  },
  "Continuous Integration": {
    "resourceId": "oRStCAqLAY4",
    "category": "Continuous Integration",
    "calculated_at": "2025-05-07T12:49:25",
    "ai_confidence": 23.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.5,
    "ai_depth": 2.8,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve tagging and categorisation in a Hugo-based blog. While there is a brief mention of 'CI/CD' as an example tag, there are no direct or substantive discussions of Continuous Integration (CI) principles, practices, tools, or its role in software development workflows. The main themes revolve around content management, automation, and editorial oversight, not CI. The technical depth is centred on scripting, data architecture, and AI-human collaboration for classification, with no exploration of code integration, automated testing, or CI pipelines. The intent is to inform about AI-driven content classification, not CI. The audience is likely technical, but not specifically practitioners of CI. The signal-to-noise ratio is low for CI relevance, as nearly all content is off-topic for this category. No penalties were applied, as the content is not outdated or critical of CI, but the fit is very weak, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Scrum Values": {
    "resourceId": "oRStCAqLAY4",
    "category": "Scrum Values",
    "calculated_at": "2025-05-07T12:49:31",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.5,
    "ai_audience": 3.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. While the author briefly mentions their background, including experience with Scrum, and references 'values' as a high-level concept in their taxonomy, there are no direct or substantive discussions of the Scrum Values (Commitment, Courage, Focus, Openness, Respect) as defined in the Scrum Guide. The main focus is on technical architecture, automation, and editorial workflow, not on the principles or cultural aspects of Scrum. The intent is to inform about AI-driven classification, not to educate or reflect on Scrum Values. The audience is technical practitioners interested in automation and content management, not specifically Scrum teams or Agile practitioners. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is not outdated or critical of Scrum Values. Overall, the confidence that this content fits under 'Scrum Values' is very low.",
    "level": "Ignored"
  },
  "Lean Principles": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lean Principles",
    "calculated_at": "2025-05-07T12:49:37",
    "ai_confidence": 36.7,
    "ai_mentions": 0.6,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 4.1,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of Lean Principles, Lean thinking, waste reduction, Kaizen, or related Lean tools and concepts. The main focus is on automation, traceability, and human oversight in content management, not on minimising waste or maximising value through iterative process improvement as defined by Lean. While there are some tangential overlaps—such as the desire to reduce manual labour, improve efficiency, and ensure process transparency—these are not explicitly framed within Lean philosophy or terminology. The depth of discussion is high regarding technical implementation, but not in relation to Lean Principles. The intent is to inform technical practitioners about AI-driven classification, not to teach or discuss Lean. The audience is technical (developers, site maintainers), which could overlap with Lean practitioners, but the content is not tailored to those seeking Lean guidance. The signal-to-noise ratio is moderate: the content is focused, but not on Lean. No penalties were applied as the content is current and not critical of Lean. Overall, the confidence score is low, reflecting that the content does not substantively fit the Lean Principles category.",
    "level": "Ignored"
  },
  "Definition of Done": {
    "resourceId": "oRStCAqLAY4",
    "category": "Definition of Done",
    "calculated_at": "2025-05-07T12:49:45",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.0,
    "ai_depth": 1.2,
    "ai_intent": 0.8,
    "ai_audience": 2.0,
    "ai_signal": 1.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and PowerShell to automate and improve tagging and categorisation in a Hugo-based blog. There are no direct mentions of the Definition of Done (DoD), nor is there any discussion of its purpose, criteria, or role in Agile or Scrum. The main ideas revolve around content classification, automation, auditability, and human oversight in AI-driven workflows, which are unrelated to the DoD. The depth of discussion is substantial, but entirely focused on technical implementation and editorial processes, not on Agile artefacts or quality criteria. The intent is to inform practitioners about AI-powered content management, not to discuss or exemplify the DoD. The audience is technical, but not specifically Agile or Scrum practitioners interested in DoD. The signal-to-noise ratio is high for its actual topic, but nearly all content is off-topic for the Definition of Done category. No penalties were applied, as the content is current and not critical or satirical, but the confidence score is very low due to the lack of relevance.",
    "level": "Ignored"
  },
  "Estimation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Estimation",
    "calculated_at": "2025-05-07T12:49:50",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.1,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and scripting to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses classification, categorisation, and the use of AI for multi-factor scoring (including confidence, mentions, alignment, etc.), it does not directly address estimation in the Agile or Scrum context. There are no explicit mentions of estimation techniques, empirical forecasting, or collaborative estimation practices as defined in the Estimation category. The main themes are automation, content management, and responsible AI use, not estimation of work, effort, or forecasting in Agile. The audience is more aligned with technical practitioners interested in automation and AI-driven content management rather than Agile teams seeking to improve estimation. The signal-to-noise ratio is moderate, as the content is focused but not on the Estimation topic. No penalties were applied as the content is not outdated or contradictory, but the fit for the Estimation category is weak, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Service Level Expectation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Service Level Expectation",
    "calculated_at": "2025-05-07T12:49:57",
    "ai_confidence": 7.2,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 0.5,
    "ai_audience": 2.0,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. It focuses on the architecture, data structures, and human-in-the-loop validation for content classification. There is no direct mention of Service Level Expectation (SLE), nor any discussion of its definition, calculation, or application within Agile, Scrum, or Kanban frameworks. The main themes are automation, AI-human collaboration, and content management, which do not conceptually align with SLE. The audience is technical practitioners interested in AI-driven content workflows, not specifically those seeking guidance on SLE. The signal-to-noise ratio is low for the SLE category, as all discussion is off-topic with respect to SLE. No penalties were applied, as the content is not outdated or critical of SLE, but the confidence score is extremely low due to the complete lack of relevance.",
    "level": "Ignored"
  },
  "Test Automation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Test Automation",
    "calculated_at": "2025-05-07T12:50:03",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 4.0,
    "ai_signal": 3.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on automating the classification and tagging of blog posts using generative AI and PowerShell scripts, with a strong emphasis on human oversight, auditability, and technical architecture. While it discusses automation, the automation is applied to content management (tagging, categorisation) rather than software testing. There are no direct mentions of test automation, testing frameworks, or automated testing practices. The conceptual alignment is weak, as the main ideas revolve around AI-driven content classification, not automating software testing processes. The depth of discussion is substantial but entirely within the domain of content management automation, not test automation. The intent is to inform about automating editorial workflows, not testing. The audience is technical (developers, site maintainers), but not specifically test automation practitioners. The signal-to-noise ratio is moderate, as the content is focused but off-topic for test automation. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence score is low, reflecting that the content does not fit the 'Test Automation' category.",
    "level": "Ignored"
  },
  "Time to Market": {
    "resourceId": "oRStCAqLAY4",
    "category": "Time to Market",
    "calculated_at": "2025-05-07T12:50:10",
    "ai_confidence": 19.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 6.2,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of 'Time to Market' or its associated metrics (lead time, cycle time, development duration), nor is there discussion of strategies to reduce the time from idea to delivery in a business or product context. The main themes are content management, automation, AI-human collaboration, and technical architecture for classification. While there is a tangential connection in that automation can sometimes improve efficiency, the content does not frame this in terms of delivering value to customers faster or optimising organisational processes for speed. The audience is technical (blog owners, developers, automation enthusiasts), which partially overlaps with the Time to Market category, but the intent and depth are not aligned. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant topic. No penalties were applied as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Time to Market' is very low.",
    "level": "Ignored"
  },
  "Behaviour Driven Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Behaviour Driven Development",
    "calculated_at": "2025-05-07T12:50:16",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 2.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is a detailed discussion of technical architecture, data structures, and the integration of AI for classification, with an emphasis on human oversight and auditability. However, there are no direct mentions of Behaviour Driven Development (BDD), its principles, practices, or tools. The conceptual alignment is minimal, as the main ideas revolve around content management automation rather than aligning software development with business objectives through BDD. The depth of discussion is substantial for the topic of AI-driven classification, but not for BDD. The intent is to inform about AI-powered content classification, not BDD practices. The audience is technical (developers, site maintainers), which could overlap with BDD practitioners, but the content is not targeted at BDD-specific roles or concerns. The signal-to-noise ratio is moderate, as the content is focused but not on BDD. No penalties were applied, as the content is current and does not contradict the category. Overall, the confidence that this content fits under 'Behaviour Driven Development' is very low.",
    "level": "Ignored"
  },
  "Remote Working": {
    "resourceId": "oRStCAqLAY4",
    "category": "Remote Working",
    "calculated_at": "2025-05-07T12:50:21",
    "ai_confidence": 7.7,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.6,
    "ai_intent": 0.3,
    "ai_audience": 0.5,
    "ai_signal": 0.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of remote working, distributed teams, or Agile practices in a remote context. The main themes are automation, AI-human collaboration, and content management, which do not conceptually align with the Remote Working category. The depth of discussion is substantial, but it is focused entirely on technical implementation for personal content management, not on remote work challenges or solutions. The intent is to inform about AI-driven classification, not to address remote working issues. The audience is technical (blog owners, developers, automation enthusiasts), but not specifically remote Agile practitioners. The signal-to-noise ratio is high for its own topic, but almost entirely off-topic for Remote Working. No penalties were applied as the content is not outdated or contradictory, but the fit is extremely low, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Customer Satisfaction": {
    "resourceId": "oRStCAqLAY4",
    "category": "Customer Satisfaction",
    "calculated_at": "2025-05-07T12:50:27",
    "ai_confidence": 19.85,
    "ai_mentions": 0.3,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 5.1,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of customer satisfaction, customer experience, or related measurement techniques. The main focus is on improving editorial consistency, discoverability, and workflow efficiency for the author's own blog, not on understanding or enhancing customer happiness or aligning with product-market fit. While there is some mention of aligning categories with user needs and improving searchability, these are incidental and not explored in the context of customer satisfaction as defined in Agile, Lean, or DevOps frameworks. The depth of discussion is high for technical automation and classification, but not for customer satisfaction. The intent is technical and process-oriented, targeting content creators or technical practitioners rather than those focused on customer satisfaction strategies. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence that this content fits under 'Customer Satisfaction' is very low.",
    "level": "Ignored"
  },
  "Pragmatic Thinking": {
    "resourceId": "oRStCAqLAY4",
    "category": "Pragmatic Thinking",
    "calculated_at": "2025-05-07T12:50:34",
    "ai_confidence": 86.7,
    "ai_mentions": 3.7,
    "ai_alignment": 9.2,
    "ai_depth": 8.8,
    "ai_intent": 8.6,
    "ai_audience": 8.1,
    "ai_signal": 8.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 87.0,
    "reasoning": "The content provides a detailed, experience-driven account of applying generative AI and automation to a real-world content management problem, with a strong emphasis on practical problem-solving, adaptability, and critical thinking. It describes the evolution of the author's workflow, the technical and architectural decisions made, and the iterative refinement of the classification system, all of which are hallmarks of pragmatic thinking. The discussion is deeply rooted in actual implementation (PowerShell scripting, OpenAI integration, audit trails, penalty logic), and the author repeatedly stresses the importance of human oversight, accountability, and explainability—directly aligning with the category's focus on real-world application and evidence-based management. While the term 'pragmatic thinking' is not explicitly mentioned (hence a lower 'mentions' score), the conceptual alignment, depth, and intent are very strong, as the content is clearly written for practitioners and technical leaders seeking actionable strategies. The audience is well-matched, and the content is focused with minimal off-topic material. No penalties were applied, as the content is current, constructive, and fully consistent with the category's framing. The final confidence score reflects the high degree of fit, with only a modest deduction for the lack of direct category naming.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the category, as it offers a hands-on account of using generative AI and automation to solve real-world challenges. It highlights practical decision-making, technical implementation, and the importance of human oversight, making it highly relevant for practitioners seeking actionable, evidence-based strategies. The focus and depth align well with the category, even though the exact term isn’t explicitly used."
  },
  "Software Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Software Development",
    "calculated_at": "2025-05-07T12:50:43",
    "ai_confidence": 91.7,
    "ai_mentions": 8.6,
    "ai_alignment": 9.5,
    "ai_depth": 9.2,
    "ai_intent": 9.0,
    "ai_audience": 8.7,
    "ai_signal": 8.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content is a detailed technical case study describing the use of generative AI and PowerShell scripting to automate and improve the tagging and categorisation of blog posts in Hugo. It directly references software development practices such as scripting, automation, version control (GitHub, PRs), and technical architecture, aligning closely with the Software Development category. The discussion is conceptually deep, covering the rationale, data architecture, technical implementation, and validation strategies, including audit trails and penalty logic for quality assurance. The intent is clearly to inform and guide practitioners on building robust, auditable automation systems for content management, which is a relevant software engineering concern. The audience is technical, targeting developers, DevOps practitioners, and those interested in software automation and best practices. The signal-to-noise ratio is high, with minimal digression and a strong focus on process, methodology, and technical detail. No penalties are warranted, as the content is current, methodologically sound, and not satirical or critical of the category. The final confidence score reflects the strong, multi-dimensional fit with the Software Development category.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the Software Development category. It thoroughly explores how generative AI and PowerShell scripting can automate blog post tagging in Hugo, referencing key software practices like automation, version control, and technical architecture. The technical depth and focus on implementation make it highly relevant for developers and those interested in software automation."
  },
  "Continuous Delivery": {
    "resourceId": "oRStCAqLAY4",
    "category": "Continuous Delivery",
    "calculated_at": "2025-05-07T12:50:49",
    "ai_confidence": 23.85,
    "ai_mentions": 1.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.1,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo-based static site. While there is a brief mention of 'CI/CD' as an example tag, there are no direct or substantive references to Continuous Delivery as a practice, nor are its principles, automation in deployment, or delivery cycles discussed. The main themes are content management, classification, and AI-assisted editorial workflows, not software delivery pipelines or release practices. The depth of discussion is technical but unrelated to Continuous Delivery, and the intended audience is more aligned with content managers or technical bloggers rather than practitioners of Continuous Delivery. The signal-to-noise ratio is low for this category, as nearly all content is off-topic. No penalties were applied, as the content is not outdated or critical of Continuous Delivery, but the overall confidence is very low due to minimal relevance.",
    "level": "Ignored"
  },
  "Company as a Product": {
    "resourceId": "oRStCAqLAY4",
    "category": "Company as a Product",
    "calculated_at": "2025-05-07T12:50:56",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.2,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and scripting to automate and improve tagging and categorisation for a personal blog. There is no direct mention of 'Company as a Product' or any of its core terminology. The main focus is on content management, automation, and human-in-the-loop AI oversight for editorial consistency, not on treating an organisation as a product or aligning organisational strategy with customer value. While there are some tangential overlaps—such as continuous improvement, traceability, and outcome measurement—these are applied to content classification, not to organisational design or strategy. The audience is technical practitioners interested in automation and AI for content management, not executives or strategists considering CaaP. The signal-to-noise ratio is moderate, as the content is focused but not on the CaaP topic. No penalties were applied, as the content is current and not critical of the CaaP framing. Overall, the confidence that this content fits under 'Company as a Product' is very low.",
    "level": "Ignored"
  },
  "Agile Values and Principles": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Values and Principles",
    "calculated_at": "2025-05-07T12:51:02",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of Agile Values or Principles, nor is there any discussion of the Agile Manifesto, its core values, or the twelve principles. The main themes are automation, human oversight, explainability, and technical architecture for content management. While the author briefly references their background in DevOps and Scrum, these are only mentioned in passing as part of their career history and not in the context of Agile philosophy. The closest conceptual overlap is the emphasis on human accountability and transparency, which are tangentially related to Agile's focus on people and collaboration, but this is not explored in an Agile context. The intent is to inform technical practitioners about AI-driven classification, not to educate or reflect on Agile values. The audience is technical, but not specifically Agile-focused. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied, as the content is current and not critical of Agile. Overall, the content does not fit the 'Agile Values and Principles' category, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Market Adaptability": {
    "resourceId": "oRStCAqLAY4",
    "category": "Market Adaptability",
    "calculated_at": "2025-05-07T12:51:08",
    "ai_confidence": 38.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 4.1,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate and improve tagging and categorisation in a personal blog using Hugo. There is a strong focus on automation, auditability, and human oversight in content management. However, there are almost no direct mentions of 'market adaptability' or its core concepts. The main ideas revolve around content discoverability, editorial consistency, and technical implementation of classification systems, not strategies for organisational agility or responding to market shifts. While the author references their background in DevOps and Scrum, these are only mentioned in passing as part of their career history, not as frameworks for market adaptability. The depth of discussion is high for technical automation and AI-human collaboration, but not for market adaptability. The intent is to inform technical practitioners about AI-driven content management, not to address business agility or market responsiveness. The audience is technical (bloggers, developers, automation enthusiasts), which only partially overlaps with the typical audience for market adaptability (business strategists, organisational leaders). The signal-to-noise ratio is good for its actual topic, but low for the evaluated category. No penalties were applied, as the content is current and not critical of the category. Overall, the content does not fit well under 'Market Adaptability', resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Agile Product Operating Model": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Product Operating Model",
    "calculated_at": "2025-05-07T12:51:15",
    "ai_confidence": 18.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 5.2,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripting to automate and improve tagging and categorisation of blog posts in Hugo. While it discusses concepts such as classification, automation, human oversight, and technical architecture, there are no direct mentions or explicit references to the Agile Product Operating Model (APOM) or its core principles. The main themes revolve around content management, AI-assisted workflows, and editorial control, rather than transitioning from project to product ethos, integrating agile and product management, or organisational transformation as described in the APOM definition. The depth of discussion is substantial for the technical solution presented, but it does not explore APOM topics such as business/technology roadmaps, operational governance, or evidence-based management. The intent is to inform about a technical implementation for content classification, not to educate or guide on APOM. The audience is likely technical practitioners interested in automation and AI for content management, which only partially overlaps with the APOM audience. The signal-to-noise ratio is moderate, as the content is focused but not on the APOM category. No penalties were applied, as the content is current and not critical of APOM. Overall, the confidence that this content fits under the 'Agile Product Operating Model' category is very low.",
    "level": "Ignored"
  },
  "Product Discovery": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Discovery",
    "calculated_at": "2025-05-07T12:51:19",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.1,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study on automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site. There are no direct mentions of 'Product Discovery' or its core concepts. The main focus is on technical implementation, automation, and editorial workflow improvements, not on methodologies for understanding customer needs, validating product ideas, or defining product features. While there is some discussion of aligning tags and categories with user needs and improving discoverability, these are tangential and not explored in the context of product discovery practices. The depth of discussion is technical and operational, not strategic or discovery-oriented. The intended audience is technical practitioners interested in automation and content management, not product managers or discovery teams. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Product Discovery' is very low.",
    "level": "Ignored"
  },
  "Entrepreneurship": {
    "resourceId": "oRStCAqLAY4",
    "category": "Entrepreneurship",
    "calculated_at": "2025-05-07T12:51:25",
    "ai_confidence": 23.7,
    "ai_mentions": 0.4,
    "ai_alignment": 2.2,
    "ai_depth": 2.7,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of entrepreneurship, nor are entrepreneurial concepts such as innovation in business, risk-taking, value creation, or the entrepreneurial mindset discussed. The main focus is on technical implementation, workflow automation, and editorial control, not on starting or scaling ventures, business model innovation, or entrepreneurial ecosystems. The audience is primarily technical practitioners or content managers, not entrepreneurs or those interested in entrepreneurial strategy. While there is some mention of innovation in the sense of using new technology, it is strictly within the context of content management, not business creation or entrepreneurial practice. The signal-to-noise ratio is moderate, as the content is focused but not on the entrepreneurship category. No penalties were applied as the content is current and not satirical or critical of entrepreneurship. Overall, the confidence that this content fits under 'Entrepreneurship' is very low.",
    "level": "Ignored"
  },
  "Hypothesis Driven Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Hypothesis Driven Development",
    "calculated_at": "2025-05-07T12:51:30",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 8.0,
    "ai_signal": 6.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate and improve tagging and categorisation in a Hugo-based blog. It thoroughly discusses the architecture, data structures, and human-in-the-loop validation for classification, with a strong focus on transparency, auditability, and editorial control. However, there are no direct mentions of Hypothesis Driven Development, nor are there explicit references to formulating, testing, or validating hypotheses as a core product development practice. The main themes are automation, AI-assisted classification, and editorial process improvement, not experimentation or validated learning. While there is some conceptual overlap in the use of metrics, penalty logic, and iterative improvement, these are not framed as hypothesis-driven experiments but rather as deterministic validation and quality control. The audience (technical practitioners, site owners) is somewhat aligned, and the content is highly focused, but the lack of direct or substantial discussion of hypothesis-driven development principles results in a low confidence score for this category.",
    "level": "Ignored"
  },
  "Digital Transformation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Digital Transformation",
    "calculated_at": "2025-05-07T12:51:37",
    "ai_confidence": 67.6,
    "ai_mentions": 2.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.0,
    "ai_audience": 7.3,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content describes the use of generative AI and automation to overhaul and optimise the tagging and categorisation system of a personal blog, with a strong emphasis on technical architecture, process transparency, and human oversight. While the term 'digital transformation' is not directly mentioned, the project embodies several core aspects of the category: strategic adoption of digital tools (AI, scripting, automation), process innovation (automated classification, audit trails), and operational efficiency (reducing manual labour, improving discoverability). The discussion is conceptually aligned with digital transformation principles, especially in its focus on blending automation with human accountability and traceability. However, the context is limited to a personal content management workflow rather than an organisational or enterprise-wide transformation, which slightly reduces the depth and intent fit. The audience is likely technical practitioners or content strategists interested in automation and AI, which is adjacent to but not fully overlapping with the typical executive or business strategist audience for digital transformation. The content is focused and relevant, with minimal off-topic material, but the lack of explicit discussion about broader business agility, organisational change, or enterprise-level strategy keeps the confidence moderate. No penalties were applied, as the content is current, constructive, and not satirical or critical. Overall, the content is a strong example of digital transformation at a micro (individual) scale, but does not fully address the category's broader, strategic business context.",
    "level": "Secondary"
  },
  "Shift Left Strategy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Shift Left Strategy",
    "calculated_at": "2025-05-07T12:51:43",
    "ai_confidence": 18.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 6.2,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve blog post tagging and categorisation in Hugo, with an emphasis on human oversight and transparent audit trails. There are no direct mentions of the Shift-Left Strategy, nor is there any discussion of integrating testing, security, or compliance earlier in the software development lifecycle. The main themes revolve around content management, automation, and responsible AI use in editorial workflows, which do not conceptually align with the core meaning of Shift-Left. The depth of discussion is substantial but entirely focused on classification architecture, technical scripting, and AI-human collaboration for content curation, not software development process improvement. The intent is to inform about a technical solution for content management, not to advocate or explain Shift-Left practices. The audience is technical (developers, site maintainers), which partially overlaps with the Shift-Left audience, but the subject matter is not relevant to software quality or delivery speed. The signal-to-noise ratio is moderate, as the content is focused but off-topic for Shift-Left. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Shift Left Strategy' is very low.",
    "level": "Ignored"
  },
  "Azure Repos": {
    "resourceId": "oRStCAqLAY4",
    "category": "Azure Repos",
    "calculated_at": "2025-05-07T12:51:47",
    "ai_confidence": 2.7,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.3,
    "ai_intent": 0.5,
    "ai_audience": 2.0,
    "ai_signal": 0.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There is a single, brief mention of GitHub for code versioning, branching, and PRs, but no mention of Azure Repos or any of its specific features, integrations, or best practices. The main themes are automation, AI-assisted classification, and content management, not source control or Azure Repos. The audience is technical, but the focus is on content management and AI, not on Azure Repos users or practitioners. The signal-to-noise ratio for Azure Repos is extremely low, as nearly all content is off-topic for the category. No penalties were applied, as the content is not outdated or critical of Azure Repos. The very low confidence score reflects the near-total lack of relevance to Azure Repos.",
    "level": "Ignored"
  },
  "Team Collaboration": {
    "resourceId": "oRStCAqLAY4",
    "category": "Team Collaboration",
    "calculated_at": "2025-05-07T12:51:55",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of team collaboration, Agile, Scrum, or DevOps frameworks, nor are there discussions of team dynamics, communication, or shared ownership. The main focus is on individual workflow automation, technical architecture, and content management, not on improving or analysing teamwork. While the author references their own journey from web developer to process consultant, this is biographical and not about team practices. The audience is likely technical practitioners interested in automation and content management, which only partially overlaps with the Team Collaboration category. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant category. No penalties were applied, as the content is current and not critical of the category. Overall, the content does not align with the core meaning or intent of Team Collaboration, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Agile Product Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Product Management",
    "calculated_at": "2025-05-07T12:51:59",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. While it references the author's background in DevOps and Scrum, and briefly mentions 'Product Development' and 'Scrum' as example categories, there are no direct or sustained discussions of Agile Product Management principles, roles (such as Product Owner), backlog prioritisation, stakeholder engagement, or the application of Agile methodologies to product management. The main focus is on technical automation, data architecture, and the integration of AI for content classification, not on maximising product value or aligning product vision with customer needs in an Agile context. The audience is primarily technical practitioners interested in automation and content management, not Agile product managers or strategists. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is current and not critical of Agile Product Management. Overall, the confidence score is low, reflecting only a tangential and incidental connection to the category.",
    "level": "Ignored"
  },
  "Large Scale Agility": {
    "resourceId": "oRStCAqLAY4",
    "category": "Large Scale Agility",
    "calculated_at": "2025-05-07T12:52:05",
    "ai_confidence": 23.85,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.1,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts within a personal Hugo site. There is a detailed discussion of technical architecture, data structures, and the integration of AI for content classification, with an emphasis on human oversight and auditability. However, there are no direct mentions or references to large scale agility, nor to any frameworks or strategies for scaling Agile methodologies across an organisation. The main ideas and themes are centred on individual content management, automation, and editorial consistency, not on enterprise-level Agile transformation, cross-team collaboration, or alignment of business goals with Agile practices. The depth of discussion is substantial, but it is entirely focused on the technical implementation for a single-user blog, not on scaling Agile across multiple teams or organisational structures. The intended audience appears to be technical practitioners interested in automation and AI for content management, not executives or strategists involved in large scale Agile initiatives. The signal-to-noise ratio is high for its actual topic, but almost none of the content is relevant to large scale agility. Therefore, the confidence score is very low, reflecting the lack of conceptual and practical alignment with the category.",
    "level": "Ignored"
  },
  "Engineering Practices": {
    "resourceId": "oRStCAqLAY4",
    "category": "Engineering Practices",
    "calculated_at": "2025-05-07T12:52:15",
    "ai_confidence": 67.7,
    "ai_mentions": 3.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.0,
    "ai_audience": 7.5,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content provides a detailed technical walkthrough of automating blog post tagging and categorisation using generative AI and PowerShell scripts, with a strong emphasis on auditability, human oversight, and transparent reasoning. There are direct but infrequent mentions of engineering practices such as automation, scripting, version control, and validation logic, which are relevant to the category. The conceptual alignment is solid, as the post discusses automation, traceability, and the blending of AI with deterministic, human-driven validation—principles that resonate with high-quality software engineering practices. The depth is notable, with thorough explanations of the technical architecture, data structures, and process flows, though the focus is more on content management automation than on core Agile engineering practices like TDD, CI/CD, or refactoring. The intent is to inform and guide practitioners on building robust, auditable automation systems, which fits the category's audience, though the primary context is content management rather than software product development. The audience alignment is strong, targeting technically proficient readers interested in automation and process improvement. The signal-to-noise ratio is high, with minimal digression, but the content is somewhat tangential to the strictest definition of 'Engineering Practices' as it applies more to content operations than to software engineering per se. No penalties were applied, as the content is current, constructive, and not critical of the category. Overall, the confidence score reflects that while the post embodies many engineering practice principles (automation, validation, version control, human-in-the-loop), its primary domain is content management automation rather than the core Agile engineering practices outlined in the category definition.",
    "level": "Secondary"
  },
  "Customer Feedback Loops": {
    "resourceId": "oRStCAqLAY4",
    "category": "Customer Feedback Loops",
    "calculated_at": "2025-05-07T12:52:20",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.5,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate tagging and categorisation of blog posts in Hugo. There are no direct mentions of customer feedback loops, nor is there any discussion of mechanisms for collecting, analysing, or integrating customer feedback into product development. The main focus is on internal content management, automation, and editorial consistency, not on gathering or acting upon user or customer input. While the system includes human oversight and validation, this is for quality control of AI-generated classifications, not for incorporating external feedback. The audience is technical (blog owners, developers, automation enthusiasts), which partially overlaps with the category's potential audience, but the subject matter is not aligned. The signal-to-noise ratio is moderate, as the content is focused but off-topic for customer feedback loops. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence that this content fits under 'Customer Feedback Loops' is very low.",
    "level": "Ignored"
  },
  "Troubleshooting": {
    "resourceId": "oRStCAqLAY4",
    "category": "Troubleshooting",
    "calculated_at": "2025-05-07T12:52:26",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 4.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content primarily describes the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses technical architecture, automation, and the integration of AI for classification, it does not focus on the identification or resolution of technical issues, nor does it provide methodologies or case studies for diagnosing and solving problems. There are no direct mentions of troubleshooting, nor are there discussions of systematic problem-solving in the context of resolving failures or bugs. The main intent is to share a workflow and technical strategy for content management, not troubleshooting. The audience is technical, but the content is not aimed at practitioners seeking troubleshooting guidance. The signal-to-noise ratio is moderate, as the content is focused but not on the troubleshooting domain. Therefore, the confidence that this content fits under the 'Troubleshooting' category is low.",
    "level": "Ignored"
  },
  "Agile Leadership": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Leadership",
    "calculated_at": "2025-05-07T12:52:33",
    "ai_confidence": 18.7,
    "ai_mentions": 0.3,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.1,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study on automating blog post tagging and categorisation using generative AI and PowerShell scripts, with a strong emphasis on human oversight and auditability. There are no direct mentions of Agile Leadership or its key concepts such as facilitating organisational change, servant leadership, or fostering Agile culture. The main ideas revolve around content management, automation, and responsible AI use, not leadership in Agile contexts. While the author briefly references their background in DevOps and Scrum, these are incidental and not explored in relation to leadership or Agile transformation. The depth of discussion is technical, focusing on architecture, scripting, and validation logic, rather than leadership strategies or team empowerment. The intent is to inform technical practitioners about automating classification, not to guide Agile leaders. The audience is primarily technical (developers, site owners, automation enthusiasts), not Agile leaders or organisational change agents. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied, as the content is current and not critical of Agile Leadership. Overall, the content does not fit the Agile Leadership category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Revenue per Employee": {
    "resourceId": "oRStCAqLAY4",
    "category": "Revenue per Employee",
    "calculated_at": "2025-05-07T12:52:44",
    "ai_confidence": 7.6,
    "ai_mentions": 0.0,
    "ai_alignment": 0.2,
    "ai_depth": 0.1,
    "ai_intent": 0.2,
    "ai_audience": 0.5,
    "ai_signal": 0.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of 'Revenue per Employee' or any related financial observability metrics. The main themes are automation, classification, technical architecture, and editorial workflow, which do not conceptually align with the category. There is no discussion of workforce efficiency, organisational throughput, or financial performance metrics. The intent is to inform about AI-driven content management, not to analyse or interpret Revenue per Employee. The audience is technical (bloggers, developers, content managers), not financial or executive. The signal-to-noise ratio is high for its actual topic, but entirely off-topic for 'Revenue per Employee.' No penalties were applied as the content is current and not satirical or critical of the category. The extremely low confidence score reflects the complete lack of relevance to the specified category.",
    "level": "Ignored"
  },
  "Trend Analysis": {
    "resourceId": "oRStCAqLAY4",
    "category": "Trend Analysis",
    "calculated_at": "2025-05-07T12:52:50",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.8,
    "ai_intent": 2.9,
    "ai_audience": 4.1,
    "ai_signal": 3.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study about automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo site. It focuses on the architecture, data structures, and human-in-the-loop validation for classification, with strong emphasis on transparency, auditability, and editorial control. However, there are almost no direct mentions of 'trend analysis' or explicit discussion of identifying patterns or shifts within Agile, DevOps, or business agility frameworks. The main ideas revolve around content management, automation, and responsible AI use, not the analysis of trends or their strategic implications. While the author references their background in DevOps and Scrum, these are context for the taxonomy, not for trend analysis. The future enhancements section briefly mentions tracking classification shifts over time and building dashboards showing confidence trends, but these are prospective and not explored in depth. The audience is technical (developers, site maintainers), which partially overlaps with the trend analysis category, but the content is not aimed at strategists or decision-makers interested in organisational trends. The signal-to-noise ratio is moderate: the content is focused, but not on trend analysis. Overall, the content does not fit the 'Trend Analysis' category beyond a superficial, tangential connection.",
    "level": "Ignored"
  },
  "Azure Pipelines": {
    "resourceId": "oRStCAqLAY4",
    "category": "Azure Pipelines",
    "calculated_at": "2025-05-07T12:52:58",
    "ai_confidence": 7.2,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.4,
    "ai_intent": 0.3,
    "ai_audience": 0.8,
    "ai_signal": 0.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and PowerShell scripts to automate tagging and categorisation in a Hugo-based blog. While it references concepts like CI/CD and Azure Pipelines in passing (e.g., as a tag example), there is no substantive discussion of Azure Pipelines, its configuration, or its role in DevOps automation. The main focus is on content management, AI-driven classification, and workflow automation within a static site generator context. There are no direct or repeated mentions of Azure Pipelines beyond a single example in a list of tags, and no exploration of its features, best practices, or audience needs. The audience is technical, but the subject matter is not aligned with Azure Pipelines. The signal-to-noise ratio is low for this category, as nearly all content is off-topic. No penalties were applied, as the content is not outdated or critical of Azure Pipelines; it is simply unrelated. The extremely low confidence score reflects the near-total lack of relevance to the Azure Pipelines category.",
    "level": "Ignored"
  },
  "Change Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Change Management",
    "calculated_at": "2025-05-07T12:53:03",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 4.2,
    "ai_depth": 4.5,
    "ai_intent": 3.8,
    "ai_audience": 5.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There is a strong focus on automation, data architecture, and the blend of AI and human oversight for editorial control. While the post discusses change in the context of content management (e.g., restructuring categories, improving discoverability, and introducing new classification layers), it does not directly address organisational change management principles, strategies, or practices as defined in the category. There are no explicit mentions of 'change management' or its core concepts such as stakeholder engagement, resistance management, leadership in transformation, or alignment with organisational values. The main intent is technical enablement and workflow optimisation for a personal blog, not facilitating meaningful, sustainable organisational change. The audience is primarily technical practitioners interested in automation and AI-driven content management, not change leaders or strategists. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is current and not critical or satirical. Overall, the content only tangentially relates to change management in the sense of process improvement and automation, but lacks the depth, alignment, and intent required for a high confidence score in this category.",
    "level": "Ignored"
  },
  "Asynchronous Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Asynchronous Development",
    "calculated_at": "2025-05-07T12:53:08",
    "ai_confidence": 19.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 6.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of asynchronous development, nor are its principles, practices, or challenges discussed. The main focus is on automation, AI-human collaboration, and content management workflows, not on distributed or asynchronous team practices. While the technical audience overlaps somewhat with those interested in asynchronous development, the content does not address remote collaboration, time zone management, or asynchronous methodologies. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. Overall, the content does not fit the 'Asynchronous Development' category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Lead Time": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lead Time",
    "calculated_at": "2025-05-07T12:53:14",
    "ai_confidence": 7.6,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.6,
    "ai_intent": 0.7,
    "ai_audience": 1.0,
    "ai_signal": 0.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve blog post tagging and categorisation in Hugo, with an emphasis on human oversight and auditability. There are no direct mentions of 'Lead Time' as a metric, nor is there any discussion of the time from work initiation to delivery, process efficiency, or observability metrics. The main themes are content management, classification systems, and the technical architecture for automating these processes. While there is some discussion of workflow automation and efficiency, these are not framed in terms of Lead Time or its measurement. The audience is technical, but the content is not aligned with the Lead Time category's definition or key topics. The signal-to-noise ratio is high for its actual topic, but not for Lead Time. Therefore, the confidence that this content fits under the 'Lead Time' category is extremely low.",
    "level": "Ignored"
  },
  "Install and Configuration": {
    "resourceId": "oRStCAqLAY4",
    "category": "Install and Configuration",
    "calculated_at": "2025-05-07T12:53:19",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 5.0,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content primarily focuses on the use of generative AI and PowerShell scripting to automate and improve the tagging and categorisation of blog posts in Hugo. While there are technical details about the architecture, scripting, and data structures, the main thrust is on classification, automation, and editorial workflow rather than on the installation or configuration of tools, software, or platforms. There are no explicit step-by-step installation guides, configuration best practices, or troubleshooting of install/config issues. The technical audience overlap is moderate, as the content is aimed at practitioners interested in automation and scripting, but not specifically those seeking install/config guidance. The signal-to-noise ratio is fair, with some relevant technical detail, but most of the discussion is about process, strategy, and the philosophy of AI-assisted classification. There are only passing references to setting up scripts or using Hugo, but these are not explored in the context of installation or configuration. Therefore, the confidence that this content fits under 'Install and Configuration' is low.",
    "level": "Ignored"
  },
  "Automated Testing": {
    "resourceId": "oRStCAqLAY4",
    "category": "Automated Testing",
    "calculated_at": "2025-05-07T12:53:28",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 3.9,
    "ai_intent": 3.5,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on using generative AI and PowerShell scripts to automate the tagging and categorisation of blog posts in Hugo. While there is significant discussion of automation, scripting, and the use of AI for classification, there are no direct mentions or substantial exploration of automated testing principles, practices, or methodologies as defined by the category. The main ideas revolve around content management automation, not software testing. There is some conceptual overlap in the use of automation, validation, and audit trails, but these are applied to content classification rather than testing software quality or reliability. The technical depth is strong for the described use case, but it does not extend to automated testing frameworks, test types, or CI/CD testing practices. The intended audience is technical, but not specifically practitioners of automated testing. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting only tangential relevance to 'Automated Testing.'",
    "level": "Ignored"
  },
  "Product Delivery": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Delivery",
    "calculated_at": "2025-05-07T12:53:34",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.2,
    "ai_audience": 4.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content is a detailed technical narrative about automating blog post tagging and categorisation using generative AI and PowerShell within a Hugo static site. Direct mentions of 'Product Delivery' or its core terminology are absent, resulting in a low 'mentions' score. Conceptual alignment is limited: while the post discusses automation, classification, and workflow improvements, these are focused on content management and site taxonomy, not on the end-to-end delivery of software products to customers. There is no substantive discussion of agile methodologies, iterative development, deployment, release management, or cross-functional teams as defined in the Product Delivery category. The depth of discussion is high for the topic of AI-driven classification and technical scripting, but not for product delivery practices. The intent is to inform about a technical solution for content management, not to address product delivery methodologies or best practices. The audience is technical (developers, site maintainers), but not specifically those concerned with product delivery processes. The signal-to-noise ratio is moderate: the content is focused, but its focus is not on product delivery. No penalties were applied, as the content is current and does not contradict the category. Overall, the confidence score is low, reflecting that while the post is technically deep and process-oriented, it does not fit the core meaning or scope of the Product Delivery category.",
    "level": "Tertiary"
  },
  "Definition of Ready": {
    "resourceId": "oRStCAqLAY4",
    "category": "Definition of Ready",
    "calculated_at": "2025-05-07T12:53:39",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.0,
    "ai_depth": 1.2,
    "ai_intent": 0.8,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There are no direct mentions of the Definition of Ready (DoR), nor is there any discussion of DoR criteria, its role in Agile, or related practices. The main focus is on information architecture (tags, categories, concepts), automation, auditability, and human oversight in content classification. While the content does discuss the importance of clarity, traceability, and editorial standards in classification, these are not framed in the context of backlog item readiness or Agile sprint planning. The audience is technical practitioners, which partially overlaps with the DoR category, but the intent and substance are not aligned. The signal-to-noise ratio is moderate, as the content is focused but off-topic for DoR. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence that this content fits under 'Definition of Ready' is very low.",
    "level": "Ignored"
  },
  "Organisational Agility": {
    "resourceId": "oRStCAqLAY4",
    "category": "Organisational Agility",
    "calculated_at": "2025-05-07T12:53:45",
    "ai_confidence": 41.7,
    "ai_mentions": 0.7,
    "ai_alignment": 4.2,
    "ai_depth": 4.8,
    "ai_intent": 3.9,
    "ai_audience": 5.2,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content is a detailed technical case study of using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There is a strong focus on automation, data architecture, technical scripting, and the integration of AI with human oversight for editorial control. While the post discusses concepts such as adaptability, continuous improvement, and the blending of automation with human judgment, these are framed in the context of personal content management rather than organisational strategy or agility. There are no direct mentions of 'Organisational Agility' or explicit references to agile methodologies, leadership, or organisational structures. The main ideas and depth are technical and operational, not strategic or cultural as required by the category. The intent is to inform technical practitioners or bloggers about automating classification, not to guide organisations in becoming more agile. The audience is more technical than executive or organisational, and the signal-to-noise ratio is moderate, with most content focused on implementation details rather than agility principles. No penalties were applied as the content is current and not critical of agility, but overall, the fit with 'Organisational Agility' is weak, resulting in a low confidence score.",
    "level": "Tertiary"
  },
  "Test First Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Test First Development",
    "calculated_at": "2025-05-07T12:53:50",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.5,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of Test First Development, nor are its principles, practices, or key topics discussed. The main focus is on classification, automation, human oversight, and auditability in content management, not on defining success criteria before implementation or on testing practices (manual or automated). The only tangential overlap is the mention of 'penalty and validation rules' and 'deterministic enforcement,' which are generic quality control mechanisms, not Test First practices. The audience is technical, but the subject matter is not aligned with Test First Development. The signal-to-noise ratio is moderate, as the content is focused but off-topic for this category. No penalties were applied, as the content is not outdated or critical of the category. Overall, the confidence score is very low, reflecting the lack of relevance to Test First Development.",
    "level": "Ignored"
  },
  "Social Technologies": {
    "resourceId": "oRStCAqLAY4",
    "category": "Social Technologies",
    "calculated_at": "2025-05-07T12:53:57",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.2,
    "ai_audience": 5.0,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily details the technical and architectural process of automating blog post tagging and categorisation using generative AI and PowerShell scripts. While there are some conceptual overlaps with Social Technologies—such as the emphasis on transparency, traceability, and the blend of AI suggestions with human oversight—these are not the main focus. The content does not directly discuss frameworks or methodologies that promote collaboration, collective intelligence, or self-organisation within teams or organisations. There is no explicit mention of Social Technologies or their key topics (e.g., team dynamics, emergent problem-solving, or organisational culture). The audience is likely technical practitioners interested in automation and content management, which only partially overlaps with the Social Technologies category. The discussion of human vs. AI agency and the importance of accountability does touch on relevant themes, but the depth and intent are more technical and process-oriented than socially transformative. The signal-to-noise ratio is moderate, as most content is focused on technical implementation rather than social frameworks. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score reflects that while there are some tangential connections, the content does not substantially fit under Social Technologies.",
    "level": "Tertiary"
  },
  "Flow Efficiency": {
    "resourceId": "oRStCAqLAY4",
    "category": "Flow Efficiency",
    "calculated_at": "2025-05-07T12:54:03",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 7.1,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts, with an emphasis on human oversight and auditability. There are no direct mentions of 'Flow Efficiency' or its key concepts such as value stream throughput, bottleneck elimination, WIP limits, or Lean/Agile flow metrics. The main ideas revolve around information architecture, technical implementation, and responsible AI use in content management, which are not conceptually aligned with the optimisation of work throughput or flow efficiency. The depth of discussion is substantial regarding classification automation and technical strategy, but not in relation to flow efficiency. The intent is to inform about AI-driven classification, not to address flow efficiency. The audience (technical practitioners, site owners) partially overlaps with those interested in flow efficiency, but the content is not targeted at Lean/Agile or DevOps process optimisation. The signal-to-noise ratio is high for its actual topic, but almost none of the content is relevant to flow efficiency. No penalties were applied as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Flow Efficiency' is very low.",
    "level": "Ignored"
  },
  "Deployment Frequency": {
    "resourceId": "oRStCAqLAY4",
    "category": "Deployment Frequency",
    "calculated_at": "2025-05-07T12:54:08",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of deployment frequency, nor are there discussions about optimising software deployment intervals, CI/CD, or Agile/DevOps release practices. The main themes are content management, classification, automation, and human oversight in editorial workflows. While there are tangential references to DevOps and process consulting in the author's background, these are not explored in the context of deployment frequency. The audience is technical, but the subject matter is not aligned with the deployment frequency category. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant topic. No penalties were applied, as the content is not outdated or critical of the category. Overall, the confidence score is very low, reflecting the lack of relevance to Deployment Frequency.",
    "level": "Ignored"
  },
  "Scaling": {
    "resourceId": "oRStCAqLAY4",
    "category": "Scaling",
    "calculated_at": "2025-05-07T12:54:14",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 5.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo-based static site. There is no direct mention of scaling frameworks (e.g., SAFe, LeSS, Nexus), nor are there discussions about coordinating multiple teams, cross-team collaboration, or enterprise-level alignment. The main themes are technical automation, editorial consistency, and human-AI collaboration for content management, which are unrelated to the complexities of scaling Agile practices. The depth of discussion is substantial for its own topic (content classification automation), but not for scaling as defined. The intent is to inform practitioners about AI-driven content management, not to address scaling challenges. The audience is technical (developers, site maintainers), which partially overlaps with scaling audiences, but the focus is not on enterprise or multi-team coordination. The signal-to-noise ratio is moderate, as the content is focused but not on the scaling category. No penalties were applied as the content is current and not critical of the scaling category. Overall, the confidence that this content fits under 'Scaling' is very low.",
    "level": "Ignored"
  },
  "Artificial Intelligence": {
    "resourceId": "oRStCAqLAY4",
    "category": "Artificial Intelligence",
    "calculated_at": "2025-05-07T12:54:23",
    "ai_confidence": 91.7,
    "ai_mentions": 8.7,
    "ai_alignment": 9.6,
    "ai_depth": 9.3,
    "ai_intent": 9.2,
    "ai_audience": 8.8,
    "ai_signal": 9.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content directly and repeatedly references Artificial Intelligence (AI), specifically generative AI and OpenAI, as the core technology enabling the transformation of site tagging and categorisation. The main theme is the integration of AI into a software development workflow (Hugo static site generator, PowerShell scripting), with a strong focus on automation, human oversight, and transparent audit trails. The discussion is highly aligned with the category definition: it explores how AI is used to automate and improve content classification, describes technical architecture, and details the blend of AI-driven suggestions with human validation. The depth is substantial, covering architectural decisions, data structures, validation logic, and future enhancements, all within the context of AI's role in software process improvement. The intent is clearly to inform practitioners about responsible, effective AI integration in a technical workflow, matching the category's purpose. The audience is technical (developers, DevOps, process consultants), which fits the category's target. The signal-to-noise ratio is high, with nearly all content focused on the application of AI in this context. No penalties are warranted: the content is current, constructive, and does not contradict the category's framing. Overall, the confidence score is very high due to the explicit, in-depth, and relevant discussion of AI's application in software development processes.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the category, as it thoroughly explores how AI—specifically generative models—enhances content classification within a technical workflow. It details the integration of AI with development tools, highlights automation balanced by human oversight, and is clearly aimed at a technical audience, making it highly relevant and informative for practitioners in this space."
  },
  "Value Stream Mapping": {
    "resourceId": "oRStCAqLAY4",
    "category": "Value Stream Mapping",
    "calculated_at": "2025-05-07T12:54:28",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 5.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of Value Stream Mapping (VSM), nor are its principles, steps, or techniques discussed. The main ideas revolve around content classification, automation, and editorial oversight, which are not conceptually aligned with VSM's focus on visualising and optimising the flow of value in a process. The depth of discussion is substantial regarding AI-driven classification and technical architecture, but none of this relates to mapping or improving value streams. The intent is to inform about AI-powered content management, not VSM. The audience is technical, which partially overlaps with VSM practitioners, but the subject matter is not relevant to those seeking VSM insights. The signal-to-noise ratio is moderate, as the content is focused but off-topic for this category. No penalties were applied, as the content is current and not critical of VSM. Overall, the confidence score is very low, reflecting the lack of relevance to Value Stream Mapping.",
    "level": "Ignored"
  },
  "Market Share": {
    "resourceId": "oRStCAqLAY4",
    "category": "Market Share",
    "calculated_at": "2025-05-07T12:54:33",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of 'market share' or any explicit discussion of strategies, methodologies, or metrics related to increasing a product's market presence or competitive advantage. The main themes are technical automation, editorial consistency, and human-AI collaboration for content management. While there is a brief mention of promoting some tags to categories 'for marketing purposes,' this is not explored in the context of market share, competitive analysis, or audience expansion. The depth of discussion is focused on technical implementation, not on market positioning or share. The intended audience is technical practitioners interested in automation and content management, not strategists or executives focused on market share. The signal-to-noise ratio is moderate, as the content is highly relevant to its own topic but not to the 'Market Share' category. No penalties were applied, as the content is current and does not contradict the category's framing, but the overall fit is very low.",
    "level": "Ignored"
  },
  "Technical Excellence": {
    "resourceId": "oRStCAqLAY4",
    "category": "Technical Excellence",
    "calculated_at": "2025-05-07T12:54:39",
    "ai_confidence": 54.7,
    "ai_mentions": 1.2,
    "ai_alignment": 5.8,
    "ai_depth": 5.5,
    "ai_intent": 5.0,
    "ai_audience": 6.2,
    "ai_signal": 6.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content is a detailed technical case study of using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. While it demonstrates strong technical practices (automation, auditability, modular scripting, validation layers, and human-in-the-loop oversight), it does not directly discuss or reference the concept of 'Technical Excellence' as defined (i.e., high-level engineering practices like TDD, CI/CD, modular architecture, or emergent design in the context of software delivery). There are no explicit mentions of 'Technical Excellence' or its core topics; the focus is on content management, classification, and responsible AI use, not on improving software engineering practices or product quality at a systemic level. The technical depth is solid, and the audience is technical, but the alignment with the category is partial and indirect. The signal-to-noise ratio is good, with most content relevant to the technical implementation, but the main intent is not to explore or advocate for technical excellence as a discipline. No penalties were applied, as the content is current and not critical or satirical. The final confidence score reflects that, while the post is technically sophisticated, it only partially aligns with the specific meaning of 'Technical Excellence' as defined.",
    "level": "Tertiary"
  },
  "Transparency": {
    "resourceId": "oRStCAqLAY4",
    "category": "Transparency",
    "calculated_at": "2025-05-07T12:54:45",
    "ai_confidence": 91.7,
    "ai_mentions": 8.2,
    "ai_alignment": 9.4,
    "ai_depth": 9.1,
    "ai_intent": 9.0,
    "ai_audience": 8.7,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content directly and repeatedly references transparency, both in explicit language (e.g., 'transparent audit trails', 'traceable and explainable', 'records all inputs, outputs, penalties, and decisions for transparency') and in the design of the technical system. The main theme is the creation of a transparent, auditable, and accountable classification process for blog content using AI and PowerShell, with human oversight. The discussion goes beyond surface mentions, detailing how transparency is achieved through logging, audit trails, deterministic validation, and human review. The intent is strongly aligned: the author aims to make classification decisions visible, explainable, and reviewable, which is the core of the Transparency category. The audience is technical practitioners and process consultants, matching the category's typical readership. The signal-to-noise ratio is high, with most content focused on transparency, auditability, and accountability, though there is some tangential discussion of technical implementation details. No penalties are applied, as the content is current, positive, and fully aligned with the category. The final confidence score reflects the strong, multi-dimensional fit with Transparency.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the Transparency category, as it centres on making AI-driven classification processes open, explainable, and auditable. It thoroughly discusses mechanisms like audit trails, logging, and human oversight, ensuring decisions are visible and accountable. The technical focus and clear intent to foster transparency make it highly relevant for practitioners interested in transparent systems."
  },
  "Ability to Innovate": {
    "resourceId": "oRStCAqLAY4",
    "category": "Ability to Innovate",
    "calculated_at": "2025-05-07T12:54:50",
    "ai_confidence": 54.7,
    "ai_mentions": 2.6,
    "ai_alignment": 5.8,
    "ai_depth": 6.2,
    "ai_intent": 5.5,
    "ai_audience": 6.0,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content describes the use of generative AI and automation to improve blog post tagging and categorisation, with a focus on technical implementation, auditability, and human oversight. While there are elements of process improvement and the adoption of new technology (AI, PowerShell scripting), the discussion is primarily about content management and workflow optimisation for a personal blog. There is no direct mention of 'Ability to Innovate' as a value area, nor are there explicit references to innovation metrics, learning cycles, or frameworks for measuring innovation in an organisational context. The main ideas align partially with the category in that the author is innovating their own workflow, but the depth of discussion is technical and operational rather than strategic or organisational. The intent is to share a technical solution rather than to explore or enhance organisational innovation capacity. The audience is likely technical practitioners interested in automation and AI, which partially overlaps with the category's audience, but the focus is not on business agility or innovation management. The content is focused and relevant to its own topic, but only tangentially touches on the broader themes of innovation as defined in Evidence-Based Management. No penalties were applied as the content is current, constructive, and not contradictory to the category's framing.",
    "level": "Tertiary"
  },
  "Cross Functional Teams": {
    "resourceId": "oRStCAqLAY4",
    "category": "Cross Functional Teams",
    "calculated_at": "2025-05-07T12:54:56",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.5,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of cross-functional teams, nor any discussion of their structure, benefits, or role in Agile. The main themes are automation, AI-human collaboration, and technical architecture for content management. While the author briefly references their own career path (including DevOps and Scrum), this is only to provide context for evolving taxonomies and does not discuss team composition, collaboration, or cross-functional practices. The depth of discussion is focused entirely on technical implementation, not on team dynamics or cross-functional collaboration. The intent is to inform technical practitioners about AI-driven classification, not to explore or exemplify cross-functional teams. The audience is technical (developers, site owners, automation enthusiasts), which partially overlaps with Agile practitioners but is not specifically targeted at those interested in cross-functional teams. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the category. Overall, the content does not fit the 'Cross Functional Teams' category, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Platform Engineering": {
    "resourceId": "oRStCAqLAY4",
    "category": "Platform Engineering",
    "calculated_at": "2025-05-07T12:55:02",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.5,
    "ai_intent": 2.8,
    "ai_audience": 4.1,
    "ai_signal": 3.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site. While it discusses internal automation, scripting, and technical architecture, it does not directly mention or explore platform engineering, Internal Developer Platforms (IDPs), or the core principles of platform engineering such as standardised tooling, self-service developer platforms, or lifecycle automation for application development. The main intent is to describe a personal workflow for content management, not to inform or support platform engineering practitioners. The audience is more aligned with technical bloggers or site maintainers rather than platform engineers. There are only tangential overlaps, such as automation and traceability, but these are not framed within the context of platform engineering. The signal-to-noise ratio is moderate, with most content focused on the specific use case rather than broader platform engineering concepts. No penalties were applied as the content is current and not critical or satirical. Overall, the confidence score is low, reflecting the lack of direct relevance to the Platform Engineering category.",
    "level": "Ignored"
  },
  "Organisational Psychology": {
    "resourceId": "oRStCAqLAY4",
    "category": "Organisational Psychology",
    "calculated_at": "2025-05-07T12:55:08",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 2.0,
    "ai_audience": 3.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and scripting to automate blog post tagging and categorisation in Hugo. There are no direct mentions of organisational psychology, nor are any of its core concepts (motivation, leadership, team dynamics, psychological safety, etc.) discussed. The main focus is on technical architecture, automation, and editorial workflow, not on psychological principles or theories within organisations. The intent is to inform technically-minded readers about automation and content management, not to explore psychological factors in organisational settings. While there is some mention of human oversight and accountability, these are framed in terms of editorial control and system reliability, not in the context of organisational behaviour or psychology. The audience is technical practitioners, not organisational psychologists or those interested in workplace psychology. The signal-to-noise ratio is moderate, as the content is focused but entirely off-topic for this category. No penalties were applied, as the tone is neutral and the content is current, but the overall fit is extremely low.",
    "level": "Ignored"
  },
  "Agile Philosophy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Philosophy",
    "calculated_at": "2025-05-07T12:55:14",
    "ai_confidence": 23.7,
    "ai_mentions": 0.4,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and scripting to automate blog post tagging and categorisation in Hugo. There is a strong focus on automation, data architecture, technical implementation, and the balance between AI and human oversight. While the author briefly mentions their background, including experience with Scrum and process consulting, there are no direct references to Agile Philosophy, the Agile Manifesto, or its principles. The discussion of 'Concepts' as high-level thematic anchors (e.g., Philosophy, Practices, Methods, Values, Strategy) is generic and not specifically tied to Agile Philosophy. The main ideas revolve around content management, automation, and responsible AI use, not the foundational values or mindset of Agile. The depth of discussion is technical and operational, not philosophical. The intended audience is technical practitioners interested in automation and AI for content management, not those seeking insight into Agile Philosophy. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied, as the content is current and not satirical or critical of Agile. Overall, the confidence that this content fits under 'Agile Philosophy' is low, as it does not address the core meaning or key topics of the category.",
    "level": "Ignored"
  },
  "Product Strategy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Strategy",
    "calculated_at": "2025-05-07T12:55:20",
    "ai_confidence": 27.6,
    "ai_mentions": 0.7,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 3.2,
    "ai_audience": 4.1,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 28.0,
    "reasoning": "The content is a detailed technical case study on automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo site. It focuses on technical architecture, scripting, data structures, and the process of integrating AI for content classification, with strong emphasis on human oversight and auditability. There are no direct mentions of 'Product Strategy' or its core concepts such as vision formulation, roadmapping, market analysis, or alignment with organisational goals. The main ideas revolve around content management, automation, and editorial consistency, which are operational and technical rather than strategic. The depth of discussion is high for technical implementation but not for product strategy methodologies or frameworks. The intent is to inform technical practitioners or site owners about automating classification, not to guide product strategists. The audience is more technical/editorial than executive or strategic. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied as the content is current and not satirical or critical of the category. Overall, the confidence score is low, reflecting that the content does not fit the 'Product Strategy' category.",
    "level": "Ignored"
  },
  "Collaboration Tools": {
    "resourceId": "oRStCAqLAY4",
    "category": "Collaboration Tools",
    "calculated_at": "2025-05-07T12:55:27",
    "ai_confidence": 19.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 5.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve tagging and categorisation of blog posts in Hugo. While it discusses workflow automation, technical architecture, and the integration of AI for content management, it does not directly address or reference collaboration tools as defined by the category. There are no explicit mentions of platforms like Slack, Teams, Trello, or Jira, nor is there discussion of features or practices that enhance team communication or coordination within Agile teams. The main intent is to describe a personal technical solution for content classification, not to inform or support Agile team collaboration. The audience is more technical (developers, site owners, automation enthusiasts) rather than Agile practitioners seeking collaboration solutions. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant topic. Overall, the content does not fit the 'Collaboration Tools' category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Deployment Strategies": {
    "resourceId": "oRStCAqLAY4",
    "category": "Deployment Strategies",
    "calculated_at": "2025-05-07T12:55:35",
    "ai_confidence": 13.7,
    "ai_mentions": 0.6,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.1,
    "ai_audience": 4.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. It details the technical and editorial strategies for classification, human oversight, and auditability, but does not discuss deployment methodologies or practices. There are no direct mentions of deployment strategies such as blue-green deployments, canary releases, rolling updates, infrastructure as code, or risk management in software releases. The conceptual alignment is very low, as the main ideas revolve around content management and classification automation, not software deployment. The depth of discussion is substantial for its own topic but not for deployment strategies. The intent is to inform about AI-driven classification, not deployment. The audience is technical, which slightly overlaps with the deployment strategies audience, but the focus is not on deployment practitioners. The signal-to-noise ratio is moderate, as the content is focused but off-topic for this category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is very low, reflecting the lack of relevance to deployment strategies.",
    "level": "Ignored"
  },
  "Decision Making": {
    "resourceId": "oRStCAqLAY4",
    "category": "Decision Making",
    "calculated_at": "2025-05-07T12:55:41",
    "ai_confidence": 67.6,
    "ai_mentions": 2.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.5,
    "ai_audience": 7.0,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content provides a detailed account of using generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo, with a strong emphasis on human oversight, auditability, and transparent reasoning. While the term 'decision making' is not directly mentioned, the post repeatedly discusses the process of making classification decisions, blending AI suggestions with deterministic, human-validated rules. This aligns conceptually with structured, evidence-based decision-making, especially in the context of content management. The architecture described includes penalty logic, validation, and audit trails, all of which are relevant to evidence-based methodologies. The discussion of quantitative, multi-factor assessment and the explicit separation of AI's tactical role from human strategic accountability further reinforce alignment with the category. However, the primary focus is on technical implementation and workflow automation rather than a deep exploration of decision-making frameworks or cognitive biases. The audience is technical practitioners interested in automation and content management, which partially overlaps with the intended audience for decision-making methodologies. The content is focused and relevant, with minimal off-topic material, but the lack of direct references to decision-making frameworks or explicit discussion of evidence-based management principles limits the depth and directness of the fit. No penalties were applied, as the content is current, constructive, and does not contradict the category's framing.",
    "level": "Secondary"
  },
  "Team Performance": {
    "resourceId": "oRStCAqLAY4",
    "category": "Team Performance",
    "calculated_at": "2025-05-07T12:55:46",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.7,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study about automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo site. There are no direct mentions of 'team performance' or related delivery capability at the team level. The main focus is on content management, automation, and editorial consistency for a personal blog, not on evaluating or improving team outcomes, delivery metrics, or systemic team behaviours. While the author references concepts like 'classification', 'auditability', and 'systemic validation', these are applied to content workflows, not to team dynamics or throughput. The audience is primarily technical practitioners interested in automation and AI integration for content management, not those seeking to understand or improve team performance. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the 'Team Performance' category. There is no evidence of outdated practices or contradictory tone, so no penalties are applied. Overall, the content does not align with the definition or key topics of 'Team Performance', resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Professional Scrum": {
    "resourceId": "oRStCAqLAY4",
    "category": "Professional Scrum",
    "calculated_at": "2025-05-07T12:55:54",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 3.5,
    "ai_intent": 4.0,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. While the author briefly mentions their background, including experience with Scrum and process consulting, the main focus is on the architecture, scripting, and auditability of the classification system. There is a strong emphasis on human accountability versus AI agency, which conceptually aligns with some Professional Scrum values (e.g., accountability, transparency), but these are not discussed in the context of Scrum or its ethos. The term 'Scrum' appears only in passing as part of the author's career history and in example tags/categories, not as a subject of discussion. There is no exploration of Scrum values, empiricism, technical excellence in the Scrum sense, or the philosophy of Professional Scrum. The intent is to inform technical practitioners about AI-powered content management, not to discuss or promote Professional Scrum. The audience is technical (blog owners, developers, automation enthusiasts), not specifically Scrum professionals. The signal-to-noise ratio is moderate: the content is focused, but not on Professional Scrum. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Professional Scrum' is low, as it does not address the ethos, principles, or practices of Professional Scrum in any substantive way.",
    "level": "Ignored"
  },
  "Sociotechnical Systems": {
    "resourceId": "oRStCAqLAY4",
    "category": "Sociotechnical Systems",
    "calculated_at": "2025-05-07T12:56:00",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.2,
    "ai_audience": 6.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily describes the technical and process-oriented implementation of generative AI and scripting to automate blog post tagging and categorisation, with a strong emphasis on human oversight and auditability. While there are some indirect references to the interplay between technology (AI, scripting, automation) and human roles (editorial control, accountability, validation), these are framed in the context of an individual’s workflow rather than organisational structures or team dynamics. There is no explicit mention of sociotechnical systems, nor are there direct discussions of organisational culture, team effectiveness, or the integration of social and technical aspects within a broader organisational context. The main audience appears to be technical practitioners or solo content managers, not those focused on organisational or team-level sociotechnical concerns. The content is focused and relevant to automation and responsible AI use in content management, but it does not deeply explore the theoretical or practical aspects of sociotechnical systems as defined in the category. Therefore, the confidence score is low, reflecting only a partial and incidental alignment with the sociotechnical systems category.",
    "level": "Tertiary"
  },
  "Competence": {
    "resourceId": "oRStCAqLAY4",
    "category": "Competence",
    "calculated_at": "2025-05-07T12:56:07",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.0,
    "ai_audience": 6.2,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily details the technical implementation of generative AI and PowerShell scripts to automate tagging and categorisation in a Hugo-based blog. While it demonstrates a high level of technical skill and process improvement, direct mentions of 'competence' as defined in Agile, Scrum, DevOps, or Lean contexts are absent. There is some conceptual overlap: the author discusses continuous improvement, traceability, and the importance of human oversight and accountability, which are tangentially related to competence. However, the main focus is on automation, data architecture, and workflow optimisation, not on the development or inspection of professional skills, mastery, or fostering a culture of competence. The depth of discussion around competence is limited, with only indirect references to quality, validation, and responsible use of AI. The intent is more about technical enablement and process transparency than about competence as a foundational principle. The audience is technical practitioners, which aligns somewhat, but the content is not tailored to those seeking to understand or develop competence in the professional sense. The signal-to-noise ratio is moderate, as much of the content is technical detail rather than discussion of competence. Overall, the confidence score reflects that while there are minor thematic connections, the content does not substantively address the core meaning of the 'Competence' category.",
    "level": "Tertiary"
  },
  "Azure DevOps": {
    "resourceId": "oRStCAqLAY4",
    "category": "Azure DevOps",
    "calculated_at": "2025-05-07T12:56:12",
    "ai_confidence": 7.2,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 0.5,
    "ai_audience": 0.7,
    "ai_signal": 0.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. It discusses scripting, data architecture, and human-AI collaboration for content management. There is a single, passing mention of 'Azure Pipelines' as an example tag, but no substantive discussion of Azure DevOps services, tools, or practices. The main focus is on Hugo, OpenAI, PowerShell, and content classification workflows, not on Azure DevOps or its ecosystem. The audience is technical, but not specifically Azure DevOps practitioners. The signal-to-noise ratio is high for the actual topic (AI-driven classification), but almost zero for Azure DevOps. No penalties were applied, as the content is current and not critical of Azure DevOps. Overall, the confidence that this content fits under the 'Azure DevOps' category is extremely low.",
    "level": "Ignored"
  },
  "Azure Boards": {
    "resourceId": "oRStCAqLAY4",
    "category": "Azure Boards",
    "calculated_at": "2025-05-07T12:56:18",
    "ai_confidence": 7.2,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 0.5,
    "ai_audience": 2.0,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There are no direct mentions of Azure Boards, nor any discussion of its features, best practices, or integration with Agile project management. The conceptual alignment is extremely low, as the main ideas revolve around content management, AI-driven classification, and technical scripting, not Agile project tracking or Azure DevOps. The depth of discussion is high for its own topic but not for Azure Boards, so the score is minimal. The intent is to inform about AI-powered content classification, not to support or inform Azure Boards users. The audience is technical, but not the specific practitioner audience for Azure Boards. The signal-to-noise ratio is low for this category, as nearly all content is off-topic. No penalties were applied, as the content is not outdated or satirical, but the confidence score is extremely low due to the lack of relevance.",
    "level": "Ignored"
  },
  "One Engineering System": {
    "resourceId": "oRStCAqLAY4",
    "category": "One Engineering System",
    "calculated_at": "2025-05-07T12:56:24",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 8.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate and improve tagging and categorisation in a personal Hugo-based blog. There are no direct mentions of 'One Engineering System' (1ES) or its principles, nor is there any discussion of standardising or integrating software development practices across teams, which is central to the 1ES category. The main focus is on individual workflow automation, data architecture for content classification, and the blend of AI and human oversight for editorial control. While the technical depth is high and the audience is technical, the alignment with 1ES is weak: the content does not address cross-team integration, unified engineering processes, or organisational standardisation. The signal-to-noise ratio is moderate, as the content is focused but not on the 1ES topic. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence score is low, reflecting that the content does not fit the 'One Engineering System' category.",
    "level": "Ignored"
  },
  "Metrics and Learning": {
    "resourceId": "oRStCAqLAY4",
    "category": "Metrics and Learning",
    "calculated_at": "2025-05-07T12:56:29",
    "ai_confidence": 54.7,
    "ai_mentions": 2.2,
    "ai_alignment": 5.8,
    "ai_depth": 6.1,
    "ai_intent": 5.5,
    "ai_audience": 6.0,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content primarily details the technical implementation of generative AI and PowerShell scripts to automate tagging and categorisation in a Hugo-based blog. While it references the use of data, automation, and audit trails, direct mentions of 'metrics' or 'learning' in the context of Agile, DevOps, or continuous improvement are minimal. The main focus is on content management, classification architecture, and technical scripting, rather than on collecting, analysing, or leveraging metrics for iterative learning or evidence-based management. There are some conceptual overlaps, such as the use of quantitative, multi-factor assessment and the mention of tracking classification shifts and dashboards as future enhancements, which touch on metrics and feedback loops. However, these are not the central themes, and the discussion does not deeply explore continuous improvement methodologies, feedback mechanisms, or the impact of metrics on team or organisational behaviour. The intent is more about technical enablement and editorial control than fostering learning cycles or evidence-based decision-making. The audience is technical and process-oriented, which partially aligns, and the content is focused with little off-topic material. No penalties were applied as the content is current and not contradictory. Overall, the fit with 'Metrics and Learning' is moderate but not strong, resulting in a mid-range confidence score.",
    "level": "Tertiary"
  },
  "Project Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Project Management",
    "calculated_at": "2025-05-07T12:56:34",
    "ai_confidence": 54.7,
    "ai_mentions": 1.2,
    "ai_alignment": 5.7,
    "ai_depth": 5.9,
    "ai_intent": 5.5,
    "ai_audience": 6.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content primarily details the technical and editorial process of automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo site. While it references concepts such as 'technical strategy', 'process consultant', 'auditability', and 'workflow', these are discussed in the context of content management and automation, not project management methodologies or practices. There are no direct mentions of project management, its principles, or its methodologies (e.g., Waterfall, Agile, PRINCE2). The alignment score reflects that some themes—such as process improvement, traceability, and human oversight—are tangentially relevant to project management, but the main focus is on technical implementation for content classification. The depth score is moderate, as the discussion is thorough but not about project management itself. The intent is to inform about a technical solution for content management, not to guide or support project management practitioners. The audience is likely technical (developers, site owners, automation enthusiasts) rather than project managers or those interested in project delivery. The signal-to-noise ratio is decent, with most content focused on the described system, but little of it is directly relevant to project management. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low-to-moderate, reflecting that while there are some process and oversight themes, the content does not substantively fit under the 'Project Management' category.",
    "level": "Tertiary"
  },
  "Cycle Time": {
    "resourceId": "oRStCAqLAY4",
    "category": "Cycle Time",
    "calculated_at": "2025-05-07T12:56:39",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 1.2,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of 'Cycle Time' or any discussion of measuring the time taken to complete units of work from initiation to completion. The main themes revolve around content management, classification systems, automation, and human oversight, which do not conceptually align with the definition or key topics of Cycle Time in Agile or DevOps contexts. The depth of discussion is substantial, but it is entirely centred on classification and editorial workflows, not workflow efficiency or time-based metrics. The intent is to inform about technical strategies for content classification, not to address Cycle Time or related metrics. The audience is technical (blog maintainers, developers, automation practitioners), which partially overlaps with the Cycle Time category's audience, but the content is not relevant to their interests regarding Cycle Time. The signal-to-noise ratio is moderate, as the content is focused but off-topic for Cycle Time. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence that this content fits under 'Cycle Time' is very low.",
    "level": "Ignored"
  },
  "Personal": {
    "resourceId": "oRStCAqLAY4",
    "category": "Personal",
    "calculated_at": "2025-05-07T12:56:45",
    "ai_confidence": 91.7,
    "ai_mentions": 7.8,
    "ai_alignment": 9.5,
    "ai_depth": 9.2,
    "ai_intent": 9.0,
    "ai_audience": 8.7,
    "ai_signal": 8.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content is a detailed, first-person narrative describing the author's journey in transforming their blog's tagging and categorisation system using generative AI and PowerShell. It is rich in personal anecdotes (e.g., 'I moved my blog...', 'I realised pretty quickly...', 'I've been very impressed...'), reflections on challenges (legacy content, WordPress pain points), and subjective insights into the impact of automation and AI on their workflow. The main ideas are deeply aligned with the 'Personal' category, as the author shares their unique perspective and lessons learned, rather than providing a technical manual or generalised analysis. The discussion is thorough, covering motivations, technical architecture, process, and future plans, all through a personal lens. The intent is to share an individual experience and offer advice to others considering similar approaches, which fits the category's purpose. The audience is likely practitioners or content managers interested in personal stories of digital transformation, closely matching the category's target. The content is focused, with minimal off-topic material, and maintains a high signal-to-noise ratio. No penalties were applied, as the content is current, positive, and does not contradict the category's framing. The final confidence score is high, reflecting the strong conceptual and narrative fit with the 'Personal' category.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the 'Personal' category, as it centres on the author's own experiences and reflections while revamping their blog with generative AI and PowerShell. The narrative is subjective, sharing lessons learned and personal insights, making it relevant for readers interested in individual journeys rather than general technical guides."
  },
  "Internal Developer Platform": {
    "resourceId": "oRStCAqLAY4",
    "category": "Internal Developer Platform",
    "calculated_at": "2025-05-07T12:56:52",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.7,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site workflow. There is no direct mention of Internal Developer Platforms (IDPs), nor is there any discussion of their definition, purpose, architecture, or role in software development lifecycles. The main themes revolve around content management, automation, and human-in-the-loop AI validation for editorial processes, not the creation or operation of an IDP. While there are some technical details about scripting, data architecture, and automation, these are specific to personal content management and do not align with the broader, team-oriented, and process-streamlining goals of an IDP. The intended audience appears to be individual technical practitioners interested in content automation, not platform engineers or teams building internal platforms. The signal-to-noise ratio is moderate, as the content is focused but off-topic for the IDP category. No penalties were applied, as the content is not outdated or critical of the IDP concept, but the overall fit is weak, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Agnostic Agile": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agnostic Agile",
    "calculated_at": "2025-05-07T12:57:03",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 3.2,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There are no direct mentions of Agnostic Agile, its principles, or its thought leaders. The main themes revolve around automation, human oversight, and transparent audit trails in content management, not agile philosophy or context-driven agility. While there is a general emphasis on context, traceability, and ethical use of AI, these are not explicitly tied to Agnostic Agile or its unique philosophy. The depth of discussion is focused on technical implementation rather than agile methodologies or their adaptation. The intent is to inform about a technical solution for content classification, not to discuss or promote Agnostic Agile. The audience is technical practitioners interested in automation and content management, not specifically agile professionals or strategists. The signal-to-noise ratio is moderate, as the content is focused but not on the Agnostic Agile topic. No penalties were applied, as the content is current and not critical or satirical. Overall, the content does not fit the Agnostic Agile category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Hybrid Agile": {
    "resourceId": "oRStCAqLAY4",
    "category": "Hybrid Agile",
    "calculated_at": "2025-05-07T12:57:08",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 1.8,
    "ai_intent": 1.2,
    "ai_audience": 2.0,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of Hybrid Agile, nor is there any discussion of blending traditional project management with agile delivery practices. The main themes are automation, AI-human collaboration, traceability, and technical architecture for content management. There is no analysis of Hybrid Agile frameworks, no critique of command-and-control structures, and no exploration of agile role accountability in a hybrid context. The intent is to inform technical practitioners about AI-driven classification, not to examine the pitfalls or challenges of Hybrid Agile. The audience is technical (blog owners, developers, automation enthusiasts), not those interested in project management methodologies. The signal-to-noise ratio is high for its actual topic, but almost entirely irrelevant to Hybrid Agile. No penalties were applied as the content is current and does not contradict the category's framing, but the fit is extremely weak, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Scrum Team": {
    "resourceId": "oRStCAqLAY4",
    "category": "Scrum Team",
    "calculated_at": "2025-05-07T12:57:13",
    "ai_confidence": 13.7,
    "ai_mentions": 0.4,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 2.1,
    "ai_signal": 1.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. While the author briefly mentions their career progression from web developer through DevOps and Scrum to process consultant, there is no substantive discussion of the Scrum Team as an accountability in the Scrum framework. The only direct reference to 'Scrum' is as an example of a category or tag, not as a subject of analysis. There is no exploration of Scrum Team structure, responsibilities, self-management, or accountability boundaries. The main focus is on technical architecture, automation, and editorial workflow, not on Scrum Team concepts. The intended audience is technical practitioners interested in automation and content management, not specifically Scrum Team members or those seeking to understand Scrum Team accountability. The signal-to-noise ratio is low for this category, as nearly all content is off-topic with respect to the Scrum Team. Therefore, the confidence score is very low, reflecting only a minimal, incidental connection.",
    "level": "Ignored"
  },
  "Operational Practices": {
    "resourceId": "oRStCAqLAY4",
    "category": "Operational Practices",
    "calculated_at": "2025-05-07T12:57:19",
    "ai_confidence": 67.7,
    "ai_mentions": 2.6,
    "ai_alignment": 7.7,
    "ai_depth": 7.9,
    "ai_intent": 7.2,
    "ai_audience": 7.8,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content provides a detailed account of using generative AI and PowerShell scripting to automate and improve the tagging and categorisation process for a Hugo-based blog. While it does not directly mention 'Operational Practices' or use the terminology of Agile, DevOps, or Lean frameworks, it does describe practical strategies for process optimisation, automation, and workflow improvement—core aspects of operational practices. The technical architecture, auditability, and human-in-the-loop validation reflect a focus on operational efficiency and quality. The discussion is thorough, covering the rationale, data architecture, technical implementation, and future enhancements, which demonstrates depth. The main intent is to share a practical, repeatable approach to improving content management operations, aligning with the category's purpose. The audience is primarily technical practitioners interested in automation, workflow optimisation, and responsible AI use, which fits the operational practices audience. However, the content is somewhat specialised (focused on blog management rather than broader organisational operations) and does not explicitly reference Agile, DevOps, or Lean, which lowers the direct mentions score. The signal-to-noise ratio is high, with most content relevant to the process and its improvement. Overall, the content is a strong but not perfect fit for 'Operational Practices', meriting a moderate-to-high confidence score.",
    "level": "Secondary"
  },
  "Sensemaking": {
    "resourceId": "oRStCAqLAY4",
    "category": "Sensemaking",
    "calculated_at": "2025-05-07T12:57:24",
    "ai_confidence": 36.7,
    "ai_mentions": 0.4,
    "ai_alignment": 3.2,
    "ai_depth": 3.6,
    "ai_intent": 2.8,
    "ai_audience": 4.1,
    "ai_signal": 3.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a technical case study on using generative AI and scripting to automate blog post tagging and categorisation. There are no direct mentions of 'sensemaking' or its frameworks (e.g., Cynefin), nor is there explicit discussion of interpreting complexity or organisational decision-making. The main focus is on technical automation, data architecture, and workflow improvements, not on understanding or navigating complex environments. While there is some conceptual overlap—such as the need for human oversight, traceability, and the blending of machine suggestions with human judgment—these are framed in the context of content management, not organisational sensemaking. The audience is primarily technical practitioners interested in automation and AI integration, not strategists or leaders focused on sensemaking. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. Overall, the content does not substantially align with the definition or intent of the 'Sensemaking' category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Organisational Physics": {
    "resourceId": "oRStCAqLAY4",
    "category": "Organisational Physics",
    "calculated_at": "2025-05-07T12:57:31",
    "ai_confidence": 36.7,
    "ai_mentions": 0.4,
    "ai_alignment": 3.2,
    "ai_depth": 3.7,
    "ai_intent": 2.8,
    "ai_audience": 4.1,
    "ai_signal": 4.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There are no direct mentions of 'Organisational Physics' or explicit references to systems thinking, organisational dynamics, or related terminology. The main focus is on technical implementation, automation, and editorial workflow, not on understanding or influencing organisational systems or behaviour. While there are some tangential overlaps—such as the mention of 'agency' (AI vs. human), layered classification, and the need for traceability and feedback—these are framed in the context of content management, not organisational dynamics. The depth of discussion is high for technical architecture and process automation, but not for systems thinking or organisational behaviour. The intent is to inform technical practitioners about automating content classification, not to explore or apply Organisational Physics principles. The audience is technical (bloggers, developers, automation enthusiasts), not strategists or organisational theorists. The signal-to-noise ratio is good for its actual topic, but almost entirely off-topic for Organisational Physics. No penalties were applied, as the content is current and not satirical or critical of the category. Overall, the confidence that this content fits under 'Organisational Physics' is low, as it does not address the category's core themes or audience.",
    "level": "Ignored"
  },
  "Continuous Learning": {
    "resourceId": "oRStCAqLAY4",
    "category": "Continuous Learning",
    "calculated_at": "2025-05-07T12:57:37",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.0,
    "ai_audience": 6.2,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily details the technical implementation of generative AI and PowerShell scripts to automate blog post tagging and categorisation in Hugo, with a strong emphasis on human oversight, auditability, and transparent decision-making. While there are some tangential connections to Continuous Learning—such as the author's reflection on lessons learned, the iterative improvement of classification systems, and the mention of learning from experience—these are not the main focus. The content does not directly discuss growth mindset, team knowledge sharing, feedback loops, or the creation of a learning culture within Agile, DevOps, or Lean environments. There are no explicit or frequent mentions of 'Continuous Learning' or its key principles. The depth of discussion around learning is limited and mostly incidental to the technical narrative. The intent is to inform about a technical solution, not to foster or explore continuous learning practices. The audience is technical (blog maintainers, developers, automation enthusiasts), which partially overlaps with the Continuous Learning category, but the content is not tailored to teams or practitioners seeking to improve learning culture. The signal-to-noise ratio is moderate: while the content is focused, its relevance to Continuous Learning is low. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting that the content does not substantially fit under the 'Continuous Learning' category.",
    "level": "Tertiary"
  },
  "Value Stream Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Value Stream Management",
    "calculated_at": "2025-05-07T12:57:42",
    "ai_confidence": 19.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.4,
    "ai_intent": 2.0,
    "ai_audience": 1.8,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content focuses on the use of generative AI and scripting to automate and improve the tagging and categorisation of blog posts within a static site generator (Hugo). While it discusses process optimisation, automation, and the reduction of manual labour, these are applied specifically to content management and classification, not to the broader organisational flow of value as defined by Value Stream Management (VSM). There are no direct mentions of VSM, nor are its principles, techniques, or metrics discussed. The main themes are technical automation, AI-human collaboration, and editorial consistency, which are not conceptually aligned with VSM's focus on optimising end-to-end value delivery, minimising organisational waste, or aligning work with customer outcomes. The depth of discussion is substantial for content classification and AI integration, but not for VSM. The intent is to inform about technical improvements in content management, not to address value streams or business agility. The audience is technical (blog owners, developers, content managers), not the typical VSM audience (process consultants, business strategists, Lean/Agile practitioners). The content is focused and relevant to its own topic, but not to VSM. No penalties were applied as the content is current and not critical of the VSM framing. Overall, the confidence that this content fits under Value Stream Management is very low.",
    "level": "Ignored"
  },
  "Sprint Review": {
    "resourceId": "oRStCAqLAY4",
    "category": "Sprint Review",
    "calculated_at": "2025-05-13T14:02:22",
    "ai_confidence": 7.2,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 0.5,
    "ai_audience": 1.0,
    "ai_signal": 0.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog tagging and categorisation in Hugo. While it references Scrum and related terms in passing, there are no direct or indirect mentions of Sprint Review, nor any discussion of its purpose, process, or best practices. The main focus is on content management automation, not Scrum events. Thus, the content does not align with the Sprint Review category.",
    "reasoning_summary": "This content is about automating blog categorisation with AI and PowerShell, not about Sprint Reviews. It doesn't mention or discuss Sprint Review concepts, so it doesn't fit the category.",
    "level": "Ignored"
  },
  "Team Motivation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Team Motivation",
    "calculated_at": "2025-05-07T12:58:04",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 3.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of team motivation, nor are there discussions of engagement, ownership, psychological safety, or other motivational dynamics within agile teams. The main focus is on technical architecture, automation, and editorial control, not on team dynamics or motivation. The only tangentially related aspect is the mention of human oversight and accountability, but this is framed in the context of content management, not team motivation. The audience is technical practitioners interested in automation and content management, not those seeking strategies for motivating agile teams. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant category. Overall, the content does not align with the 'Team Motivation' category, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Technical Mastery": {
    "resourceId": "oRStCAqLAY4",
    "category": "Technical Mastery",
    "calculated_at": "2025-05-07T12:58:10",
    "ai_confidence": 91.7,
    "ai_mentions": 7.8,
    "ai_alignment": 9.5,
    "ai_depth": 9.2,
    "ai_intent": 9.0,
    "ai_audience": 9.1,
    "ai_signal": 9.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content provides a detailed, technical walkthrough of automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts, with a strong emphasis on software engineering best practices. Direct mentions of 'technical architecture', 'data information architecture', and explicit breakdowns of scripts, modules, and validation logic demonstrate a clear focus on software craftsmanship and engineering excellence. The discussion covers maintainability, traceability, auditability, and the integration of AI with deterministic, human-controlled validation—core concerns of technical mastery. The depth is substantial, with architectural diagrams, code examples, and a nuanced explanation of penalty and validation layers. The intent is to inform and guide practitioners on building robust, high-quality automation systems, aligning perfectly with the category. The audience is clearly technical, targeting engineers, architects, and advanced practitioners interested in automation, DevOps, and content management systems. The signal-to-noise ratio is very high, with minimal digression and a strong focus on technical implementation and lessons learned. No penalties were applied, as the content is current, constructive, and fully aligned with the category definition. The final confidence score reflects the strong, multi-dimensional fit with 'Technical Mastery'.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the 'Technical Mastery' category. It offers a thorough, practical guide to automating blog post tagging with generative AI and PowerShell, focusing on best practices, architecture, and validation. The technical depth, clear audience targeting, and actionable insights make it highly relevant for engineers and architects seeking robust automation solutions."
  },
  "Organisational Culture": {
    "resourceId": "oRStCAqLAY4",
    "category": "Organisational Culture",
    "calculated_at": "2025-05-07T12:58:16",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of organisational culture, nor does the content discuss cultural factors, leadership, team dynamics, or the impact of culture on agility or transformation. The main focus is on technical architecture, automation, and editorial workflow, with some discussion of human oversight and accountability in AI systems. While the author briefly references their evolving role (from developer to consultant) and the importance of human agency, these are not explored in the context of organisational culture or its influence on Agile, DevOps, or business agility. The audience is primarily technical practitioners interested in automation and content management, not those seeking insights on organisational culture. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the content does not align with the Organisational Culture category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Agile Planning Tools": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Planning Tools",
    "calculated_at": "2025-05-07T12:58:24",
    "ai_confidence": 13.7,
    "ai_mentions": 0.4,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.5,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve blog post tagging and categorisation in Hugo, with an emphasis on technical architecture, data structures, and human oversight. There is no direct mention of Agile Planning Tools, nor are any specific tools (e.g., Jira, Trello, Asana) or Agile planning methodologies discussed. The main themes revolve around content management, automation, and classification, not Agile frameworks or planning processes. While the author references their background in DevOps and Scrum, these are only mentioned in passing to provide context for the evolution of their taxonomy, not as a discussion of Agile planning or tools. The audience is technical, but the content is not targeted at Agile practitioners or teams seeking to improve Agile planning. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the Agile Planning Tools category. No penalties were applied, as the content is current and not satirical or critical of the category. Overall, the content does not fit the 'Agile Planning Tools' category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Customer Retention": {
    "resourceId": "oRStCAqLAY4",
    "category": "Customer Retention",
    "calculated_at": "2025-05-07T12:58:31",
    "ai_confidence": 18.7,
    "ai_mentions": 0.3,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 5.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of customer retention, nor are there references to strategies, methodologies, or metrics for maintaining user engagement or minimising churn. The main focus is on internal content management, editorial consistency, and automation, not on delivering continuous value to customers or enhancing user experience in a way that aligns with customer retention goals. While the improved discoverability and editorial standards could indirectly benefit users, the discussion is not framed around customer needs, feedback loops, or retention strategies. The audience is technical (blog owners, developers, automation practitioners), which partially overlaps with those interested in customer retention, but the content is not targeted at retention strategists or customer experience professionals. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Customer Retention' is very low.",
    "level": "Ignored"
  },
  "Release Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Release Management",
    "calculated_at": "2025-05-07T12:58:37",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses technical automation, classification, and version control in the context of content management, it does not directly address or mention release management as defined (i.e., planning, scheduling, and controlling software releases). There are no explicit references to release management practices, CI/CD, release scheduling, or coordination between development and operations. The main intent is to describe a workflow for content classification and auditability, not software delivery or release processes. The audience is technical but more aligned with content managers, bloggers, or site maintainers rather than release managers or DevOps practitioners. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. Overall, the content only tangentially touches on concepts (e.g., version control, automation) that are adjacent to release management, resulting in a low confidence score for this category.",
    "level": "Ignored"
  },
  "Lean Thinking": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lean Thinking",
    "calculated_at": "2025-05-07T12:58:44",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 3.2,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripting to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses workflow optimisation, automation, and the reduction of manual labour, it does not directly mention Lean Thinking or its core principles (such as value, value stream, flow, pull, perfection, or waste elimination). There are no explicit references to Lean tools (e.g., 5S, Kanban, JIT), nor is there a discussion of Lean leadership, value stream mapping, or continuous improvement in the Lean sense. The main intent is to share a technical solution for content management, not to explore or advocate Lean Thinking. The audience is technical (blog owners, developers, automation practitioners), which partially overlaps with Lean audiences, but the content is not tailored to Lean practitioners or strategists. The signal-to-noise ratio is moderate, as the content is focused on its technical topic but not on Lean. No penalties were applied, as the content is current and not critical of Lean. Overall, the confidence that this content fits under the 'Lean Thinking' category is very low.",
    "level": "Ignored"
  },
  "Evidence Based Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Evidence Based Management",
    "calculated_at": "2025-05-07T12:58:53",
    "ai_confidence": 38.7,
    "ai_mentions": 0.6,
    "ai_alignment": 4.2,
    "ai_depth": 4.7,
    "ai_intent": 3.8,
    "ai_audience": 5.1,
    "ai_signal": 5.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and scripting to automate and improve the tagging and categorisation of blog posts in Hugo. There is a strong focus on automation, traceability, and the blending of AI suggestions with human oversight, including the use of penalty logic and transparent audit trails. However, there are no direct mentions of Evidence-Based Management (EBM) or its key terminology. The main conceptual alignment is with data-driven classification and the use of empirical, multi-factor scoring to inform content categorisation, which is somewhat adjacent to EBM's emphasis on empirical decision-making. The depth of discussion is high regarding technical implementation, but it does not explore EBM's core topics such as Current Value, Time to Market, Ability to Innovate, Unrealised Value, or outcome management. The intent is to inform technical practitioners about automating content management, not to discuss or promote EBM as a management approach. The audience is technical (developers, site owners, automation enthusiasts), which only partially overlaps with EBM's typical audience of managers and strategists. The signal-to-noise ratio is good, with focused, relevant content, but the relevance to EBM is tangential at best. No penalties were applied, as the content is current and does not contradict the EBM framing. Overall, while there are elements of empirical, data-driven decision-making, the content does not fit well under the Evidence-Based Management category.",
    "level": "Ignored"
  },
  "Current Value": {
    "resourceId": "oRStCAqLAY4",
    "category": "Current Value",
    "calculated_at": "2025-05-07T12:59:02",
    "ai_confidence": 19.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 6.2,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content focuses on the technical implementation of generative AI and PowerShell scripts to automate tagging and categorisation in a Hugo-based blog. There is no direct mention of 'Current Value' as defined in Evidence-Based Management, nor are there references to its key metrics (customer satisfaction, revenue impact, performance feedback) or its role in Agile, DevOps, or Lean methodologies. The main themes are automation, traceability, and editorial control in content management, not the real-time assessment of value delivered to customers or organisations. While the content does discuss quantitative assessment and confidence scoring, these are applied to content classification accuracy, not to measuring product or service value. The audience is technical practitioners interested in automation and AI for content management, which only partially overlaps with the intended audience for Current Value discussions. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant category. No penalties were applied, as the content is not outdated or critical of the category. Overall, the confidence score is low, reflecting minimal alignment with the Current Value category.",
    "level": "Ignored"
  },
  "Beta Codex": {
    "resourceId": "oRStCAqLAY4",
    "category": "Beta Codex",
    "calculated_at": "2025-05-07T12:59:08",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.7,
    "ai_audience": 7.1,
    "ai_signal": 6.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of Beta Codex or its foundational theories, nor is there any explicit discussion of decentralised, adaptive, or human-centric organisational design. The main focus is on technical automation, data architecture, and the balance between AI and human oversight in editorial workflows. While there are some tangential themes (e.g., human accountability, adaptive systems, transparency), these are framed in the context of content management and AI governance, not organisational design or Beta Codex principles. The audience is technical practitioners interested in automation and content management, not those seeking insight into Beta Codex or decentralised organisational models. The signal-to-noise ratio is high for its intended topic, but almost none of the content aligns with the Beta Codex category. Therefore, the confidence score is very low, reflecting only minimal incidental overlap (such as the mention of 'adaptive systems' and human agency) but no substantive fit.",
    "level": "Ignored"
  },
  "Increment": {
    "resourceId": "oRStCAqLAY4",
    "category": "Increment",
    "calculated_at": "2025-05-07T12:59:19",
    "ai_confidence": 7.7,
    "ai_mentions": 0.0,
    "ai_alignment": 0.2,
    "ai_depth": 0.2,
    "ai_intent": 0.2,
    "ai_audience": 0.5,
    "ai_signal": 0.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. It focuses on data architecture, automation, auditability, and the blending of AI and human oversight for content classification. There are no direct mentions of 'Increment' as defined in Scrum or Agile, nor is there any discussion of delivering working software, iterative value delivery, or the role of increments in Agile methodologies. The main ideas, technical depth, and intent are all centred on content management and classification, not on the concept of Increment. The audience is technical, but not in the context of Agile software delivery. The signal-to-noise ratio is high for its actual topic, but entirely off-topic for the Increment category. Therefore, the confidence score is extremely low, reflecting only the most remote conceptual overlap (e.g., the idea of iterative improvement in classification, which is not the same as software increments).",
    "level": "Ignored"
  },
  "Liberating Structures": {
    "resourceId": "oRStCAqLAY4",
    "category": "Liberating Structures",
    "calculated_at": "2025-05-07T12:59:25",
    "ai_confidence": 7.2,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 0.5,
    "ai_audience": 0.7,
    "ai_signal": 0.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of Liberating Structures, nor any references to specific facilitation techniques, methods, or the toolkit itself. The conceptual alignment is extremely weak: while the post discusses structuring information and improving editorial processes, it does not address team facilitation, engagement, or collaborative methods as defined by Liberating Structures. The depth of discussion is focused entirely on technical automation, not on facilitation or group process. The intent is to inform about AI-driven content management, not to support or inform practitioners of Liberating Structures. The audience is technical (bloggers, developers, automation enthusiasts), not facilitators, Scrum Masters, or Agile Coaches. The signal-to-noise ratio is high for its own topic, but nearly zero for the Liberating Structures category. No penalties were applied, as the content is not outdated or critical of the category. Overall, the confidence score is extremely low, reflecting the near-total absence of relevant content for the Liberating Structures category.",
    "level": "Ignored"
  },
  "Modern Source Control": {
    "resourceId": "oRStCAqLAY4",
    "category": "Modern Source Control",
    "calculated_at": "2025-05-07T12:59:31",
    "ai_confidence": 36.7,
    "ai_mentions": 2.2,
    "ai_alignment": 3.8,
    "ai_depth": 3.5,
    "ai_intent": 3.7,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content primarily discusses the use of generative AI and PowerShell scripts to automate and improve tagging and categorisation in a Hugo-based blog. While there is a brief mention of using GitHub for versioning, branching, and pull requests, these are not the focus of the article. The main themes revolve around content management, automation, and AI-driven classification, not modern source control practices or methodologies. There is no in-depth exploration of version control systems, branching strategies, code review processes, or related best practices. The audience is more aligned with technical content managers or developers interested in automation and AI, rather than practitioners seeking guidance on modern source control. The signal-to-noise ratio is moderate, as the only relevant mention is the use of GitHub for code versioning, which is not elaborated upon. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting the tangential and minimal relevance to the 'Modern Source Control' category.",
    "level": "Ignored"
  },
  "Technical Debt": {
    "resourceId": "oRStCAqLAY4",
    "category": "Technical Debt",
    "calculated_at": "2025-05-07T12:59:38",
    "ai_confidence": 23.6,
    "ai_mentions": 0.7,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses the challenges of managing legacy content, categories, and tags, and the pain of updating them in previous platforms, it does not directly mention or explore the concept of technical debt as defined (i.e., the accumulation of suboptimal code or design decisions that hinder sustainable development). There are no explicit references to technical debt, nor is there a discussion of its types, measurement, impact on velocity, or remediation strategies. The main themes are automation, AI-human collaboration, and content management, not the management or implications of technical debt. The audience is technical (blog maintainers, developers), but the focus is on content classification and workflow automation rather than codebase health or long-term maintainability. The signal-to-noise ratio is moderate, as the content is focused but not on the technical debt topic. No penalties were applied, as the content is current and not satirical or critical of the category. Overall, the confidence that this content fits under 'Technical Debt' is low.",
    "level": "Ignored"
  },
  "Business Agility": {
    "resourceId": "oRStCAqLAY4",
    "category": "Business Agility",
    "calculated_at": "2025-05-07T12:59:44",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.8,
    "ai_intent": 3.5,
    "ai_audience": 4.1,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of 'business agility' or its core principles. The main focus is on technical automation, data architecture, and workflow optimisation for content management, not on organisational adaptability, leadership, or agile transformation. While some concepts (automation, adaptability, traceability) are tangentially relevant to business agility, they are discussed strictly in the context of personal site management, not organisational change or market responsiveness. The depth of discussion is strong for technical implementation but shallow regarding business agility concepts. The intended audience is technical practitioners interested in AI-driven content management, not business leaders or strategists. The signal-to-noise ratio is high for its actual topic but low for business agility relevance. No penalties were applied, as the content is current and not critical of the category. Overall, the content does not fit well under 'Business Agility,' resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Miscellaneous": {
    "resourceId": "oRStCAqLAY4",
    "category": "Miscellaneous",
    "calculated_at": "2025-05-07T12:59:59",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 5.3,
    "ai_intent": 4.5,
    "ai_audience": 5.0,
    "ai_signal": 5.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content is a detailed technical narrative about automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo site. It focuses on the architecture, scripting, and process of integrating AI for content management, with strong emphasis on human oversight and auditability. \n\nDirect Mentions (1.2): The term 'Miscellaneous' is not mentioned, nor is there any explicit reference to the category. The content is highly specific to technical implementation and personal workflow, not to general or catch-all discussions.\n\nConceptual Alignment (4.8): While the content is tangentially related to business agility (in the sense of improving workflows and content management), it does not fit the core meaning of 'Miscellaneous' as defined. It is not a general discussion, anecdote, or non-framework-aligned reflection; rather, it is a technical case study with clear objectives and methods.\n\nDepth of Discussion (5.3): The discussion is deep and thorough, but it is focused on technical architecture, scripting, and process, not on miscellaneous or off-framework topics. The depth is in the technical domain, not in the catch-all or non-specific area the category describes.\n\nIntent / Purpose Fit (4.5): The main intent is to inform and share a technical solution for content classification, not to provide a general, non-framework-aligned discussion. The purpose is not aligned with the 'Miscellaneous' category, which is for content that does not fit elsewhere.\n\nAudience Alignment (5.0): The audience is technical practitioners interested in automation, AI integration, and content management, which only partially overlaps with the broad audience for 'Miscellaneous' (which could include non-technical or general business agility readers).\n\nSignal-to-Noise Ratio (5.2): The content is focused and relevant to its technical topic, but not to the 'Miscellaneous' category. There is little off-topic or filler content, but the focus is not on the catch-all or non-framework-aligned discussions the category is meant for.\n\nNo penalties were applied, as the content is current, not satirical, and does not contradict the category's framing. Overall, the confidence score is low, reflecting that while the content is not a fit for any specific Agile, Scrum, DevOps, Lean, or EBM category, it is also not a strong fit for 'Miscellaneous' as defined, since it is a technical case study rather than a general or non-framework-aligned discussion.",
    "level": "Tertiary"
  },
  "Complexity Thinking": {
    "resourceId": "oRStCAqLAY4",
    "category": "Complexity Thinking",
    "calculated_at": "2025-05-07T13:00:06",
    "ai_confidence": 23.7,
    "ai_mentions": 0.4,
    "ai_alignment": 2.2,
    "ai_depth": 2.7,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the technical and process-oriented transformation of blog post tagging and categorisation using generative AI and PowerShell scripting. There are no direct mentions of complexity science, complexity thinking, or related frameworks such as Cynefin, emergence, non-linear dynamics, or organisational uncertainty. The main ideas revolve around automation, human oversight, and transparent audit trails in content management, which are not conceptually aligned with the core meaning of Complexity Thinking. While the author discusses the increasing complexity of managing large numbers of tags and categories, this is in the colloquial sense of 'complicated' rather than engaging with complexity theory or its principles. The depth of discussion is substantial regarding technical implementation but does not explore complexity science concepts. The intent is to inform about AI-driven classification and workflow improvements, not to discuss or apply complexity thinking. The audience is likely technical practitioners interested in automation and content management, not those seeking insights into complexity science or organisational dynamics. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the Complexity Thinking category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting the lack of direct or conceptual fit with Complexity Thinking.",
    "level": "Ignored"
  },
  "Site Reliability Engineering": {
    "resourceId": "oRStCAqLAY4",
    "category": "Site Reliability Engineering",
    "calculated_at": "2025-05-07T13:00:13",
    "ai_confidence": 23.7,
    "ai_mentions": 0.4,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripting to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses automation, auditability, and technical architecture, there are no direct mentions of Site Reliability Engineering (SRE) or its core principles as defined by Google. The main themes revolve around content management, editorial consistency, and leveraging AI for classification, not the reliability, scalability, or performance of production systems. The technical depth is substantial but is applied to content workflows rather than system reliability. The intent is to inform about AI-driven content classification, not SRE practices. The audience is technical but more aligned with content managers, developers, or automation enthusiasts than SRE practitioners. The signal-to-noise ratio is moderate, with most content focused on the described system but not on SRE. No penalties were applied as the content is current and not satirical or critical of SRE. Overall, the content does not fit the SRE category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Frequent Releases": {
    "resourceId": "oRStCAqLAY4",
    "category": "Frequent Releases",
    "calculated_at": "2025-05-07T13:00:23",
    "ai_confidence": 23.6,
    "ai_mentions": 0.7,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo-based static site. There is no direct mention of 'Frequent Releases' or related practices such as Continuous Delivery, Continuous Deployment, or DevOps-driven release automation. The main themes are content classification, AI-human collaboration, and technical architecture for metadata management. While there are tangential references to automation, scripting, and version control (e.g., GitHub, PRs), these are in service of content management, not software release frequency or incremental delivery to users. The audience is technical, but the subject matter is not aligned with the principles, best practices, or metrics of frequent software releases. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence score is low due to minimal conceptual overlap and lack of direct relevance.",
    "level": "Ignored"
  },
  "Strategic Goals": {
    "resourceId": "oRStCAqLAY4",
    "category": "Strategic Goals",
    "calculated_at": "2025-05-07T13:00:33",
    "ai_confidence": 38.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 4.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and scripting to automate and improve blog post tagging and categorisation in Hugo. While it discusses the architecture, data model, and process improvements, it does not directly address or reference strategic goals, long-term objectives, or business agility in the sense defined by the category. There is some conceptual overlap in the sense that the author is seeking to improve editorial consistency, traceability, and scalability, which could be seen as supporting broader site management objectives. However, these are operational and tactical improvements rather than strategic ones. The main focus is on technical implementation, automation, and human oversight, not on aligning organisational strategy with agile principles or fostering competitive advantage. The audience is primarily technical practitioners and site owners, not strategists or executives. The signal-to-noise ratio is moderate, as the content is focused but not on the strategic level required. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Strategic Goals' is low, as it is much more about operational tactics and technical execution than about defining or achieving long-term strategic objectives.",
    "level": "Ignored"
  },
  "Enterprise Agility": {
    "resourceId": "oRStCAqLAY4",
    "category": "Enterprise Agility",
    "calculated_at": "2025-05-07T13:00:43",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 4.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study of using generative AI and PowerShell to automate and improve tagging and categorisation for a personal blog using Hugo. There is a strong focus on automation, auditability, and the blend of AI and human oversight in content management. However, there are no direct mentions of 'Enterprise Agility' or its frameworks (e.g., SAFe, LeSS), nor is there any discussion of organisational agility, leadership, or change management at the enterprise level. The main ideas are about technical implementation, data architecture, and responsible AI use in a solo or small-scale editorial context, not about scaling agility across an organisation. The depth is high for the technical topic, but not for enterprise agility. The intent is to inform technical practitioners or bloggers, not enterprise leaders or strategists. The audience is more technical and individual than organisational. The signal-to-noise ratio is good for the topic, but the topic itself is not aligned with enterprise agility. No penalties were applied as the content is current and not critical or satirical. Overall, the confidence that this content fits under 'Enterprise Agility' is low, as it does not address the broader organisational, cultural, or leadership aspects required by the category.",
    "level": "Ignored"
  },
  "Working Software": {
    "resourceId": "oRStCAqLAY4",
    "category": "Working Software",
    "calculated_at": "2025-05-07T13:00:49",
    "ai_confidence": 19.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 6.0,
    "ai_signal": 5.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content is a detailed technical case study about automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site. While it thoroughly discusses automation, scripting, and the architecture of a classification system, it does not directly mention or focus on 'working software' as defined in the Agile/Scrum context. There are no explicit references to working software as an artifact, nor is there discussion of iterative delivery, increments, or value delivery to customers through software. The main intent is to describe a content management automation process, not to deliver or discuss working, high-quality software increments. The audience is technical and the content is focused, but the conceptual alignment and depth regarding 'working software' are low. The signal-to-noise ratio is moderate, as the content is relevant to automation and scripting but not to the core category. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence that this content fits under 'Working Software' is low.",
    "level": "Ignored"
  },
  "Agile Transformation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Transformation",
    "calculated_at": "2025-05-07T13:00:57",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.1,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. While the author briefly mentions their background, including experience with DevOps and Scrum, there are no direct or explicit references to Agile Transformation, its principles, or organisational change. The main focus is on technical automation, data architecture, and human-AI collaboration for content management. There is no discussion of Agile frameworks, change management, leadership in transformation, or organisational agility. The audience is primarily technical practitioners interested in automation and content management, not those seeking guidance on Agile Transformation. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant category. No penalties were applied, as the content is current and not critical of Agile. Overall, the content does not fit the Agile Transformation category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Experimentation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Experimentation",
    "calculated_at": "2025-05-07T13:01:05",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.6,
    "ai_intent": 2.8,
    "ai_audience": 4.1,
    "ai_signal": 3.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. While it thoroughly discusses automation, classification, and the integration of AI with human oversight, it does not directly or indirectly address experimentation as defined by the category. There are no explicit or implicit references to hypothesis-driven approaches, systematic testing of ideas, or validation of assumptions within Agile workflows. The main focus is on technical implementation, data architecture, and process automation, not on running experiments, analysing results, or iterating based on findings. The audience is technical (developers, site maintainers), which partially overlaps with the experimentation category, but the intent and depth are not aligned with experimentation in Agile. The signal-to-noise ratio is moderate, as the content is focused but not on the target topic. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence score is low, reflecting the lack of conceptual and direct alignment with the Experimentation category.",
    "level": "Ignored"
  },
  "Systems Thinking": {
    "resourceId": "oRStCAqLAY4",
    "category": "Systems Thinking",
    "calculated_at": "2025-05-07T13:01:12",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.8,
    "ai_intent": 3.5,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on the technical and process aspects of automating blog post classification using generative AI and scripting, with an emphasis on human oversight and auditability. There are no direct mentions of 'Systems Thinking' or its foundational principles, nor are there references to its key tools (e.g., causal loop diagrams, system dynamics) or frameworks (e.g., Cynefin, Soft Systems Methodology). While the author describes a multi-level classification structure (concepts, categories, tags) and discusses interconnectedness in the context of taxonomy, this is primarily a data architecture and automation discussion, not a holistic analysis of organisational systems or complex interdependencies as defined by Systems Thinking. The intent is to inform technical practitioners about AI-driven content management, not to explore or apply Systems Thinking methodologies. The audience is technical (bloggers, developers, process consultants), which partially overlaps with Systems Thinking practitioners, but the content is not tailored to strategists or organisational change agents. The signal-to-noise ratio is moderate: the content is focused, but its relevance to Systems Thinking is tangential at best. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence score is low, reflecting minimal conceptual alignment and depth regarding Systems Thinking.",
    "level": "Ignored"
  },
  "Product Validation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Validation",
    "calculated_at": "2025-05-07T13:01:19",
    "ai_confidence": 23.7,
    "ai_mentions": 0.4,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 8.1,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts, with an emphasis on technical architecture, data structures, and human oversight. There are no direct mentions of product validation or its key methodologies (user testing, market fit, prototyping, customer feedback loops, A/B testing, Lean Startup, or evidence-based management). The main conceptual alignment is weak: while the content discusses validation in the sense of ensuring accurate classification and traceability, this is about metadata and content management, not validating product ideas with real users or market needs. The depth of discussion is substantial, but it is technical and process-oriented, not about product validation practices. The intent is to inform technical practitioners about automating content classification, not to explore or teach product validation. The audience is technical (developers, site owners), which partially overlaps with product validation practitioners, but the focus is not on product validation. The signal-to-noise ratio is high, as the content is focused and relevant to its own topic, but not to product validation. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence score is low, reflecting that the content does not fit the 'Product Validation' category.",
    "level": "Ignored"
  },
  "Agile Planning": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Planning",
    "calculated_at": "2025-05-07T13:01:25",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.8,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of Agile Planning, nor are Agile methodologies, principles, or practices discussed. The main focus is on information architecture, automation, and human-AI collaboration for content management. While the author briefly references their background in DevOps and Scrum, these are only mentioned in passing and not explored in the context of Agile Planning. The content does not discuss sprints, backlogs, iterative planning, or any Agile frameworks or ceremonies. The intent is to inform technical practitioners about automating classification, not to guide or support Agile Planning. The audience is technical (blog owners, developers, automation enthusiasts), not specifically Agile practitioners or planners. The signal-to-noise ratio is moderate, as the content is focused but not on the Agile Planning topic. No penalties were applied, as the content is current and not critical of Agile. Overall, the content has minimal conceptual overlap with Agile Planning, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Open Space Agile": {
    "resourceId": "oRStCAqLAY4",
    "category": "Open Space Agile",
    "calculated_at": "2025-05-07T13:01:32",
    "ai_confidence": 13.7,
    "ai_mentions": 0.0,
    "ai_alignment": 2.0,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.2,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of Open Space Agile or Open Space Technology, nor are there references to Agile transformation, psychological safety, co-creation, or emergence as defined in the category. The main themes are automation, human oversight, and technical architecture for content management, which do not conceptually align with Open Space Agile. The depth of discussion is high, but it is focused entirely on AI-driven classification and workflow automation, not on organisational agility or collaborative change processes. The intent is to inform technical practitioners about AI-powered content management, not to discuss or promote Open Space Agile. The audience is technical (blog owners, developers, automation enthusiasts), not those interested in Agile transformation or organisational change. The signal-to-noise ratio is high for its own topic, but almost entirely off-topic for Open Space Agile. No penalties were applied, as the content is not outdated or critical of the category, but the confidence score is very low due to a lack of relevance.",
    "level": "Ignored"
  },
  "Portfolio Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Portfolio Management",
    "calculated_at": "2025-05-07T13:01:48",
    "ai_confidence": 18.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 1.8,
    "ai_audience": 6.0,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate tagging and categorisation of blog posts in Hugo. There are no direct mentions of portfolio management, nor are its core concepts (such as strategic alignment of projects, investment prioritisation, value stream optimisation, or portfolio-level risk management) discussed. The main focus is on content classification, metadata management, and technical automation, not on managing a portfolio of projects or aligning execution with organisational strategy. The depth of discussion is substantial, but it is entirely about content management and AI-assisted classification, not portfolio management. The intent is to inform technical practitioners about automating editorial workflows, not to address portfolio management concerns. The audience is technical (blog owners, developers, automation enthusiasts), which only partially overlaps with the typical portfolio management audience (executives, strategists, PMO leads). The signal-to-noise ratio is high for its actual topic, but almost none of the content is relevant to portfolio management. Therefore, the confidence that this content fits under the 'Portfolio Management' category is very low.",
    "level": "Ignored"
  },
  "Decision Theory": {
    "resourceId": "oRStCAqLAY4",
    "category": "Decision Theory",
    "calculated_at": "2025-05-07T13:01:57",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.1,
    "ai_intent": 3.5,
    "ai_audience": 5.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content primarily focuses on the technical and process aspects of automating blog post tagging and categorisation using generative AI and PowerShell scripts. There is a strong emphasis on workflow automation, data architecture, and the integration of AI for classification, with human oversight and auditability. While the post discusses 'classification decisions', 'penalty logic', and 'probabilistic suggestions', these are framed in the context of content management and technical implementation, not as an exploration of decision theory as defined (i.e., the study of decision-making under uncertainty, heuristics, probability, or behavioural economics). There are no direct mentions of decision theory, nor are its core concepts (such as heuristics, risk assessment, or decision-making frameworks) discussed in depth. The intent is to inform technical practitioners about automating editorial processes, not to analyse or improve decision-making under uncertainty. The audience is technical (bloggers, developers, site maintainers), which only partially overlaps with the typical decision theory audience. The signal-to-noise ratio is moderate, as the content is focused but not on decision theory. No penalties were applied, as the content is current and not contradictory. Overall, the confidence score is low, reflecting only a tangential and superficial connection to decision theory through the use of terms like 'decision', 'penalty', and 'probabilistic', but without substantive alignment to the category.",
    "level": "Ignored"
  },
  "Empirical Process Control": {
    "resourceId": "oRStCAqLAY4",
    "category": "Empirical Process Control",
    "calculated_at": "2025-05-07T13:02:07",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.2,
    "ai_audience": 6.0,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily focuses on the technical and architectural implementation of generative AI and scripting to automate tagging and categorisation in a Hugo-based blog. While there are some tangential references to transparency, auditability, and human oversight—concepts that are adjacent to empirical process control—the content does not directly discuss empirical process control, its principles, or its application within Agile, Scrum, or related frameworks. There are no explicit mentions of empirical process control, nor are its core practices (transparency, inspection, adaptation) explored in depth or within the context of Agile methodologies. The main intent is to share a technical solution for content management, not to inform or guide on empirical process control. The audience is technical practitioners, which partially overlaps with the category, but the signal-to-noise ratio is moderate as most of the content is about automation, scripting, and AI integration rather than empirical process control. No penalties were applied as the content is current and not critical of the category. Overall, the confidence score is low, reflecting only a loose conceptual alignment and minimal direct relevance to the category.",
    "level": "Tertiary"
  },
  "Application Lifecycle Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Application Lifecycle Management",
    "calculated_at": "2025-05-07T13:02:15",
    "ai_confidence": 36.7,
    "ai_mentions": 0.8,
    "ai_alignment": 3.2,
    "ai_depth": 3.7,
    "ai_intent": 3.0,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site. While it discusses lifecycle-like processes (e.g., migration, automation, auditability, and maintenance of content metadata), it does not directly address the management of software applications across their full lifecycle as defined by Application Lifecycle Management (ALM). There are no explicit mentions of ALM, its methodologies, or its core practices such as application governance, compliance, or risk management. The technical depth is substantial but is centred on content management and classification automation, not on application lifecycle stages or ALM tools/frameworks. The intent is to inform about a content classification system, not to guide or support ALM practitioners. The audience is technical but more aligned with content managers, site owners, or automation enthusiasts rather than ALM professionals. The signal-to-noise ratio is moderate, as the content is focused but not on the ALM topic. No penalties were applied as the content is current and not satirical or critical of ALM. Overall, the confidence score is low, reflecting that the content is tangential and does not fit the ALM category.",
    "level": "Ignored"
  },
  "Daily Scrum": {
    "resourceId": "oRStCAqLAY4",
    "category": "Daily Scrum",
    "calculated_at": "2025-05-07T13:02:20",
    "ai_confidence": 7.2,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.3,
    "ai_intent": 0.5,
    "ai_audience": 1.0,
    "ai_signal": 0.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. While the author briefly mentions their background, including experience with Scrum, there are no direct or indirect references to the Daily Scrum event, its structure, purpose, or best practices. The main focus is on content management, automation, and AI-human collaboration for editorial workflows. There is no discussion of Scrum events, team meetings, or agile ceremonies. The intended audience is technical practitioners interested in automation and content management, not specifically Scrum teams or Daily Scrum participants. The signal-to-noise ratio is high for its actual topic, but entirely unrelated to the Daily Scrum category. Therefore, the confidence score is extremely low, reflecting only the faintest possible conceptual overlap (the author's background in Scrum) and no substantive relevance to the Daily Scrum category.",
    "level": "Ignored"
  },
  "Agile Frameworks": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Frameworks",
    "calculated_at": "2025-05-07T13:02:26",
    "ai_confidence": 18.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.0,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 5.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. While there are brief references to Agile-related terms (e.g., 'Scrum', 'process consultant', 'Technical Leadership', 'Product Development'), these are only mentioned as examples of categories or tags within the author's taxonomy. There is no substantive discussion of Agile frameworks, their principles, comparative analysis, implementation challenges, or organisational impact. The main focus is on automation, data architecture, and human-AI collaboration in content management, not on Agile frameworks themselves. The audience is technical and process-oriented, which partially overlaps with Agile practitioners, but the content is not targeted at those seeking insights into Agile frameworks. The signal-to-noise ratio is moderate, as most content is relevant to the technical automation topic, not Agile frameworks. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence that this content fits under 'Agile Frameworks' is very low.",
    "level": "Ignored"
  },
  "Minimum Viable Product": {
    "resourceId": "oRStCAqLAY4",
    "category": "Minimum Viable Product",
    "calculated_at": "2025-05-07T13:02:35",
    "ai_confidence": 23.85,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 8.0,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate and improve tagging and categorisation in a Hugo-based blog. There is no direct mention of 'Minimum Viable Product' (MVP), nor is the concept of MVP, as defined in the classification, discussed or implied. The main focus is on automation, AI-human collaboration, and content management workflows, not on building or iterating a product to test market assumptions. While the content does discuss iterative improvement and technical strategies, these are in the context of site taxonomy and classification, not MVP development or validation. The audience (technical practitioners, developers) overlaps with those interested in MVPs, but the subject matter is not aligned. The signal-to-noise ratio is high, as the content is focused and relevant to its stated purpose, but that purpose is not MVP-related. No penalties were applied, as the content is current and not critical of the MVP concept. Overall, the confidence that this content fits under the 'Minimum Viable Product' category is very low.",
    "level": "Ignored"
  },
  "Test Driven Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Test Driven Development",
    "calculated_at": "2025-05-07T13:02:41",
    "ai_confidence": 8.7,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 1.0,
    "ai_audience": 1.2,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content does not mention Test Driven Development (TDD) directly or indirectly. Its focus is on using generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo, with an emphasis on human oversight and auditability. There are no references to the TDD cycle, writing tests before code, or any TDD-related practices, tools, or challenges. The main intent is to describe a technical workflow for content classification, not software development methodology. The audience is technical, but not specifically practitioners of TDD. The signal-to-noise ratio is low for this category, as all discussion is off-topic with respect to TDD. No penalties were applied, as the content is not outdated or critical of TDD; it is simply unrelated.",
    "level": "Ignored"
  },
  "Common Goals": {
    "resourceId": "oRStCAqLAY4",
    "category": "Common Goals",
    "calculated_at": "2025-05-07T13:02:49",
    "ai_confidence": 36.85,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.6,
    "ai_intent": 3.0,
    "ai_audience": 4.1,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study about automating blog post tagging and categorisation using generative AI and PowerShell scripts. It focuses on improving editorial consistency, discoverability, and traceability in content management. While the post discusses alignment of tags and categories and the importance of human accountability versus AI agency, it does not directly address the concept of Common Goals as defined in Agile or DevOps contexts. There are no explicit mentions of Common Goals, nor is there substantive discussion of aligning strategy with execution, shared objectives, or frameworks like OKRs. The main intent is technical process improvement for personal content management, not organisational goal alignment. The audience is technical (bloggers, developers, automation enthusiasts), which partially overlaps with the category's audience but is not a direct match. The signal-to-noise ratio is moderate, as the content is focused but not on the core topic of Common Goals. Overall, the content only tangentially touches on themes of alignment and accountability, resulting in a low confidence score for this category.",
    "level": "Ignored"
  },
  "Agentic Agility": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agentic Agility",
    "calculated_at": "2025-05-07T13:02:59",
    "ai_confidence": 67.2,
    "ai_mentions": 3.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.0,
    "ai_audience": 7.5,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 67.0,
    "reasoning": "The content provides a detailed account of integrating generative AI into a blog's classification workflow, with a strong emphasis on maintaining human oversight and accountability. There are explicit references to agency, such as the statement that 'AI systems have agency, but it is limited to tactical optimisation' and that 'AI here has no editorial authority.' The distinction between human and AI agency is discussed, aligning with the Agentic Agility category's focus on intentional, adaptive action and the importance of accountability. The content explores the mechanisms by which AI suggestions are validated and controlled by deterministic, human-authored rules, which resonates with the category's themes of agency, adaptive action, and the interplay between human and AI roles. However, the primary focus is on technical implementation and workflow automation, with Agentic Agility serving as a supporting concept rather than the central theme. The discussion of agency is meaningful and non-trivial, but it is not the main subject; rather, it is woven into the broader narrative about responsible AI use in content management. The audience is technical practitioners interested in automation, AI, and workflow optimisation, which aligns well with the intended audience for Agentic Agility. The content is focused and relevant, with minimal off-topic material. No penalties were applied, as the content is current, respectful of the category's framing, and does not reference obsolete practices. The confidence score reflects a strong but not primary alignment with Agentic Agility, acknowledging the depth and relevance of the agency discussion while recognising that it is not the sole or dominant focus.",
    "level": "Secondary"
  },
  "Mentoring": {
    "resourceId": "oRStCAqLAY4",
    "category": "Mentoring",
    "calculated_at": "2025-05-07T13:03:05",
    "ai_confidence": 18.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 6.2,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of mentoring, coaching, or related concepts. The main themes are technical automation, data architecture, and workflow optimisation, not the development of skills, behaviours, or leadership in Agile or Scrum contexts. While the author briefly references their own professional journey (from web developer to process consultant), this is background and not a discussion of mentoring or professional growth strategies. The intent is to inform technically-minded readers about a classification system, not to provide guidance or coaching for agile professionals. The audience is likely technical practitioners or content managers, not those seeking mentoring or leadership development. The signal-to-noise ratio is moderate, as the content is focused but entirely off-topic for the mentoring category. No penalties were applied, as the content is current and not critical or satirical. Overall, the content does not fit the 'Mentoring' category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Unrealised Value": {
    "resourceId": "oRStCAqLAY4",
    "category": "Unrealised Value",
    "calculated_at": "2025-05-07T13:03:12",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 8.0,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of 'Unrealised Value' or Evidence-Based Management, nor are the core concepts of identifying untapped organisational value, market demand, or innovation potential discussed. The main focus is on technical implementation, workflow automation, and editorial control, not on measuring or strategising around potential value capture. While the content is thorough and well-aligned for a technical or practitioner audience, its intent and depth are not relevant to the Unrealised Value category. The only tangential alignment is in the improvement of content discoverability, which could, in a very broad sense, relate to unlocking value, but this is not framed or explored in the context of Unrealised Value as defined. The signal-to-noise ratio is moderate, as the content is focused but not on the target topic. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence that this content fits the 'Unrealised Value' category is very low.",
    "level": "Ignored"
  },
  "Throughput": {
    "resourceId": "oRStCAqLAY4",
    "category": "Throughput",
    "calculated_at": "2025-05-07T13:03:21",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 4.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of 'throughput' as a delivery metric, nor is there any discussion of measuring, analysing, or visualising the number of work items completed over time. The main themes are automation, classification, editorial consistency, and human oversight in content management. While there is some technical depth regarding the architecture and process, none of it aligns with the core meaning of 'Throughput' as defined in the classification. The intent is to inform about AI-driven classification, not to discuss delivery metrics or system performance. The audience is technical (bloggers, developers, content managers), but not specifically those interested in throughput as a metric. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the 'Throughput' category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence that this content fits under 'Throughput' is very low.",
    "level": "Ignored"
  },
  "Evidence Based Leadership": {
    "resourceId": "oRStCAqLAY4",
    "category": "Evidence Based Leadership",
    "calculated_at": "2025-05-07T13:03:27",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.0,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and scripting to automate and improve blog post tagging and categorisation, with a strong emphasis on human oversight, auditability, and transparent decision-making. While it discusses the use of empirical, data-driven methods (such as multi-factor scoring, penalty logic, and audit trails) to inform content management decisions, it does not directly address leadership or organisational decision-making. There are no explicit mentions of 'Evidence Based Leadership' or its core frameworks (e.g., Evidence-Based Management, KPIs for leadership, or leadership case studies). The main audience appears to be technical practitioners or content managers rather than organisational leaders. The intent is to share a technical solution for content classification, not to inform or enhance leadership practices. However, the content does touch on some principles that are adjacent to evidence-based leadership, such as the importance of traceability, accountability, and data-driven decision-making, but these are applied to content management rather than leadership. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the content is only tangentially related to Evidence Based Leadership, resulting in a low-to-moderate confidence score.",
    "level": "Tertiary"
  },
  "Working Agreements": {
    "resourceId": "oRStCAqLAY4",
    "category": "Working Agreements",
    "calculated_at": "2025-05-07T13:03:31",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 2.0,
    "ai_audience": 3.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on automating blog post tagging and categorisation using generative AI and PowerShell scripts. There are no direct mentions of 'working agreements' or related team norms, nor is there any discussion of team collaboration principles, Agile/Scrum working agreements, or methods for establishing team norms. The main focus is on technical architecture, automation, and editorial control, not on team-based agreements or collaborative practices. The audience is technical practitioners interested in automation and content management, not teams seeking to improve collaboration through working agreements. The signal-to-noise ratio is low for this category, as nearly all content is off-topic for 'Working Agreements.' No penalties were applied, as the content is not outdated or satirical, but the fit is extremely weak, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Employee Engagement": {
    "resourceId": "oRStCAqLAY4",
    "category": "Employee Engagement",
    "calculated_at": "2025-05-07T13:03:37",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 4.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of employee engagement, nor are there discussions of motivation, commitment, team dynamics, or any of the psychological or social aspects central to the Employee Engagement category. The main themes are technical automation, data architecture, and workflow optimisation, with a focus on content management rather than people management. The depth of discussion is substantial, but it is entirely technical and process-oriented, not aligned with employee engagement concepts. The intended audience is technical practitioners interested in automation and AI integration, not HR professionals, leaders, or those focused on team motivation. The signal-to-noise ratio is high for its technical purpose, but nearly all content is off-topic for Employee Engagement. No penalties were applied, as the content is current and not satirical or critical of the category. The low confidence score reflects the near-total lack of relevance to Employee Engagement.",
    "level": "Ignored"
  },
  "Lean Product Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lean Product Development",
    "calculated_at": "2025-05-07T13:03:42",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.7,
    "ai_intent": 3.5,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on the use of generative AI and scripting to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses process optimisation, automation, and continuous improvement in content management, it does not directly mention Lean Product Development or its core principles. There are no explicit references to Lean Thinking, waste elimination, value stream mapping, or customer feedback loops as applied to product development. The main ideas are more aligned with technical automation, editorial workflow, and responsible AI use rather than Lean Product Development. The depth of discussion is substantial regarding technical architecture and process, but not in the context of Lean Product Development. The intent is to inform about a technical solution for content classification, not to educate or guide on Lean Product Development practices. The audience is likely technical practitioners interested in automation and AI, which partially overlaps with Lean audiences but is not a direct match. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied as the content is current and does not contradict the category, but overall, the fit is weak, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Psychological Safety": {
    "resourceId": "oRStCAqLAY4",
    "category": "Psychological Safety",
    "calculated_at": "2025-05-07T13:03:47",
    "ai_confidence": 8.7,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.4,
    "ai_intent": 0.6,
    "ai_audience": 0.8,
    "ai_signal": 0.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of 'psychological safety' or any of its synonyms. The main themes are automation, AI-human collaboration, data architecture, and technical implementation. While there is a brief emphasis on human oversight, accountability, and transparency, these are framed in the context of content management and responsible AI use, not in terms of fostering a psychologically safe environment for teams. There is no discussion of team dynamics, risk-taking, open communication, or any of the key topics outlined in the psychological safety category definition. The intended audience is technical practitioners interested in automation and AI, not those seeking guidance on psychological safety in teams. The content is highly focused on its technical subject, with no tangential or off-topic material, but it is not relevant to psychological safety. Therefore, the confidence score is extremely low, reflecting only the most remote conceptual overlap (e.g., human accountability), which is incidental and not aligned with the category.",
    "level": "Ignored"
  },
  "Value Delivery": {
    "resourceId": "oRStCAqLAY4",
    "category": "Value Delivery",
    "calculated_at": "2025-05-07T13:03:51",
    "ai_confidence": 38.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.9,
    "ai_intent": 3.8,
    "ai_audience": 5.2,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content primarily details the technical and editorial process of automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site. Direct mentions of 'value delivery' or its synonyms are absent, and the focus is on content management, automation, and traceability rather than on strategies for delivering value to customers in Agile, Scrum, or DevOps contexts. While there are tangential references to improving discoverability, editorial consistency, and reducing manual labour, these are framed as benefits to the site owner and readers, not as part of a structured value delivery methodology. The discussion of iterative improvement and auditability is technical and process-oriented, not explicitly tied to customer value or business agility. The audience appears to be technical practitioners interested in automation and content management, not specifically those focused on value delivery in Agile or DevOps. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting the lack of direct relevance to the Value Delivery category.",
    "level": "Ignored"
  },
  "Self Organisation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Self Organisation",
    "calculated_at": "2025-05-07T13:03:57",
    "ai_confidence": 38.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 5.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content primarily focuses on the technical and architectural implementation of generative AI and scripting to automate blog post tagging and categorisation. There is a strong emphasis on human oversight, accountability, and the distinction between AI agency and human decision-making. While these themes tangentially touch on concepts like autonomy and responsibility, which are relevant to self-organisation, the discussion is not situated within the context of team dynamics, Agile, or Scrum frameworks. There are no direct mentions of self-organisation, nor are there explorations of fostering team autonomy, leadership support for self-organising teams, or Agile principles. The main audience appears to be technical practitioners interested in automation and content management, not specifically those seeking to understand or implement self-organisation in teams. The depth of discussion around self-organisation is minimal; any alignment is incidental rather than intentional. The signal-to-noise ratio is moderate, as the content is focused but not on the self-organisation topic. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting the lack of direct relevance to the 'Self Organisation' category.",
    "level": "Ignored"
  },
  "Cell Structure Design": {
    "resourceId": "oRStCAqLAY4",
    "category": "Cell Structure Design",
    "calculated_at": "2025-05-07T13:04:04",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 2.0,
    "ai_audience": 3.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate tagging and categorisation in a personal blog using Hugo. There are no direct mentions of Cell Structure Design, the Beta Codex, or any of the core principles or terminology associated with the category. The conceptual alignment is extremely weak: while the content discusses decentralisation of decision-making between AI and human oversight, this is in the context of content classification, not organisational design or autonomous cells. The depth of discussion is focused entirely on technical implementation, not on organisational models or network-based structures. The intent is to inform about AI-powered content management, not to explore or advocate for Cell Structure Design. The audience is technical (bloggers, developers, automation enthusiasts), not organisational designers or strategists. The signal-to-noise ratio is low for this category, as nearly all content is off-topic. No penalties were applied, as the content is not outdated or critical of the category, but the fit is extremely poor, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Acceptance Test Driven Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Acceptance Test Driven Development",
    "calculated_at": "2025-05-07T13:04:09",
    "ai_confidence": 7.6,
    "ai_mentions": 0.0,
    "ai_alignment": 0.3,
    "ai_depth": 0.2,
    "ai_intent": 0.5,
    "ai_audience": 0.5,
    "ai_signal": 0.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell scripts to automate and improve tagging and categorisation in a Hugo-based blog. There are no direct mentions of Acceptance Test Driven Development (ATDD), nor are there references to acceptance criteria, stakeholder collaboration, or any of the core principles or practices of ATDD. The main focus is on content classification, automation, and human oversight in the context of blog management, not software feature development or acceptance testing. The audience is technical, but not specifically practitioners of ATDD or related methodologies. The signal-to-noise ratio is high for its actual topic, but entirely unrelated to ATDD. No penalties were applied as the content is not outdated or critical of ATDD; it is simply off-topic. The extremely low confidence score reflects the near-total lack of relevance to the ATDD category.",
    "level": "Ignored"
  },
  "Coaching": {
    "resourceId": "oRStCAqLAY4",
    "category": "Coaching",
    "calculated_at": "2025-05-07T13:04:14",
    "ai_confidence": 19.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 6.2,
    "ai_signal": 6.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of coaching, nor are there references to coaching techniques, roles, or mindsets. The main themes are automation, classification, technical architecture, and human oversight in content management. While the author discusses the importance of human accountability and oversight, this is framed in the context of editorial control and responsible AI use, not in the context of coaching, mentoring, or facilitating growth in teams or individuals. The audience is technical practitioners interested in automation and content management, not those seeking guidance on coaching practices. The signal-to-noise ratio is high for its intended topic, but the content is almost entirely unrelated to coaching as defined. No penalties were applied, as the content is current and not critical or satirical. The low confidence score reflects the near-total lack of conceptual or practical overlap with the Coaching category.",
    "level": "Ignored"
  },
  "Windows": {
    "resourceId": "oRStCAqLAY4",
    "category": "Windows",
    "calculated_at": "2025-05-07T13:04:19",
    "ai_confidence": 23.35,
    "ai_mentions": 2.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.7,
    "ai_audience": 6.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "Direct mentions of Windows are minimal: the only explicit reference is the author's statement 'I'm a Windows user and have been for years, so I wrote all of the scripting in PowerShell.' This is a passing mention and not a focus of the content. Conceptual alignment is weak; the main themes are about automating blog post classification using generative AI, Hugo, and PowerShell, not about Windows OS installation, configuration, troubleshooting, or management. The depth of discussion regarding Windows is negligible—the content does not explore Windows-specific features, issues, or best practices. The intent is to share a technical workflow for content classification, not to inform or support users in managing Windows environments. The audience is technical, which partially overlaps with the Windows category, but the focus is on content creators and automation enthusiasts rather than Windows administrators or users. The signal-to-noise ratio is low for the Windows category, as the vast majority of the content is off-topic for Windows. No penalties were applied, as the content is not outdated or satirical. Overall, the confidence score is low, reflecting the lack of substantive connection to the Windows category.",
    "level": "Ignored"
  },
  "GitHub": {
    "resourceId": "oRStCAqLAY4",
    "category": "GitHub",
    "calculated_at": "2025-05-07T13:04:26",
    "ai_confidence": 13.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.0,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 2.5,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a detailed technical narrative about automating blog post tagging and categorisation in Hugo using generative AI and PowerShell. There is a single, brief mention of GitHub: 'all of my code is in GitHub where it can be versioned, branched, and reviewed with a PR.' However, this is a passing reference and not a focus of the discussion. The main themes are automation, AI integration, scripting, and content management, not GitHub's services, features, or best practices. There is no exploration of GitHub Actions, CI/CD, collaboration features, or project management within GitHub. The audience is technical, but the content is not aimed at GitHub practitioners or those seeking GitHub-specific guidance. The signal-to-noise ratio is low for the GitHub category, as nearly all content is off-topic for this classification. No penalties were applied, as the content is current and not critical of GitHub, but the confidence score is very low due to minimal relevance.",
    "level": "Ignored"
  },
  "Organisational Change": {
    "resourceId": "oRStCAqLAY4",
    "category": "Organisational Change",
    "calculated_at": "2025-05-07T13:04:35",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study about automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo-based static site. It focuses on the architecture, data structures, and workflow for classification, with an emphasis on human oversight and auditability. \n\nDirect Mentions (0.6): There are no explicit references to 'Organisational Change' or its frameworks, nor are there direct mentions of change management, agility, or related terminology. The only tangential connection is the use of the word 'transformation' in the context of site management, not organisational transformation.\n\nConceptual Alignment (2.2): The main ideas revolve around technical automation, AI-assisted classification, and editorial workflow improvements for a personal blog. While there is a process of change (moving platforms, improving workflows), it is not organisational in scope or intent. There is no discussion of organisational agility, resilience, or change management methodologies.\n\nDepth of Discussion (2.5): The content is thorough in its technical depth but does not explore organisational change concepts, frameworks, or practices. The discussion is limited to the technical and editorial domain, not organisational transformation.\n\nIntent / Purpose Fit (2.0): The primary intent is to share a technical solution for content management, not to inform or support organisational change initiatives. Any overlap is incidental and not the main purpose.\n\nAudience Alignment (3.1): The target audience is technical practitioners, bloggers, and developers interested in automation and AI for content management, not organisational leaders, change agents, or strategists.\n\nSignal-to-Noise Ratio (2.8): The content is focused and relevant to its technical topic, but almost none of it is relevant to organisational change. The signal for the evaluated category is very low.\n\nNo penalties were applied, as the content is current, not satirical, and does not contradict the category's framing. Overall, the confidence score is low, reflecting that the content does not fit the 'Organisational Change' category beyond a superficial, coincidental process improvement.",
    "level": "Ignored"
  },
  "Scrum Master": {
    "resourceId": "oRStCAqLAY4",
    "category": "Scrum Master",
    "calculated_at": "2025-05-07T13:04:43",
    "ai_confidence": 13.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.0,
    "ai_depth": 1.8,
    "ai_intent": 2.0,
    "ai_audience": 2.5,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. While the author briefly mentions their career progression, including a period working with Scrum and process consulting, there is no substantive discussion of the Scrum Master accountability, its responsibilities, or its systemic impact. The only direct reference to 'Scrum' is in a list of categories and tags, and 'Scrum Mastery' appears as an example tag, but neither is explored in any depth. The main focus is on technical architecture, automation, and editorial workflow, not on the Scrum Master role or its unique accountability within Scrum. The audience is primarily technical content managers or developers, not Scrum Masters or those interested in Scrum Mastery as a discipline. The signal-to-noise ratio for the Scrum Master category is low, as nearly all content is off-topic for this classification. No penalties were applied, as the content is current and does not contradict the category's framing, but the confidence score is very low due to minimal relevance.",
    "level": "Ignored"
  },
  "System Configuration": {
    "resourceId": "oRStCAqLAY4",
    "category": "System Configuration",
    "calculated_at": "2025-05-07T13:04:49",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 5.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily discusses the use of generative AI and PowerShell scripting to automate and improve the tagging and categorisation of blog posts within a Hugo static site. While there are technical details about scripting, automation, and data architecture, the focus is on content classification, editorial consistency, and workflow optimisation for content management—not on system configuration as defined (i.e., setup and integration of software/hardware for optimal performance, configuration management, or system reliability). There are some tangential overlaps, such as automation practices (PowerShell scripts, audit trails, version control), but these are applied to content metadata rather than system-level configuration. The audience is technical, but the main intent is not to inform about system configuration tools, methodologies, or best practices. Direct mentions of system configuration are absent, and the conceptual alignment is limited. The depth of discussion is substantial for content classification and automation, but not for system configuration. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting that the content does not fit well under 'System Configuration' despite some technical overlap.",
    "level": "Tertiary"
  },
  "Continuous Improvement": {
    "resourceId": "oRStCAqLAY4",
    "category": "Continuous Improvement",
    "calculated_at": "2025-05-07T13:04:55",
    "ai_confidence": 67.6,
    "ai_mentions": 2.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.0,
    "ai_audience": 7.5,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "Direct mentions of 'Continuous Improvement' or its synonyms are minimal; the term itself is not explicitly referenced, and the focus is on technical automation and AI-driven classification. However, the conceptual alignment is moderately strong: the content describes an ongoing, iterative process of improving blog tagging and categorisation, leveraging automation, empirical feedback (audit trails, penalty logic), and human oversight. These are core aspects of continuous improvement, though the framing is more about technical optimisation than explicit process or team effectiveness. The depth of discussion is solid, with detailed explanations of architecture, validation, and future enhancements, but it is primarily technical rather than process-oriented. The intent is to share a method for improving a system over time, which fits the spirit of continuous improvement, though the main purpose is not to advocate for continuous improvement as a discipline. The audience is technical practitioners and content managers, which partially overlaps with the typical audience for continuous improvement (e.g., process consultants, agile teams). The signal-to-noise ratio is high, with most content relevant to the described system and its evolution. No penalties are applied, as the content is current, constructive, and not critical of the category. Overall, while the content embodies many principles of continuous improvement (iteration, feedback, measurable enhancement), it does so in a technical, site-specific context rather than as a primary subject, resulting in a moderate confidence score.",
    "level": "Secondary"
  },
  "Forecasting": {
    "resourceId": "oRStCAqLAY4",
    "category": "Forecasting",
    "calculated_at": "2025-05-07T13:05:04",
    "ai_confidence": 18.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 1.8,
    "ai_audience": 6.0,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of 'Forecasting' or related Agile/Scrum forecasting practices. The main themes are automation, classification, and content management, not empirical prediction, delivery timelines, or risk management. While the content discusses data-driven classification and the use of metrics for validation, these are not in the context of forecasting outcomes or optimising value delivery as defined in the category. The depth of discussion is substantial but focused on technical implementation, not forecasting methodologies. The intent is to inform practitioners about AI-powered classification, not to support or explore forecasting in Agile/Scrum. The audience (technical practitioners) partially overlaps with the category, but the signal-to-noise ratio is moderate since the content is highly relevant to automation and classification, not forecasting. No penalties were applied as the content is current and not critical of the category. Overall, the confidence score is low, reflecting minimal conceptual overlap with the 'Forecasting' category.",
    "level": "Ignored"
  },
  "Product Owner": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Owner",
    "calculated_at": "2025-05-07T13:05:12",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There is no direct mention of the Product Owner role or its accountability within Scrum or Agile frameworks. The only tangential reference is the author's career path, which briefly mentions moving through DevOps and Scrum to process consulting, but this is not elaborated upon and does not discuss Product Owner responsibilities, decision-making, or stakeholder management. The main themes are automation, human oversight, and technical architecture for content classification, not maximising product value or backlog prioritisation. The audience is technical practitioners interested in automation and content management, not specifically Product Owners or those interested in their accountability. The signal-to-noise ratio is low for the Product Owner category, as nearly all content is off-topic for this classification. No penalties were applied, as the content is not outdated or satirical, but the confidence score is very low due to lack of relevance.",
    "level": "Ignored"
  },
  "Practice": {
    "resourceId": "oRStCAqLAY4",
    "category": "Practice",
    "calculated_at": "2025-05-10T13:04:07",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.1,
    "ai_intent": 3.5,
    "ai_audience": 6.2,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on automating blog tagging and categorisation using generative AI and PowerShell, with an emphasis on technical implementation, auditability, and human oversight. While it references 'practices' in the context of classification and editorial standards, it does not discuss repeatable team techniques or actionable habits that improve team effectiveness, as defined by the Practice category. There are no direct mentions of key practices like retrospectives, TDD, or Kanban. The main audience is technical implementers, but the discussion is about system architecture and automation, not about team practices. The depth is moderate regarding automation and classification, but not on actionable team practices. The signal is somewhat diluted by technical details unrelated to Practice as defined.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Philosophy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Philosophy",
    "calculated_at": "2025-05-10T13:04:18",
    "ai_confidence": 54.7,
    "ai_mentions": 2.2,
    "ai_alignment": 5.7,
    "ai_depth": 5.9,
    "ai_intent": 5.5,
    "ai_audience": 7.1,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "Direct mentions of 'Philosophy' are minimal, appearing only as an example within a taxonomy structure, not as a discussion topic. The content's main focus is on technical implementation, automation, and editorial workflow, with only tangential references to philosophical concepts (e.g., human vs. AI agency, accountability). While there is some conceptual overlap—such as the distinction between human and AI roles, and the idea of foundational 'Concepts'—these are not explored in depth as philosophical frameworks. The depth of discussion is primarily technical and procedural, not theoretical. The intent is to inform about a technical solution, not to explore or advocate for philosophical underpinnings. The audience is likely to include strategists and technical leaders, which aligns somewhat with the Philosophy category, but the content is not targeted at those seeking philosophical discourse. The signal-to-noise ratio is high, as the content is focused and well-structured, but the focus is not on Philosophy. No penalties were applied as the content is current and not critical of the category.",
    "reasoning_summery": null,
    "level": "Tertiary"
  },
  "Capability": {
    "resourceId": "oRStCAqLAY4",
    "category": "Capability",
    "calculated_at": "2025-05-10T13:04:35",
    "ai_confidence": 41.6,
    "ai_mentions": 1.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.9,
    "ai_intent": 4.2,
    "ai_audience": 5.1,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and scripting. While it references 'capability' in a general sense and discusses building a robust, auditable classification system, it does not directly address organisational or team capabilities as defined in the category. The main themes are technical implementation, automation, and editorial control, not the enduring competencies or systemic capabilities that empower teams or organisations. There is some conceptual overlap in the sense of building a sustainable, repeatable process, but the discussion is largely about tooling, workflow, and personal site management. The audience is technical practitioners, but the depth and alignment with the Capability category are limited.",
    "reasoning_summery": null,
    "level": "Tertiary"
  },
  "Principle": {
    "resourceId": "oRStCAqLAY4",
    "category": "Principle",
    "calculated_at": "2025-05-10T13:04:49",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.1,
    "ai_intent": 3.5,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a technical case study on using generative AI and scripting to automate blog tagging and categorisation. While it references concepts like accountability, human oversight, and transparent decision-making, these are discussed as operational practices rather than as explicit, actionable principles guiding team behaviour. There is no direct or in-depth discussion of Agile, Lean, or DevOps principles, nor are foundational beliefs or guiding rules for decision-making explored. The main focus is on technical implementation, workflow automation, and system architecture, not on the principles that shape team conduct or decision-making. The audience is technical, but the content is not intended to teach or discuss principles as defined by the category. Any alignment is incidental and not the main purpose.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Framework": {
    "resourceId": "oRStCAqLAY4",
    "category": "Framework",
    "calculated_at": "2025-05-10T13:04:56",
    "ai_confidence": 23.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.1,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on using generative AI and scripting to automate tagging and categorisation in a personal blog, with a strong emphasis on technical implementation, human oversight, and auditability. While it references categories such as 'Scrum' and 'Kanban' as examples of editorial groupings, it does not discuss frameworks themselves, their principles, implementation strategies, or adaptation. There is no exploration of Agile, DevOps, or Lean frameworks, nor any comparison, best practices, or case studies related to frameworks. The main intent is to describe a technical solution for content classification, not to inform or guide on frameworks. The audience is primarily technical implementers interested in automation, not those seeking guidance on frameworks. The signal-to-noise ratio is low for the Framework category, as the content is focused on automation and AI, not frameworks.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Model": {
    "resourceId": "oRStCAqLAY4",
    "category": "Model",
    "calculated_at": "2025-05-10T13:05:05",
    "ai_confidence": 41.7,
    "ai_mentions": 2.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.9,
    "ai_intent": 4.5,
    "ai_audience": 5.1,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content focuses on the technical implementation of generative AI and scripting to automate tagging and categorisation in a blog, with a strong emphasis on workflow, automation, and human oversight. While it introduces a multi-level classification structure (Concepts, Categories, Tags) and discusses the architecture for AI-driven classification, it does not directly discuss or analyse conceptual models as defined in the category (e.g., Cynefin, Three Ways of DevOps, Lean Startup, Kanban flow models). The closest alignment is the mention of 'Concepts' as thematic anchors, but these are not explored as models for organisational decision-making or systems thinking. The main intent is technical enablement and process improvement, not the exploration or application of models in Agile, DevOps, or Lean contexts. The audience is technical practitioners interested in automation and content management, which partially overlaps with the category's audience but is not a direct match. The signal-to-noise ratio is moderate, with some relevant discussion of classification structures but little focus on models as conceptual frameworks.",
    "reasoning_summery": null,
    "level": "Tertiary"
  },
  "Observability": {
    "resourceId": "oRStCAqLAY4",
    "category": "Observability",
    "calculated_at": "2025-05-10T13:05:11",
    "ai_confidence": 36.7,
    "ai_mentions": 0.8,
    "ai_alignment": 3.2,
    "ai_depth": 3.7,
    "ai_intent": 3.5,
    "ai_audience": 4.1,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on using generative AI and scripting to automate and improve tagging and categorisation in a static site generator (Hugo). While it discusses technical automation, auditability, and transparency, it does not directly address observability as defined (measuring and understanding internal system states via metrics, logs, or traces). There are no explicit mentions of observability, nor does the content explore its principles, tools, or impact on team or business outcomes. The main audience is technical practitioners, but the topic is content management automation, not observability in software systems. The signal-to-noise ratio is moderate, as the content is focused but not on the target category.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Accountability": {
    "resourceId": "oRStCAqLAY4",
    "category": "Accountability",
    "calculated_at": "2025-05-10T13:05:22",
    "ai_confidence": 67.7,
    "ai_mentions": 4.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.0,
    "ai_audience": 6.2,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content directly discusses the distinction between AI agency and human accountability, explicitly stating that AI cannot 'own accountability' and that humans retain outcome ownership. It references accountability as a structural mechanism (e.g., 'deterministic enforcement', 'humans set direction and own accountability'), aligning with the category's definition. However, the main focus is on technical implementation of AI-driven classification and workflow automation, with accountability as a supporting theme rather than the central topic. The discussion of accountability is thoughtful and non-superficial, but not deeply explored in the context of organisational design or role-specific accountabilities. The audience is technical practitioners interested in automation and content management, which partially overlaps with the category's target. The content is focused, with minimal off-topic material, but the primary intent is not to analyse accountability as a work system mechanism. No penalties are warranted as the content is current and not critical of the accountability concept.",
    "reasoning_summery": null,
    "level": "Secondary"
  },
  "Strategy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Strategy",
    "calculated_at": "2025-05-10T13:05:28",
    "ai_confidence": 67.2,
    "ai_mentions": 3.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.5,
    "ai_audience": 7.0,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 67.0,
    "reasoning": "The content references 'technical strategy' and discusses high-level decisions about structuring site classification, blending automation with human oversight, and aligning taxonomies for editorial consistency. It describes a multi-layered classification system (concepts, categories, tags) and the rationale for these choices, which aligns with strategic thinking. However, the primary focus is on technical implementation and process improvement, not on organisational or business strategy. The discussion of 'Strategy' as a concept is present but not deeply explored in the context of organisational goal alignment or leadership. The audience is likely technical practitioners or site owners, not executive strategists. The content is focused and relevant, but the strategic dimension is more about system design than classic organisational strategy.",
    "reasoning_summery": null,
    "level": "Secondary"
  },
  "Discipline": {
    "resourceId": "oRStCAqLAY4",
    "category": "Discipline",
    "calculated_at": "2025-05-10T13:05:35",
    "ai_confidence": 54.7,
    "ai_mentions": 2.2,
    "ai_alignment": 5.8,
    "ai_depth": 6.1,
    "ai_intent": 5.5,
    "ai_audience": 6.0,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content focuses on the technical and editorial process of automating blog post classification using generative AI and PowerShell, with an emphasis on human oversight and traceability. While it references concepts like editorial standards, classification systems, and the importance of consistent principles, it does not directly discuss the systemic application, maturation, or governance of professional disciplines such as Agile, DevOps, or Lean. The main thrust is on workflow automation and content management, not on the evolution or characteristics of a discipline. There are some conceptual overlaps (e.g., continuous improvement, structured methodologies), but these are incidental rather than central. The audience is technical and process-oriented, but the discussion remains at the level of tooling and editorial practice rather than discipline theory or governance.",
    "reasoning_summery": null,
    "level": "Tertiary"
  },
  "Artifact": {
    "resourceId": "oRStCAqLAY4",
    "category": "Artifact",
    "calculated_at": "2025-05-10T13:05:47",
    "ai_confidence": 23.7,
    "ai_mentions": 0.7,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and scripting, with an emphasis on workflow, traceability, and editorial control. While it discusses the structure and management of tags, categories, and concepts, these are not formal Agile, Scrum, Lean, or DevOps artifacts as defined in the classification. There are no direct mentions of artifacts in the Agile sense, nor is there exploration of their role in transparency, empirical control, or evidence-based decision-making. The discussion is technical and process-oriented but does not align with the core meaning of 'Artifact' in Agile or Lean systems.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Tool": {
    "resourceId": "oRStCAqLAY4",
    "category": "Tool",
    "calculated_at": "2025-05-10T13:05:55",
    "ai_confidence": 87.7,
    "ai_mentions": 8.2,
    "ai_alignment": 9.1,
    "ai_depth": 8.7,
    "ai_intent": 8.5,
    "ai_audience": 8.0,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 88.0,
    "reasoning": "The content provides a detailed, technical account of integrating generative AI and PowerShell scripts to automate tagging and categorisation in Hugo, a static site generator. It directly discusses the use, architecture, and workflow impact of specific tools (Hugo, PowerShell, OpenAI, GitHub), aligning with the Tool category. The discussion is deep, covering implementation, auditability, and future enhancements, and is aimed at practitioners interested in workflow automation and tool integration. The content is highly focused, with minimal off-topic material, and the intent is to inform and guide on tool-based solutions for content management. No penalties were applied as the content is current, constructive, and fits the category well.",
    "reasoning_summery": null,
    "level": "Primary"
  },
  "Method": {
    "resourceId": "oRStCAqLAY4",
    "category": "Method",
    "calculated_at": "2025-05-10T13:06:04",
    "ai_confidence": 54.7,
    "ai_mentions": 2.2,
    "ai_alignment": 5.7,
    "ai_depth": 5.3,
    "ai_intent": 5.0,
    "ai_audience": 6.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content primarily details a technical workflow for automating blog post classification using generative AI and PowerShell scripts. While it references structured procedures (e.g., multi-layer classification, audit trails, penalty logic), these are not discussed as formal 'methods' in the Agile, Lean, or DevOps sense. There is some conceptual overlap with methodical approaches (e.g., deterministic validation, iterative improvements), but the main focus is on tooling, automation, and technical implementation rather than on step-by-step methods for process improvement or delivery. The audience is technical and process-oriented, but the discussion of 'method' is indirect and not central. The signal is strong for automation and classification, but only tangential for the Method category as defined.",
    "reasoning_summery": null,
    "level": "Tertiary"
  },
  "Tenet": {
    "resourceId": "oRStCAqLAY4",
    "category": "Tenet",
    "calculated_at": "2025-05-10T13:06:11",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.1,
    "ai_intent": 3.5,
    "ai_audience": 4.0,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on using generative AI and scripting to automate and improve blog tagging and categorisation, with an emphasis on human oversight and auditability. While it discusses principles like accountability, transparency, and blending automation with human judgment, these are not framed as actionable organisational tenets in the sense defined by the category. There are no direct mentions of tenets or prescriptive rules guiding organisational behaviour, nor is there a deep exploration of tenets within Agile, DevOps, Lean, or similar methodologies. The main intent is technical process improvement, not the application or discussion of tenets. The audience is technical practitioners, but the content is not structured around tenet-driven guidance. The signal-to-noise ratio is moderate, with some relevant discussion of principles but not in the context required for this category.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Ethos": {
    "resourceId": "oRStCAqLAY4",
    "category": "Ethos",
    "calculated_at": "2025-05-13T14:02:00",
    "ai_confidence": 38.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.9,
    "ai_intent": 4.2,
    "ai_audience": 5.1,
    "ai_signal": 5.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content primarily details a technical implementation of AI-driven tagging and categorisation for a blog, focusing on automation, auditability, and human oversight. While it briefly references 'ethos' in the context of human accountability versus AI agency, this is not the main theme. The discussion of foundational beliefs or system-level convictions is minimal and mostly implicit, with only a few sentences touching on the distinction between human and AI roles. The majority of the content is technical, describing scripts, data structures, and workflow improvements, rather than exploring ethos as the underpinning of sustainable delivery or authentic transformation. The audience is technical practitioners, and the signal-to-noise ratio is moderate, with some relevant reflections but mostly implementation details. No penalties were applied as the content is current and not satirical or critical.",
    "reasoning_summary": "This content is mainly a technical case study on AI-powered blog categorisation, with only brief, indirect references to ethos—mainly around human accountability. It does not deeply explore foundational beliefs or system-level convictions, so confidence for the 'Ethos' category is low.",
    "level": "Ignored"
  },
  "First Principal": {
    "resourceId": "oRStCAqLAY4",
    "category": "First Principal",
    "calculated_at": "2025-05-13T14:02:08",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.8,
    "ai_intent": 2.0,
    "ai_audience": 7.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell, with an emphasis on human oversight and auditability. While it discusses concepts like 'foundational ideas' and 'non-negotiable' distinctions between human and AI agency, it does not explicitly identify, explain, or apply first principles as defined in Lean, Agile, Scrum, or DevOps contexts. The main themes are technical implementation, editorial workflow, and responsible automation, not the articulation or application of first principles as immutable constraints. There are no direct mentions of 'first principles,' nor is there a substantive exploration of their role in system design or professional conduct. The audience and signal are reasonably aligned with technical practitioners, but the core content is not about first principles.",
    "reasoning_summary": "This content is about automating blog classification with AI and human oversight, not about identifying or applying first principles in Lean, Agile, Scrum, or DevOps. It lacks direct references or deep discussion of first principles, so confidence in this category is low.",
    "level": "Ignored"
  },
  "Customer Focus": {
    "resourceId": "oRStCAqLAY4",
    "category": "Customer Focus",
    "calculated_at": "2025-05-13T14:02:15",
    "ai_confidence": 27.6,
    "ai_mentions": 1.2,
    "ai_alignment": 2.8,
    "ai_depth": 3.1,
    "ai_intent": 2.5,
    "ai_audience": 4.0,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 28.0,
    "reasoning": "The content is a technical case study on using generative AI and scripting to automate blog tagging and categorisation. While it discusses improving discoverability and aligning tags/categories with user needs, it does not explicitly address defining, measuring, or prioritising customer outcomes as required by the Customer Focus category. The main focus is on editorial consistency, automation, and workflow optimisation for the author's own site, not on delivering measurable value to customers or establishing feedback loops with real users. There are no direct mentions of customer value, customer feedback, or outcome-driven development. The audience is technical practitioners, but the discussion is not anchored in customer-centric agile or DevOps philosophies.",
    "reasoning_summary": "This content focuses on automating blog tagging and categorisation using AI, with an emphasis on editorial standards and workflow efficiency. It lacks explicit discussion of customer outcomes, feedback, or value delivery, so it only weakly aligns with the Customer Focus category.",
    "level": "Ignored"
  },
  "Definition of Workflow": {
    "resourceId": "oRStCAqLAY4",
    "category": "Definition of Workflow",
    "calculated_at": "2025-05-23T22:06:14",
    "ai_confidence": 23.6,
    "ai_mentions": 0.4,
    "ai_alignment": 2.8,
    "ai_depth": 2.3,
    "ai_intent": 1.7,
    "ai_audience": 9.1,
    "ai_signal": 5.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on using AI and PowerShell scripts for blog post categorization and workflow automation within a Hugo site, describing the technical system and editorial taxonomy (Concepts, Categories, Tags), and emphasizing human oversight in AI-driven processes. However, it does not mention or explore the Definition of Workflow as defined in Kanban/agile contexts, nor does it address entry/exit policies, WIP limits, or similar agreements. While 'workflow' is mentioned, this refers to personal publishing or editorial processes rather than Kanban/DevOps workflow concepts. Audience aligns as technical practitioners, and signal is moderate, but there is no substantive discussion of Kanban-style Definition of Workflow.",
    "reasoning_summary": "This content describes a technical and editorial process for automating blog categorization with AI and human oversight. It does not explore the Definition of Workflow as defined in Kanban or agile contexts, and thus only minimally fits the category.",
    "level": "Ignored"
  },
  "Product Developer": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Developer",
    "calculated_at": "2025-06-23T09:02:06",
    "ai_confidence": 18.61,
    "ai_mentions": 0.4,
    "ai_alignment": 2.0,
    "ai_depth": 2.7,
    "ai_intent": 1.5,
    "ai_audience": 4.3,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content focuses on using generative AI and automation for content classification and tagging in a static blog platform. While there is brief mention of AI agency and accountability, it is within a technical implementation context rather than the Product Developer role as defined in agile frameworks. There are no direct references to Product Developer accountabilities, skills, or responsibilities, nor is there exploration of collective accountability, cross-functionality, or other key attributes tied to the Product Developer category. Therefore, the coverage is largely peripheral, with nearly all discussion targeted at technical system builders and content managers instead of product development teams or practitioners.",
    "reasoning_summary": "The content centers on AI-powered classification and tagging for blogs, not on the Product Developer role or accountability. It lacks direct references or thematic depth relevant to Product Developers in agile or product frameworks, resulting in a low confidence fit.",
    "level": "Ignored"
  },
  "Collective Intelligence": {
    "resourceId": "oRStCAqLAY4",
    "category": "Collective Intelligence",
    "calculated_at": "2025-06-23T09:01:49",
    "ai_confidence": 69.32,
    "ai_mentions": 3.7,
    "ai_alignment": 7.7,
    "ai_depth": 8.2,
    "ai_intent": 7.9,
    "ai_audience": 8.0,
    "ai_signal": 8.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 69.0,
    "reasoning": "The content discusses a human-AI collaborative workflow, emphasizing the complementary roles of generative AI and human oversight in blog content classification. There is explicit discussion about shared agency, traceability, deterministic human enforcement, and AI providing tactical suggestions rather than owning editorial decisions—directly referencing and aligning with the core themes of collective intelligence. It details how multi-factor assessments blend AI output and human judgment to achieve better results than either alone, and proposes further improvements to these hybrid workflows. However, 'collective intelligence' as a term is not directly mentioned and the scenario, while an exemplar of human-AI teaming, is focused on an individual practitioner context rather than a team-based socio-technical system. Thus, depth and alignment are high, intent and audience fit are strong, and the signal-to-noise ratio is excellent, but partial topical fit and indirectness in labeling slightly lower the mentions score.",
    "reasoning_summary": "The content offers a detailed case of practical human-AI collaboration, showcasing distributed accountability, shared agency, and combining human judgment with AI recommendations—a strong fit to collective intelligence in process, though not by explicit label and within a single-author context.",
    "level": "Secondary"
  },
  "Objective Key Results": {
    "resourceId": "oRStCAqLAY4",
    "category": "Objective Key Results",
    "calculated_at": "2025-06-23T09:01:55",
    "ai_confidence": 7.45,
    "ai_mentions": 0.1,
    "ai_alignment": 0.2,
    "ai_depth": 0.2,
    "ai_intent": 0.1,
    "ai_audience": 0.1,
    "ai_signal": 0.09,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content provides a detailed walkthrough of how generative AI and automation were used to overhaul tagging and categorization on a personal blog. There are in-depth discussions about classification, content organization, automation oversight, and multi-layered taxonomies (concepts, categories, tags), but there are no direct or indirect references to OKRs, their principles, theory, or practices. The system's scoring approach, mentioned as multi-factor with penalties, superficially resembles OKR-style measurement but is explicitly and exclusively focused on content classification—not outcome-driven strategic alignment or value realization. The content's main purpose is technical process improvement in content management, not structured objective setting, measurable key results, or iterative goal alignment. There is no discussion of John Doerr's OKR framework, nor are topics such as focus, alignment through transparency, outcome-based measurement, or OKR integration into Agile, Scrum, or DevOps explored.",
    "reasoning_summary": "This content is about leveraging AI to automate tagging and categorization in a blog, focusing on technical improvements to content management. It does not address OKRs, outcome-driven goal setting, or strategic alignment, so it falls entirely outside the intended OKR category.",
    "level": "Ignored"
  }
}