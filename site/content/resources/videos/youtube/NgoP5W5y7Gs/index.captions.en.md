Many companies make the mistake of treating security as an afterthought, doing security validation and security checks at the end of the process. This is not a small company problem; it's not a big company problem; it's an all-company problem. Some of the largest tech companies have resolved this with something you'll probably hear about in the Dora report, which is shift left. Shifting left means shifting everything as left as you can, as close to the developers and engineers as possible, to resolve these issues.

What has been happening is that we will do many years of work on a product—could be months, could be years, could be weeks. We do a whole bunch of work on a product and then we ship it to pen testing or someone who's going to do some security validation for your product, even if it's yourselves doing it. But you just do it at the end, and you find a whole bunch of problems. Some of those problems are going to be systemic to how you've built your product in the first place. In order to fix that, we're going to have to rearchitect.

If we're late in the game, we're ready to ship, and everybody's asking us when it's going live, we need to get out. We need to blue Peter the heck out of that, and we get out our super glue, our sticky tape, and we go figure out how to paper over the cracks in our product to prevent the hackers from getting in. The problem is that hackers are super good at peeling away the edges of those things to get underneath and gain access to your system and take it over.

I've been involved with some exercises that the Azure DevOps team did, where they hired a team of professional hackers. This is a red-blue exercise: hire a team of professional hackers, bring them in, and their job—the red team's job—is to hack the system. The blue team's job is to detect them and do something about them, either prevent them from getting in or push them out, or all of those things. The red team always wins. That's the thing you have to realise: eventually, the red team is always going to win. They're going to find a flaw; they're going to find ways to peel up that tape. The only way for you to prevent those things is to not have vulnerable code in the first place, not have vulnerable architectures in the first place. 

The only way to do that is to refactor the heck out of your system to make those things go away and then stop those things from happening in the first place. For example, the Azure DevOps team does these red-blue exercises, and the red team's job is to go around all of the teams in the organisation and show them how the red team was able to use their code to get access to the system and how they could have coded it differently or architected it differently or changed the way they do something in order to prevent hackers from getting in. That's security by design; that's security from the start; that's security baked into the problem.

This is true for a lot of different facets of software engineering: it's every team member's problem. What the business wants is every team member's problem. How much it's going to cost is every team member's problem. The customer's worries are every team member's problem, and security is every team member's problem. So building security in rather than testing it in, building quality in rather than testing it in, is about shifting left, getting as many of those skills that you need for your context into the hands of the developers that are doing the work.

There are a bunch of tools out there that can help with that. There’s SonarQube and SonarCloud, which enable your developers to analyse their code and find and hopefully deal with vulnerabilities. There are known vulnerabilities that happen in the code. You can also use GitHub, which has an advanced security protection system that you can use in GitHub or as part of Azure DevOps to again analyse the code, find problems, and poke at it. 

It's why, if you're a developer and you try to upload some code that has a PAT token or something that looks like a security token or a password into the system, you will be prevented from checking in that code, from committing that code, from the repo, from doing a push to production by GitHub and Azure DevOps, because the advanced threat protection is detecting that and preventing it from getting into the system in the first place. Shifting as far left as we possibly can to validate that those things are not going to cause vulnerabilities.

A really common vulnerability is developers on dev machines putting passwords in text files. On dev machines, there are all sorts of vectors that hackers can use. My advice is to help you within the context of shifting left and enabling your teams to have the knowledge and skills they need to be able to prevent and remove as many of these issues as possible before they become a problem.