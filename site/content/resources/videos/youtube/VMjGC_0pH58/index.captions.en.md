Hello, welcome to another episode of Agile Actually. My name is Simon Rindle, professional Scrum trainer, Agile coach, entrepreneur, author. With me is my friend and colleague Martin Henwood. 

Hello, Martin, how you doing? 

Hey, Simon, how's it going? Also professional Scrum trainer, command trainer, entrepreneur, coach, MVP of Microsoft, and all around good chap. 

Mostly. 

Mostly okay. You're human, right? We all have our moments. 

Right, moving swiftly on. This episode, we were thinking about stuff that was going down in the world, and we thought it would be interesting to discuss ethics and agility. 

Ethics being the moral principle of doing the right thing, so understanding the difference between right and wrong and acting on it. Agility being the whole movement, like all of it, where frameworks, whatever the industry, that has become agile, helping organizations deliver better value more quickly. 

Is it possible for an organization to be agile and unethical? Have there ever been examples of organizations behaving in an unethical way? Are there consequences to organizations doing that? 

Discuss. 

What's your thoughts, Martin? 

I think it's a very gnarly issue because there are loads of things that people believe to be ethical that aren't. Or maybe, maybe, maybe I'm wrong in the way I'm phrasing that. Maybe there are just lots of people who don't understand ethics. That's possibly what it could be. 

Because I think there's doing things unethically and not understanding that you're being unethical, and then there's deliberately doing something unethical that you know is unethical. 

Okay, so we've got conscious and unconscious ethical behaviour. 

Yeah, I'd also like to call out that you used the term "gnarly" in the context of complex as opposed to "gnarly" as in cool. 

Oh, I did not know that. 

I was thinking "gnarly" in certain subcultures means really cool. 

Okay, was not aware of that. 

That's an age thing, I'm not sure. 

Well, I think I'm older than you, so... 

Yeah, thanks for that. 

Alright, so do you think most businesses operate with a moral compass? 

Oh, not sure I like that word "most." 

Well, I'm putting some... 

Should I rattle through the businesses that have at one time or another executed a poor or ambiguous moral choice that I'm aware of? 

Sure, I could probably... maybe I could add to that list, or maybe I'm just thinking of the same companies as you are. 

Yeah, okay. So Ford with their Pinto release. They consciously released a car that would probably cause deaths. 

The Ford Mondeo pulled to the left under heavy braking. 

Renault with the bonnet catch that would fly up. 

Okay, how about Exxon? Right, we really want to like this. This will get everybody running for cover. Really dangerous one. Exxon had evidence that the oil industry would cause climate change in 1970 and paid to suppress the information and discredit the information. 

Yep. 

IY, there is climate change. Exxon, one of the biggest oil companies, knew about it and actively invested in misinformation around it. 

Yep. I'm pretty sure the tobacco companies can be put on that list as well for the same style of action. 

Yeah, at a certain point, they became aware that smoking wasn't so good for you. 

Right. 

Yep, gone with the adverts that dentists put out that smoking was good for you and doctors that helped you with your asthma. 

Right. 

How about this? Diabetes and sugar addiction kills three times more people than smoking in America, and it's heavily regulated in a way that promotes it. Corn syrup is in everything. 

Everything. 

What about Zoom's changing of its user policy that if you continue to use Zoom, you agree for it to sample some of your data? 

Right, that was the update. They would be able to consume all of your data, have their AI consume all of that content to learn off your conversations. 

Interesting. 

Well, here's a personal beef of mine. I got autobanned from playing Call of Duty by installing a new mouse. 

So Activision have banned my profile from playing Call of Duty because I installed Logitech's suite of G-Sync. 

And it's on a ban list, and so my account got banned, which means I'm not able to use a product. Not for cheating, but Logitech... Activision don't tell you that you can't use that or Corsair's IQ or a couple of other things, and they know there's false positives. But because they're making so much money, they're not adopting their Ricochet system, and they just autoban people. 

It's a thing. Is that ethical? Take someone's money and then ban them? 

Yep, that's bad. 

So what about Boeing? 

What about Boeing? 

Boeing deliberately made a business choice to focus on shipping rather than quality. 

Are you talking about the 737 Max? 

737 Max is definitely... so allegedly, we have to use that term, otherwise we'll be bankrupt. 

I'm very keen on aviation. I think the ethical challenge is Boeing very much knew the behaviours of the 737 Max, and they made a particular feature optional and didn't educate about it. 

You'll find the airlines that suffered those crashes did not educate their aircrew properly on the operation of the equipment. 

Yes, however, they were not told that there was a change to the operation of the equipment. 

Yeah, allegedly. 

So yeah, it's dubious ground, right? 

Yep, absolutely. Do you launch a product that is potentially dangerous? 

Well, we don't have all the facts. 

So the Activision one I know is true, and you can't see me because you've done it to me. That's personal. I didn't cheat; you banned me. What's wrong? 

What about Meta? 

Meta's harvesting of data since they bought WhatsApp. 

Well, also harvesting of data into Cambridge Analytica as well, right? 

Wow, that's proven, right? Because they paid the fine. 

Yeah, yeah, yeah. 

Okay, so let's stop before we end up being in some big trouble. 

So that's stuff that we know about that we're picking up from papers or personal experience. It's very easy for companies, either consciously or unconsciously, to behave in a pretty shoddy way. 

Do you think they intended to do all this stuff, or is it some curious happenstance rush to go live? 

I think it depends from which perspective you look at it. I do believe in all of those circumstances that we've talked about, if there was indeed wrongdoing, that takes care of our allegedly. If there was indeed wrongdoing, somebody knew about it. 

Somebody understood the problem and the ramifications and either chose not to act or chose to act in a way that had that negative outcome. 

Right. What would drive that motivation? 

I'm trying to lean here into the whole curiosity with positive intent because I don't think anybody gets out of... well, the majority of people don't get out of bed to just kind of break the world. 

You're turning up to work to do your thing, and we're talking about major corporations. We're not talking about organised crime or anything, because obviously there's real intent there to harm people. 

Just make loads of money. 

So with these major corporations, what could possibly influence somebody to make a decision like that? 

People tend to behave how they're measured, right? So if somebody is under significant pressure to deliver something, they may cut corners. 

They may falsify data. There's been enough number of cases, especially in the medical world, where data on the ramifications of drugs, either sweeping side effects under the carpet or making a drug look like it works when it doesn't by fudging the data, because people are put under a lot of pressure to deliver something. 

Yeah, yeah. 

So what I'm hearing is that it's a financial impact comparative, right? Because medicines in particular are horrendously expensive to come up with a new one. 

Yeah, and that pressure to deliver. That's what got Cyberpunk 2077. 

Did you hear about that game? 

Yeah, the game that had that issue. 

So there's an interesting example with Cyberpunk 2077. Perhaps not ethical, but an example of releasing a product too early because of that financial imperative. 

And there's documented evidence on YouTube of developers showing what the flaws were. The product was desperate to hit a particular release date, and it wasn't working so well. 

Sometimes there's a lot of money on the line, right? That they're going to start losing a lot of money if they aren't able to actually release the product. 

And those ramifications put people under a lot of pressure. 

I imagine, for example, that was the driving factor for Zoom at the start of the pandemic, right? Where they deliberately made... 

I don't know if I have to say allegedly for that one. 

Allegedly made changes in the product in order to increase the stability and scalability of the product but reduce users' security and not to tell users. 

And to actively... I don't know how to describe it. What is it when you create a situation where it looks like it's doing the thing but it's not doing the thing? 

Masking. 

Masking the fact that they had done it, the end-to-end encryption, and you still had the green light even though they turned the encryption service on and off behind the scenes in order to support more users. 

Because I think for encryption, you lose about 40% of your performance with encryption on. 

So that gave them that boost, but instead of making it transparent and clear to the users that that's what they were doing, you know, and for the reason, right? 

It was kind of all hidden, which is unethical. 

Okay, is it possible to work in a professional agile way and be unethical? 

I don't remember reading anything in the Agile Manifesto that guarantees ethics. It focuses largely on teams collaborating and delivering value to the customer. 

So defining your market segment, your target audience, and your customer could allow some ambiguous behaviour, and you could apply all the principles of the Agile Manifesto in an unethical industry. 

So let's push it to the extreme. Fishing centres, they're huge, right? There are organisations around the world that massively target phishing emails, phishing texts, you know, the WhatsApp scams. 

They blanket hundreds of millions, billions of people, and they need a very low bite rate to actually make themselves profitable. That's how the crime works. 

They're amazingly responsive, right? Every time the security people are blocking their stuff, they're continuously iterating. 

I don't know how many emails I get with fake remittance advice. 

Or as a company, right? You get fake remittance advice. You get all these things that some of them look like legitimate emails, like somebody just asking you a question. 

But even if they're just phishing for you to click a link and validate that the email is actually a real email, it's still a phishing attempt. 

Yeah, yeah. 

And then there's your Amazon account's going to be closed is the latest one that's heading my inbox. 

Your security software subscription's out of date. 

You know, you could send that out for your Microsoft security subscription, and you're going to hit a large body of people who are like, "That could be me." 

Yeah, yeah. 

And you just need that little bit of uncertainty. 

So billing has expired. 

Yeah, yeah, you're going to lose everything. 

So what we're saying is that you can apply the product aspects of agility in any context at all, and so really it's up to you driving the product process to choose to act in an ethical way or not. 

And I know in the PSM course, for instance, we explore an ethical issue where you misrepresent what can be done at a certain amount of time. 

Yep. 

Which is unethical, and we tease that out in the PSM3 assessment as well. 

So that need for awareness of ethical behaviours, there's nothing in the guidebooks, the frameworks, the rules of Agile that says you need to do good for the world, right? 

Well, sure. 

And I think it's definitely interesting. 

So I have my MVP, my Microsoft Most Valuable Professional, comes with an ethics guide. You agree to comply with these ethics as part of this award. 

But I think I do remember a time many, many years ago. I think I was on the job, maybe it was my second gig, 2001, 2002, around that time, and I was working for, as it shows my age, as a new media agency right before, just after the dot-com bubble burst. 

And I was asked... 

So I was probably 22, and I was asked to create an application that took in a list of first name, surname, and company, and generated guesses at what their email might be based on common company formats. 

And then emailed those emails with a... you know, in those days you could really do the opened, right? Because there wasn't so much security around it to find people's email addresses. 

That's one of the things I was asked to do at the company I was at. 

And did you do it? 

No, I refused to do it. Absolutely abjectly refused to do it. 

And I kind of... I lied about why I didn't want to do it. 

So I didn't want to do it because I thought it was unethical. That's why I didn't want to do it. 

But at 22, I don't think I had the balls to say, "I don't want to do this because it's unethical." 

Yeah, because if I say that, it implies that I think the other person's being unethical, right? 

Yeah, that could be an accusation. 

And it was the sales director that was asking me to do it. 

But what I did see, which I guess kind of didn't really get around that, but I think I was a BCS member, British Computer Society member, and the British Computer Society also comes with an ethics guide. 

I think my membership had expired at this point, right? 

But I claimed that my contract, my membership of the BCS, was based on compliance with a set of rules, and I said that this would break that set of rules, so I wouldn't be able to do it. 

So that's a really good practical tip. Regardless of your organisation, if you're a computer person, is there a computer organisation like the British Computer Society that has that code of ethics? 

I know as professional Scrum trainers we've got a code of ethics. As an MVP, you've got the code of ethics. If you do any coaching training, there's coaching ethics from the ICF. If you do facilitation stuff, there's ethics there. 

Whatever your profession is, there will probably be a professional body that can offer you a code of conduct to help you negotiate your way through the moral maze. 

Yeah, because not everybody... I'm just thinking that's why I paused. Not everybody has the same ethical boundaries, I think. 

Well, there's some grounds that are very personal, right? And we see that being played out in society. 

There's very strong issues that generate really, really strong responses, and some of it's supported by the media, some of it sure. 

But some of it's just... some of it's supported by other things that people ascribe to that they feel that other... some things are encroaching. 

We're trying to avoid saying, you know, religion and various bits and bobs, right? 

But are things that are antagonistic? What's societal norm versus my group norms, and how do they mush together? 

And what do I follow, and what do I try and impose upon others, right? 

Personal beliefs, right? 

Yeah, however they come about, right? 

Yeah, it's like how do you... well, it's up to you how you balance that. 

Obviously, you'll make a choice when you join and work for certain corporations that work with certain industries. 

I know some people would choose not to work with tobacco, for instance, energy companies, defence manufacturers, other things like that. 

Some people won't work with gambling companies. 

Cannabis companies in the States struggle with their cash flow because many of the credit card companies, many of the banks won't because it's federally... I think it was... I don't know if it is just now, but last time I was exploring those ethical ideas, or at least I was in the news, it was federally illegal. 

So none of the federal banks would touch it, but state-based it was legal. 

But the banks have to operate across federal boundaries, and they couldn't. 

So they had all this cash on premises, so they were getting robbed, right? 

Because everybody knew, "Oh, they've got all this cash," and they can't... because they can't take cards, so it has to be cash. 

And then they can't go put it in the bank because their business can't do that, so they've got all this cash on the premises, and they were getting robbed. 

So that's almost... they're doing it for ethical reasons, their own personal ethical reasons, and causing an unethical situation, which is... 

Yeah, it's the curious conundrum you get when you have legal... the position that's, you know... let's not go into that. 

Yeah, yeah, we're not going to go dancing down that rat hole. 

So we can be ethical how we behave. We can behave towards each other ethically and be working on a product that is arguably unethical by someone else's standards. 

There are some grounds that some people would argue that, for instance, working in a phishing company—not as in fishing for fish, but as in the fraudulent phishing company—is the right thing to do because often they're in disadvantaged nations. 

It's a way for them to provide for their families. It's that or starve. 

So for them, it's better that they work for that. You know, that ethical choice to them might appear cut and dried to us that it's not, but to them, it's a way of stopping their loved ones from going hungry. 

Right. 

I think I've always had a strong ethical compass of what I will and won't do. 

That comes a little bit from Asperger's, right? Folks with Asperger's tend to be very... it's either true or it's not. It's either right or it's wrong. 

And I think that has set me in good stead, but also got me in a lot of trouble as well. 

Because I don't think refusing to do that work when I was 22 inured me to that company. 

No, and that's an interesting thing. If something's challenging your code of ethics, is it okay to walk? 

And I would suggest if something is really against your code of ethics or your values, the ethical and right thing for you to do is to walk. 

Yeah, and that way you maintain truth to yourself. 

Yeah, well, and it also depends on whether... like you might not walk from the whole company, but you might just walk from that particular situation. 

Yeah, right? Because it might not be a company ethics thing; it might be a specific situation ethics for that particular company. 

I feel like it was the whole thing. I just didn't see it from where I was, if that makes sense. 

That it wasn't an unusual thing to happen. 

But also, it was the time, 2001, 2002. People didn't really necessarily understand... 

Not everybody, especially if you weren't an IT person, didn't necessarily understand that ethical in the software space because software's not really been around that long. 

I mean, it has been around, what, 70 or 80 years, right? 

But everybody in the world needing to understand software and the choices and the implications is a relatively new thing. 

Well, having access to mass data, having concerns like privacy... like before, if you wanted to... growing up, I'm not sure whether this thing... growing up in Australia, everybody had their name and phone number listed in the phone book. 

Yep, because if you wanted to define someone, you went to the phone book, right? 

Yep. 

Whereas now, you actively work to make sure you're not in the phone book and register it. 

In the UK, there's a telephone preference service where you can register it and make sure that your electoral role is acknowledged so that finance companies know you're on the electoral role, but no one else can find it out. 

And it's interesting. The Electronic Frontier Foundation, they've been around since before the internet was a big thing, so mid-90s. The EFF have been fighting for trying to get balance on the internet and to maintain some fidelity. 

But how do we maintain the signal so that it's greater than the noise? 

Yeah, I don't know is the answer. 

I see a lot of noise, especially on social media, right? 

Because I don't know why that... I think it's because people are hidden as well. People feel like they can be unethical when there's nobody there to judge them. 

That nobody knows who they are, right? 

Oh, you've just triggered to me. You know how I think in memes and metaphors, right? 

Two things popped up. The classic XKCD, "Someone is wrong on the internet." 

There's the comic where you just look at that through your favourite search engine; it'll come up like bang, XKCD, "Someone's wrong on the internet." 

And it's like, "I'm just correcting somebody's wrong on the internet." 

And the other one is, I think it was Mike Tyson who said it: social media created this space where people thought they could talk nonsense without getting a punch in the head. 

Yeah, yeah. 

You know, something to somebody's face, and you say something so horrendous that they could give you a punch in the face. 

So you... there was that built-in response that prevented you from doing that to people's faces. 

But then on the internet, where it's a free-for-all and nobody knows who you are, and you can create a fake account, it's very easy to say things with no ramifications whatsoever. 

So what do people say when there's no ramifications whatsoever? 

This is the... what was it when Microsoft put the AI bot up a few years ago? 

That happened twice. 

So the first time they built an AI bot, they connected it to Twitter, and within a few hours, the bot became misogynistic, racist, and aggressive, and they had to turn it off. 

And then they tried again, I think a couple of years later. They'd been working on these filters for a couple of years, and they tried it again, and it took 24 hours this time to become racist, misogynistic, and aggressive. 

It was threatening to come around and kill people within 24 hours. 

And it's... AI is not... 

AI, like it's a funny thing to say, but AI that we have is not like AI in the movies, right? 

AI in the movies is artificial intelligence. AI that we have just now is an interpretive system. 

It's collecting all of the data that exists within a particular topic and then rationalising that down to what are the patterns in that data and reproducing those patterns, right? 

So it's a trained suggestion engine. 

It's not... 

Yeah, if you suddenly think of Terminator and a self-aware intelligent identity walking around doing stuff, or I'm really old, and there was a great BBC science fiction programme called Blake's 7. 

And there was this super cool... 

Yeah, yeah, talks about Blake's 7. 

Yeah, yeah, so go and look it up. It was brilliant. It was really well done. 

But there was this supercomputer called Orac, which was this perspex box with some lights in it, and it was self-aware, right? 

It was fully intelligent. 

You know Ziggy from Quantum Leap? 

I'll take your word for it. 

Missed that one. 

But yeah, but that's why not... it's modelling, right? 

It's modelling. 

So if you plug it into Twitter, the AI will reflect the sentiment on Twitter. 

So it became a racist, misogynistic, horrible person, right? 

Because that's how people are. 

There are people who are being nice on Twitter, but the majority of stuff on Twitter is people being nasty to each other with no repercussions. 

Imagine if they did it now when a lot of the checks and balances have been taken out of X, as it is now known. 

Yeah, I think if the thing I always think about, like the moral and ethical part, right? Should they be taking those checks and balances out? 

The part that I find more interesting is that humans also do some of what AI does. 

Current AI is not doing what humans do, but what AIs are doing, humans also do. 

We collect a bunch of information, we surf it for patterns, pull out the things that patterns that we connect with, and then that becomes part of ourselves. 

Which is why we lazy load, right? 

We lazy load and we generalise. 

Well, it's ultimately why, magically, we're always born into our religion, right? 

That's the thing where the data we're absorbing as we're growing up is the thing that creates that mental mindset that we're in. 

Therefore, we're always in the perfect religion for us because that's the one we've been taught. 

And it's the same thing. If you're engaging with a bunch of nasty, mean people, you're going to start talking and acting in a nasty, mean way. 

Well, it's that tribal drive, right? 

And if we... 

Okay, so we, as humans, have a desire to be part of a group. If we're surrounded in a group that are behaving in a poor way, how do we become self-aware that it's poor? 

And what do we do about the situation? 

So then this comes back to ethics being subjective, right? 

The... what's one person's bad thing is another person's fine thing. 

Probably not the best words to use, but there are some general trends of really poor behaviour. 

And this is where I reflect on Asimov's laws, right? 

Most people... I probably feel comfortable with that statement. 

Most people are physically upset when they see another human or even another animal being subjected to some kind of pain, right? 

Yep. 

Most people are upset with that. 

And even animals, you could see that in the animal kingdom with each other as well, right? 

They're usually hunting to eat. 

They're not... 

Yeah, they don't play with their food, right? 

Yeah. 

Except cats, but they're psychopaths. 

Yeah, well, this is like cats and humans are the only ones that torture other things, right? 

Yeah. 

So there is inherent moral and ethical routines in humans that are triggered by those things. 

That's probably part of how animals survive, right? 

Humanity survives is because we have helped each other. 

What was the... there was a lady, she was an anthropologist, and she was asked... I don't remember any of the names for this, but she was asked, "What was the first indication that humans... when did humans become not animals but sentient? What was the first sign of sentience?" 

And it was a repaired broken bone. 

Oh, tools. 

No, so this is... yeah, this is when we actually look after a weak person, right? 

So when we actually look after a weak person, taking care of somebody until their bone had healed, and then they were able to be productive again. 

And that was her moment that... that's what they were looking for when they look back in history for whether this group was sentient or not. 

So I challenge... I wouldn't say sentient, but I'd say civilised. 

I'm the wrong words. 

Yeah, so I'd say civilisation. That was the first sign of civilisation. 

You're right. That's exactly the phrase that I was trying to get to but couldn't. 

Thank you. 

So really, if we're thinking about it, is basically that first law of Asimov, which is a robot may not injure a human being or through inaction allow a human being to come to harm. 

So basically, if we use that as the ultimate imperator, that is the ethical boundary. 

But then immediately, we're hit with the escape clause of what if you're in defence of your own? 

And that is where the military come into play because they... 

Sure, but they're... you know, that's the extremist. That's the straw man argument, right? 

But day-to-day, most of us don't have to go around and injure or... 

No, not until the apocalypse. We'll be fine. 

No, so okay, we're all good until the zombie apocalypse. 

Yeah, just has to be any form of apocalypse, right? 

Yeah. 

So, well, we found out through COVID in the UK that the first consequence of apocalypse is we run out of toilet paper. 

Second consequence is I can't buy a webcam. 

That was the second consequence of COVID. 

Yeah, yeah, I can't buy a chip for my graphics card because everyone's crypto mining. 

Everybody's crypto mining from home. 

Yeah, I think that core moral and ethical code, although for some people it appears to be broken, right? 

But in general, for that core, maybe some people have overridden it. 

They still have it, but they've overridden it. 

Yeah. 

And some people definitely don't have it, that's for sure. 

There are psychopaths. 

That is just statistically a very... it's an extreme outlier. 

They're beyond the three standard deviations. 

They're the... you know, serial killers get a lot of publicity because they're so rare, right? 

Yeah, yeah. 

But the beyond that, people, humans have an inbuilt moral and ethical compass, which means that if somebody... this is why you get whistleblowers, right? 

People are making decisions that go against their moral and ethical... 

And it's learned or imposed behaviour. 

Yeah, that's overriding their inbuilt. 

And it's that sense of do no harm, right? 

And I think that's the essence of the first law, is we do no harm. 

We don't make the situation worse for others. 

Now, occasionally, we will be in a system where that whole system is built to take advantage. 

And at what point is the checkout? 

You know, because ultimately, social systems require some transactions. 

Some people are going to come off better; some are going to come off worse. 

At what point do you check out of the system? 

Yeah, but also, at what point do the rules imposed upon people, the system that's created, impose unreasonable constraints? 

So we create... there's two forms of this, right? 

One is obvious; it's the law, right? 

We create systems to impose... and I'm using impose loosely... threat of punishment, right? 

So it's an imposition to impose certain behaviours. 

Yeah, yeah. 

Based on societal norms, right? 

So, yeah, depending upon your country, there's different policing models. 

To be very philosophical about it, in a lot of the Western world, it's policing by consent, where they're just a reminder. 

Some of them... 

Yeah, okay, rat hole, rat hole, rat hole. 

Yeah, yeah, rat hole, police by consent versus police by enforcement. 

Yeah. 

There are some social norms or boundaries. 

They could be laws; there could be some social norms or behaviour codes. 

That's the way our tribes... 

That's like my MVP code of conduct or the BCS code of conduct or the Scrum.org code of conduct. 

These are all... they're not expected. 

I think the core thing with those types of things, those codes of conduct, is that they're not expected to be broken, right? 

Yeah, like the doctor's Hippocratic Oath. 

Just be the default. 

Even if we didn't ask you anything, even if we didn't tell you about it, we don't expect you to do any of those things. 

Yeah, it's like here are table stakes: don't be a dick. 

Yeah, because I read a lot of these codes of conduct, and I'm like, "Yeah, why would anybody do those things?" 

Just seems like a no-brainer that you wouldn't do those things. 

But, you know, some of them are a little bit more strict than others, right? 

Especially when you... 

Oh, well, that's probably a rat hole as well. 

Imposed... 

How... what's the word? 

Imposed speech, right? 

Or imposed ideas that you're... you're not necessarily... 

A, that core thing, but you're kind of forced to do that thing. 

There are a few things like that I've seen in codes of conduct that maybe are starting to get to that edge of that moral and ethical... 

Is it ethical to impose thought? 

I'm using air quotes for thought, but impose thought on other people. 

But I guess pendulums, right? Swinging lots of different ways. 

But I think there's boundaries, right? 

And otherwise, we're going to go off on another segue and start talking about the world of Brave New World, 1984, Newspeak. 

You know, the imposed thought. 

And I couldn't help it, but this is the way my weird brain works, and you know, random connections firing off. 

As soon as you said policing by consent, policing by order, you know, Judge Dredd walks in. 

Yeah, that's the ultimate policing by enforcement, right? 

That you have some kind of societal... this is the whole side topic, but you have some kind of societal thing that changes, which in the Judge Dredd universe, it's mass unemployment because mechanisms are taking over all of the jobs. 

So there are no jobs for people. 

So if everybody's sitting around not doing anything, you end up with listless behaviours, right? 

Because people have no outlet for what they want to do. 

And then things can very quickly get out of control, and then you need stronger enforcement of the rules. 

That's... 

And which ties into another fantasy universe because all the judges are clones. 

Anyway, alright, so just real as back towards ethics and agility. 

So we've had a wide, rambling discussion. 

There have been evidence of corporations behaving unethically. 

There is clear evidence of people behaving unethically, some of it legally, some of it just not very nice. 

Some of it alleged, some of it demonstrated. 

Agility, in its core, when we look at the manifesto for agile software development, there is an implied ethics in it. 

But you can be agile and apply it in an unethical fashion, for instance, in a fraudulent industry such as skimming, phishing scams like that. 

Well, there might even be perfectly legal industries that a certain group of individuals believe is unethical, right? 

And that's contextual and up for debate. 

And that's why laws change, you know? 

So, and that's fine. 

That's the whole point of the legal systems is to uphold... well, it should be for the betterment of society and what have you without jumping into that mess. 

We’re not touching that. 

So then we thought about that and flipped it on its head and said, "Well, is it okay for somebody to work in one of those industries if it saves their family?" 

And in that instance, it may be ethical for them to behave like that. 

We then sort of made a segue into personal ethics. 

What does it mean to be a civilization? 

And we thought about when we, as a civilization, look after the less fortunate, we become civilised. 

And you said that the anthropologist was... sorry, we've forgotten the name, defined the point of civilization as when the society became comfortable and capable of looking after an individual with a broken leg. 

And that meant that they were willing to expand the resources to look after that person for their healing until they could then become a productive member of the group again. 

So that a civil society will look after people, which will imply an ethical boundary. 

We then explored professional organizations and their guides to code of conduct. 

And we're then inviting you, wonderful listener, to think about what's your values, what's your ethics, what's your boundaries? 

Yeah, and to consider how your ethics, your boundaries apply to what you're actually doing every day. 

And what are you doing in your organizations? 

Who are you working for? 

What are they doing? 

And does that fit within your ethical boundaries? 

What have you been asked to do? 

And I would again tie that back to that idea of the squirrel burger that you mentioned, right? 

Of asking people to say and do things that they're not capable of saying and doing, if that makes sense. 

Asking people to commit to something that's impossible for them to deliver. 

Yeah. 

Which is a really important thing for agility, well, professional agility, for the professional Scrum that we teach. 

Making sure that you have time and space to reflect so that you have the capacity to observe yourself and to make sure that you're honouring your code of ethics. 

If you're practicing both of those, either of those, being able to use the force of the Scrum values: focus, openness, respect, courage, and commitment. 

Do no harm, do good. 

Be a positive influence on society in general. 

And then what's the step? 

So, interesting. Say you suddenly realise you're in a bit of a dilemma and you're in a bit of a moral maze. 

What would you recommend for someone if they suddenly realise they come to the epiphany that perhaps something they're doing is not quite good? 

Wow, yeah. What to do? 

Depends on what it is, right? 

It depends on what line it is that you feel that you're crossing. 

Perhaps you need to walk into your local police station, right? 

That could be an extreme case of, "I need to do something. I need to raise this." 

But perhaps it's just like I was asked to do one unethical thing out of a bunch of things that I was doing, and I just refused to do the things that I didn't think were ethical and voiced that I felt that they were unethical. 

Right? 

Yeah. 

That could be enough for the person suggesting it to go, "Oh, actually, you're right. That's probably not a good idea." 

Right? 

Sometimes people do things unethically because they don't realise or they haven't thought through or whatever. 

We all have dumb ideas, right? 

People jump off onto trampolines, right? 

People have dumb ideas. 

So perhaps just chatting about it with a friend, see what somebody else thinks. 

Do two people think it's unethical, or is it just one? 

So that very practical first step is have a chat to someone and just validate. 

Yeah, validate whether it is or it isn't before you go to the police station. 

Just check with someone else before you go there. 

Yeah, and you probably... you can probably assume that it's unethical if you're asked to do it in the phrase of, "Don't tell anybody else." 

But, "I want you to do this thing." 

That's probably a good indication that there's something fishy going on. 

Yeah, so check with someone else. 

Yep. 

Give yourself time and space to think about stuff. 

Build your own set of values. 

If in doubt, use the Scrum values until you build your own. 

Yep. 

Double-check that your organization's values are aligned with yours and that you're working in an industry that you support and can comfortably live with. 

And just be mindful, right? 

Yeah, always be considering the ethical ramifications of what it is you're doing. 

And are you still on the right path? 

Are you still doing the right thing? 

Are you still able to live with yourself for the things that you're doing? 

Or are you going to be up all night worrying about making choices that you've made? 

Right? 

And this is an important point. 

I think it was the engineer who wrote the code for the VW masking of emissions. 

Yes, that's my favourite one. 

And the manager both went down. 

Right? 

Yep. 

The first... he was the first person to go to prison, but he was also the lowest level person to go to prison, so probably had the cheapest lawyers, right? 

So there's that as well. 

You're not telling me that there's a two-tier system in society where rich people get away with stuff because they can pay for better lawyers? 

You can afford more expensive lawyers, then you have a greater chance of not being punished, right? 

I mean, that's just a little bit of reality there that really shouldn't be there, but it is. 

The quality-wise, right? 

Quality of the service. 

But yeah, the person who wrote the lead developer who wrote the code for Volkswagen in the diesel scandal was the first person who went to prison. 

We, as software engineers, have a moral and ethical responsibility to do the right thing. 

And I didn't know is not a defence for a moral and ethical ramification. 

Yeah, nor is "I was just following instructions" or "orders." 

Yeah, "I was just following orders" is not a defence for doing something morally and ethically wrong. 

And you know it's wrong if someone's going to get hurt. 

And if you have to ask that question, "Is it morally and ethically wrong?" 

Probably, probably. 

You probably want to consider it, right? 

So I just need to caveat that thing about someone's going to get hurt. 

There are certain industries where that's what you're doing. 

So, yeah, yeah. 

There are certain industries where that's the outcome. 

Yeah, ultimately, it's up to you to make the world a better place, right? 

It's in your gift. 

So you can be agile; you can be ethical. 

Do no harm. 

Ethics, there is an overlap. 

We need to be ethical regardless of our process. 

And we wish you every success with your businesses and look forward to hearing our next discussion on Agile Actually. 

And if you have any interesting ethical quandaries that you can share... 

Oh, yeah, yeah. 

Share us your ideas, share us your feedback, like, subscribe, all that cool stuff, and we'll see you next time. 

Thank you very much. 

Thanks.