{
  "Lean": {
    "category": "Lean",
    "calculated_at": "2025-04-29T12:57:27",
    "ai_confidence": 10.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 10.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on concepts of efficiency and optimisation, it does not explicitly mention Lean principles or methodologies. The discussion lacks depth in Lean-related topics such as waste reduction, continuous improvement, or Lean tools, leading to a low confidence score in alignment with the Lean category.",
    "level": "Ignored"
  },
  "Engineering Excellence": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Engineering Excellence",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 38.4,
    "ai_mentions": 1.1,
    "ai_alignment": 4.0,
    "ai_depth": 3.8,
    "ai_intent": 3.1,
    "ai_audience": 3.7,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content primarily addresses the distinction between human and AI agency within adaptive systems, focusing on strategic vs. tactical roles. Its exploration of decision making, accountability, and the boundaries between human and machine is conceptually related to effective system design and responsible use of AI. However, it does not explicitly reference engineering excellence, software craftsmanship, or specific development practices such as coding standards, testing, CI/CD, technical debt, or engineering metrics. Most of the discussion orbits organisational adaptation and ethical considerations rather than promoting or deeply discussing best practices in software engineering or craftsmanship. The article targets a mixed audience, possibly including technical leaders, but spends most of its effort on philosophy of agency rather than concrete engineering practices. Therefore, direct mentions, alignment, depth, and intent scores are all low-to-moderate. The signal-to-noise is slightly higher because the content is tightly focused on its topic, but this topic isn't engineering excellence per se. No penalties are applied, as the content is current and does not undermine the category; its issue is one of alignment rather than contradiction.",
    "level": "Ignored"
  },
  "Technical Leadership": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Technical Leadership",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 48.2,
    "ai_mentions": 2.6,
    "ai_alignment": 5.7,
    "ai_depth": 5.2,
    "ai_intent": 5.3,
    "ai_audience": 6.1,
    "ai_signal": 6.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 48.0,
    "reasoning": "The content focuses primarily on distinguishing human and AI agency in adaptive systems, emphasizing the critical role of human-driven strategic intent, ethical stewardship, accountability, and system direction. It draws a firm line between human leadership functions and the tactical optimization capabilities of AI. While 'leadership' is mentioned directly once (in 'abdicated leadership'), there are no explicit, repeated references to 'technical leadership,' and key terms such as 'mentoring,' 'agile,' 'DevOps,' 'agile ceremonies,' or 'team dynamics' do not appear. The discussion is conceptually adjacent to technical leadership, particularly in its treatment of accountability, strategy, and decision-making boundaries in technical systems, which partially overlaps with the evaluated category. However, it largely lacks in-depth engagement with the practices, processes, and team-oriented aspects that define technical leadership in an agile context. The primary audience appears to be technical or organizational decision-makers, which is loosely aligned with the technical leadership audience. Signal-to-noise is moderate, as the content stays thematically consistent but does not directly address technical leadership at the level of practice or team guidance. No penalties are warranted, as the content is neither outdated nor contrary in tone.",
    "level": "Tertiary"
  },
  "Leadership": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Leadership",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 81.37,
    "ai_mentions": 6.6,
    "ai_alignment": 8.7,
    "ai_depth": 8.1,
    "ai_intent": 8.4,
    "ai_audience": 7.5,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 81.0,
    "reasoning": "The content explicitly references leadership (including one direct link to the leadership category) and strongly aligns conceptually: it argues that strategic agency, ethical stewardship, and accountability—hallmarks of leadership—are irrevocably human roles, and must not be delegated to AI. Depth of discussion is high: it deeply explores the delineation of human (leadership) vs AI (tactical) agency, discusses risks to strategic sensing, accountability, and gives practical guidance for operational boundaries. The overall intent is to warn and instruct leaders about the perils of abdicating leadership roles to AI, fitting the category well. The intended audience is executives, strategists, and decision-makers in adaptive/agile environments, closely matching the category, though it's broad enough to include technical practitioners as well. The signal-to-noise ratio is robust; content is focused, with only minimal filler. No penalties were applied: the tone is serious, not outdated, not critical of leadership as a discipline, and references are current.",
    "level": "Primary"
  },
  "Scrum": {
    "category": "Scrum",
    "calculated_at": "2025-04-29T12:57:40",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Scrum or its principles, roles, events, or artifacts, which are essential for alignment with the Scrum category. The discussion is more aligned with general project management and decision-making rather than the specific practices and frameworks of Scrum.",
    "level": "Ignored"
  },
  "Product Management": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Product Management",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 67.9,
    "ai_mentions": 2.1,
    "ai_alignment": 7.3,
    "ai_depth": 7.0,
    "ai_intent": 6.1,
    "ai_audience": 7.8,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content centers on the role of human versus AI agency in adaptive systems, emphasizing strategic intent, direction-setting, and organizational adaptation—concepts resonant with product management, particularly at the strategic level (product vision, business alignment, leadership, and ethical stewardship). There are strong conceptual overlaps: the distinction between strategy (human) and tactics (AI) mirrors the product manager's responsibility to define vision, direction, and prioritize higher-order goals while relying on other tools (potentially AI) for optimization. The table mapping layers of decision-making and the discussion of accountability reference key product management concerns. However, the article never explicitly mentions 'product management,' nor does it discuss core frameworks (Agile, Scrum, Lean), techniques for customer feedback, nor does it provide actionable product management methodologies or metrics. Mentions are limited to indirect strategic themes, not explicit category references. The depth score is moderate: ideas of adaptation, decision boundaries, and organizational consequences are discussed in detail, but from a systems/leadership perspective rather than classic product management. The intent is moderately aligned, aiming to shape thinking about strategic roles in organizational change, which is relevant to product management, though not exclusive to it. The audience appears to be senior leaders, product strategists, or system designers; this overlaps, but isn't perfectly tailored to product management roles. The signal-to-noise ratio is strong: content is dense and purposeful, though some themes could be viewed as general leadership or systems thinking rather than product management-focused. No penalties are warranted: the article is current, serious in tone, and does not contradict the category. The final confidence reflects significant conceptual alignment and relevance, but is held back by limited direct mentions and partial audience/intent fit.",
    "level": "Secondary"
  },
  "DevOps": {
    "resourceId": "ffJaR9AaTl7",
    "category": "DevOps",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 23.02,
    "ai_mentions": 0.2,
    "ai_alignment": 2.4,
    "ai_depth": 2.1,
    "ai_intent": 1.5,
    "ai_audience": 2.6,
    "ai_signal": 2.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "The content focuses on the delineation between human and AI agency in adaptive systems, emphasizing strategic versus tactical decision-making and the risks of overdelegating adaptation to AI. There are no direct or indirect mentions of DevOps, nor do the main ideas clearly map to key DevOps principles such as cross-functional collaboration, automation for delivery, shared accountability between dev and ops, or continuous improvement in software delivery pipelines. While the article discusses accountability, adaptation, and operational discipline, these are approached from an AI-human governance perspective rather than the DevOps cultural and process integration context. The intended audience appears to be technology strategists or organisational leaders interested in AI governance, not DevOps practitioners. The signal-to-noise ratio is moderate; content remains on topic for its own aims, but almost none of the substance aligns with DevOps as defined. No penalties are applied as there are no outdated ideas or critical/satirical tone toward DevOps.",
    "level": "Ignored"
  },
  "Kanban": {
    "category": "Kanban",
    "calculated_at": "2025-04-29T12:57:50",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Kanban or its principles, nor does it align with the core themes of visualising work processes, managing flow, or continuous improvement as defined in the Kanban methodology. The discussion is more aligned with general concepts of agency and decision-making rather than the specific practices of Kanban.",
    "level": "Ignored"
  },
  "Product Development": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Product Development",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 42.577,
    "ai_mentions": 0.6,
    "ai_alignment": 5.8,
    "ai_depth": 4.2,
    "ai_intent": 6.1,
    "ai_audience": 5.4,
    "ai_signal": 5.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "The content primarily discusses the distinction between human and AI agency in adaptive systems, focusing on strategic intent (human) versus tactical optimisation (AI). There are indirect overlaps with product development, particularly regarding adaptation, accountability, and system governance, but these are not explicitly framed within the methodologies or practices core to product development. 'Product' or 'Product Development' is never directly mentioned (mentions: 0.6). The conceptual alignment is moderate (5.8) as the principles of strategy, adaptation, and continuous improvement echo some agile and product thinking. The depth is low to moderate (4.2) because the content is thorough in discussing agency but does not connect with product development practices or lifecycle specifics. Intent is mostly to clarify the boundary between AI and human agency for system resilience rather than to educate or guide in product development directly (6.1). The audience leans toward strategists and system designers, potentially adjacent to product leaders, but is broader than typical product development teams (5.4). Signal-to-noise is moderate (5.3) as the entire text revolves around agency models rather than methodologies or best practices for delivering valuable software products. No penalties were needed: there's no outdated info, and the tone is earnest and not critical of product methodologies. Overall, while there are some transferable principles, the content does not sufficiently align with product development to warrant a higher confidence.",
    "level": "Tertiary"
  },
  "Company as a Product": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Company as a Product",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 53.43,
    "ai_mentions": 0.85,
    "ai_alignment": 5.85,
    "ai_depth": 6.4,
    "ai_intent": 5.3,
    "ai_audience": 6.05,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 53.0,
    "reasoning": "The content centers around the interplay of human and AI agency in adaptive systems, focusing sharply on organisational adaptation, strategy, and accountability—concepts that do intersect with the principles behind 'Company as a Product' (CaaP), especially regarding organisational evolution and governance mechanisms. There are high-depth discussions on roles and boundaries in decision-making, adaptation, and strategic versus tactical thinking. However, the text does not directly mention 'Company as a Product' or CaaP nomenclature or frameworks, and while there are tangential alignments (e.g., cross-functional system design, feedback-driven adaptation, the need for continuous evolution), there are no explicit references to treating the company as a product or to CaaP-specific implementation or culture. Audience is reasonably aligned toward strategic/leadership-level practitioners, as in CaaP. Signal is high—the content is focused and dense, with minimal filler. Scoring low on direct mentions due to the absence of the category term, moderate to strong on alignment/depth due to overlap in ideas and organisational themes, and meaningful but not perfect on intent/purpose fit since the main goal is about agency boundaries in adaptive systems rather than CaaP as such. No outdatedness or negative tone was found; therefore, no penalties were warranted. The overall confidence reflects that while there is high thematic overlap and relevant strategic/organisational insight, CaaP is neither central nor explicitly discussed in methodology or by name.",
    "level": "Tertiary"
  },
  "Agile Values and Principles": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Agile Values and Principles",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 38.75,
    "ai_mentions": 0.8,
    "ai_alignment": 4.9,
    "ai_depth": 5.2,
    "ai_intent": 5.8,
    "ai_audience": 6.6,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content focuses on the differences between human and AI agency in adaptive systems, emphasizing the importance of strategic human intent in guiding adaptation, with AI serving in a tactical optimization capacity. While there are certain conceptual parallels to Agile values—such as adaptation, accountability, sense-making, and responsiveness to change—the core Agile philosophy, terminology, and explicit principles are almost entirely absent. There are no direct mentions of 'Agile', the Agile Manifesto, its core values, or principles. Depth of discussion is moderate but remains in the domain of agency boundaries, not Agile. Intent and purpose are aligned toward leadership in complex, adaptive systems, which could resonate with Agile audiences seeking to foster adaptability, ethical stewardship, and resilience. However, the primary audience appears broader (leadership, system designers, technologists—not specifically Agile practitioners), and the framing is about AI governance rather than Agile philosophy. The signal-to-noise ratio is moderate: the piece is coherent and in-depth but the focus is largely outside Agile context. Therefore, the confidence score is low to mid-range because while some themes conceptually overlap, there is insufficient direct evidence and alignment to justify a higher association with Agile Values and Principles.",
    "level": "Ignored"
  },
  "Test Driven Development": {
    "category": "Test Driven Development",
    "calculated_at": "2025-04-29T12:58:06",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Test Driven Development (TDD) or its principles, practices, or methodologies. The discussion is entirely unrelated to TDD, making it clear that the content does not align with the category.",
    "level": "Ignored"
  },
  "Market Share": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Market Share",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 11.58,
    "ai_mentions": 0.3,
    "ai_alignment": 1.6,
    "ai_depth": 1.8,
    "ai_intent": 1.0,
    "ai_audience": 1.2,
    "ai_signal": 0.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content focuses on the delineation between human and AI agency in adaptive systems, arguing for the necessity of human strategic oversight and the dangers of over-automation. Nowhere does it explicitly mention market share, strategies for expanding market presence, or competitive metrics. While there are minimal thematic links (such as strategic decision-making and organisational relevance), these are framed in terms of organisational resilience and adaptive capacity rather than approaches to increasing market share or competitive advantage. The main audience appears to be organisational leaders or designers concerned with governance and system adaptability, not specifically those seeking to learn about market share. Any possible connection to market share (e.g., the risk of obsolescence by ignoring human agency) is extremely indirect and not a primary or secondary topic. Thus, scores in all dimensions remain very low, and the total confidence rating appropriately reflects this scarce alignment.",
    "level": "Ignored"
  },
  "Scaling": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Scaling",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 11.385,
    "ai_mentions": 0.5,
    "ai_alignment": 1.2,
    "ai_depth": 1.8,
    "ai_intent": 1.4,
    "ai_audience": 2.2,
    "ai_signal": 1.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 11.0,
    "reasoning": "The content focuses primarily on the distinction between human and AI agency in adaptive systems, particularly emphasizing the importance of human strategic intent over AI-driven tactical optimization. While it does discuss organizational issues and practices relevant to adaptation and agency, it does not directly mention or address frameworks, methodologies, or challenges specifically associated with Scaling as defined (e.g., cross-team coordination, large-scale Agile, SAFe, LeSS, enterprise-wide flow, or alignment across multiple teams). There are ideas about adaptation, leadership, and system design that have peripheral relevance to topics like governance structures and escalation frameworks, but these remain generic and not explicitly aligned to 'Scaling' as a formal practice or challenge in product and enterprise delivery. There are no direct mentions of scaling practices or frameworks, and the content is not targeting the specific audience of scaling practitioners or leaders managing multiple teams. While the article has depth concerning the agency dichotomy, it is not sufficiently relevant to scaling methodologies. Hence, the overall confidence score is very low, with minor points for some conceptual alignment and organizational-level thinking.",
    "level": "Ignored"
  },
  "Lead Time": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Lead Time",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 7.2,
    "ai_mentions": 0.3,
    "ai_alignment": 1.1,
    "ai_depth": 0.7,
    "ai_intent": 1.0,
    "ai_audience": 2.2,
    "ai_signal": 1.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content centers around the distinction and interaction between human and AI agency in adaptive systems, focusing on strategic versus tactical roles. There are no explicit or implicit mentions of Lead Time or its associated concepts, such as the measurement of work from initiation to delivery, workflow efficiency, or observability metrics. The main theme is decision-making structure, agency boundaries, risk of overdelegation, and adaptation within organizations, which do not overlap with the Lead Time category or its intended audience (teams tracking delivery efficiency or process bottlenecks). The discussion does reference optimisation and efficiency at a high level, but these references are about general operational improvement rather than time-to-delivery or process metrics. No part of the content addresses measurement techniques, lead/cycle time relationships, or delivery tracking. Thus, all dimensions score very low, with small nonzero values only to reflect minimal topical overlap via generic mentions of optimisation. The confidence score accurately reflects the near-total absence of Lead Time relevance in the material.",
    "level": "Ignored"
  },
  "Acceptance Test Driven Development": {
    "category": "Acceptance Test Driven Development",
    "calculated_at": "2025-04-29T12:58:46",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Acceptance Test Driven Development (ATDD) or its principles, nor does it address acceptance criteria, collaboration among stakeholders, or techniques for writing acceptance tests. The themes of ATDD are not present, leading to a very low confidence score.",
    "level": "Ignored"
  },
  "Increment": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Increment",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 5.63,
    "ai_mentions": 0.0,
    "ai_alignment": 1.2,
    "ai_depth": 3.0,
    "ai_intent": 1.5,
    "ai_audience": 6.1,
    "ai_signal": 8.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The content focuses on the distinction between human agency and AI agency in adaptive systems, particularly emphasizing strategy, purpose, and adaptation versus optimization. There are no direct mentions of 'Increment' or discussion related to the delivery of working software increments, Agile, or Scrum practices. Conceptual and intent alignment with the 'Increment' category is minimal, as the main themes revolve around system-level governance and the allocation of agency, rather than iteration-based software delivery. The depth score is slightly higher than alignment due to a thorough exploration of its chosen theme, but that theme is unrelated to 'Increment'. The audience score is somewhat elevated, as it potentially appeals to technical and organizational leaders (common with Increment content), and the content stays focused overall (high signal). No penalties were applied, as the content is not outdated or satirical. The resulting confidence is very low, appropriately reflecting that the material does not fit under the 'Increment' classification.",
    "level": "Ignored"
  },
  "Application Lifecycle Management": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Application Lifecycle Management",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 24.225,
    "ai_mentions": 0.6,
    "ai_alignment": 2.9,
    "ai_depth": 2.8,
    "ai_intent": 1.2,
    "ai_audience": 2.3,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on human and AI agency in adaptive systems, discussing boundaries for strategic and tactical decision-making. It primarily centers on organizational strategy, agency, and ethical considerations, not on the practices, methodologies, or tools specific to application lifecycle management (ALM). There are no direct mentions of application lifecycle, ALM stages, tools, or governance frameworks. Conceptual alignment is limited—while the topic touches on system design and governance, it does not cover the software lifecycle or associated management practices. The depth is at the level of agency separation, rather than practical or technical aspects of ALM. The intended audience seems to be strategists and organizational leaders, not specifically ALM professionals, though some overlap with technical governance exists. Signal-to-noise ratio is moderate, with most content focused on the theme but not on ALM, creating some tangential relevance. No penalties apply, as the content is current and respectful. Overall, confidence is low because the discussion is tangential to, but not meaningfully about, Application Lifecycle Management.",
    "level": "Ignored"
  },
  "Platform Engineering": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Platform Engineering",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 14.8,
    "ai_mentions": 0.2,
    "ai_alignment": 1.9,
    "ai_depth": 2.3,
    "ai_intent": 2.1,
    "ai_audience": 4.9,
    "ai_signal": 5.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 15.0,
    "reasoning": "The content is a thought leadership piece distinguishing between human and AI agency in adaptive systems. There is no direct mention of Platform Engineering or its key concepts—nothing about Internal Developer Platforms, developer self-service, automation in the application lifecycle, or the standardisation of development tools and processes. Alignment is very low, as the content is about abstract decision-making principles, not platform construction or developer enablement. Some concepts such as 'system design' and 'governance practices' could (at a stretch) overlap with the concerns of platform engineers, but the discussion is theoretical, not technical or practical. The intent is to discuss agency and adaptation, not to inform, support, or guide practitioners in Platform Engineering. The technical sophistication and consideration of adaptive systems may resonate slightly with a technical reader, justifying mid/low audience and signal-to-noise scores, but this is peripheral. The overall confidence in this content fitting the Platform Engineering category is very low.",
    "level": "Ignored"
  },
  "Deployment Frequency": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Deployment Frequency",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 8.4,
    "ai_mentions": 0.0,
    "ai_alignment": 0.7,
    "ai_depth": 0.8,
    "ai_intent": 0.6,
    "ai_audience": 1.0,
    "ai_signal": 1.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content does not directly mention deployment frequency, nor does it discuss deployment intervals, CI/CD, Agile, or DevOps practices. Its focus is on human and AI roles in adaptive systems, emphasising agency, accountability, and strategy versus optimisation. While 'optimisation' is referenced, it is discussed at a philosophical/organizational level around decision-making and adaptation, not in the context of software deployment practices. There is no discussion of release cadence, metrics, automation, or the feedback loop central to deployment frequency. The intent, audience, and depth are not aligned with deployment frequency as a category, resulting in minimum possible scores. The signal-to-noise ratio is slightly higher to reflect that the content is on-topic for its own subject but off-topic with respect to deployment frequency. No penalties were applied, as there is no evidence of outdated information or tone issues regarding deployment frequency; it is simply unrelated. The overall confidence score is extremely low, accurately reflecting that the content does not fit the intended category in any substantive way.",
    "level": "Ignored"
  },
  "Remote Working": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Remote Working",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 3.6,
    "ai_mentions": 0.3,
    "ai_alignment": 0.8,
    "ai_depth": 1.0,
    "ai_intent": 0.4,
    "ai_audience": 5.1,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 4.0,
    "reasoning": "The content primarily focuses on the roles of human and AI agency within adaptive systems, strategic versus tactical decision-making, and the risks of over-relying on AI for adaptation and leadership. Nowhere does it mention remote working, distributed teams, or Agile practices explicitly or even indirectly; no key terms such as remote, distributed collaboration, or team communication appear. Conceptual alignment with 'Remote Working' is negligible as the themes are about system governance and agency boundaries—not challenges or strategies related to remote Agile team practices. Depth of discussion, while significant for the topic at hand, is absent with regard to the Remote Working category; there is no effort to connect AI/human agency discussion to remote collaboration or virtual teams. The intent is off-purpose for the requested category, as the target audience seems to be strategists or leaders designing adaptive organizations—not specifically remote workers. The audience might, incidentally, overlap with people interested in modern workplace dynamics, but the focus is not on remote work. Signal-to-noise is low with respect to 'Remote Working'; the content is highly focused but not on this category. No penalty is applied, as the content is not outdated nor satirical or critical toward the Remote Working framing—it's just not connected to it. Overall, the confidence is extremely low, as the content does not address or reference the Remote Working category in any meaningful way.",
    "level": "Ignored"
  },
  "Customer Satisfaction": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Customer Satisfaction",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 14.85,
    "ai_mentions": 0.2,
    "ai_alignment": 2.0,
    "ai_depth": 2.1,
    "ai_intent": 1.3,
    "ai_audience": 4.3,
    "ai_signal": 1.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 15.0,
    "reasoning": "The content, while nuanced and in-depth regarding the distinctions between human and AI agency in adaptive systems, does not directly mention or focus on customer satisfaction. There are no explicit references to customer experience, satisfaction metrics, customer feedback, or practices/mechanisms that connect strategy and optimization to customer happiness—the core of the Customer Satisfaction category. The concept of aligning organization adaptation with external needs could tangentially relate to product-market fit and, by weak extension, customer satisfaction, but this is neither directly stated nor explored. The depth of discussion around 'agency' is strong but not relevant to customer satisfaction principles in Agile, DevOps, or Lean contexts. The audience seems more geared toward system designers, strategists, or leadership, not necessarily those focused on customer-centric methodologies, leading to a moderately low audience alignment score. The signal-to-noise ratio is moderate, as the content remains tightly focused, but the focus is not on the category being assessed. Therefore, with these dimension scores and lack of penalizable factors, the overall confidence this fits the 'Customer Satisfaction' category is very low.",
    "level": "Ignored"
  },
  "Continuous Delivery": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Continuous Delivery",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 18.55,
    "ai_mentions": 0.25,
    "ai_alignment": 2.6,
    "ai_depth": 2.75,
    "ai_intent": 2.3,
    "ai_audience": 4.15,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "This content focuses on the distinction between human and AI agency within adaptive systems, emphasizing the irreplaceable role of human strategic intent and the bounded utility of AI in optimization. Nowhere does it directly mention or discuss Continuous Delivery, its principles, practices, benefits, tools, or techniques. The writing is philosophical and governance-oriented, centering on leadership, agency boundaries, and accountability. There are thematic overlaps with operational discipline and systems design; however, these are discussed only in the context of adaptive decision-making—not delivering software in reliable, incremental cycles. The closest alignment comes from the brief discussion of operationalizing boundaries, which could relate to system governance but not specifically to delivery pipelines, automation, or rapid feedback loops central to Continuous Delivery. The primary audience appears to be strategists and executives thinking about digital transformation and responsible AI integration rather than practitioners of software delivery. No references are outdated or satirical, so no penalties applied. Ultimately, the confidence is very low, as the fit is largely tangential and lacks any explicit or substantive engagement with Continuous Delivery.",
    "level": "Ignored"
  },
  "Market Adaptability": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Market Adaptability",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 74.56,
    "ai_mentions": 5.2,
    "ai_alignment": 8.8,
    "ai_depth": 8.9,
    "ai_intent": 7.0,
    "ai_audience": 7.6,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 75.0,
    "reasoning": "The content centers on the delineation of human versus AI agency in adaptive systems, emphasizing the uniquely human capacity for strategic adaptation and purposeful reframing in complex environments. This directly aligns with the principles of market adaptability—highlighting the necessity for human-driven adaptation, strategic sensing, and ethical stewardship to keep organizations agile and resilient amidst change. The depth is strong: concrete frameworks and detailed risk discussions (e.g., collapse of strategic sensing, fragility under complexity) are provided, showing thoughtful engagement with adaptation and resilience. Direct mentions of 'market adaptability' or related jargon (agile, devops, lean) are limited (thus a middling Mentions score), but repeated reference to 'adaptive systems,' 'adaptation,' and organizational relevance anchors it conceptually. The main intent is to caution organizations against misplacing adaptive agency in AI, advocating practices that ensure continuous human-led adaptation—this is highly aligned with the category, though slightly diluted by the broader focus on agency rather than process or methodology, and with some discussion bordering on philosophical. The intended audience appears to be organizational strategists, system designers, and leaders, which aligns well with the Market Adaptability category's typical readership. While not all content is strictly procedural or method-based as per category exemplars, the overall focus remains on building organizational capability to adjust to change. No penalties are applied: the content is current, not critical of the adaptability imperative itself, and references no obsolete methods. Confidence is strong but not maximal due to limited explicit category terminology and only moderate discussion of specific methodologies (Agile, DevOps, Lean), though the broad conceptual overlap is evident and substantial.",
    "level": "Secondary"
  },
  "Miscellaneous": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Miscellaneous",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 63.77,
    "ai_mentions": 7.6,
    "ai_alignment": 6.7,
    "ai_depth": 5.8,
    "ai_intent": 7.2,
    "ai_audience": 6.3,
    "ai_signal": 5.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 64.0,
    "reasoning": "The content does not reference or apply Agile, Scrum, DevOps, Lean, or Evidence-Based Management principles, thus avoiding exclusion per the strict guidelines. It deals with the philosophical and practical interplay between human and AI agency in adaptive systems. The content is predominantly general and theoretical in nature, mapping roles and boundaries but not anchoring them in any established business agility framework or author. It fits 'Miscellaneous' because it is a broad exploration disconnected from specific actionable methodologies or recognised theories, instead offering perspectives, warnings, and a conceptual framework. Mentions of the category occur implicitly through generic and boundary-spanning discussion (7.6), while alignment is moderate (6.7) as the themes fit the definition but occasionally verge into system design which could brush on broader management topics. Depth is adequate (5.8), exploring the subject beyond a superficial level via multi-layer mapping and risk breakdown, but not thoroughly embedding it in Miscellaneous themes. Intent is solidly relevant (7.2), offering discussion most useful to strategy-thinkers or leadership reflecting on human/AI balance, not technical practitioners. Audience fit is moderate (6.3) as the targets are broad (executive, strategist, thought leader), though not narrowed to technical agility professionals. Signal-to-noise is fair (5.9); while the narrative is dense and relevant, semi-redundant cautionary points and didactic repetition weaken its focus on a single topic. No penalties were necessary as content is current, not satirical or critical toward Miscellaneous framing. The scored dimensions and the confidence align: this is a reasonable, broad, somewhat theoretical fit for 'Miscellaneous', neither a perfect exemplar nor inapplicable.",
    "level": "Secondary"
  },
  "Cell Structure Design": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Cell Structure Design",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 18.95,
    "ai_mentions": 0.1,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 5.2,
    "ai_signal": 3.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content does not directly mention Cell Structure Design, the Beta Codex, autonomous cells, decentralisation, or network-based structures. The central discussion is about human vs AI agency in adaptive (organizational) systems, which conceptually overlaps with the kind of distributed agency found in Cell Structure Design, but the fit is indirect. The piece deeply explores the boundaries between human and AI roles in adaptation, highlighting the necessity of human-driven strategy and purpose, but does not tie these concepts to the decentralized, cell-based organizational architecture or its principles. Intent and audience both lean toward strategy, adaptation, and organizational change, but not explicitly toward Cell Structure Design or its practitioner community. The signal is dominated by the agency and adaptation theme, with much less explicit or implicit Cell Structure Design content. There are no penalties applied as the piece is neither outdated nor critical of Cell Structure Design; rather, its relevance is tangential. Overall, the confidence score is low, reflecting the lack of direct mention or substantial alignment with the core category.",
    "level": "Ignored"
  },
  "Change Management": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Change Management",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 61.21,
    "ai_mentions": 1.3,
    "ai_alignment": 6.6,
    "ai_depth": 6.7,
    "ai_intent": 6.1,
    "ai_audience": 7.4,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 61.0,
    "reasoning": "Direct mentions of 'change management' or directly related terms are absent; the primary explicit focus is agency differences (human vs. AI) and their roles in system adaptation. Conceptually, the piece strongly aligns with themes underlying change management—such as strategic adaptation, the centrality of human leadership, the risks of over-reliance on automation for change, and the need for accountability and stewardship—but it frames these through the lens of agency and system design rather than formal change management frameworks or methodologies. The depth of discussion is considerable, going beyond superficiality to give clear insight into decision layers, risks, and operational boundaries, which is related to organizational change and resilience. The content’s intent is partly relevant: it supports meaningful and sustainable adaptation in organisations, which is at the heart of change management, but it does not explicitly aim to provide change management practices, case studies, or tools. Its audience includes strategic leaders and system designers, overlapping with but not exclusive to the change management or Agile leadership community. The signal-to-noise ratio is high; the arguments are focused with little extraneous material, though the lens is mostly about agency, not change management directly. No penalties are applied, as the content is current and not contradictory or satirical. The overall confidence is moderate: the content provides valuable, in-depth, conceptually relevant discussion and actionable boundaries that align with the philosophies of the 'Change Management' category, but lack of explicitness and a direct focus on category-defining practices lower the final confidence.",
    "level": "Secondary"
  },
  "Coaching": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Coaching",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 21.25,
    "ai_mentions": 0.2,
    "ai_alignment": 1.3,
    "ai_depth": 2.1,
    "ai_intent": 1.5,
    "ai_audience": 2.9,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 21.0,
    "reasoning": "The content focuses on the distinctions between human and AI agency in adaptive systems, emphasising strategic versus tactical roles, the dangers of overdelegating to AI, and the importance of human-led decision-making. There is no explicit mention of coaching or its key elements (guidance, unlocking potential, fostering team growth, or coaching practices). Conceptual alignment is minimal: while human stewardship and facilitation are discussed, they are positioned at a leadership/strategic decision-making level—not in the context of developing individuals or teams via coaching. The depth of the discussion is substantial regarding agency, but not regarding coaching; relevant coaching concepts (feedback, trust, collaboration, frameworks like GROW) are absent. The intent is broader strategy and risk, not skills development, and it targets strategists or executives more than scrum masters or coaches. Although the content is not off-topic or filler, its focus is not sufficiently aligned with the core coaching definition. Therefore, all scores are low and confidence is proportionately minimal.",
    "level": "Ignored"
  },
  "Current Value": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Current Value",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 9.593,
    "ai_mentions": 0.2,
    "ai_alignment": 1.3,
    "ai_depth": 1.4,
    "ai_intent": 1.0,
    "ai_audience": 2.0,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content does not explicitly reference Current Value or Evidence-Based Management. There are no direct mentions, nor does the focus align with Current Value's metrics, measurement, or application in Agile or DevOps. The main ideas center on distinguishing human and AI agency in adaptive systems, strategic versus tactical roles, and organisational risk when over-automating adaptation. Although tangential connections could be drawn—such as the impact of agency boundaries on organisational value—these remain theoretical and do not address practical measurement or real-time assessment, which are core to the Current Value category. The audience appears to be organisational leaders interested in AI strategy, not those directly focused on evidence-based value measurement. Signal-to-noise is low for this category: the content is focused, but not on Current Value. No penalties were applied as there are no outdated references or contradictions; the tone is contemporary and earnest. Overall, this content does not substantively or directly address Current Value, leading to an extremely low confidence score per classification guidelines.",
    "level": "Ignored"
  },
  "Organisational Change": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Organisational Change",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 61.178,
    "ai_mentions": 4.2,
    "ai_alignment": 7.6,
    "ai_depth": 6.9,
    "ai_intent": 6.4,
    "ai_audience": 7.0,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 61.0,
    "reasoning": "The content does not directly mention 'organisational change' or classic change management frameworks, hence the low Direct Mentions score. However, Conceptual Alignment is moderately strong (7.6), as the discussion relates to governance, strategic leadership, operational discipline, and resilience in organisations—core themes of organisational change—as applied to the balance of human and AI agency. The Depth of Discussion (6.9) reflects thorough exploration of boundaries and operationalising agency, but it doesn't delve deeply into established change frameworks or Agile transformation. Intent/Purpose Fit (6.4) is solid; although the piece focuses on adaptive systems, its intent includes shaping organisational practices and cultural approaches to human-AI collaboration rather than pure theory or technicalities. The Audience score (7.0) is above average, targeting leaders, strategists, and those responsible for organisational adaptation—matching the category's typical audience. Signal-to-Noise (6.3) is slightly above average: almost all content is on-topic regarding adaptation in organisations, but part of it is conceptual and not tightly anchored to mainstream organisational change methodologies or case studies. There are no tone issues or outdated practices, so no penalties were applied. Overall, the content meaningfully overlaps with Organisational Change but from an adjacent, not direct, angle, justifying a confidence well above 50 yet not in the highest band.",
    "level": "Secondary"
  },
  "Lean Product Development": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Lean Product Development",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 18.32,
    "ai_mentions": 0.7,
    "ai_alignment": 2.76,
    "ai_depth": 2.65,
    "ai_intent": 2.2,
    "ai_audience": 4.13,
    "ai_signal": 3.07,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content focuses on the roles of human and AI agency in adaptive systems, exploring the boundaries between strategy (human) and optimisation (AI). While there is some discussion of efficiency, experimentation, and systemic adaptation, these are abstracted at the level of system governance rather than the concrete frameworks, principles, or waste-reduction techniques specific to Lean Product Development. There are no direct mentions of Lean, its principles, or tools such as Value Stream Mapping. Conceptual overlap is limited to the general idea of continuous improvement and purposeful adaptation, but the core themes are centered on agency and ethics, not on minimising waste or maximising learning in product creation. The audience may have mild overlap with strategic product leaders interested in Lean, but the content is not tailored to practitioners of Lean Product Development. The signal-to-noise ratio reflects that, while on topic for system design and collaboration, the material is not focused on Lean-specific topics. Therefore, the confidence score remains low, in proportion to the small degree of abstract alignment.",
    "level": "Ignored"
  },
  "Behaviour Driven Development": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Behaviour Driven Development",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 7.7,
    "ai_mentions": 0.0,
    "ai_alignment": 1.4,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 2.3,
    "ai_signal": 1.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content under review rigorously discusses the distinction between human and AI agency in adaptive systems, emphasizing strategy, purpose, and accountability. Nowhere in the title, description, or main content is Behaviour Driven Development (BDD) mentioned, referenced, or alluded to — scoring 0.0 for direct mentions. Conceptual alignment is minimal (1.4): While the content discusses system design and accountability, there is no substantive overlap with BDD's focus on aligning software requirements, writing user stories, collaborative practices, or BDD tooling. Depth (1.3) is low since the article deep-dives into organisational ethics, strategic adaptation, and AI limits, but not in ways relevant to BDD. The intent (1.0) centers on leadership, human-centric system design, and critical reflection on AI's role, not on BDD or aligning technical and business understanding of software requirements. The audience is potentially technical but more slanted to strategists and leadership (2.3), not BDD's typical developer-tester-business collaboration demographic. The signal-to-noise ratio is low for BDD purposes (1.1) since all content is off-topic relative to the category. No penalties are necessary: the tone is neutral and current. Thus, based on the explicit weighting, the overall confidence that this content is relevant to 'Behaviour Driven Development' is extremely low (7.7), reflecting the tangential or absent fit across all dimensions.",
    "level": "Ignored"
  },
  "Product Discovery": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Product Discovery",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 28.65,
    "ai_mentions": 0.35,
    "ai_alignment": 3.35,
    "ai_depth": 2.75,
    "ai_intent": 2.85,
    "ai_audience": 6.2,
    "ai_signal": 6.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 29.0,
    "reasoning": "The content focuses on the distinction between human and AI agency in adaptive systems, exploring strategic versus tactical roles in decision-making. While strategic intent, hypothesis framing, and adaptation are somewhat adjacent to product discovery (which involves understanding user needs, defining product features, and validating ideas), there are no direct mentions or methodologies related to Product Discovery (e.g., user research, MVP, customer feedback analysis). The main emphasis is on organisational strategy, adaptation, and governance rather than explicit exploration or definition of product features or customer requirements. The content may interest advanced product leaders or strategists but is not purpose-built for the Product Discovery category. The discussion is deep and well-structured on its core topic but only tangentially overlaps with the conceptual focus of Product Discovery, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Troubleshooting": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Troubleshooting",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 21.488,
    "ai_mentions": 0.5,
    "ai_alignment": 2.3,
    "ai_depth": 2.0,
    "ai_intent": 2.5,
    "ai_audience": 5.7,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 21.0,
    "reasoning": "The content is a strategic discussion of the distinction between human and AI agency in adaptive systems, focusing on governance, accountability, and the appropriate assignment of roles. It does not directly reference troubleshooting, nor does it provide methods or case studies for diagnosing or resolving technical issues within software, hardware, or systems. The core themes are about strategic intent and the limits of AI's role in adaptation, not systematic problem identification or resolution. Although there is some relevance for technical practitioners (audience alignment), the alignment and depth scores remain low, as there is little to no direct connection to troubleshooting or detailed exploration of diagnoses or fixes. The mention of brittleness or system failure is philosophical and not actionable troubleshooting content. No penalties were needed, as the content is not outdated or satirical. The confidence score is low, appropriately reflecting minor conceptual overlap but, fundamentally, a misalignment with the Troubleshooting category.",
    "level": "Ignored"
  },
  "Test First Development": {
    "category": "Test First Development",
    "calculated_at": "2025-04-29T12:59:54",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Test First Development or its principles, nor does it explore topics related to testing practices, success criteria, or the impact of testing on collaboration. The discussion is centred around decision-making and accountability rather than software development methodologies, leading to a very low confidence score in relation to the Test First Development category.",
    "level": "Ignored"
  },
  "Windows": {
    "category": "Windows",
    "calculated_at": "2025-04-29T12:59:58",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content focuses entirely on the concepts of human and AI agency within adaptive systems, with no mention or relevance to the Windows operating system or its functionalities. It does not discuss installation, configuration, troubleshooting, or any other aspect related to Windows, making it irrelevant to the specified category.",
    "level": "Ignored"
  },
  "Large Scale Agility": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Large Scale Agility",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 47.82,
    "ai_mentions": 1.1,
    "ai_alignment": 4.8,
    "ai_depth": 5.3,
    "ai_intent": 5.6,
    "ai_audience": 6.7,
    "ai_signal": 7.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 48.0,
    "reasoning": "The content discusses the distinction and interplay between human agency (strategy, adaptation) and AI agency (tactical optimisation) in adaptive systems. It repeatedly references organisational adaptation, accountability, system design, and governance—but does not use explicit language or frameworks central to 'Large Scale Agility' (such as SAFe, LeSS, enterprise transformation, cross-team collaboration, etc.). While the focus on organisational adaptation and human leadership has thematic overlap with values in large-scale agility (e.g., leadership stewardship, strategic pivoting, adaptive governance), it lacks direct citations of the agile scaling domain. There is some conceptual alignment in the emphasis on strategic intent, anti-fragility, responsible adaptation, and clear roles, but it stops short of connecting these specifically to enterprise-level Agile practices, transformation strategies, or scaled Agile frameworks. Its depth lies in strategic vs. tactical decision analysis, but not in large-scale Agile implementation or culture. The intent is relevant for leaders examining adaptation and accountability—one of the key audiences for large-scale agility—but remains broader, appealing to general organisational and systems thinkers rather than specifically those engaged with scaling Agile. High signal-to-noise ratio: the argument is focused and relevant, though not tailored to Agile context. No penalties apply; it is neither outdated nor oppositional. Overall confidence is moderate, as the content is tangentially relevant to topics like leadership and accountability in organisational adaptation but does not directly fit into the strict definition or key topics of 'Large Scale Agility'.",
    "level": "Tertiary"
  },
  "Agile Product Operating Model": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Agile Product Operating Model",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 23.837,
    "ai_mentions": 1.2,
    "ai_alignment": 3.7,
    "ai_depth": 2.9,
    "ai_intent": 2.9,
    "ai_audience": 5.4,
    "ai_signal": 5.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content deeply explores the distinction between human and AI agency in adaptive systems, focusing on the strategic versus tactical roles of each. While there are conceptual elements (e.g., governance, system design, operational discipline, continuous adaptation) that tangentially relate to themes within the Agile Product Operating Model (APOM), the explicit focus is not on APOM, nor on transitioning from project to product, product-oriented mindset, Scrum, or product management principles central to the category. There is no direct mention or reference to 'Agile Product Operating Model', agile methodologies, product management, or their hybridised structure in APOM. The main intent is not to discuss APOM or its audience (e.g., agile product leaders, strategists), but rather to warn organisational leaders and practitioners about over-reliance on AI for adaptation. There are minor alignments in governance and organisational design discourses, which support a moderate audience and signal score, but the overall confidence must remain low, as the themes and purpose only occasionally intersect with APOM concerns and do not offer detailed discussion or practical guidance in this domain.",
    "level": "Ignored"
  },
  "Hybrid Agile": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Hybrid Agile",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 14.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.3,
    "ai_depth": 1.5,
    "ai_intent": 1.4,
    "ai_audience": 4.6,
    "ai_signal": 6.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 15.0,
    "reasoning": "The content focuses on the distinction between human and AI agency within adaptive systems, emphasizing the boundaries and risks associated with overdelegating adaptive work to AI. Nowhere does it mention Hybrid Agile by name or synonym, nor does it explicitly address project management, blending of agile/traditional methodologies, or the dysfunctions of Hybrid Agile. There is some conceptual overlap in highlighting risks of accountability erosion and system-level dysfunctions, which could loosely relate to critiques of compromised frameworks like Hybrid Agile, but this is indirect at best. The primary audience appears to be organizational strategists, somewhat overlapping with the intended Hybrid Agile readership. The discussion is in-depth regarding its chosen topic, but that topic is not Hybrid Agile or its core analytic concerns. There is no content that would merit penalty for being outdated or contradictory in tone—the material is relevant and clearly against certain misuses of automation, but not specifically framed against Hybrid Agile. Therefore, confidence is low and appropriately reflects the lack of direct relevance.",
    "level": "Ignored"
  },
  "Organisational Physics": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Organisational Physics",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 91.8,
    "ai_mentions": 7.2,
    "ai_alignment": 9.6,
    "ai_depth": 9.4,
    "ai_intent": 9.1,
    "ai_audience": 8.7,
    "ai_signal": 9.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content discusses the strategic role of human versus AI agency specifically within adaptive systems and organisational contexts. It maps agency to layers of organisational decision-making, references system adaptation, feedback, accountability, and complexity, all central to Organisational Physics. Systems thinking is implied through references to adaptation, feedback loops, and the interplay between strategy, decision layers, and organisational resilience. Depth is high due to nuanced differentiation between human and AI roles, examples of operationalising these boundaries, and a thorough risk discussion around overdelegating adaptation tasks. The intent is clearly aligned: the purpose is to inform, caution, and provide guidance to organisational leaders and strategists about systemic boundaries and dynamics, precisely the target audience. Audience alignment is strong, aimed at those responsible for governance, leadership, and organisational systems design. While 'Organisational Physics' is not named directly, there are multiple explicit references to core concepts (systems thinking, adaptation, dynamics). Signal is very high—minimal filler—almost all content is on-topic, only minor tangents (such as general remarks on AI) slightly reduce perfect focus. No outdated or contradictory material is present, so no penalties apply. Overall, the document demonstrates deep, practical engagement with Organisational Physics themes.",
    "level": "Primary"
  },
  "Site Reliability Engineering": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Site Reliability Engineering",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 14.35,
    "ai_mentions": 0.9,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.1,
    "ai_audience": 3.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content extensively discusses human and AI agency in adaptive systems, focusing on the strategic-versus-tactical division of labor in complex sociotechnical environments. However, there are no direct or even implicit references to Site Reliability Engineering (SRE), SRE principles, practices, or terminology—terms like SLO/SLI/SLA, reliability, post-mortem, incident response, or system performance optimization are never used or alluded to. The main ideas revolve around leadership, governance, and accountability at a strategic and adaptation level, rather than the operational reliability, automation, or monitoring concerns at the heart of SRE. The content seems aimed more at executives or strategists thinking about AI integration, rather than SRE practitioners, though there is some technical systems framing. The signal-to-noise ratio for SRE is very low because nearly all substance is off-category. Confidence is thus minimal, reflecting only a faint conceptual overlap regarding resilient systems and operational frameworks.",
    "level": "Ignored"
  },
  "Portfolio Management": {
    "category": "Portfolio Management",
    "calculated_at": "2025-04-29T13:00:22",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on strategic decision-making, it does not explicitly address portfolio management or the alignment of projects with organisational strategy. The themes of strategic alignment and adaptation are present but are not explored in the context of managing a portfolio of projects. The depth of discussion is more about agency roles rather than portfolio management practices, leading to a low confidence score.",
    "level": "Ignored"
  },
  "Lean Startup": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Lean Startup",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 23.6,
    "ai_mentions": 0.2,
    "ai_alignment": 2.9,
    "ai_depth": 3.4,
    "ai_intent": 2.5,
    "ai_audience": 4.1,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content thoroughly explores the distinction between human and AI agency in adaptive systems, focusing on strategy versus optimization. While the notion of experimentation, adaptation, and hypothesis-driven change are discussed, there is no direct or explicit mention of Lean Startup, MVPs, Build-Measure-Learn loops, validated learning, or the Lean methodology. The alignment is weak: although the themes of adaptation, hypothesis-driven exploration, and pivoting are tangentially related to Lean Startup concepts, the core frameworks and language are absent. The depth is moderate as it substantively discusses adaptive practices but not Lean Startup itself. The purpose is broader—informing readers about effective boundaries between human strategic intent and AI optimization—not specifically supporting Lean Startup practice or its audience. The target audience (organizational leaders, strategists, system designers) could include those interested in Lean Startup but is not focused on startup practitioners or innovators using Lean methods. The signal-to-noise ratio is reasonable; most of the content is on-topic for its own theme, but none is distinctly Lean Startup. No penalties were necessary, as the material is current and the tone is not critical of Lean Startup; it simply addresses a different topic. Overall, the lack of direct conceptual overlap, terminology, and clear intent toward Lean Startup justifies a low confidence score.",
    "level": "Ignored"
  },
  "Estimation": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Estimation",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 5.35,
    "ai_mentions": 0.2,
    "ai_alignment": 0.4,
    "ai_depth": 0.5,
    "ai_intent": 0.2,
    "ai_audience": 0.15,
    "ai_signal": 0.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 5.0,
    "reasoning": "The content focuses on the distinction between human and AI agency in adaptive systems, particularly in strategy versus tactical optimisation. Direct mentions of 'estimation' do not occur; neither does the content discuss Agile or Scrum frameworks, empirical data use, or collaborative estimation practices. There are no references to estimation techniques, velocity, retrospectives, or other Agile estimation concerns. The conceptual themes (human vs. AI agency, accountability in adaptive systems, organisational risk) are largely unrelated to estimation as defined by the category. Any inferred relation to estimation is extremely tangential, possibly surfacing via the discussion of optimisation or decision-making, but never explicitly or substantively. The audience is likely managerial, strategic, or involved in systems thinking—not specifically Agile practitioners seeking to improve estimation. The content is highly focused, but on topics outside the definition of estimation in Agile, so the signal-to-noise ratio for the 'Estimation' category is very low. No penalties were applied, as there is no tone or outdated practice that would justify deduction. The very low score reflects minimal overlap with the target category, per evidence.",
    "level": "Ignored"
  },
  "Agile Planning": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Agile Planning",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 25.8,
    "ai_mentions": 0.2,
    "ai_alignment": 2.7,
    "ai_depth": 3.1,
    "ai_intent": 2.8,
    "ai_audience": 5.0,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 26.0,
    "reasoning": "The content directly discusses human and AI agency in adaptive systems, primarily focusing on the distinction between strategic (human) and tactical (AI) decision-making. It does not explicitly mention Agile Planning, nor does it reference Agile methodologies, practices, or key concepts like sprints, backlogs, or iteration. There is some loose conceptual connection around adaptation and strategy, which are relevant to Agile thinking, but the main discussion centers on system-level agency boundaries and governance, not on principles or practices of Agile Planning itself. The audience is partially aligned (organizational leaders and system designers, which could include agile practitioners), but the overall focus, depth, and intent are not matched to Agile Planning as strictly defined in the category guidance. Signal-to-noise is moderate, as the discussion is focused but only tangential to Agile Planning. No penalties are applied, as the content is recent, not obsolete, and does not contradict the Agile Planning framing directly. The low confidence score reflects the minimal overlap with the specific concerns and practices of Agile Planning.",
    "level": "Ignored"
  },
  "Product Backlog": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Product Backlog",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 2.869,
    "ai_mentions": 0.1,
    "ai_alignment": 0.8,
    "ai_depth": 0.6,
    "ai_intent": 1.2,
    "ai_audience": 0.1,
    "ai_signal": 0.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content does not mention or reference Product Backlog at any point. Its primary focus is on differentiating human and AI agency in adaptive systems, exploring boundaries, responsibilities, and risks of overdelegating adaptation to AI. There are no discussions of Agile, Scrum, backlog refinement, roles of Product Owner, user stories, tools for backlog management, or any practices associated with Product Backlog management. Conceptual overlap is minimal: while some organizational and strategic themes are discussed, they are independent from backlog concepts and don't address backlog prioritization, structure, or use cases. No information is present on Product Backlog audiences (Agile/Scrum teams, Product Owners). The content is coherent and in-depth regarding its actual topic, but it is almost entirely noise in relation to Product Backlog. No penalties were applied since the tone is not critical or outdated regarding Product Backlog; it is simply off-topic. The low confidence score reflects the near-total irrelevance to the Product Backlog category.",
    "level": "Ignored"
  },
  "Agile Product Management": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Agile Product Management",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 24.66,
    "ai_mentions": 0.3,
    "ai_alignment": 2.8,
    "ai_depth": 3.2,
    "ai_intent": 2.5,
    "ai_audience": 4.2,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 25.0,
    "reasoning": "The content makes no direct mention of Agile Product Management, nor does it reference Agile, Scrum, Product Owners, backlogs, or any of the core practices or terminology exclusive to the category. The primary topic centers around the differentiation between human and AI agency within adaptive systems, focusing on strategic versus tactical decision-making—a theme that may conceptually intersect with modern product leadership but is not specifically linked to Agile frameworks or practices. There is substantial depth in discussing what constitutes human versus AI agency, including risks and operational guidelines, but these discussions are positioned at a general systems or organizational level, not in the context of maximizing product value or Agile ways of working. The intent of the content is more philosophical and strategic rather than practical or actionable within Agile Product Management. While the likely audience (executives, strategists, technologists) could overlap with some in Agile leadership, there is no targeting of product management practitioners or those invested in Agile transformation. The content is focused and coherent, but its relevance to 'Agile Product Management' is mainly tangential—any application to that category is interpretative at best and not explicit. No penalties were needed as the content is neither outdated nor satirical. Overall, the confidence score is kept low due to the absence of direct or detailed category relevance.",
    "level": "Ignored"
  },
  "Self Organisation": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Self Organisation",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 31.975,
    "ai_mentions": 0.4,
    "ai_alignment": 3.6,
    "ai_depth": 3.9,
    "ai_intent": 2.1,
    "ai_audience": 4.2,
    "ai_signal": 5.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 32.0,
    "reasoning": "The content focuses on the division of agency between humans and AI within adaptive systems, centering on the strategic value of human decision-making over tactical AI optimisation. There are no direct or explicit mentions of 'self-organisation' or related terminology (e.g., autonomous teams, Agile, Scrum, empowerment, retrospectives), so Direct Mentions is extremely low. The main thrust is about organisational boundaries and accountability in socio-technical contexts, which has partial conceptual overlap with self-organisation (e.g., emphasis on human adaptation, accountability, autonomy at a high level), but it does not specifically address autonomous teams, collaborative practices, or frameworks that facilitate self-organisation as defined. Depth is moderate since the article explores human vs. AI roles in-depth, but only tangentially echos elements relevant to self-organisation (e.g., accountability, critical adaptation roles), and does not discuss methods or practices central to the category. The intent is not to inform about self-organisation per se, but about responsible governance of human and AI agency, so Intent/Purpose Fit is low. The probable audience (leaders and technical strategists) has some overlap with practitioners interested in self-organisation, but the framing is more about high-level system design than team empowerment, so Audience Alignment is moderate. Signal-to-Noise is above average due to focus and clarity, but not tightly tied to the category. No penalties were necessary; content tone is appropriate and up-to-date. The final confidence score reflects a weak fit—while the content has glancing conceptual resonance with the values of self-organisation, it does not meet the threshold for strong alignment with the provided definition.",
    "level": "Ignored"
  },
  "Agile Philosophy": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Agile Philosophy",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 46.75,
    "ai_mentions": 0.9,
    "ai_alignment": 5.5,
    "ai_depth": 6.7,
    "ai_intent": 5.2,
    "ai_audience": 5.6,
    "ai_signal": 6.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 47.0,
    "reasoning": "The content deeply explores the contrast and synergy between human and AI agency in adaptive systems, emphasizing the crucial role of human strategic intent, accountability, and adaptation. While the themes of adaptability, continuous improvement, and human-centric decision-making are conceptually adjacent to Agile Philosophy, the piece does not directly mention Agile, the Agile Manifesto, or any of its 12 principles. Explicit references to Agile values, principles, teams, organizational behavior, or Agile cultural shifts are absent. The conceptual overlap lies mainly in the discussion of adaptability, sensemaking, accountability, and human leadership—all qualities foundational to the Agile philosophy, but here they are discussed in the context of AI/human roles, not directly within Agile frameworks or culture. The depth of discussion about human adaptation and purpose is notable, akin to Agile values, but the connection to Agile as a philosophy is implicit and requires interpretive inference. The intent targets organizational leaders and strategists—possibly an Agile-adjacent audience—but stops short of targeting Agile practitioners or those explicitly focused on Agile mindset. The content remains tightly focused on the core comparison of human/AI agency in adaptation, lending it moderate signal-to-noise. Final confidence reflects these conceptual overlaps but appropriately down-weights for the lack of explicit Agile philosophy reference or framing.",
    "level": "Tertiary"
  },
  "Sociotechnical Systems": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Sociotechnical Systems",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 93.1,
    "ai_mentions": 7.4,
    "ai_alignment": 9.8,
    "ai_depth": 9.5,
    "ai_intent": 9.2,
    "ai_audience": 9.0,
    "ai_signal": 9.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 93.0,
    "reasoning": "This content thoroughly examines the interaction of human and AI agency within adaptive systems, mapping roles in decision-making, strategic vs. tactical boundaries, and accountability—all core themes in sociotechnical systems. While the term 'Sociotechnical Systems' is not used verbatim, the article explicitly discusses the integration of human (social/organisational) and AI (technical) elements in organisational contexts, notably in software adaptation, team responsibility, and governance practices. The depth includes specific risks, responsibilities, a decision flowchart, and prescriptive advice for practitioners and leaders, evidencing significant engagement with sociotechnical theory. The audience is clearly technical leaders and strategists concerned with successful, resilient organisations at the intersection of technology and organisational culture. The signal-to-noise ratio is high: nearly all content relates directly to sociotechnical themes, with only minor tangents. No outdated content or hostile tone was identified, so no penalties were applied. The confidence score reflects both comprehensive exploration and high alignment across all evaluation dimensions.",
    "level": "Primary"
  },
  "Internal Developer Platform": {
    "category": "Internal Developer Platform",
    "calculated_at": "2025-04-29T13:01:01",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Internal Developer Platforms or their components, benefits, or best practices. The themes of the content do not align with the core topics of IDPs, and there is minimal depth regarding any relevant aspects of software development processes or environments.",
    "level": "Ignored"
  },
  "GitHub": {
    "category": "GitHub",
    "calculated_at": "2025-04-29T13:01:05",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, with no direct mention of GitHub or its functionalities. While it touches on themes of collaboration and decision-making, these are not specific to GitHub or its tools, thus lacking alignment with the core topics of the GitHub category.",
    "level": "Ignored"
  },
  "Value Stream Management": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Value Stream Management",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 17.55,
    "ai_mentions": 0.25,
    "ai_alignment": 2.5,
    "ai_depth": 2.0,
    "ai_intent": 1.7,
    "ai_audience": 5.4,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content focuses on the distinction between human and AI agency in adaptive systems, emphasizing the need for strategy-setting and accountability to remain with humans while AI executes tactical optimisation. This is a foundational organisational design discussion, centering on adaptation, accountability, and effective decision-making, but it does not address Value Stream Management directly or by analogy: there are no explicit mentions of value stream mapping, process optimisation against customer value, waste identification, or aligning flow with business outcomes. The ideas about boundaries and optimisation could tangentially relate to process efficiency, but the text completely lacks reference to value streams or typical VSM techniques. The closest parallel is an abstract argument about the locus of adaptation versus optimisation, but this is not explicitly or implicitly mapped to value flows or streams. The audience (organisational leaders, strategists, or technologists) may overlap with VSM, but the content’s primary focus, terminology, and depth are not aligned. Signal-to-noise is moderate, as the text is focused but not relevant to VSM per se. There is no out-of-dateness, undermining, or satirical tone, so no penalties apply. The low scores in all direct-fit dimensions and moderate audience/signal yield a low overall confidence score, as per weighting.",
    "level": "Ignored"
  },
  "Definition of Done": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Definition of Done",
    "calculated_at": "2025-05-08T08:55:02",
    "ai_confidence": 2.9,
    "ai_mentions": 0.2,
    "ai_alignment": 0.6,
    "ai_depth": 0.5,
    "ai_intent": 1.0,
    "ai_audience": 4.3,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content does not reference or discuss the Definition of Done (DoD) or its associated Agile/Scrum practices in any form. 'Definition of Done' and related terminology (e.g., acceptance criteria, product increment, backlog) are never mentioned. The conceptual focus is solely on delineating roles and boundaries between human and AI agency in adaptive systems, emphasizing strategy, purpose, and accountability—none of which are tied to DoD or Agile completion criteria. While the intended audience may slightly overlap with technical or managerial practitioners (hence the modest audience score), the depth is minimal regarding DoD, with all substantive discussion dedicated to system adaptation, ethics, and strategic leadership. The signal-to-noise ratio is low for DoD relevance; almost none of the content pertains to the category. No penalties apply as the content is not outdated or oppositional—just off-topic. Overall, this piece merits an extremely low confidence for inclusion under 'Definition of Done.'",
    "level": "Ignored"
  },
  "Azure DevOps": {
    "category": "Azure DevOps",
    "calculated_at": "2025-04-29T13:01:16",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Azure DevOps or its functionalities, nor does it align with the core themes of Azure DevOps, such as CI/CD, project management, or collaboration tools. The discussion is abstract and philosophical, lacking any practical insights or best practices related to Azure DevOps.",
    "level": "Ignored"
  },
  "Competence": {
    "category": "Competence",
    "calculated_at": "2025-04-29T13:01:20",
    "ai_confidence": 32.0,
    "ai_mentions": 10.0,
    "ai_alignment": 40.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on the importance of human accountability and decision-making, it does not explicitly address continuous learning or skill development, which are central to the concept of competence. The discussion is more about the balance of agency rather than the development of competence within teams or organisations, leading to a lower confidence score.",
    "level": "Ignored"
  },
  "Team Motivation": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Team Motivation",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 26.3,
    "ai_mentions": 0.6,
    "ai_alignment": 3.2,
    "ai_depth": 2.8,
    "ai_intent": 2.6,
    "ai_audience": 4.2,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 26.0,
    "reasoning": "The content focuses on delineating human and AI roles in decision-making within adaptive systems, emphasising the necessity of human agency for strategic intent and ethical stewardship. There is no explicit mention of 'team motivation' or direct references to techniques, strategies, or social dynamics that enhance engagement within agile teams. Conceptually, while the material touches on leadership, accountability, and adaptation, these are addressed in the context of organisational system design and strategy, not in relation to motivating teams or fostering team dynamics. Depth is moderate in its primary topic but remains peripheral to team motivation. The main intent is to guide strategy and agency boundaries, not to provide motivational practices or frameworks for teams. The target audience skews towards organisational leaders and system designers rather than team facilitators or agile practitioners. The content is focused and coherent, though its relevance to 'Team Motivation' is quite tangential overall. Thus, the confidence in this category fit is low and proportionate to the very limited overlap.",
    "level": "Ignored"
  },
  "Daily Scrum": {
    "category": "Daily Scrum",
    "calculated_at": "2025-04-29T13:01:27",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content does not mention the Daily Scrum or its principles. It focuses on human and AI agency in adaptive systems, which is unrelated to the structure, roles, or practices of the Daily Scrum event.",
    "level": "Ignored"
  },
  "Agentic Agility": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Agentic Agility",
    "calculated_at": "2025-05-08T08:55:03",
    "ai_confidence": 94.36,
    "ai_mentions": 8.4,
    "ai_alignment": 9.7,
    "ai_depth": 9.4,
    "ai_intent": 9.0,
    "ai_audience": 9.2,
    "ai_signal": 9.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 94.0,
    "reasoning": "The content is explicitly and deeply focused on the distinctions and interplay between human and AI agency in adaptive (socio-technical) systems, directly referencing key terms and nuances of agentic agility. The term 'agency' is repeatedly and centrally discussed, highlighting both human and AI forms—their roles, boundaries, and strategic vs. tactical functions. The alignment with the Agentic Agility definition is exceptionally strong, especially regarding intentionality, adaptive action, accountability, and outcome alignment. Depth is demonstrated through thorough exploration of agency layers, the risks of overdelegating to AI, and practical strategies for operationalising agency boundaries. The content's primary intent is to inform and guide practitioners—in Agile, DevOps, and adaptive system contexts—about maintaining agentic boundaries and the crucial role of human agency, matching the intended audience of the category. Signal-to-noise ratio is very high; nearly every section elaborates directly on the relevant themes, with minimal tangents or filler. There are no outdated or contradictory references; the tone is urgent but constructive. No penalties were warranted. The final confidence score reflects the exceptional directness, conceptual match, and depth, just shy of perfection in mentions (as 'Agentic Agility' as a phrase is somewhat implicit rather than cited verbatim).",
    "level": "Primary"
  },
  "Collaboration Tools": {
    "category": "Collaboration Tools",
    "calculated_at": "2025-04-29T13:01:35",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 10,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention collaboration tools or their impact on Agile teams, nor does it provide any insights into enhancing communication or coordination within teams. The themes of collaboration and Agile methodologies are not present, leading to a very low confidence score in relation to the specified category.",
    "level": "Ignored"
  },
  "Frequent Releases": {
    "category": "Frequent Releases",
    "calculated_at": "2025-04-29T13:01:40",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention software delivery, release frequency, or related practices, which are central to the 'Frequent Releases' category. The discussion lacks any direct relevance to continuous delivery or deployment principles, making it largely irrelevant to the category.",
    "level": "Ignored"
  },
  "Sensemaking": {
    "category": "Sensemaking",
    "calculated_at": "2025-04-29T13:01:45",
    "ai_confidence": 87.0,
    "ai_mentions": 3,
    "ai_alignment": 85.0,
    "ai_depth": 90.0,
    "non_ai_confidence": 0,
    "final_score": 87.0,
    "reasoning": "The content explicitly discusses the role of human agency in adaptive systems, particularly in the context of strategic decision-making and sensemaking. It highlights the importance of interpreting signals and detecting patterns, which aligns closely with the core themes of sensemaking. The depth of discussion is significant, as it explores the risks of over-relying on AI for adaptation and the necessity of human discernment in complex environments. Overall, the content provides a thorough examination of how organisations can navigate complexity and uncertainty, making it a strong fit for the Sensemaking category.",
    "level": "Primary"
  },
  "Social Technologies": {
    "category": "Social Technologies",
    "calculated_at": "2025-04-29T13:01:50",
    "ai_confidence": 68.0,
    "ai_mentions": 2,
    "ai_alignment": 75.0,
    "ai_depth": 60.0,
    "non_ai_confidence": 0,
    "final_score": 68.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, highlighting the importance of human strategic intent and decision-making, which aligns with the core themes of Social Technologies. It touches on collaboration between human and AI roles, but the primary focus is on the delineation of responsibilities rather than fostering collective intelligence or transparency within teams. While it provides a detailed exploration of agency boundaries and the risks of overdelegating to AI, it does not delve deeply into methods for enhancing collaboration or specific tools that support emergent problem-solving, which slightly limits its depth in the context of Social Technologies.",
    "level": "Secondary"
  },
  "Product Validation": {
    "category": "Product Validation",
    "calculated_at": "2025-04-29T13:01:55",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of decision-making and accountability, it does not directly address product validation methodologies, user testing, or customer feedback loops. The discussion lacks explicit references to validating product ideas through user engagement, which is essential for the 'Product Validation' category.",
    "level": "Ignored"
  },
  "Lean Principles": {
    "category": "Lean Principles",
    "calculated_at": "2025-04-29T13:01:59",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on concepts of efficiency and optimisation, it does not explicitly mention Lean principles, waste reduction, or value maximisation. The discussion lacks depth in Lean-specific tools or practices, and the core themes of Lean are not a primary focus.",
    "level": "Ignored"
  },
  "Engineering Practices": {
    "category": "Engineering Practices",
    "calculated_at": "2025-04-29T13:02:02",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of decision-making and accountability, it does not directly address core engineering practices such as clean code, TDD, CI/CD, or automation. The discussion is more philosophical and strategic rather than technical or methodological, leading to a low confidence score in alignment with the 'Engineering Practices' category.",
    "level": "Ignored"
  },
  "Liberating Structures": {
    "category": "Liberating Structures",
    "calculated_at": "2025-04-29T13:02:06",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Liberating Structures or any specific facilitation techniques, nor does it align with the core themes of engagement and collaboration that are central to the category. The discussion is more about decision-making and accountability rather than facilitation methods, leading to a very low confidence score.",
    "level": "Ignored"
  },
  "Systems Thinking": {
    "category": "Systems Thinking",
    "calculated_at": "2025-04-29T13:02:11",
    "ai_confidence": 82.0,
    "ai_mentions": 3,
    "ai_alignment": 85.0,
    "ai_depth": 75.0,
    "non_ai_confidence": 10,
    "final_score": 82.0,
    "reasoning": "The content discusses the interplay between human and AI agency within adaptive systems, which aligns closely with Systems Thinking principles. It highlights the importance of strategic intent and the need for human discernment in decision-making, reflecting the interconnectedness of components within a system. The detailed mapping of agency roles and the risks of overdelegating adaptation to AI demonstrate a holistic analysis of organisational dynamics. However, while the content is rich in relevant themes, it does not explicitly mention Systems Thinking or its foundational principles, which slightly lowers the confidence score.",
    "level": "Primary"
  },
  "Product Delivery": {
    "category": "Product Delivery",
    "calculated_at": "2025-04-29T13:02:15",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on decision-making and the importance of human oversight, it does not directly address product delivery methodologies, practices, or the end-to-end process of delivering software products. The themes of product delivery, such as Agile methodologies, testing, and deployment, are absent, leading to a low confidence score in this category.",
    "level": "Ignored"
  },
  "Customer Feedback Loops": {
    "category": "Customer Feedback Loops",
    "calculated_at": "2025-04-29T13:02:19",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention customer feedback or its integration into product development processes, which are central to the 'Customer Feedback Loops' category. The discussion lacks any techniques or methods for gathering customer insights or integrating feedback into development, leading to a very low confidence score in alignment with the specified category.",
    "level": "Ignored"
  },
  "Trend Analysis": {
    "category": "Trend Analysis",
    "calculated_at": "2025-04-29T13:02:23",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent versus tactical optimisation. While it touches on themes of adaptation and decision-making, it does not explicitly analyse trends within Agile, DevOps, or business agility frameworks. The discussion lacks direct references to emerging trends or their implications for organisational practices, which are central to the Trend Analysis category. Therefore, the content is only tangentially related to the category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Decision Theory": {
    "category": "Decision Theory",
    "calculated_at": "2025-04-29T13:02:28",
    "ai_confidence": 78.0,
    "ai_mentions": 3,
    "ai_alignment": 85.0,
    "ai_depth": 70.0,
    "non_ai_confidence": 0,
    "final_score": 78.0,
    "reasoning": "The content discusses the roles of human and AI agency in decision-making processes, particularly in adaptive systems. It explicitly mentions decision-making layers and the importance of human discernment in strategic contexts, aligning well with key topics in Decision Theory. The depth of discussion on the risks of overdelegating adaptation to AI and the necessity of human accountability further supports its relevance to the category. However, while it touches on decision-making, the primary focus is on the relationship between human and AI agency rather than a comprehensive exploration of decision theory itself.",
    "level": "Secondary"
  },
  "Business Agility": {
    "category": "Business Agility",
    "calculated_at": "2025-04-29T13:02:33",
    "ai_confidence": 72.0,
    "ai_mentions": 15,
    "ai_alignment": 30,
    "ai_depth": 25,
    "non_ai_confidence": 0,
    "final_score": 72.0,
    "reasoning": "The content discusses the critical role of human agency in adaptive systems, which aligns with the principles of business agility, particularly in terms of responding to changes and maintaining strategic direction. It highlights the importance of human discernment in decision-making and the risks of over-relying on AI for adaptation, which speaks to the need for organisations to be agile and responsive. However, while it touches on themes relevant to business agility, such as adaptation and strategic intent, it does not delve deeply into specific strategies or frameworks for fostering business agility within organisations, which slightly limits its depth of discussion. Overall, the content is relevant but not exclusively focused on business agility, hence the confidence score reflects a strong but not complete alignment.",
    "level": "Secondary"
  },
  "Enterprise Agility": {
    "category": "Enterprise Agility",
    "calculated_at": "2025-04-29T13:02:37",
    "ai_confidence": 72.0,
    "ai_mentions": 3,
    "ai_alignment": 80.0,
    "ai_depth": 60.0,
    "non_ai_confidence": 0,
    "final_score": 72.0,
    "reasoning": "The content discusses the importance of human agency in adaptive systems, which aligns with the principles of responsiveness and adaptability central to enterprise agility. It highlights the need for organisations to maintain strategic direction and purpose while leveraging AI for tactical optimisation, reflecting a broader organisational context. However, while it touches on themes relevant to enterprise agility, such as accountability and the risks of overdelegating to AI, it does not delve deeply into specific frameworks, metrics, or case studies that would further solidify its alignment with the category.",
    "level": "Secondary"
  },
  "Technical Debt": {
    "category": "Technical Debt",
    "calculated_at": "2025-04-29T13:02:42",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent versus tactical optimisation. While it touches on the importance of human oversight and the risks of over-relying on AI, it does not explicitly mention technical debt or its management. The themes of strategic decision-making and the consequences of neglecting human agency do not align closely with the core topics of technical debt, such as code quality or design decisions. Therefore, the confidence score reflects a very low relevance to the category.",
    "level": "Ignored"
  },
  "Evidence Based Leadership": {
    "category": "Evidence Based Leadership",
    "calculated_at": "2025-04-29T13:02:46",
    "ai_confidence": 32.0,
    "ai_mentions": 0,
    "ai_alignment": 25.0,
    "ai_depth": 50.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on decision-making and accountability, it does not explicitly reference evidence-based leadership principles or empirical evidence to support its claims. The discussion lacks direct mentions of evidence-based practices, metrics, or case studies, which are crucial for a higher confidence score in this category.",
    "level": "Ignored"
  },
  "Artificial Intelligence": {
    "category": "Artificial Intelligence",
    "calculated_at": "2025-04-29T13:02:51",
    "ai_confidence": 78.0,
    "ai_mentions": 15,
    "ai_alignment": 32,
    "ai_depth": 30,
    "non_ai_confidence": 0,
    "final_score": 78.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on how AI optimises tactics while humans define strategy and purpose. It aligns well with the category by exploring the integration of AI in decision-making processes and the implications for organisational practices. The depth of discussion is significant, addressing the risks of over-relying on AI and the necessity of maintaining human accountability. However, while it touches on AI's role in optimisation, it does not delve deeply into specific Agile or DevOps methodologies, which slightly lowers the overall confidence score.",
    "level": "Secondary"
  },
  "Empirical Process Control": {
    "category": "Empirical Process Control",
    "calculated_at": "2025-04-29T13:02:54",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of adaptation and decision-making, it does not explicitly mention empirical process control or its principles. The discussion lacks depth in relation to Agile methodologies and does not provide concrete examples or case studies relevant to empirical process control, leading to a low confidence score.",
    "level": "Ignored"
  },
  "Ability to Innovate": {
    "category": "Ability to Innovate",
    "calculated_at": "2025-04-29T13:03:00",
    "ai_confidence": 72.0,
    "ai_mentions": 15,
    "ai_alignment": 30,
    "ai_depth": 35,
    "non_ai_confidence": 20,
    "final_score": 72.0,
    "reasoning": "The content discusses the critical role of human agency in adaptive systems, emphasising the importance of strategic intent and adaptation, which are essential for fostering innovation. It highlights the risks of over-relying on AI for adaptation, suggesting that innovation requires human discernment and accountability. While it does not explicitly mention innovation metrics or frameworks, it aligns well with the core themes of the category by addressing the need for a balance between human and AI roles in innovation processes. The depth of discussion on the implications of agency in adaptive systems contributes to a strong confidence score, though it lacks specific metrics or case studies that would further enhance its alignment with the category.",
    "level": "Secondary"
  },
  "One Engineering System": {
    "category": "One Engineering System",
    "calculated_at": "2025-04-29T13:03:04",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 10,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention the One Engineering System (1ES) framework or its principles, components, or implementation. The discussion is centred around the interaction between human and AI roles rather than the integration and standardisation of engineering processes, which is the core focus of the 1ES category.",
    "level": "Ignored"
  },
  "Agile Planning Tools": {
    "category": "Agile Planning Tools",
    "calculated_at": "2025-04-29T13:03:07",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Agile Planning Tools or related methodologies, nor does it explore topics such as backlog management, sprint planning, or team collaboration within Agile frameworks. The discussion is more philosophical and theoretical, lacking any practical application to Agile planning tools.",
    "level": "Ignored"
  },
  "Evidence Based Management": {
    "category": "Evidence Based Management",
    "calculated_at": "2025-04-29T13:03:12",
    "ai_confidence": 32.0,
    "ai_mentions": 0,
    "ai_alignment": 25.0,
    "ai_depth": 50.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on decision-making and the importance of human accountability, it does not explicitly mention Evidence-Based Management or its key topics. The discussion is more philosophical and theoretical, lacking direct references to empirical evidence or metrics that are central to EBM. Therefore, while there is some conceptual alignment, the depth of discussion does not sufficiently meet the criteria for a strong classification in this category.",
    "level": "Ignored"
  },
  "Metrics and Learning": {
    "category": "Metrics and Learning",
    "calculated_at": "2025-04-29T13:03:17",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 10,
    "final_score": 25.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of decision-making and adaptation, it does not explicitly mention metrics, data collection, or feedback mechanisms, which are central to the 'Metrics and Learning' category. The discussion lacks depth in terms of evidence-based decision-making and continuous improvement methodologies, leading to a low confidence score in alignment with the category.",
    "level": "Ignored"
  },
  "Product Strategy": {
    "category": "Product Strategy",
    "calculated_at": "2025-04-29T13:03:21",
    "ai_confidence": 75.0,
    "ai_mentions": 15,
    "ai_alignment": 30,
    "ai_depth": 35,
    "non_ai_confidence": 10,
    "final_score": 75.0,
    "reasoning": "The content discusses the importance of human agency in defining strategy and purpose within adaptive systems, which aligns with the core themes of product strategy. It highlights the need for strategic intent and the risks of over-relying on AI for tactical optimisation, indicating a clear understanding of strategic planning. However, while it touches on strategic concepts, it does not delve deeply into specific methodologies or frameworks for product strategy, which slightly limits its depth of discussion.",
    "level": "Secondary"
  },
  "Scrum Master": {
    "category": "Scrum Master",
    "calculated_at": "2025-04-29T13:03:25",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention the Scrum Master role or its specific responsibilities within the Scrum framework. While it touches on themes of accountability and decision-making, these are not directly related to the Scrum Master accountability or its impact on Scrum teams. Therefore, the content does not align well with the category.",
    "level": "Ignored"
  },
  "Strategic Goals": {
    "category": "Strategic Goals",
    "calculated_at": "2025-04-29T13:03:30",
    "ai_confidence": 87.0,
    "ai_mentions": 15,
    "ai_alignment": 35,
    "ai_depth": 40,
    "non_ai_confidence": 20,
    "final_score": 87.0,
    "reasoning": "The content extensively discusses the importance of human agency in defining strategic intent and purpose within adaptive systems, which aligns closely with the category of Strategic Goals. It highlights the necessity of human discernment in setting direction and adapting strategies, thus directly addressing long-term objectives and business agility. The depth of discussion is significant, as it elaborates on the risks of over-relying on AI for strategic sensing and the importance of maintaining human accountability in decision-making. Overall, the content is primarily focused on strategic goals, making it a strong fit for the category.",
    "level": "Primary"
  },
  "Minimum Viable Product": {
    "category": "Minimum Viable Product",
    "calculated_at": "2025-04-29T13:03:34",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Minimum Viable Products or related concepts such as core features, user feedback, or Lean Startup methodology. The discussion is more about decision-making and agency rather than product development or market validation, leading to a very low confidence score in relation to the MVP category.",
    "level": "Ignored"
  },
  "Agile Frameworks": {
    "category": "Agile Frameworks",
    "calculated_at": "2025-04-29T13:03:39",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of adaptation and decision-making, it does not explicitly mention Agile frameworks or principles. The discussion lacks direct references to Agile methodologies, their implementation, or their impact on organisational agility, which are central to the category of Agile Frameworks.",
    "level": "Ignored"
  },
  "Digital Transformation": {
    "category": "Digital Transformation",
    "calculated_at": "2025-04-29T13:03:47",
    "ai_confidence": 65.0,
    "ai_mentions": 3,
    "ai_alignment": 70.0,
    "ai_depth": 60.0,
    "non_ai_confidence": 0,
    "final_score": 65.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, highlighting the importance of strategic intent and the limitations of AI in decision-making. While it touches on themes relevant to digital transformation, such as the integration of AI and the need for human oversight, it does not explicitly focus on the broader strategic adoption of digital technologies for business transformation. The discussion is more centred on the philosophical and operational aspects of agency rather than specific digital transformation strategies or case studies, which slightly limits its depth in this category.",
    "level": "Secondary"
  },
  "Lean Thinking": {
    "category": "Lean Thinking",
    "calculated_at": "2025-04-29T13:03:51",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of efficiency and optimisation, it does not explicitly mention Lean principles, waste minimisation, or continuous improvement. The discussion lacks depth in Lean concepts and does not align with the core themes of Lean Thinking, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Operational Practices": {
    "category": "Operational Practices",
    "calculated_at": "2025-04-29T13:03:55",
    "ai_confidence": 32.0,
    "ai_mentions": 5,
    "ai_alignment": 15,
    "ai_depth": 12,
    "non_ai_confidence": 10,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on operational aspects, such as the need for clear agency boundaries and the risks of overdelegating to AI, it primarily centres on the philosophical implications of agency rather than practical operational practices. The discussion lacks specific techniques or strategies for enhancing operational efficiency within Agile, DevOps, or Lean frameworks, which diminishes its alignment with the category. Therefore, while there are relevant mentions, the depth and focus on operational practices are limited.",
    "level": "Ignored"
  },
  "Sprint Review": {
    "category": "Sprint Review",
    "calculated_at": "2025-04-29T13:03:59",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content does not mention Sprint Reviews or any related concepts within the Scrum framework. It focuses on the roles of human and AI agency in adaptive systems, which is unrelated to the inspection of work increments or stakeholder feedback that characterises a Sprint Review.",
    "level": "Ignored"
  },
  "Cross Functional Teams": {
    "category": "Cross Functional Teams",
    "calculated_at": "2025-04-29T13:04:03",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 15.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention cross-functional teams or their characteristics, nor does it explore the collaboration or diverse skill sets that define such teams. The discussion is centred around decision-making layers and the risks of overdelegating to AI, which are not relevant to the concept of cross-functional teams in Agile methodologies.",
    "level": "Ignored"
  },
  "Scrum Values": {
    "category": "Scrum Values",
    "calculated_at": "2025-04-29T13:04:07",
    "ai_confidence": 10.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 10.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention or align with the Scrum Values of commitment, courage, focus, openness, or respect. The discussion is more about decision-making frameworks rather than the collaborative principles that underpin Scrum, leading to a very low confidence score.",
    "level": "Ignored"
  },
  "Deployment Strategies": {
    "category": "Deployment Strategies",
    "calculated_at": "2025-04-29T13:04:11",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 5.0,
    "non_ai_confidence": 10,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention or align with any deployment strategies, methodologies, or practices related to software deployment. The discussion is theoretical and does not provide actionable insights into deployment strategies, thus falling far outside the specified category.",
    "level": "Ignored"
  },
  "Organisational Psychology": {
    "category": "Organisational Psychology",
    "calculated_at": "2025-04-29T13:04:16",
    "ai_confidence": 32.0,
    "ai_mentions": 2,
    "ai_alignment": 25.0,
    "ai_depth": 40.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, touching on themes of strategic intent and accountability, which are relevant to organisational psychology. However, it primarily focuses on the interaction between human and AI roles rather than delving deeply into psychological principles or theories that influence motivation, engagement, or team dynamics. The mentions of human agency and accountability are present but do not constitute a primary focus on organisational psychology as defined in the category. The depth of discussion on these psychological aspects is limited, leading to a moderate confidence score.",
    "level": "Ignored"
  },
  "Agile Transformation": {
    "category": "Agile Transformation",
    "calculated_at": "2025-04-29T13:04:20",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of adaptation and decision-making, it does not explicitly mention Agile principles, frameworks, or transformation strategies. The discussion lacks depth in Agile-specific methodologies and does not address key topics such as change management or leadership roles in Agile transformations, leading to a low confidence score in alignment with the Agile Transformation category.",
    "level": "Ignored"
  },
  "Agile Leadership": {
    "category": "Agile Leadership",
    "calculated_at": "2025-04-29T13:04:28",
    "ai_confidence": 32.0,
    "ai_mentions": 5,
    "ai_alignment": 15,
    "ai_depth": 12,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the importance of human agency in adaptive systems, which touches on leadership roles in guiding strategic direction and decision-making. However, it primarily focuses on the distinction between human and AI agency rather than explicitly addressing Agile leadership principles or practices. While there are mentions of accountability and strategic intent, the depth of discussion does not sufficiently align with the core themes of Agile Leadership, such as fostering a culture of trust or servant leadership. Therefore, while there are relevant elements, the overall focus is more on the interaction between human and AI roles rather than on Agile leadership itself.",
    "level": "Ignored"
  },
  "Organisational Culture": {
    "category": "Organisational Culture",
    "calculated_at": "2025-04-29T13:04:32",
    "ai_confidence": 32.0,
    "ai_mentions": 2,
    "ai_alignment": 40.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, touching on themes of strategic intent and accountability, which can relate to organisational culture. However, it primarily focuses on the interaction between human and AI roles rather than explicitly addressing organisational culture's influence on agility or transformation. The mentions of accountability and strategic direction hint at cultural aspects but lack depth in exploring how these elements foster or hinder Agile methodologies or team dynamics.",
    "level": "Ignored"
  },
  "Agnostic Agile": {
    "category": "Agnostic Agile",
    "calculated_at": "2025-04-29T13:04:36",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent versus tactical optimisation. While it touches on themes of adaptability and the importance of human decision-making, it does not explicitly mention Agnostic Agile or its principles. The discussion lacks depth regarding Agnostic Agile's core themes, such as comparisons to specific agile frameworks or ethical considerations in agile practices. Overall, the content is more focused on the relationship between human and AI roles rather than on agile methodologies or principles.",
    "level": "Ignored"
  },
  "Team Collaboration": {
    "category": "Team Collaboration",
    "calculated_at": "2025-04-29T13:04:40",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 5.0,
    "non_ai_confidence": 10,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on collaboration between humans and AI, it does not explicitly address team dynamics, communication, or shared ownership within Agile, Scrum, or DevOps frameworks. The discussion lacks depth in terms of team collaboration techniques or practices, leading to a low confidence score in this category.",
    "level": "Ignored"
  },
  "Throughput": {
    "category": "Throughput",
    "calculated_at": "2025-04-29T13:04:44",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of optimisation, it does not explicitly mention throughput as a delivery metric or provide any analysis, visualisation, or interpretation of throughput. The discussion lacks depth in relation to throughput metrics, making it a secondary topic rather than a primary focus.",
    "level": "Ignored"
  },
  "Technical Excellence": {
    "category": "Technical Excellence",
    "calculated_at": "2025-04-29T13:04:48",
    "ai_confidence": 32.0,
    "ai_mentions": 0,
    "ai_alignment": 25.0,
    "ai_depth": 40.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on the importance of human decision-making and accountability, it does not explicitly mention or explore key technical practices such as TDD, CI/CD, or modular architecture. The discussion is more philosophical and strategic rather than rooted in engineering practices that ensure high-quality software delivery. Therefore, while there is some conceptual alignment with the idea of maintaining quality through human oversight, the lack of direct mentions and specific technical practices leads to a lower confidence score in the category of Technical Excellence.",
    "level": "Ignored"
  },
  "Agile Strategy": {
    "category": "Agile Strategy",
    "calculated_at": "2025-04-29T13:04:52",
    "ai_confidence": 72.0,
    "ai_mentions": 15,
    "ai_alignment": 30,
    "ai_depth": 25,
    "non_ai_confidence": 10,
    "final_score": 72.0,
    "reasoning": "The content discusses the importance of human agency in defining strategy and purpose within adaptive systems, which aligns with the Agile Strategy category's focus on organisational vision and adaptability. It highlights the need for strategic intent and the risks of over-relying on AI for tactical optimisation, which touches on the integration of Agile principles into strategic planning. However, while it addresses strategic concepts, it does not explicitly mention Agile methodologies or practices, leading to a moderate confidence score. The depth of discussion on the interplay between human and AI roles in strategy provides valuable insights but lacks specific Agile context.",
    "level": "Secondary"
  },
  "Team Performance": {
    "category": "Team Performance",
    "calculated_at": "2025-04-29T13:04:55",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 15.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of decision-making and accountability, it does not explicitly address team performance or delivery metrics at the team level. The discussion lacks depth regarding team dynamics, systemic constraints, or delivery patterns, which are crucial for the 'Team Performance' category.",
    "level": "Ignored"
  },
  "Install and Configuration": {
    "category": "Install and Configuration",
    "calculated_at": "2025-04-29T13:05:01",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 10,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic and tactical decision-making rather than any specific installation or configuration processes. There are no direct mentions of installation procedures, configuration best practices, or troubleshooting related to Agile or DevOps tools, which are essential for this category. The discussion is theoretical and strategic, lacking the actionable instructions or insights required for effective implementation of technologies in an organisational context.",
    "level": "Ignored"
  },
  "Professional Scrum": {
    "category": "Professional Scrum",
    "calculated_at": "2025-04-29T13:05:05",
    "ai_confidence": 32.0,
    "ai_mentions": 0,
    "ai_alignment": 40.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 10,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and accountability. However, it does not explicitly mention Scrum or its principles, which limits its direct relevance to the Professional Scrum category. While there are elements of accountability and the importance of human decision-making that align with Scrum values, the depth of discussion on Scrum-specific practices is minimal.",
    "level": "Ignored"
  },
  "Transparency": {
    "category": "Transparency",
    "calculated_at": "2025-04-29T13:05:09",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 5.0,
    "non_ai_confidence": 0,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on accountability, it does not explicitly address transparency in Agile processes or the importance of clear communication and visibility within teams. The discussion lacks depth in relation to transparency, making it a secondary theme rather than a primary focus.",
    "level": "Ignored"
  },
  "Automated Testing": {
    "category": "Automated Testing",
    "calculated_at": "2025-04-29T13:05:13",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention automated testing, its principles, practices, or methodologies, nor does it align with the key topics outlined for the 'Automated Testing' category. The discussion is more philosophical and strategic rather than technical or related to software testing.",
    "level": "Ignored"
  },
  "Azure Pipelines": {
    "category": "Azure Pipelines",
    "calculated_at": "2025-04-29T13:05:16",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content discusses human and AI agency in adaptive systems, focusing on strategic and tactical roles rather than Azure Pipelines or any related CI/CD practices. There are no direct mentions of Azure Pipelines, and the themes do not align with the core topics of Azure Pipelines, such as build and release management, YAML configurations, or deployment strategies.",
    "level": "Ignored"
  },
  "Employee Engagement": {
    "category": "Employee Engagement",
    "calculated_at": "2025-04-29T13:05:20",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of accountability and decision-making, it does not explicitly address employee engagement, motivation, or practices that enhance team commitment. The discussion lacks direct relevance to the core principles of employee engagement, making it a secondary topic at best.",
    "level": "Ignored"
  },
  "Psychological Safety": {
    "category": "Psychological Safety",
    "calculated_at": "2025-04-29T13:05:24",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of accountability and decision-making, it does not explicitly address psychological safety or its importance in team dynamics, communication, or innovation. The discussion lacks depth in relation to psychological safety, making it a secondary topic rather than a primary focus.",
    "level": "Ignored"
  },
  "Value Stream Mapping": {
    "category": "Value Stream Mapping",
    "calculated_at": "2025-04-29T13:05:27",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 10,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Value Stream Mapping or its principles, nor does it align with the core themes of VSM, such as workflow visualisation or waste elimination. The discussion is more about decision-making layers and the risks of overdelegating to AI, which is outside the scope of Value Stream Mapping.",
    "level": "Ignored"
  },
  "Working Agreements": {
    "category": "Working Agreements",
    "calculated_at": "2025-04-29T13:05:32",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not explicitly mention working agreements or their importance in team collaboration, nor does it provide techniques or examples related to working agreements. The discussion is more about decision-making layers and the risks of overdelegating to AI, which deviates from the core principles of teamwork and collaboration outlined in the category definition.",
    "level": "Ignored"
  },
  "Software Development": {
    "category": "Software Development",
    "calculated_at": "2025-04-29T13:05:36",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on decision-making and operational practices, it does not directly address software development methodologies, coding practices, or any of the key topics outlined in the Software Development category. The discussion is more philosophical and strategic rather than technical or methodological, leading to a low confidence score in alignment with the Software Development category.",
    "level": "Ignored"
  },
  "Backlog Refinement": {
    "category": "Backlog Refinement",
    "calculated_at": "2025-04-29T13:05:40",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention backlog refinement, Agile practices, or Scrum methodologies, which are essential for this category. The themes of collaboration and iterative improvement are present but are not related to backlog refinement specifically.",
    "level": "Ignored"
  },
  "Time to Market": {
    "category": "Time to Market",
    "calculated_at": "2025-04-29T13:05:43",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 5.0,
    "non_ai_confidence": 10,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of efficiency and adaptation, it does not explicitly mention Time to Market or related metrics. The discussion lacks depth in addressing how these concepts impact the speed of delivering value to customers, which is central to the Time to Market category.",
    "level": "Ignored"
  },
  "Continuous Integration": {
    "category": "Continuous Integration",
    "calculated_at": "2025-04-29T13:05:47",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Continuous Integration or related practices, tools, or principles. The themes of CI, such as code integration, automated testing, and team collaboration, are absent, leading to a very low confidence score for alignment with the Continuous Integration category.",
    "level": "Ignored"
  },
  "Forecasting": {
    "category": "Forecasting",
    "calculated_at": "2025-04-29T13:05:51",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of adaptation and decision-making, it does not explicitly address forecasting methods, empirical data utilisation, or Agile and Scrum practices. The discussion lacks direct relevance to the core topics of forecasting, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Personal": {
    "category": "Personal",
    "calculated_at": "2025-04-29T13:05:55",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. However, it lacks personal anecdotes or reflections that would align it with the 'Personal' category. While it touches on themes relevant to Agile and decision-making, it does not provide individual experiences or insights, making it more of a theoretical discussion rather than a personal reflection.",
    "level": "Ignored"
  },
  "Mentoring": {
    "category": "Mentoring",
    "calculated_at": "2025-04-29T13:05:58",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 15.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of accountability and decision-making, it does not explicitly mention mentoring, coaching, or the development of skills and behaviours necessary for effective practice in Agile or related methodologies. The discussion lacks depth in terms of mentoring techniques or strategies for professional growth, leading to a low confidence score in the 'Mentoring' category.",
    "level": "Ignored"
  },
  "Azure Repos": {
    "category": "Azure Repos",
    "calculated_at": "2025-04-29T13:06:01",
    "ai_confidence": 0,
    "ai_mentions": 0,
    "ai_alignment": 0,
    "ai_depth": 0,
    "non_ai_confidence": 0,
    "final_score": 0.0,
    "reasoning": "The content focuses on the roles of human and AI agency in adaptive systems, discussing strategic intent and tactical optimisation. It does not mention Azure Repos or any related topics such as source control, branching strategies, or CI/CD processes, making it entirely irrelevant to the category.",
    "level": "Ignored"
  },
  "Project Management": {
    "category": "Project Management",
    "calculated_at": "2025-04-29T13:06:05",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on decision-making and accountability, which are relevant to project management, it does not explicitly address project management methodologies, lifecycle phases, or tools. The discussion is more philosophical and theoretical rather than practical and actionable, leading to a low confidence score in the context of project management.",
    "level": "Ignored"
  },
  "System Configuration": {
    "category": "System Configuration",
    "calculated_at": "2025-04-29T13:06:09",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 10,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on concepts relevant to system dynamics, it does not explicitly address system configuration, tools, or methodologies for setup and maintenance. The discussion lacks direct mentions of system configuration practices, and the depth of exploration into system setup or integration is minimal, leading to a low confidence score in this category.",
    "level": "Ignored"
  },
  "Beta Codex": {
    "category": "Beta Codex",
    "calculated_at": "2025-04-29T13:06:13",
    "ai_confidence": 72.0,
    "ai_mentions": 3,
    "ai_alignment": 85.0,
    "ai_depth": 65.0,
    "non_ai_confidence": 0,
    "final_score": 72.0,
    "reasoning": "The content discusses the importance of human agency in adaptive systems, which aligns with the human-centric approach of BetaCodex. It highlights the need for strategic intent and ethical stewardship, resonating with the principles of decentralisation and adaptive organisational cultures. However, while it touches on relevant themes, it does not explicitly mention BetaCodex or provide detailed case studies or comparisons with traditional models, which limits its depth of discussion. Overall, the content is closely aligned with the category but lacks some explicit references and depth in certain areas.",
    "level": "Secondary"
  },
  "Product Owner": {
    "category": "Product Owner",
    "calculated_at": "2025-04-29T13:06:17",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on accountability, it does not specifically address the Product Owner's accountability within Scrum or Agile frameworks. The primary focus is on the distinction between human and AI roles rather than the Product Owner's responsibilities, leading to a low confidence score in this category.",
    "level": "Ignored"
  },
  "Definition of Ready": {
    "category": "Definition of Ready",
    "calculated_at": "2025-04-29T13:06:20",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 10,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention the Definition of Ready or its criteria, nor does it address backlog item readiness, which are central to the category. The discussion lacks any direct relevance to the DoR, making it a very low confidence score.",
    "level": "Ignored"
  },
  "Unrealised Value": {
    "category": "Unrealised Value",
    "calculated_at": "2025-04-29T13:06:25",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent versus tactical optimisation. While it touches on the importance of human agency in defining strategy and purpose, it does not explicitly mention 'Unrealised Value' or its indicators, nor does it explore untapped opportunities or potential improvements in a way that aligns with the category's core themes. The discussion lacks depth regarding the identification or measurement of unrealised value, leading to a low confidence score.",
    "level": "Ignored"
  },
  "Release Management": {
    "category": "Release Management",
    "calculated_at": "2025-04-29T13:06:28",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention release management, software delivery, or any related practices. The themes of release management, such as version control, risk management, or CI/CD, are absent, leading to a very low confidence score in alignment with the category.",
    "level": "Ignored"
  },
  "Cycle Time": {
    "category": "Cycle Time",
    "calculated_at": "2025-04-29T13:06:31",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Cycle Time or its measurement, nor does it explore its implications within Agile or DevOps practices. The discussion is more about decision-making and agency rather than workflow efficiency or Cycle Time metrics.",
    "level": "Ignored"
  },
  "Technical Mastery": {
    "category": "Technical Mastery",
    "calculated_at": "2025-04-29T13:06:35",
    "ai_confidence": 25.0,
    "ai_mentions": 5,
    "ai_alignment": 15,
    "ai_depth": 10,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on the importance of human discernment and accountability, it does not delve into specific software craftsmanship practices, methodologies, or principles that are central to the 'Technical Mastery' category. The discussion is more philosophical and strategic rather than technical, leading to a low confidence score in alignment with the category.",
    "level": "Ignored"
  },
  "Continuous Improvement": {
    "category": "Continuous Improvement",
    "calculated_at": "2025-04-29T13:06:40",
    "ai_confidence": 32.0,
    "ai_mentions": 0,
    "ai_alignment": 40.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on the importance of adaptation and the risks of over-relying on AI, it does not explicitly mention Continuous Improvement or its principles. The conceptual alignment is moderate as it hints at the need for ongoing adaptation, but the depth of discussion on Continuous Improvement practices is minimal, leading to a lower confidence score.",
    "level": "Ignored"
  },
  "Complexity Thinking": {
    "category": "Complexity Thinking",
    "calculated_at": "2025-04-29T13:06:44",
    "ai_confidence": 87.0,
    "ai_mentions": 15,
    "ai_alignment": 35,
    "ai_depth": 30,
    "non_ai_confidence": 10,
    "final_score": 87.0,
    "reasoning": "The content extensively discusses the roles of human and AI agency within adaptive systems, highlighting the importance of human strategic intent in the face of complexity. It aligns well with key topics of Complexity Thinking, such as the need for human discernment in decision-making and the implications of uncertainty in management. The depth of discussion on the risks of overdelegating adaptation to AI and the necessity of maintaining clear agency boundaries further supports its relevance to the category. The content does not merely mention complexity but engages with its principles, making it a strong fit for the classification.",
    "level": "Primary"
  },
  "Value Delivery": {
    "category": "Value Delivery",
    "calculated_at": "2025-04-29T13:06:48",
    "ai_confidence": 25.0,
    "ai_mentions": 5,
    "ai_alignment": 15,
    "ai_depth": 5,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on the importance of human agency in defining purpose and direction, it does not explicitly address value delivery within Agile, Scrum, or DevOps frameworks. The discussion lacks depth in terms of methodologies or practices that enhance customer satisfaction or business agility, which are central to the Value Delivery category. Therefore, while there are relevant mentions, the overall alignment and depth are limited.",
    "level": "Ignored"
  },
  "Experimentation": {
    "category": "Experimentation",
    "calculated_at": "2025-04-29T13:06:53",
    "ai_confidence": 32.0,
    "ai_mentions": 2,
    "ai_alignment": 40.0,
    "ai_depth": 25.0,
    "non_ai_confidence": 50,
    "final_score": 32.0,
    "reasoning": "The content discusses the role of AI in tactical optimisation and mentions rapid experimentation within bounded parameters, which aligns with the concept of experimentation. However, the primary focus is on the distinction between human and AI agency rather than on hypothesis-driven approaches or systematic testing of ideas. The depth of discussion on experimentation techniques is limited, and while there are mentions of experimentation, they are not the central theme of the content.",
    "level": "Ignored"
  },
  "Azure Boards": {
    "category": "Azure Boards",
    "calculated_at": "2025-04-29T13:06:56",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content does not mention Azure Boards or any related concepts. It focuses on the roles of human and AI agency in adaptive systems, which is unrelated to Azure Boards or Agile project management. There is no discussion of work items, customisation, or any features relevant to Azure Boards, leading to a very low confidence score.",
    "level": "Ignored"
  },
  "Revenue per Employee": {
    "category": "Revenue per Employee",
    "calculated_at": "2025-04-29T13:06:59",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention Revenue per Employee or relate to workforce efficiency, organisational throughput, or financial performance metrics. The discussion is more philosophical and strategic rather than empirical or metric-based, which is essential for the category.",
    "level": "Ignored"
  },
  "Modern Source Control": {
    "category": "Modern Source Control",
    "calculated_at": "2025-04-29T13:07:03",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention version control systems, branching strategies, or any other key topics related to modern source control. The discussion is centred around decision-making and organisational dynamics rather than version control practices, leading to a very low confidence score in alignment with the category.",
    "level": "Ignored"
  },
  "Working Software": {
    "category": "Working Software",
    "calculated_at": "2025-04-29T13:07:07",
    "ai_confidence": 10.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 10.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not directly address working software as an output artifact, nor does it engage with Agile or Scrum principles. The mention of optimisation and adaptation is more theoretical and does not connect to the delivery of tangible software products, leading to a very low confidence score in the 'Working Software' category.",
    "level": "Ignored"
  },
  "Scrum Team": {
    "category": "Scrum Team",
    "calculated_at": "2025-04-29T13:07:12",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention the Scrum Team, its structure, or its responsibilities as defined in the Scrum framework. The themes of accountability and team dynamics are not addressed in relation to Scrum, leading to a very low confidence score for alignment with the 'Scrum Team' category.",
    "level": "Ignored"
  },
  "Common Goals": {
    "category": "Common Goals",
    "calculated_at": "2025-04-29T13:07:16",
    "ai_confidence": 32.0,
    "ai_mentions": 10.0,
    "ai_alignment": 40.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 10,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on the importance of strategic direction, it does not explicitly address the concept of Common Goals as defined in Agile and DevOps frameworks. The discussion lacks a clear connection to shared objectives or alignment within teams, which are central to the Common Goals category. The depth of discussion on aligning strategy with execution is minimal, leading to a low confidence score.",
    "level": "Ignored"
  },
  "Open Space Agile": {
    "category": "Open Space Agile",
    "calculated_at": "2025-04-29T13:07:21",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not directly mention Open Space Agile or its principles, nor does it engage with the core themes of collective participation, psychological safety, or co-creation in Agile transformations. While there are elements of organisational agility, they are not framed within the context of Open Space Agile, leading to a low confidence score.",
    "level": "Ignored"
  },
  "Continuous Learning": {
    "category": "Continuous Learning",
    "calculated_at": "2025-04-29T13:07:25",
    "ai_confidence": 32.0,
    "ai_mentions": 10.0,
    "ai_alignment": 40.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on the importance of human discernment and adaptation, it does not explicitly address continuous learning principles or practices. The discussion lacks depth in terms of techniques for knowledge sharing, feedback loops, or creating a culture of experimentation, which are key topics in the Continuous Learning category. Therefore, while there are relevant themes, the primary focus is not on continuous learning itself.",
    "level": "Ignored"
  },
  "Asynchronous Development": {
    "category": "Asynchronous Development",
    "calculated_at": "2025-04-29T13:07:29",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic versus tactical decision-making. It does not mention asynchronous development or its principles, tools, or practices. While it touches on collaboration and decision-making, it does not align with the core themes of asynchronous development, nor does it provide any depth on the topic. Therefore, the confidence score is low, reflecting minimal relevance to the category.",
    "level": "Ignored"
  },
  "Organisational Agility": {
    "category": "Organisational Agility",
    "calculated_at": "2025-04-29T13:07:33",
    "ai_confidence": 78.0,
    "ai_mentions": 15,
    "ai_alignment": 32,
    "ai_depth": 30,
    "non_ai_confidence": 0,
    "final_score": 78.0,
    "reasoning": "The content discusses the critical role of human agency in adaptive systems, emphasising the need for strategic intent and adaptability, which aligns well with the principles of organisational agility. It highlights the importance of human decision-making in response to changing environments, a key aspect of agility. The depth of discussion on the risks of over-relying on AI for adaptation and the need for clear boundaries between human and AI roles further supports its relevance to the category. However, while it touches on agility, it does not explicitly discuss agile methodologies or frameworks, which slightly lowers the confidence score.",
    "level": "Secondary"
  },
  "Flow Efficiency": {
    "category": "Flow Efficiency",
    "calculated_at": "2025-04-29T13:07:37",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 25.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 10,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on concepts of optimisation, it does not explicitly address flow efficiency or the optimisation of work throughput across a value stream. The discussion lacks direct mentions of flow efficiency principles, metrics, or techniques for eliminating bottlenecks, which are central to the category. Overall, the content is more about the philosophical implications of agency rather than practical applications related to flow efficiency.",
    "level": "Ignored"
  },
  "Hypothesis Driven Development": {
    "category": "Hypothesis Driven Development",
    "calculated_at": "2025-04-29T13:07:41",
    "ai_confidence": 32.0,
    "ai_mentions": 2,
    "ai_alignment": 40.0,
    "ai_depth": 25.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the importance of human agency in defining strategy and setting hypotheses, which aligns with the conceptual framework of hypothesis-driven development. However, it primarily focuses on the distinction between human and AI roles in adaptive systems rather than detailing the process of formulating, testing, and validating hypotheses through experimentation. The mention of 'hypothesis-driven exploration' is relevant but not central to the overall discussion, leading to a lower confidence score.",
    "level": "Ignored"
  },
  "Pragmatic Thinking": {
    "category": "Pragmatic Thinking",
    "calculated_at": "2025-04-29T13:07:46",
    "ai_confidence": 82.0,
    "ai_mentions": 15,
    "ai_alignment": 32,
    "ai_depth": 35,
    "non_ai_confidence": 10,
    "final_score": 82.0,
    "reasoning": "The content discusses the critical roles of human and AI agency in adaptive systems, emphasising the importance of human strategic intent and decision-making in complex environments. It aligns well with pragmatic thinking by addressing practical problem-solving strategies, particularly in the context of AI and human collaboration. The depth of discussion is significant, providing detailed insights into the risks of overdelegating to AI and the necessity of maintaining human accountability. The content effectively illustrates real-world applications and the need for clear operational boundaries, which are key aspects of pragmatic thinking.",
    "level": "Primary"
  },
  "Entrepreneurship": {
    "category": "Entrepreneurship",
    "calculated_at": "2025-04-29T13:07:50",
    "ai_confidence": 32.0,
    "ai_mentions": 10.0,
    "ai_alignment": 40.0,
    "ai_depth": 50.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of decision-making and adaptation, which are relevant to entrepreneurship, it does not explicitly address entrepreneurship principles, innovation, or risk-taking. The discussion is more about operational dynamics rather than entrepreneurial strategies or mindsets, leading to a lower confidence score in the entrepreneurship category.",
    "level": "Ignored"
  },
  "Shift Left Strategy": {
    "category": "Shift Left Strategy",
    "calculated_at": "2025-04-29T13:07:54",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 10,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent versus tactical optimisation. While it touches on themes of decision-making and accountability, it does not explicitly mention or align with the Shift-Left Strategy, which is centred on integrating testing, security, and compliance earlier in the software development lifecycle. The discussion lacks depth regarding the principles, techniques, or tools associated with the Shift-Left approach, leading to a low confidence score.",
    "level": "Ignored"
  },
  "Test Automation": {
    "category": "Test Automation",
    "calculated_at": "2025-04-29T13:07:58",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. It does not mention test automation, frameworks, or practices related to software testing. The themes of the content do not align with the principles of test automation, and there is no depth of discussion on any relevant topics within this category.",
    "level": "Ignored"
  },
  "Decision Making": {
    "category": "Decision Making",
    "calculated_at": "2025-04-29T13:08:01",
    "ai_confidence": 82.0,
    "ai_mentions": 15,
    "ai_alignment": 32,
    "ai_depth": 28,
    "non_ai_confidence": 0,
    "final_score": 82.0,
    "reasoning": "The content discusses the critical roles of human and AI agency in decision-making within adaptive systems, focusing on strategic intent versus tactical optimisation. It explicitly mentions decision-making layers and the importance of human accountability in the process. The depth of discussion on the risks of overdelegating to AI and the need for clear agency boundaries further aligns with evidence-based decision-making principles. However, while it touches on decision-making, it does not delve deeply into structured methodologies or empirical frameworks, which slightly lowers the confidence score.",
    "level": "Primary"
  },
  "Customer Retention": {
    "category": "Customer Retention",
    "calculated_at": "2025-04-29T13:08:05",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic intent and tactical optimisation. While it touches on themes of adaptation and decision-making, it does not directly address customer retention strategies, user engagement, or methodologies for minimising churn. The discussion lacks explicit references to customer satisfaction, feedback mechanisms, or personalisation, which are crucial for the Customer Retention category.",
    "level": "Ignored"
  },
  "Principle": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Principle",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 78.0,
    "ai_mentions": 15,
    "ai_alignment": 32,
    "ai_depth": 28,
    "non_ai_confidence": null,
    "final_score": 78.0,
    "reasoning": "The content centers around the principles of human agency and the role of AI in adaptive systems, explicitly discussing how humans define strategy and purpose while AI focuses on tactical optimisation. There is a clear categorization of decision-making layers that aligns with key Agile principles such as accountability, adaptability, and the distinction between strategic and tactical roles. Additionally, it advocates for a principled approach to collaboration between humans and AI, making it actionable in the context of adaptive systems. Overall, the depth of discussion is substantial, covering practical implications and risks associated with misallocating agency, which further supports a high confidence in alignment with the category 'Principle'.",
    "level": "Secondary"
  },
  "Tool": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Tool",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 10.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": null,
    "final_score": 10.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency in adaptive systems, focusing on strategic vs. tactical decision-making. There are no mentions of specific tools or mechanisms that facilitate workflows, nor does it explore the implementation of any tools or their integration within Agile, Lean, or DevOps practices. Although it touches on concepts that can tangentially relate to tools (such as optimization), it does not provide sufficient depth or focus on tool utilization in a context relevant to the category.",
    "level": "Ignored"
  },
  "Accountability": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Accountability",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 82.0,
    "ai_mentions": 60.0,
    "ai_alignment": 90.0,
    "ai_depth": 90.0,
    "non_ai_confidence": null,
    "final_score": 82.0,
    "reasoning": "The content discusses the differentiation between human agency and AI agency, particularly emphasizing the importance of human accountability in strategic decision-making and system adaptation. It explicitly mentions accountability in the context of human responsibility for systemic impacts and outcomes, which is a crucial aspect of the 'Accountability' category. The alignment with key themes of the category, such as the ownership of outcomes and the risks of weak accountability due to overdelegating tasks to AI, is strong. The depth of the discussion is extensive, providing detailed insights into how accountability operates within the framework of adaptive systems. This makes the content a good fit for the 'Accountability' category.",
    "level": "Primary"
  },
  "Values": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Values",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 82.0,
    "ai_mentions": 15,
    "ai_alignment": 32,
    "ai_depth": 39,
    "non_ai_confidence": null,
    "final_score": 82.0,
    "reasoning": "The content extensively discusses the role of human agency in decision-making and strategic direction, emphasizing underlying values such as accountability, ethical stewardship, and the necessity for human leadership in contrast to AI's tactical capabilities. It aligns well with the category of 'Values' by exploring how these principles influence organizational behavior and decision-making. The focus on avoiding over-delegation of responsibility to AI reflects a commitment to preserving crucial human values in adaptive systems. The depth of discussion regarding human accountability and decision-making further reinforces this classification.",
    "level": "Primary"
  },
  "Philosophy": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Philosophy",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 87.0,
    "ai_mentions": 15,
    "ai_alignment": 34,
    "ai_depth": 32,
    "non_ai_confidence": null,
    "final_score": 87.0,
    "reasoning": "The content aligns strongly with the category of Philosophy as it discusses the foundational beliefs surrounding human agency and AI agency within adaptive systems. It emphasizes the importance of human strategic intent versus AI's role in tactical optimization, exploring the ethical implications and responsibilities inherent in this relationship. The depth of discussion covers various layers of decision-making and the risks associated with overdelegating to AI, framing it within a philosophical context of agency and accountability. It explicitly discusses the 'why' behind these practices and the cultural implications for organizations, meeting the essence of philosophical exploration as required by the category.",
    "level": "Primary"
  },
  "Discipline": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Discipline",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 58.0,
    "ai_mentions": 2,
    "ai_alignment": 60.0,
    "ai_depth": 55.0,
    "non_ai_confidence": null,
    "final_score": 58.0,
    "reasoning": "The content discusses the role of human agency vs. AI in adaptive systems, highlighting the importance of human accountability and strategic intent, which ties into governance structures and ethical considerations in a discipline. However, while it touches on principles of organisation and decision-making, it does not delve deeply into the implementation of Agile, DevOps, or Lean methodologies as specific disciplines. The mention of 'operational discipline' suggests some alignment, but the focus does not exclusively remain on established disciplines and their evolution, which lowers the overall confidence score.",
    "level": "Tertiary"
  },
  "Artifact": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Artifact",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 12.0,
    "ai_mentions": 10.0,
    "ai_alignment": 5.0,
    "ai_depth": 3.0,
    "non_ai_confidence": null,
    "final_score": 12.0,
    "reasoning": "The content focuses primarily on the roles of human and AI agency within adaptive systems, discussing strategic and tactical dimensions rather than specific artifacts relevant to Agile or similar frameworks. While it hints at the importance of agency and decision-making processes, it does not explicitly address artifacts or their management, structure, or purpose in a way that aligns with the category. The discussion is more abstract and philosophical, without connecting to key artifact types or best practices that are central to the 'Artifact' classification.",
    "level": "Ignored"
  },
  "Observability": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Observability",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": null,
    "final_score": 15.0,
    "reasoning": "The content primarily focuses on the relationship between human and AI agency in adaptive systems. While it mentions concepts of decision-making and adaptation, it does not discuss observability in the context of software systems, metrics, logs, traces, or tools that enhance observability. The themes presented do not align with the key topics outlined for the observability category, such as monitoring solutions or best practices in Agile and DevOps environments. Overall, the content does not meet the criteria for a robust discussion on observability.",
    "level": "Ignored"
  },
  "Practice": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Practice",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 5.0,
    "non_ai_confidence": null,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses the philosophical and theoretical aspects of human and AI agency in adaptive systems rather than presenting actionable practices or techniques for enhancing team performance. It mentions concepts that could be tangentially related to collaborative decision-making or optimization, but it does not explore specific practices that teams can implement to improve their effectiveness or collaboration. Therefore, it scores low in direct mentions, alignment with the core themes of the category, and depth of discussion related to practical techniques.",
    "level": "Ignored"
  },
  "Method": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Method",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 25.0,
    "ai_mentions": 100.0,
    "ai_alignment": 35.0,
    "ai_depth": 20.0,
    "non_ai_confidence": null,
    "final_score": 25.0,
    "reasoning": "The content discusses the roles of human agency and AI agency in adaptive systems, focusing mainly on strategic versus tactical dimensions. While it briefly mentions operationalizing agency boundaries, it lacks a detailed, structured, step-by-step method specific to Agile, Lean, or DevOps practices. Instead, it presents conceptual discussions about agency in systems without offering procedural insights or practical methods for implementation.",
    "level": "Ignored"
  },
  "Strategy": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Strategy",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 85.0,
    "ai_mentions": 16,
    "ai_alignment": 35,
    "ai_depth": 30,
    "non_ai_confidence": null,
    "final_score": 85.0,
    "reasoning": "The content extensively discusses the roles of human agency in defining strategy and purpose within adaptive systems, distinct from AI's tactical optimisation role. The text emphasizes strategic intent, decision-making, and the importance of human oversight in a world increasingly influenced by AI, which strongly aligns with strategic discussions. There are multiple direct mentions of strategic aspects such as 'strategic intent', 'purpose setting', and the 'collapse of strategic sensing', indicating a thorough engagement with strategic concepts. However, while the depth of discussion is rich, some areas delve more into tactical implications rather than purely strategic frameworks, slightly reducing the overall alignment score. Overall, it is a deep strategic analysis with clear references to high-level decision-making frameworks.",
    "level": "Primary"
  },
  "Model": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Model",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 32.0,
    "ai_mentions": 12,
    "ai_alignment": 24,
    "ai_depth": 20,
    "non_ai_confidence": null,
    "final_score": 32.0,
    "reasoning": "The content discusses human and AI agency in adaptive systems, emphasizing strategy and purpose, but does not explicitly mention any models, frameworks, or structures that directly relate to the 'Model' category. While it touches on the conceptual roles of human and AI agency suggesting a layered approach to decision-making, it lacks the detailed discussion of specific models or frameworks aligned with Agile, DevOps, or Lean principles. Thus, while there are elements of discussion that are conceptually relevant, they do not fully align with the classification requirements.",
    "level": "Ignored"
  },
  "Framework": {
    "resourceId": "Human-AI-Agency",
    "category": "Framework",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 22.0,
    "ai_mentions": 10.0,
    "ai_alignment": 40.0,
    "ai_depth": 30.0,
    "non_ai_confidence": null,
    "final_score": 22.0,
    "reasoning": "The content primarily discusses the roles of human and AI agency within adaptive systems, emphasizing strategic vs. tactical distinctions rather than framing discussions around specific frameworks like Agile or Lean. While it touches on themes related to human decision-making and system adaptation, it lacks a clear focus on established frameworks or methodologies that would align it with the Framework category. The mention of agency does not translate into a structured framework discussion as defined in the category description, thus resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Tenet": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Tenet",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 23.0,
    "ai_mentions": 5,
    "ai_alignment": 15,
    "ai_depth": 30,
    "non_ai_confidence": null,
    "final_score": 23.0,
    "reasoning": "The content discusses the roles and boundaries of human and AI agency in adaptive systems, which could relate to decision-making processes. However, it does not explicitly present actionable guiding rules or doctrines that are prescriptive for organizations, which is essential for the Tenet category. While there are mentions of strategic direction and accountability, the overall focus is not on the application of specific tenets in methodologies like Agile, Lean, or DevOps.",
    "level": "Ignored"
  },
  "Capability": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Capability",
    "calculated_at": "2025-05-01T14:48:24",
    "ai_confidence": 38.0,
    "ai_mentions": 5,
    "ai_alignment": 45.0,
    "ai_depth": 30.0,
    "non_ai_confidence": null,
    "final_score": 38.0,
    "reasoning": "The content primarily discusses the distinct roles of human and AI agency in adaptive systems. While there are elements that touch on capabilities, such as the need for strategic intent and the cultivation of human discernment, it largely focuses on the roles and accountabilities of humans versus AI, which falls outside the core themes of capability. Additionally, it emphasizes the risks of relying too heavily on AI without placing enough importance on the development of enduring competencies, thus leading to a lower confidence score in terms of depth and alignment with the Capability category.",
    "level": "Ignored"
  },
  "Service Level Expectation": {
    "resourceId": "ffJaR9AaTl7",
    "category": "Service Level Expectation",
    "calculated_at": "2025-05-06T20:54:05",
    "ai_confidence": 0,
    "ai_mentions": 0,
    "ai_alignment": 0,
    "ai_depth": 0,
    "ai_intent": 0,
    "ai_audience": 0.1,
    "ai_signal": 0.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 0.0,
    "reasoning": "The content does not mention Service Level Expectation (SLE) or reference any of its key concepts, such as cycle time ranges, probability-based forecasts, or Agile/Scrum/Kanban flow metrics. The focus is entirely on delineating human versus AI agency in adaptive systems, with no connection to SLE definition, calculation, use, or improvement in Agile contexts. There are no references to Kanban, Scrum, SLE metrics, or relevant authoritative sources. The content may tangentially relate to adaptation in systems, but this does not overlap with Service Level Expectation as defined. Accordingly, all relevant scores are near or at zero, and confidence is 0 on the required scale.",
    "level": "Ignored"
  }
}
