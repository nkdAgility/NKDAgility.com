{
  "Market Share": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Market Share",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 14.955,
    "ai_mentions": 0.2,
    "ai_alignment": 1.3,
    "ai_depth": 1.0,
    "ai_intent": 1.1,
    "ai_audience": 4.7,
    "ai_signal": 3.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 15.0,
    "reasoning": "The Kendall Guide outlines a framework for AI adoption in organisations, with strong emphasis on problem prioritisation, context, adaptive leadership, and evidence-based decision-making. However, there is no direct mention or discussion of 'market share', competitive positioning, customer targeting, or strategies aiming at increasing a product's presence in a market. No market analysis, sales strategies, or market metrics are discussed. The intended audience (organisation leaders, coaches, and teams) is only somewhat related to those seeking market share growth, but the Guide's scope is fixing internal adoption processes, not external market competition. Overall, the content only indirectly aligns at all, and lacks both depth and intent to fit the market share category.",
    "reasoning_summary": "The content is focused on AI adoption frameworks and internal organisational clarity; it does not address market share strategies, metrics, or competitive positioning. Fit with 'Market Share' is very weak and mostly incidental.",
    "level": "Ignored"
  },
  "Organisational Physics": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Organisational Physics",
    "calculated_at": "2025-09-17T23:12:36",
    "ai_confidence": 89.63,
    "ai_mentions": 7.8,
    "ai_alignment": 9.3,
    "ai_depth": 9.1,
    "ai_intent": 8.5,
    "ai_audience": 8.9,
    "ai_signal": 9.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 90.0,
    "reasoning": "The content consistently uses systems thinking principles to frame AI adoption decisions—not just as technical problems, but as dynamic organisational processes involving flow, feedback loops, empirical adaptation, and cross-team alignment. Terms like 'system of work,' 'feedback loops,' and 'organisational learning' directly align with Organisational Physics' focus on structure, process, and organisational behaviour. The framework is described as part of an adaptive system and highlights the interplay of structure, roles, and learning. Accountability roles (Kendall Coach, Opportunity Lead, Context Champion) map directly onto systemic functions aimed at maintaining organisational cohesion and adaptive performance. There are in-depth descriptions of feedback mechanisms (cadence events, learning cycles), holistically focused prioritisation approaches, and emergent value streams in AI contexts. There are very frequent references to system-level concepts, with thorough, purposeful intent and a highly relevant audience (practitioners, leaders focused on systemic organisational improvement). There is no outdated or undermining material. While the term 'Organisational Physics' is not directly mentioned, core systems thinking principles are made central, justifying a high but not perfect Direct Mentions score.",
    "reasoning_summary": "This framework is deeply aligned with Organisational Physics—emphasising systems thinking, feedback loops, and adaptive dynamics in organisational AI adoption. The content is highly relevant, holistic, and audience-appropriate, though the category is not directly named.",
    "level": "Primary"
  },
  "Model": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Model",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 90.4,
    "ai_mentions": 9.4,
    "ai_alignment": 9.7,
    "ai_depth": 9.3,
    "ai_intent": 9.1,
    "ai_audience": 8.8,
    "ai_signal": 8.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 90.0,
    "reasoning": "The content repeatedly names the Kendall Framework as a system of work, conceptual model, and structured approach to AI adoption. It details its principles, accountabilities, events, and artifacts, contextualising it like other models (e.g., Lean, DevOps). It discusses systems thinking, flow, adaptation, and informed decision-making, all highly allied to model-based organisational improvement. The main audience is practitioners, strategists, and leaders interested in using conceptual models to guide systems change. There are explicit, in-depth explorations of practices (e.g., accountabilities, artifacts), but very little off-topic or filler. No penalties applied; the fit is direct, thorough, and purposeful.",
    "reasoning_summary": "This content directly and extensively discusses the Kendall Framework as a conceptual model for AI adoption, deeply aligning with the 'Model' category’s themes, intent, and audience. Fit is clear, purposeful, and sustained throughout.",
    "level": "Primary"
  },
  "Observability": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Observability",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 31.53,
    "ai_mentions": 1.2,
    "ai_alignment": 3.9,
    "ai_depth": 2.6,
    "ai_intent": 3.8,
    "ai_audience": 7.0,
    "ai_signal": 5.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 32.0,
    "reasoning": "Direct mentions of 'observability' are minimal—it's referenced once as a complementary practice rather than a focus. The core theme is AI adoption frameworks, not the measurement or understanding of system internals as per the observability category. While some wording (e.g., transparency, feedback loops, flow of value) could indirectly relate to observability’s spirit, the guide neither defines, explores, nor applies observability concepts, practices, or tools in depth. Audience alignment is moderate since both address organizational improvement, but the signal-to-noise ratio and intent are low on observability relevance. No penalties for outdated or undermining tone.",
    "reasoning_summary": "The content briefly mentions observability but does not discuss its principles, tools, or applications. Its focus is an AI adoption framework, so observability is peripheral, with themes only partially overlapping the category definition.",
    "level": "Ignored"
  },
  "Organisational Culture": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Organisational Culture",
    "calculated_at": "2025-09-17T23:13:20",
    "ai_confidence": 73.89,
    "ai_mentions": 4.6,
    "ai_alignment": 8.8,
    "ai_depth": 8.2,
    "ai_intent": 7.3,
    "ai_audience": 7.0,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 74.0,
    "reasoning": "The content frequently references cultural elements such as collaboration, leadership accountabilities (Coach, Champions, Leads), feedback loops, and continuous improvement—all core to organisational culture and agility. It explores how these roles and ceremonies shape learning, alignment, reflection, and adaptability, with repeated stress on collective ownership, flow, disciplined alignment, and empirical adaptation. However, the framing is more focused on system/process design for AI adoption, and the explicit term 'organisational culture' is never directly named. While the examples (e.g., mentoring, feedback loops, cross-team alignment) are fundamentally cultural practices, the primary focus is practical AI adoption rather than theorising or deeply analysing culture for its own sake. The audience includes organisational leaders, teams, and facilitators, aligning partly with culture change agents, though also extending to technical and strategic stakeholders.",
    "reasoning_summary": "The guide thoroughly addresses practices and structures that influence organisational culture—especially regarding collaboration, learning, and adaptation—even if not explicitly framed as a culture transformation treatise. Its fit is strong but not absolute.",
    "level": "Secondary"
  },
  "Open Space Agile": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Open Space Agile",
    "calculated_at": "2025-09-17T23:13:22",
    "ai_confidence": 36.724,
    "ai_mentions": 0.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.6,
    "ai_intent": 4.3,
    "ai_audience": 5.7,
    "ai_signal": 5.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content does not directly mention Open Space Agile or Open Space Technology. Some concepts such as collective ownership, collaboration, empirical adaptation, and regular cadence resemble Agile and complexity-informed principles, but there are no explicit discussions of Open Space events, emergence, or the core mechanisms of Open Space Agile. The main focus is a framework for AI adoption, not on organisational agility transformation through the Open Space approach. Audience overlap is partial—readers interested in modern org change might be engaged, but the core audience is those adopting AI, not Agile transformation facilitators.",
    "reasoning_summary": "The content focuses on a framework for AI adoption, not Open Space Agile. While collaborative and adaptive elements partly align, it lacks Open Space Agile principles, events, and language; fit is weak and primarily tangential.",
    "level": "Ignored"
  },
  "Practice": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Practice",
    "calculated_at": "2025-09-17T23:13:20",
    "ai_confidence": 62.6,
    "ai_mentions": 3.7,
    "ai_alignment": 7.3,
    "ai_depth": 7.9,
    "ai_intent": 7.1,
    "ai_audience": 7.4,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 63.0,
    "reasoning": "The Kendall Guide describes a framework with actionable techniques like opportunity backlogs, discovery cadences, and role accountabilities. It defines inspect-and-adapt habits and dedicated events, all of which align with the concept of 'Practice.' However, the content's primary framing is as a system or framework for AI adoption, rather than focusing exclusively on specific, well-established team practices like pair programming or daily stand-ups. While practical guidance is present, some content is about structures or organizational roles, which dilutes the direct match with the 'Practice' category. The terminology and content closely target practitioners looking to operationalize AI in teams, but with moderate mentions of specific practices, and some content at the boundary between process/framework and concrete action. No penalties, as there is no outdated or critical tone present.",
    "reasoning_summary": "The content provides actionable guidance, roles, events, and techniques, aligning moderately well with 'Practice.' Its framework/system focus dilutes a purely practice-oriented fit but offers enough actionable techniques for reasonable confidence.",
    "level": "Secondary"
  },
  "Customer Focus": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Customer Focus",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 66.804,
    "ai_mentions": 2.8,
    "ai_alignment": 7.7,
    "ai_depth": 8.0,
    "ai_intent": 7.1,
    "ai_audience": 6.7,
    "ai_signal": 6.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 67.0,
    "reasoning": "The content centers on disciplined, evidence-based, and outcome-driven approaches to AI adoption, emphasizing solving real problems, prioritization, transparency, collaboration, and empirical feedback loops—principles congruent with customer focus. The framework describes mechanisms (Opportunity Backlog, prioritization, alignment to purpose and value) that can directly support customer centricity, and it references stakeholders and value creation. However, it does not consistently or explicitly invoke 'customer', 'user', or end-user outcomes, but seems to target a broader 'stakeholder' group. It leans toward creating value (which may include for customers), but the emphasis is frequently on organizational alignment, context, and clarity, sometimes at the expense of consistently foregrounding measurable customer value. Depth of discussion is strong on mechanisms for empiricism, alignment, learning, and adaptability, all compatible with customer focus, but only partially mapped directly to customer outcomes. The primary audience is transformation leaders, team coaches, and organizational change agents, which is proximate to (but a bit broader than) the direct target for customer focus. Few direct mentions exist, and some ambiguity remains in whether 'value' is always defined from the customer’s perspective.",
    "reasoning_summary": "Strong on evidence-based, outcome-driven approaches and alignment, but rarely focuses directly on measurable customer value or outcomes. Fit is partial—principles support customer focus, but explicit customer-centric discussion is limited.",
    "level": "Secondary"
  },
  "Agile Product Operating Model": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agile Product Operating Model",
    "calculated_at": "2025-09-17T23:13:20",
    "ai_confidence": 54.08,
    "ai_mentions": 1.2,
    "ai_alignment": 6.7,
    "ai_depth": 6.3,
    "ai_intent": 6.1,
    "ai_audience": 7.5,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 54.0,
    "reasoning": "The Kendall Guide presents a framework for AI adoption with strong emphasis on empirical, iterative, and evidence-based practices. It aligns with concepts seen in Agile Product Operating Model (APOM), such as continuous improvement, organisational learning loops, value flow visibility, and adaptive governance. Artifacts like Opportunity Backlog and Roadmap echo product management practices. Explicit APOM terminology, however, is never mentioned. Intent and target audience fit APOM-adjacent roles (coaches, product leaders); depth covers several APOM-compatible layers (flow, feedback, alignment). Still, the orientation is slightly more generic than APOM—grounded in AI systems of work rather than direct APOM principles or full integration with Professional Scrum. No outdated or contradictory content detected.",
    "reasoning_summary": "Content significantly overlaps with APOM ideas (iteration, value alignment, backlogs, empirical cycles) but lacks explicit references and is tailored to AI adoption, not APOM per se. Fit is partial; substantial conceptual alignment.",
    "level": "Tertiary"
  },
  "Product Developer": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Product Developer",
    "calculated_at": "2025-09-17T23:12:27",
    "ai_confidence": 19.79,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.6,
    "ai_intent": 1.7,
    "ai_audience": 6.1,
    "ai_signal": 3.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The Kendall Guide describes a bespoke framework for AI adoption, focusing on roles such as Kendall Coach, Opportunity Lead, and Context Champion. Nowhere does it mention Product Developer or analogous accountability as defined in the category. The structure, accountabilities, and practices described are about strategic adoption and organisational AI frameworks, not the skills, behaviors, or formal collective responsibilities of Product Developers. Concepts like Opportunity Backlog and adaptive accountabilities have parallels to modern product practices but remain distant from the precise Product Developer context. While there’s mention of collaboration and some collective ownership, these are in service of AI adoption, not about the Product Developer's technical and professional accountability to create Increments. The audience may overlap in a technical/managerial sense, but main themes and intent do not align.",
    "reasoning_summary": "Content discusses AI adoption frameworks and custom roles, not Product Developer accountability. No explicit alignment with Product Developer concepts, structure, or purpose as required by the category. Fit is minimal, with only tangential relevance.",
    "level": "Ignored"
  },
  "Large Scale Agility": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Large Scale Agility",
    "calculated_at": "2025-09-17T23:12:28",
    "ai_confidence": 59.682,
    "ai_mentions": 2.7,
    "ai_alignment": 7.2,
    "ai_depth": 6.7,
    "ai_intent": 7.1,
    "ai_audience": 7.6,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 60.0,
    "reasoning": "Direct references to 'Large Scale Agility' frameworks, scaling, or Agile transformation are absent. The Kendall Guide describes an organisational-level approach with cross-team accountabilities, alignment mechanisms, collaboration, and adaptation, partly mirroring large-scale Agile structures (e.g., roles akin to enterprise Agile leadership, regular feedback loops, prioritisation artifacts). However, its context is AI adoption, not Agile scaling per se. While the framework shares principles with large-scale Agile—such as organisational alignment, cross-discipline collaboration, and adaptive learning—it does not discuss scaling Agile methodologies, specific frameworks (SAFe, LeSS, etc.), or explicitly tie content to Agile enterprise transformation. The audience, themes, and artifacts overlap with those of large-scale Agile initiatives but fit partially. Most content focuses on systematising AI adoption rather than scaling Agile across multiple teams. Quality of alignment is moderate; conceptual overlap exists but is not complete.",
    "reasoning_summary": "The content partially fits: it presents an organisational framework with roles, alignment, and iterative improvement like large-scale Agile, but focuses on AI adoption—not scaling Agile. There's conceptual overlap, but not a direct fit with 'Large Scale Agility.'",
    "level": "Tertiary"
  },
  "Working Agreements": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Working Agreements",
    "calculated_at": "2025-09-17T23:12:20",
    "ai_confidence": 29.53,
    "ai_mentions": 1.6,
    "ai_alignment": 3.7,
    "ai_depth": 3.65,
    "ai_intent": 2.0,
    "ai_audience": 6.3,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 30.0,
    "reasoning": "The content outlines a framework for AI adoption centered on team clarity, roles, collaboration, and events, which partially overlaps with themes of working agreements. However, it lacks explicit reference to the establishment or maintenance of working agreements or explicit norms/principles governing team interactions. While elements (e.g., alignment, accountability, collaboration) coincide conceptually with topics discussed in working agreements, its main focus is not on the formulation, review, or use of working agreements themselves, but rather on overall system organisation for AI adoption. Key components such as examples of working agreements, methods for reviewing/adapting norms, or deep discussion on foundational team principles are absent. Therefore, the fit is partial but mostly tangential.",
    "reasoning_summary": "The content discusses team roles and collaboration but does not focus on the definition or management of working agreements; its fit with the category is partial and mainly indirect.",
    "level": "Ignored"
  },
  "Azure Boards": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Azure Boards",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 3.12,
    "ai_mentions": 0.2,
    "ai_alignment": 4.1,
    "ai_depth": 3.2,
    "ai_intent": 3.3,
    "ai_audience": 6.0,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content focuses entirely on the Kendall Framework for AI adoption. Azure Boards is never mentioned, and there are no references to its features, best practices, or Agile project management with Azure Boards. Terms like 'Opportunity Backlog' and 'Roadmap' are similar to Agile concepts, but are defined within the proprietary Kendall context and not directly linked to Azure Boards or Azure DevOps. The audience might tangentially overlap with those interested in project management tools, but the depth, intent, and alignment are all firmly about AI adoption and the Kendall system, not about Azure Boards in any substantive way. The signal is relatively high due to focus, but on a non-matching topic.",
    "reasoning_summary": "Content is about the Kendall Framework for AI adoption, not Azure Boards. No direct or indirect discussion of Azure Boards' functionalities, best practices, or role in Agile project management. Fit is minimal and largely coincidental.",
    "level": "Ignored"
  },
  "Release Management": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Release Management",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 8.0,
    "ai_mentions": 0.4,
    "ai_alignment": 1.6,
    "ai_depth": 1.2,
    "ai_intent": 1.0,
    "ai_audience": 2.0,
    "ai_signal": 1.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content focuses on organisational frameworks and practices for AI adoption with strong emphasis on alignment, context, opportunity prioritisation, and feedback loops. However, it does not mention or discuss release planning, release scheduling, CI/CD, risk management in releases, or tools/frameworks specific to software release management. Artifacts like 'Opportunity Backlog' and 'Roadmap' pertain to AI strategy and opportunity management, not to release processes. The cadence of events is for discovery and prioritisation, not for software releases. Audience overlap exists (potentially for practitioners or strategists in software organisations), but the core thematic, intent, and depth are not about Release Management. There is negligible direct mention of release practices.",
    "reasoning_summary": "This content does not fit Release Management; it is about AI adoption, strategy, and opportunity prioritisation, not planning, controlling, or delivering software releases.",
    "level": "Ignored"
  },
  "Psychological Safety": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Psychological Safety",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 34.02,
    "ai_mentions": 0.3,
    "ai_alignment": 3.7,
    "ai_depth": 3.4,
    "ai_intent": 2.6,
    "ai_audience": 8.0,
    "ai_signal": 5.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 34.0,
    "reasoning": "Direct mentions of psychological safety are absent, and terms like 'trust', 'collaboration', and 'learning orientation' are present but only loosely mapped to the category. The framework focuses on problem-driven AI adoption, clarity, and adaptive systems. While there is emphasis on learning cycles, transparency, feedback, and collaboration—related to aspects of psychological safety—the discussion does not explicitly explore how to create an environment where team members feel safe to take risks or speak up without fear. The bulk of the content centers on governance, workflow, roles, and artifacts for AI work, not on fostering psychological safety as a team dynamic or leadership concern. The alignment, depth, and intent scores are moderate because cultural and interpersonal elements are implicit and secondary, not the main focus.",
    "reasoning_summary": "The Kendall Guide does not directly address psychological safety. Although it discusses collaboration, feedback, and learning, it lacks explicit focus on safety, open risk-taking, or psychological team dynamics. Fit is partial and indirect.",
    "level": "Ignored"
  },
  "Tool": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Tool",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 39.041,
    "ai_mentions": 2.1,
    "ai_alignment": 4.8,
    "ai_depth": 3.3,
    "ai_intent": 4.1,
    "ai_audience": 5.2,
    "ai_signal": 5.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content introduces the Kendall Framework as a 'system of work' for AI adoption, emphasizing principles, roles, events, and artifacts. However, it explicitly states it does not prescribe specific tools, software, or techniques—instead, it's a guiding methodology/framework. While artifacts like 'Opportunity Backlog' and 'Context Repository' are mentioned, they are abstract concepts rather than practical tools (mechanisms or software) as defined by the category. There is no direct discussion or deep exploration of tools facilitating workflows or practical implementation within Agile, Lean, or DevOps. The intended audience overlaps somewhat, but the main focus is not tool-specific, and only conceptual or process-related 'tools' (in a broad sense) are referenced. Thus, the fit is partial and indirect.",
    "reasoning_summary": "This content centers on a framework/methodology, not on tools. While abstract artifacts are referenced, there’s little discussion of mechanisms, software, or tool implementation per the category definition. Only a weak, indirect alignment is present.",
    "level": "Ignored"
  },
  "Azure Repos": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Azure Repos",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 3.56,
    "ai_mentions": 0.2,
    "ai_alignment": 0.7,
    "ai_depth": 0.5,
    "ai_intent": 0.5,
    "ai_audience": 6.8,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 4.0,
    "reasoning": "The content never explicitly mentions Azure Repos, source control, Git, TFVC, or any version control-related topic. Its focus is squarely on AI adoption frameworks, artifact management (opportunity backlog, context repository), and organisational learning principles for AI projects. While it describes collaboration, adaptive practices, and repository-like concepts, these are used in a generic or AI-specific sense, not in the context of source control tools or Azure Repos functionalities. The audience overlap exists at a very broad level (change agents, technical leaders), but none of the key dimensions for Azure Repos are met. Scoring primarily reflects signal/audience, as the rest are extremely low or absent.",
    "reasoning_summary": "Content is fully focused on AI adoption frameworks and does not reference Azure Repos or source control. No substantive or conceptual overlap with the Azure Repos category.",
    "level": "Ignored"
  },
  "Windows": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Windows",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 2.966,
    "ai_mentions": 0.0,
    "ai_alignment": 0.3,
    "ai_depth": 0.2,
    "ai_intent": 0.45,
    "ai_audience": 4.0,
    "ai_signal": 2.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content makes no mention of Windows (0 for Direct Mentions). The framework is an abstract system for AI adoption with no focus on Windows OS, installation, troubleshooting, or configuration. Its conceptual alignment with Windows is nearly zero; while some IT practitioners might read it, the intended audience is general organisational decision-makers and AI strategy teams—not Windows users or admins. Depth and Intent also score nearly zero as the piece never discusses any aspect or feature of Windows, nor is its intent aligned with Windows management or usage. Audience is scored higher only due to a general technical/managerial overlap but remains misaligned in substance. Most content is off-topic regarding Windows, so Signal-to-Noise is very low. No penalties are needed because content is neither outdated nor derogatory.",
    "reasoning_summary": "The content does not discuss Windows or any relevant topics per the category definition. It fully concerns a generic AI adoption framework and does not meet the intent, scope, or audience for the Windows category.",
    "level": "Ignored"
  },
  "Daily Scrum": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Daily Scrum",
    "calculated_at": "2025-09-17T23:12:34",
    "ai_confidence": 6.5,
    "ai_mentions": 0.3,
    "ai_alignment": 0.8,
    "ai_depth": 0.75,
    "ai_intent": 0.7,
    "ai_audience": 1.5,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "There is no direct mention or reference to the Daily Scrum, Scrum framework, or its practices. The concepts described pertain to AI adoption and the Kendall Framework, with a focus on iterative improvement, regular events, and collaboration; however, these overlap only superficially with some agile practices. The 'events' and rhythm described in the content refer to quarterly or half-yearly cycles, which are far outside the time-box and intent of a Daily Scrum. No Scrum-specific language or stakeholders (e.g., Scrum Master, Product Owner, Developers) is present. While there is a general theme of empirical inspection and adaptation familiar to Agile, it is not mapped to Daily Scrum as defined. The audience is practitioners adopting frameworks, but not specifically Scrum teams.",
    "reasoning_summary": "The content is not about the Daily Scrum or Scrum framework. It relates to AI adoption using the Kendall Framework and does not discuss topics or themes aligned to the Daily Scrum category.",
    "level": "Ignored"
  },
  "Cross Functional Teams": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Cross Functional Teams",
    "calculated_at": "2025-09-17T23:12:25",
    "ai_confidence": 55.53,
    "ai_mentions": 2.2,
    "ai_alignment": 6.6,
    "ai_depth": 6.4,
    "ai_intent": 5.7,
    "ai_audience": 7.8,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 56.0,
    "reasoning": "The Kendall Guide discusses collaboration, collective ownership, and cross-team alignment, which overlap with cross-functional team principles in Agile. However, it never explicitly defines or focuses on cross-functional teams; the main purpose is AI adoption via structured framework roles (Coach, Lead, Champion). Several concepts like collaboration and role diversity align with cross-functional ideals; the content demonstrates moderate depth in discussing accountable roles and information flow across disciplines. However, it falls short of in-depth coverage on cross-functional team structure, forming, challenges, or directly naming the concept, limiting alignment and depth scores. Audience match is good, as it's aimed at organisational practitioners. Most content is relevant with little noise.",
    "reasoning_summary": "The piece references collaboration and cross-discipline alignment but does not explicitly focus on cross-functional teams. While some principles align, the main intent centers on AI adoption frameworks, so category fit is moderate and indirect.",
    "level": "Tertiary"
  },
  "Service Level Expectation": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Service Level Expectation",
    "calculated_at": "2025-09-17T23:12:34",
    "ai_confidence": 4.23,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.4,
    "ai_intent": 0.6,
    "ai_audience": 0.7,
    "ai_signal": 0.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 4.0,
    "reasoning": "The content focuses entirely on the Kendall Framework for AI adoption, discussing principles, practices, accountabilities, artifacts, and events for enabling evidence-based, collaborative implementation of AI in organizations. There are explicit mentions of flow, transparency, inspection, adaptation, and continuous improvement. However, nowhere does it mention, explain, or apply the concept of Service Level Expectation (SLE) as defined in Agile, Scrum, or Kanban contexts. No references are made to lead time, cycle time, time ranges, or probabilities associated with SLE. While there is some thematic overlap in emphasis on flow, cadence, and feedback loops, these do not meet the strict criteria for classification under SLE. There are no penalties, as the content is not outdated or satirical.",
    "reasoning_summary": "Content does not mention or address Service Level Expectation (SLE). Its themes of flow and adaptation do not specifically relate to SLE as defined in Agile, Scrum, or Kanban. Not a category fit except for minimal procedural overlap.",
    "level": "Ignored"
  },
  "Engineering Excellence": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Engineering Excellence",
    "calculated_at": "2025-09-17T23:12:26",
    "ai_confidence": 40.47,
    "ai_mentions": 0.7,
    "ai_alignment": 4.6,
    "ai_depth": 4.1,
    "ai_intent": 4.5,
    "ai_audience": 7.0,
    "ai_signal": 6.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 40.0,
    "reasoning": "The content presents a framework for AI adoption focused on organisational strategy, prioritisation, and context definition. While it includes concepts adjacent to engineering excellence such as continuous improvement and collaboration, it does not directly address technical software engineering practices (e.g., coding standards, testing, CI/CD, technical debt). The main audience is organisations and teams adopting AI, some of whom may include engineers, but the focus is on workflow, leadership, and accountability structures, not explicit engineering discipline. Mentions of engineering are indirect, mainly relating to 'modern engineering' as a complementary practice, rather than as the central subject. Overall, the thematic fit and depth are tangential to the strict definition of 'Engineering Excellence', with some overlap in areas of process discipline and collaborative improvement, but lacking direct technical coverage.",
    "reasoning_summary": "Content centers on AI adoption workflow and strategy, not technical engineering excellence. Some overlap in continuous improvement and collaboration, but limited direct relevance to software engineering best practices as defined in the category.",
    "level": "Ignored"
  },
  "Technical Leadership": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Technical Leadership",
    "calculated_at": "2025-09-17T23:12:35",
    "ai_confidence": 73.635,
    "ai_mentions": 3.4,
    "ai_alignment": 8.6,
    "ai_depth": 8.1,
    "ai_intent": 7.7,
    "ai_audience": 7.9,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 74.0,
    "reasoning": "The Kendall Guide describes accountabilities, leadership roles (e.g., Kendall Coach, Opportunity Lead), and facilitation practices that closely parallel technical leadership concepts: mentoring, enabling team learning, facilitating cadence-based events, and driving alignment. However, while themes such as collaboration, feedback loops, coaching, and continuous improvement are prominent, references to agile, DevOps, technical architectural decision-making, and direct team-centric servant leadership are more implicit. The framework targets technical practitioners, change agents, and organisational leaders engaged in AI adoption, aligning with the expected audience. The discussion is in-depth about organisational learning, flow, and leadership accountabilities but anchors them specifically to AI adoption, not more broadly to agile/technical leadership as such. No significant off-topic matter or outdated practices are observed. The lack of explicit agile or technical terms and focus on AI narrows the alignment, thus the middle-high confidence.",
    "reasoning_summary": "Content discusses leadership, mentoring, and team enablement in the context of AI adoption, aligning well with technical leadership, but with only indirect references to agile and technical practices. Confidence is high but not absolute due to its AI focus.",
    "level": "Secondary"
  },
  "Pragmatic Thinking": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Pragmatic Thinking",
    "calculated_at": "2025-09-17T23:12:28",
    "ai_confidence": 91.19,
    "ai_mentions": 7.3,
    "ai_alignment": 9.7,
    "ai_depth": 9.5,
    "ai_intent": 9.1,
    "ai_audience": 9.0,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 91.0,
    "reasoning": "The content embodies Pragmatic Thinking by presenting a practical, structured approach to AI adoption with a clear focus on problem-first, context-driven strategies. It features in-depth coverage of adaptive practices, collaboration, continuous improvement (inspect-and-adapt), evidence-based prioritization (Opportunity Backlog, Roadmap), and real-world accountabilities, all central to the definition. The audience (organizations, teams, practitioners) and content purpose (practical application, actionable guidance) align closely with Agile/Scrum/DevOps contexts. Depth is high, with detailed roles, events, and artifacts. While 'Pragmatic Thinking' isn't named explicitly, the core principles recur throughout. There is a minor gap in explicit Agile/Scrum/DevOps references, but the practical, adaptability-centric approach makes the conceptual fit very strong. No outdated or contradicting elements were found. The signal-to-noise ratio is robust; nearly all content is focused.",
    "reasoning_summary": "Content fits 'Pragmatic Thinking' very well: it details practical, adaptive frameworks for real-world AI adoption, prioritization, and collaboration. Intent, themes, and audience closely match the category definition, though explicit naming is moderate.",
    "level": "Primary"
  },
  "Engineering Practices": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Engineering Practices",
    "calculated_at": "2025-09-17T23:12:28",
    "ai_confidence": 41.589,
    "ai_mentions": 1.2,
    "ai_alignment": 4.9,
    "ai_depth": 4.3,
    "ai_intent": 4.0,
    "ai_audience": 4.7,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily presents an organisational framework for AI adoption, focusing on problem prioritisation, context, accountabilities, and empirical adaptation. While it discusses some principles shared with engineering practices (e.g., continuous improvement, collaboration, feedback), it does not substantially address core engineering topics such as clean code, TDD, CI/CD, automation, or specific software development techniques. The framework emphasises high-level process and governance rather than hands-on technical or coding disciplines. Direct references to engineering practices are minimal or indirect. The intended audience includes practitioners and leaders but not specifically technical or engineering roles. Thus, the overlap with the category is partial and incidental, not central to the text’s purpose.",
    "reasoning_summary": "The content is only partially relevant to Engineering Practices, with few explicit engineering references and a primary focus on organisational frameworks for AI adoption, rather than specific Agile engineering principles or techniques.",
    "level": "Tertiary"
  },
  "Software Development": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Software Development",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 49.14,
    "ai_mentions": 1.8,
    "ai_alignment": 4.6,
    "ai_depth": 5.1,
    "ai_intent": 3.9,
    "ai_audience": 4.5,
    "ai_signal": 4.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 49.0,
    "reasoning": "The content details a framework for AI adoption focused on organisational and strategic practices like prioritisation, context management, and evidence-based improvement. It thoroughly describes roles, events, and artifacts, but discussion of actual software development lifecycle, coding, design practices, engineering techniques, or team-level software practices (e.g., Scrum, DevOps, code quality, architecture) is minimal to non-existent. Its emphasis is on high-level management and adoption processes rather than specific technical or engineering methods within software development. The target audience spans organisational leaders and strategists more than software engineers, though some indirect overlap exists via adaptability, learning, and opportunity backlogs which can integrate with software work, but the fit is partial and mostly indirect.",
    "reasoning_summary": "The Kendall Guide focuses on AI adoption strategy, prioritisation, and evidence-based improvement at an organisational level. It does not directly discuss software development practices or engineering, so fit with the 'Software Development' category is partial and indirect.",
    "level": "Tertiary"
  },
  "Site Reliability Engineering": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Site Reliability Engineering",
    "calculated_at": "2025-09-17T23:12:37",
    "ai_confidence": 14.7,
    "ai_mentions": 0.1,
    "ai_alignment": 1.8,
    "ai_depth": 1.6,
    "ai_intent": 1.2,
    "ai_audience": 6.3,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 15.0,
    "reasoning": "There are no explicit mentions of Site Reliability Engineering (SRE) or its principles throughout the Kendall Guide. The framework is focused on AI adoption, clarity, accountability, and adaptive decision-making, which—while touching on some generic concepts like reliability, flow, and learning loops—do not directly map to SRE's unique practices such as SLOs, SLIs, incident response, or automation for reliability in production. The audience could partially overlap (technical and leadership roles), but the core intentions, themes, and artifacts are unrelated to the engineering principles of SRE. The content is highly focused, but its signal is off-topic regarding SRE.",
    "reasoning_summary": "The Kendall Guide is about AI adoption and does not address Site Reliability Engineering principles, practices, or goals. There is virtually no overlap in topic, intent, or theme—confidence in fit is extremely low.",
    "level": "Ignored"
  },
  "Metrics and Learning": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Metrics and Learning",
    "calculated_at": "2025-09-17T23:12:31",
    "ai_confidence": 77.13,
    "ai_mentions": 6.8,
    "ai_alignment": 8.5,
    "ai_depth": 7.9,
    "ai_intent": 8.0,
    "ai_audience": 7.4,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 77.0,
    "reasoning": "The content discusses the Kendall Framework with a focus on continuous improvement, feedback loops, evidence-based adaptation, and learning cycles—topics central to Metrics and Learning. Clarity about feedback mechanisms and empirical inspection supports strong conceptual alignment. However, while terms like 'inspecting', 'evidence', 'feedback loops', 'learning orientation', and 'adaptation' appear throughout, explicit and repeated mention of quantitative metrics, actual data collection techniques, or specific measurement tools is less pronounced. The discussion is deep regarding the system of learning and adaptation but spreads across AI adoption more broadly, not solely metrics. The intended audience (organisations, teams, coaches) overlaps well with the category, but the focus is slightly more on frameworks/process rather than directly on metrics or learning methodologies. No penalties applied, as the content is current and in a constructive tone.",
    "reasoning_summary": "The content aligns notably with Metrics and Learning via feedback loops and evidence-based adaptation but addresses metrics in a supporting role rather than the primary focus. Strong fit, though not maximally direct.",
    "level": "Secondary"
  },
  "Operational Practices": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Operational Practices",
    "calculated_at": "2025-09-17T23:12:37",
    "ai_confidence": 85.35,
    "ai_mentions": 6.2,
    "ai_alignment": 9.3,
    "ai_depth": 8.9,
    "ai_intent": 8.2,
    "ai_audience": 8.0,
    "ai_signal": 8.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 85.0,
    "reasoning": "The content presents a practical, detailed framework for AI adoption, explicitly focusing on systematising work, prioritisation, flow, feedback loops, and empirical improvement—strongly aligning with the category's themes. It details roles, events, and artifacts (e.g., Opportunity Backlog, Context Repository) that operationalise adoption in a way suited to Agile/Lean/DevOps thinking. While 'Operational Practices' is never named, core methods—cadences, flow management, empirical adaptation, context/leverage, and backlog—are deeply explored. Audience, purpose, and depth all fit the category, though the AI focus slightly narrows generalisability.",
    "reasoning_summary": "The content deeply aligns with Operational Practices, structuring AI adoption through practical, iterative frameworks focused on flow, feedback, and evidence—matching the category’s themes and intent, but with partial generality due to its AI focus.",
    "level": "Primary"
  },
  "Agile Philosophy": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agile Philosophy",
    "calculated_at": "2025-09-17T23:12:34",
    "ai_confidence": 67.18,
    "ai_mentions": 2.9,
    "ai_alignment": 8.2,
    "ai_depth": 7.7,
    "ai_intent": 7.9,
    "ai_audience": 7.0,
    "ai_signal": 6.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 67.0,
    "reasoning": "Direct mentions of 'Agile Philosophy' or the Agile Manifesto are absent, resulting in a low 'mentions' score. However, the content conceptually aligns, prioritizing principles such as continuous improvement, collaboration, adaptability, and feedback loops—all core Agile Philosophy themes. The framework emphasizes empirical inspection, adaptation, problem-first thinking, and stakeholder accountability, which echo Agile's foundational ethos. Depth and intent are strong, with detailed articulation of how these values guide team structure, roles, and rituals. Still, significant portions are oriented around bespoke AI adoption rather than the general Agile mindset, bringing 'signal' and 'audience' slightly lower—some detail is specific to operational AI, not universal Agile philosophy. No deductive penalties apply, as the tone is positive, current, and not critical of Agile ideals.",
    "reasoning_summary": "The content embodies Agile Philosophy values (adaptation, collaboration, feedback), but rarely names them outright. It deeply integrates Agile-like principles within an AI adoption context, making the fit strong but not complete or directly explicit.",
    "level": "Secondary"
  },
  "Scrum Values": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Scrum Values",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 12.211,
    "ai_mentions": 0.2,
    "ai_alignment": 1.7,
    "ai_depth": 1.7,
    "ai_intent": 2.1,
    "ai_audience": 2.3,
    "ai_signal": 2.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content does not explicitly mention Scrum Values or directly discuss them. While themes like collaboration, transparency, and continuous improvement are present, these are common in many agile frameworks and do not reference or align specifically with Scrum Values. There is no in-depth exploration or naming of Commitment, Courage, Focus, Openness, or Respect, nor any mention of their role in Scrum. The framework is about AI adoption, not Scrum or its core values. The intended audience is broader than Scrum practitioners, and the signal-to-noise ratio is low due to lack of relevant discussion. No outdated practices or critical tone are detected, so no penalties applied.",
    "reasoning_summary": "Content does not directly relate to Scrum Values. No explicit mention or meaningful alignment; related themes are generic to agile practices. Fit is weak and mostly incidental rather than intentional.",
    "level": "Ignored"
  },
  "Kanban": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Kanban",
    "calculated_at": "2025-09-17T23:12:34",
    "ai_confidence": 14.76,
    "ai_mentions": 0.0,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.2,
    "ai_audience": 4.0,
    "ai_signal": 3.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 15.0,
    "reasoning": "There are no explicit mentions of Kanban and no direct references to Kanban practices or principles such as WIP limits, Kanban boards, or Kanban-specific metrics. While there is some vague overlap with ideas like 'flow', 'feedback loops', and 'continuous improvement', these are generic management or agile concepts and not uniquely Kanban. The framework is about AI adoption via the 'Kendall' method and does not discuss Kanban as a methodology, its visualisation techniques, or other core elements specified by the category definition. The target audience (organizations interested in structured, evidence-based AI adoption) does slightly overlap with Kanban's possible audience but the content is not directed at Kanban practitioners. Little of the discussion is specifically focused or relevant to Kanban practices, and nearly all main themes fall outside the category.",
    "reasoning_summary": "The content does not fit the Kanban category. It lacks explicit mentions, thematic alignment, and core Kanban practices. Any overlap in terms like 'flow' is incidental rather than rooted in Kanban methodology.",
    "level": "Ignored"
  },
  "Remote Working": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Remote Working",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 13.292,
    "ai_mentions": 0.4,
    "ai_alignment": 1.3,
    "ai_depth": 1.6,
    "ai_intent": 1.2,
    "ai_audience": 3.0,
    "ai_signal": 2.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content describes a framework for AI adoption focusing on problem-first thinking, context, collaboration, and evidence-based improvement. Collaboration and communication are mentioned, but there is no explicit or substantive discussion of remote working, distributed teams, or the specific practices, tools, or challenges associated with remote work in Agile contexts. The references to team collaboration are generic and not framed in the context of remote or distributed Agile work. There is no mention of remote work technologies, time zones, remote ceremonies, or culture. Although concepts like collaboration and cadence are present, these are not aligned to the Remote Working category's definition.",
    "reasoning_summary": "Content is not focused on Remote Working; team collaboration is discussed in general, not remote/distributed-specific. No direct or conceptual alignment with remote Agile practices, tools, or challenges. Fit for this category is very low.",
    "level": "Ignored"
  },
  "Lean Product Development": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Lean Product Development",
    "calculated_at": "2025-09-17T23:12:35",
    "ai_confidence": 61.45,
    "ai_mentions": 1.7,
    "ai_alignment": 7.2,
    "ai_depth": 5.9,
    "ai_intent": 7.9,
    "ai_audience": 6.3,
    "ai_signal": 6.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 61.0,
    "reasoning": "There are no direct mentions of 'Lean Product Development,' and explicit lean terminology (waste reduction, value-stream mapping, A3, etc.) is absent. However, the content has some alignment: it emphasizes continuous improvement, flow, evidence-based adaptation, and learning—principles central to Lean. The concepts of 'flow of information, decisions, and value,' 'continuous improvement,' and 'feedback loops' align with Lean themes, as does the focus on customer/stakeholder value and iterative processes. The approach is adaptive and problem-first, resonating with Lean's philosophy. However, the discussion is generic to frameworks for AI adoption, without explicit focus on minimising waste or in-depth treatment of Lean Product Development tools or techniques. The audience (organizational leaders, practitioners) partly overlaps, yet the core context is AI adoption, not product development per se. Few artifacts or events map directly to classic Lean PD practices. Thus, while intent and some principles fit, the overall fit is partial and mostly indirect.",
    "reasoning_summary": "Content partially aligns with Lean Product Development via emphasis on continuous improvement, flow, and stakeholder value, but lacks explicit Lean terminology or tools. Fit is indirect; focus is on AI adoption, not Lean Product Development specifically.",
    "level": "Secondary"
  },
  "Forecasting": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Forecasting",
    "calculated_at": "2025-09-17T23:12:41",
    "ai_confidence": 36.56,
    "ai_mentions": 1.3,
    "ai_alignment": 4.9,
    "ai_depth": 4.6,
    "ai_intent": 4.8,
    "ai_audience": 7.2,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content describes the Kendall Framework for AI adoption, focusing on prioritisation, empirical inspection, adaptive learning, and evidence-based decision-making. While these align with some foundational aspects of forecasting, the discussion does not explicitly reference or deeply explore forecasting methods within Agile or Scrum. Key forecasting concepts, such as delivery prediction, risk management through forecasts, or the use of Agile forecasting metrics, are not covered. The framework’s emphasis is on opportunity identification, alignment, and adaptive flow, with empirical adaptation being more about learning than predictive forecasting. Thus, the fit is partial and mostly indirect, lacking direct and substantive treatment of the specified forecasting category.",
    "reasoning_summary": "Content focuses on empirical learning, prioritisation, and adaptive flow for AI adoption, but lacks explicit or in-depth discussion of forecasting practices within Agile or Scrum. Alignment with 'Forecasting' is indirect and partial.",
    "level": "Ignored"
  },
  "Sociotechnical Systems": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Sociotechnical Systems",
    "calculated_at": "2025-09-17T23:12:36",
    "ai_confidence": 90.029,
    "ai_mentions": 7.6,
    "ai_alignment": 9.6,
    "ai_depth": 9.3,
    "ai_intent": 9.6,
    "ai_audience": 8.9,
    "ai_signal": 9.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 90.0,
    "reasoning": "The content presents the Kendall Framework as a 'system of work' emphasizing the interplay between organizational structures (e.g., accountabilities, collaboration, feedback loops) and technical processes (AI adoption, context repositories). Explicit focus on role definitions and cross-disciplinary collaboration shows strong sociotechnical alignment. Detailed discussions of flows of information, feedback, and organisational learning indicate depth. Although the specific phrase 'sociotechnical systems' isn't mentioned verbatim, the principles, audience, and structural concepts throughout map directly to the classification. The target audience clearly includes technical leaders, strategists, and practitioners seeking to bridge organizational and technical domains. Signal is strong, with virtually all content backing the category definition, and no obsolete/contradictory or purely technical sections.",
    "reasoning_summary": "Content demonstrates deep integration of organizational and technical practices, focusing on structure, collaboration, and feedback in AI adoption—aligning very well with sociotechnical systems. Indirect rather than direct category mention, but a strong conceptual fit.",
    "level": "Primary"
  },
  "Agnostic Agile": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agnostic Agile",
    "calculated_at": "2025-09-17T23:12:37",
    "ai_confidence": 55.67,
    "ai_mentions": 0.2,
    "ai_alignment": 7.7,
    "ai_depth": 6.9,
    "ai_intent": 5.9,
    "ai_audience": 6.4,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 56.0,
    "reasoning": "There is no direct mention of Agnostic Agile or its named principles, and the content is not about agile frameworks. However, the Kendall Framework adopts a context-driven, empirical, and principle-based approach, favoring adaptability and stakeholder-centricity, which aligns conceptually with Agnostic Agile. Content emphasizes critical thinking, continuous improvement, and value delivery over process, but it does not reference Agile history, ethics, or contrasting frameworks. The audience is practitioners interested in adaptive work practices, related to but not targeting the Agnostic Agile movement specifically. The discussion is deep on its own principles but not on the philosophy of Agnostic Agile itself.",
    "reasoning_summary": "Content is not about Agnostic Agile but shares context-driven, adaptive, and principled approaches. No direct mentions; alignment is partial—related in spirit but not explicitly. Content focus is on AI work, not agile philosophy.",
    "level": "Tertiary"
  },
  "Sensemaking": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Sensemaking",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 86.2,
    "ai_mentions": 6.3,
    "ai_alignment": 9.2,
    "ai_depth": 8.9,
    "ai_intent": 9.0,
    "ai_audience": 8.4,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 86.0,
    "reasoning": "The Kendall Guide deeply explores how organisations can navigate complexity and uncertainty in AI adoption. It discusses structured sensemaking (context clarification, iterative feedback loops, prioritisation of problems, accountability structures) without labeling it directly as 'Sensemaking' or referencing frameworks like Cynefin. Its purpose is to guide decision-making under complexity using context-driven and adaptive practices. Content emphasizes interpreting and aligning on context, flow of information, empirical inspection, adaptation, and collective learning, all core to sensemaking. Audience is clearly leaders, practitioners, and strategists in organisational settings. Nearly all sections are highly relevant, aside from possibly detailed role/accountability breakdowns that somewhat broaden focus, but these still serve the main sensemaking intent.",
    "reasoning_summary": "Content thoroughly fits 'Sensemaking' through its focus on interpreting complex situations for organisational AI adoption using context, iterative learning, and adaptive practices—even though it rarely names 'Sensemaking' or its frameworks directly.",
    "level": "Primary"
  },
  "Product Development": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Product Development",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 93.353,
    "ai_mentions": 6.9,
    "ai_alignment": 9.8,
    "ai_depth": 9.7,
    "ai_intent": 9.0,
    "ai_audience": 9.3,
    "ai_signal": 9.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 93.0,
    "reasoning": "The Kendall Guide content centers on a practical framework for AI adoption, emphasizing iterative improvement, evidence-based decisions, context-driven prioritization, feedback loops, backlog refinement, outcome measurement, strategy alignment, and adaptive learning. These are closely aligned with the key methodologies and purposes of 'Product Development.' Artifacts like backlogs, roadmaps, and regular cadence events mirror Agile and Lean practices. The audience is clearly product leaders, teams, and strategists seeking to build valuable products with minimized risk. The only limitation is that the content refrains from frequently naming 'product development' directly, focusing instead on AI-specific terms, but the concepts map nearly one-to-one. No penalties apply; the content is timely, comprehensive, and positive.",
    "reasoning_summary": "This content closely matches the 'Product Development' category by describing a framework for iterative, evidence-based, and context-driven AI adoption. It thoroughly explores strategy, delivery, feedback, and improvement practices for product development.",
    "level": "Primary"
  },
  "Minimum Viable Product": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Minimum Viable Product",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 23.09,
    "ai_mentions": 0.2,
    "ai_alignment": 2.7,
    "ai_depth": 2.9,
    "ai_intent": 2.5,
    "ai_audience": 7.1,
    "ai_signal": 5.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "There are no direct mentions of MVP or clear reference to Minimum Viable Product concepts. The Kendall Guide describes a system for AI adoption with evidence-based, iterative, and flow-oriented principles, which conceptually overlap a little with MVP's rapid iteration and learning. However, it does not address MVP-specific topics (definition, core features, user feedback, success metrics, lean startup methodology, etc.). The primary intent is about structured AI adoption, not MVP development or validation. The intended audience overlaps (technical, evidence-driven organizations), but most content does not focus on MVP-related concepts, rendering topical signal moderate at best. No penalties for outdated or contradictory material.",
    "reasoning_summary": "Content is about AI adoption frameworks—not MVP. While it references iteration, evidence, and learning, there are no direct or substantial links to Minimum Viable Product. Fit is weak and partial at best; MVP is not discussed.",
    "level": "Ignored"
  },
  "Objective Key Results": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Objective Key Results",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 32.56,
    "ai_mentions": 0.7,
    "ai_alignment": 3.8,
    "ai_depth": 4.1,
    "ai_intent": 3.3,
    "ai_audience": 5.6,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content presents the Kendall Framework for AI adoption, focusing on clarifying problems, context, and adaptive decision-making. There are indirect, very minor overlaps with OKR principles such as outcome alignment, inspection/adaptation, and clarity of purpose, but the text never mentions 'Objective Key Results' nor any explicit OKR methodology, terminology, or foundational principles as defined by John Doerr. The event and artifact structures emphasize outcomes and alignment but do not use Objectives or Key Results as constructs, nor do they discuss stretch goals or the tracking mechanisms of OKRs. The audience (organizational, team, and change agents) partially overlaps with those interested in OKRs, but the main intent is AI adoption, not OKR processes or philosophy. Most of the discussion is off-topic for OKRs, with only generic outcome, alignment, and review language connecting them loosely and superficially.",
    "reasoning_summary": "Content is about the Kendall Framework for AI adoption. While it mentions alignment and outcomes, there is no reference to OKRs, and only broad overlap with OKR-like concepts. It does not fit the category except in minor, indirect ways.",
    "level": "Ignored"
  },
  "Company as a Product": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Company as a Product",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 57.98,
    "ai_mentions": 1.4,
    "ai_alignment": 6.7,
    "ai_depth": 6.9,
    "ai_intent": 6.1,
    "ai_audience": 7.2,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 58.0,
    "reasoning": "The content presents a comprehensive framework for AI adoption focused on solving real problems, collaboration, iterative learning, and aligning initiatives with organisational goals. Principles such as evidence-based adaptation, outcome orientation, and cross-functional roles (e.g., Kendall Coach, Opportunity Lead) partially align with 'Company as a Product' themes like continuous improvement and stakeholder-centric design. However, the content never directly refers to the company-as-a-product paradigm, nor does it explicitly discuss re-conceptualising the company itself as a product or deeply compare organisational structures. While outcome-centricity, agility, and customer/stakeholder alignment are present, the framing and intent are more about operationalising AI adoption than positioning the overall organisation as a product. The signal-to-noise ratio is high, and the audience is suitable, but direct, deep discussion of CaaP is lacking.",
    "reasoning_summary": "The content is strongly outcome- and stakeholder-oriented, with elements relevant to CaaP, but it is fundamentally about AI adoption rather than treating the company as a dynamic product. Fit is partial and more tangential than direct.",
    "level": "Tertiary"
  },
  "Continuous Integration": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Continuous Integration",
    "calculated_at": "2025-09-17T23:12:43",
    "ai_confidence": 8.125,
    "ai_mentions": 0.0,
    "ai_alignment": 1.3,
    "ai_depth": 1.1,
    "ai_intent": 1.2,
    "ai_audience": 2.0,
    "ai_signal": 1.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content focuses on an AI adoption framework (the Kendall Guide) emphasizing organisational clarity, strategy, and problem-first approaches. Nowhere does it mention or explore Continuous Integration (CI), CI practices, or related tooling/concepts. The content is aligned with technical and process-improvement audiences, but not specifically CI practitioners. There is no direct, indirect, or thematic discussion of code integration, automated testing, CI pipelines, or relevant practices. Scores are very low or near zero across every dimension per strict criteria.",
    "reasoning_summary": "This content is unrelated to Continuous Integration. It covers AI adoption frameworks and never discusses CI principles, practices, or tools. There is no fit to the category definition.",
    "level": "Ignored"
  },
  "Principle": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Principle",
    "calculated_at": "2025-09-17T23:12:26",
    "ai_confidence": 94.24,
    "ai_mentions": 9.4,
    "ai_alignment": 9.7,
    "ai_depth": 9.5,
    "ai_intent": 9.6,
    "ai_audience": 9.1,
    "ai_signal": 9.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 94.0,
    "reasoning": "The content repeatedly references and explicitly names first principles—such as 'Problem Before Solution', 'Continuous Improvement', and 'Collaboration Sustains Value'—aligning closely with Agile and Lean principles. It explores how these principles are applied within the Kendall Framework in depth, discussing their actionable impacts on roles, events, and artifacts. The main intent is to guide teams and organisations with actionable, principle-oriented approaches for AI adoption. The target audience—teams, leaders, and practitioners seeking structural, principle-driven methods—matches the category. Nearly all sections uphold focus and eliminate noise or tangential diversions. There is no evidence of outdated practices or contradiction to the category.",
    "reasoning_summary": "The content explicitly defines, discusses, and applies actionable principles guiding AI adoption. Its focus, intent, and depth are strongly aligned with the 'Principle' category; the fit is very clear and comprehensive.",
    "level": "Primary"
  },
  "Agile Leadership": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agile Leadership",
    "calculated_at": "2025-09-17T23:12:43",
    "ai_confidence": 74.89,
    "ai_mentions": 3.4,
    "ai_alignment": 8.2,
    "ai_depth": 7.9,
    "ai_intent": 7.1,
    "ai_audience": 8.3,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 75.0,
    "reasoning": "The content does not directly mention 'Agile Leadership' but aligns with many of its themes: it outlines leadership accountabilities (Kendall Coach, Opportunity Lead, Context Champions), emphasises empowerment, psychological safety (feedback loops, escalation), and continuous improvement (inspect‑and‑adapt). The core focus is on AI adoption, but the framework’s leadership roles, collaborative practices, and organisational learning aspects embody Agile leadership principles, serving an audience of change agents, executives, and facilitators. The treatment is substantive, not superficial. However, 'Agile' as a term is absent, and leadership is framed generically for AI rather than explicitly Agile transformation—hence, moderate confidence.",
    "reasoning_summary": "The content embodies Agile leadership themes via leadership roles (Coach, Lead, Champions), empowerment, and continuous improvement, but does not mention Agile or explicitly frame itself as Agile Leadership guidance, resulting in only moderate category fit.",
    "level": "Secondary"
  },
  "Estimation": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Estimation",
    "calculated_at": "2025-09-17T23:12:27",
    "ai_confidence": 19.85,
    "ai_mentions": 1.0,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 1.8,
    "ai_audience": 5.1,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The Kendall Guide focuses on problem prioritisation and evidence-based adaptation for AI adoption, using backlogs, roadmaps, and review cycles. While topics like prioritisation, backlogs, and cadence overlap with Agile practices, there is no explicit or substantive discussion of estimation concepts, techniques, collaborative practices, forecasting, or velocity. Terms and concepts central to the 'Estimation' category (like Planning Poker, story points, T-shirt sizing, or empirical data specifically for estimation) are absent. The guide’s audience and iterative dimension may be somewhat relevant for Agile practitioners, but estimation is neither a primary nor secondary theme. Only minimal overlap with estimation context exists.",
    "reasoning_summary": "Content is about evidence-based AI adoption, focusing on prioritisation and context. It does not address estimation methods, concepts, or goals as required for this category. Fit is very low and largely incidental.",
    "level": "Ignored"
  },
  "Systems Thinking": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Systems Thinking",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 71.54,
    "ai_mentions": 5.2,
    "ai_alignment": 8.7,
    "ai_depth": 8.1,
    "ai_intent": 7.6,
    "ai_audience": 7.4,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 72.0,
    "reasoning": "Direct mentions of 'systems thinking' occur as part of describing the Kendall Framework’s integration of management clarity, systems thinking, and iterative improvement, and in discussion of systemic constraints, feedback loops, and flow of value. While not solely or deeply about Systems Thinking theory or tools, the framework strongly aligns with its principles: holistic, context-driven decision making, attention to feedback loops, interdependencies, and systemic impediments. Roles like the Kendall Coach explicitly surface systemic constraints and cultivate feedback loops, which are clear elements of systems thinking. However, the content’s main purpose is to guide AI adoption, not to primarily teach systems thinking, and it doesn’t cover mapping techniques (CLDs, system dynamics) or frameworks like Cynefin – though its ideas resonate with the systems perspective. Audience and signal match well (change, tech, leadership), though with a broader focus on practical AI adoption. No outdated content or negative tone. Some important category techniques/tools (e.g., causal loops, Cynefin) are missing, so the fit is strong but not maximal.",
    "reasoning_summary": "The content applies systems thinking principles—emphasizing flow, feedback loops, holistic problem analysis, and interdependencies—within an AI adoption framework. While not focused on systems thinking theory or tools, the alignment is strong but not complete.",
    "level": "Secondary"
  },
  "Strategy": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Strategy",
    "calculated_at": "2025-09-17T23:12:27",
    "ai_confidence": 92.487,
    "ai_mentions": 8.6,
    "ai_alignment": 9.7,
    "ai_depth": 9.3,
    "ai_intent": 9.0,
    "ai_audience": 8.8,
    "ai_signal": 8.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content repeatedly and explicitly references strategic alignment, prioritisation, and high-level adaptation in AI adoption. It discusses strategic roles (Kendall Coach, Opportunity Lead), strategic events (Opportunity & Context Sourcing), and artifacts (Backlog, Roadmap) used for aligning teams and initiatives with objectives. The discussion is thorough, delving into frameworks, feedback loops, context, leadership responsibilities, and evidence-based adaptation—which are core issues in strategic planning. Its main audience is leaders, strategists, and decision-makers in organisations, not just technical practitioners. No penalties applied as the content is modern, constructive, and fits the definition well. Slightly lower on direct mentions as 'strategy' is often implied rather than always named, and the signal-to-noise ratio accounts for some operational detail.",
    "reasoning_summary": "Content is deeply aligned with Strategy—framing AI adoption as a high-level, adaptive, evidence-based approach. Focuses on planning, alignment, roles, and feedback loops. Thorough, strategic, and fitting for organisational leaders. Strong fit overall.",
    "level": "Primary"
  },
  "Agile Planning Tools": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agile Planning Tools",
    "calculated_at": "2025-09-17T23:12:28",
    "ai_confidence": 49.573,
    "ai_mentions": 2.1,
    "ai_alignment": 5.2,
    "ai_depth": 4.6,
    "ai_intent": 3.9,
    "ai_audience": 6.2,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 50.0,
    "reasoning": "While the Kendall Guide mentions concepts resembling Agile practices (e.g., backlogs, iterative events, inspection/adaptation, collaboration), it is focused on AI adoption frameworks, not on Agile planning tools or their usage. Agile terms appear in artifact names like 'Opportunity Backlog' and in the cadence of events, but there is no discussion of mainstream Agile planning tools (e.g., Jira, Asana, Trello), tool comparisons, or explicit Agile methodologies. The guide does not provide concrete techniques for sprint planning, backlog management within an Agile software context, or direct references to use or selection of Agile Planning Tools. The main audience overlaps (leaders, teams, practitioners) but the intent and depth stay centered on a proprietary AI adoption process. Thus, there is partial but not direct or substantial fit to the 'Agile Planning Tools' category.",
    "reasoning_summary": "Content draws on Agile-adjacent concepts (e.g., backlogs, cadence) but focuses on an AI adoption framework, not on Agile Planning Tools themselves. Fit is partial, mainly conceptual, with little direct coverage of Agile planning tool topics.",
    "level": "Tertiary"
  },
  "Shift Left Strategy": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Shift Left Strategy",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 23.61,
    "ai_mentions": 0.4,
    "ai_alignment": 2.1,
    "ai_depth": 2.8,
    "ai_intent": 2.5,
    "ai_audience": 7.2,
    "ai_signal": 3.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on a framework for AI adoption emphasizing problem-first approaches, context clarification, and adaptive decision-making. While it discusses early stakeholder involvement, feedback loops, and iterative improvement, it does not mention or meaningfully explore Shift Left Strategy, nor does it directly address early integration of testing, security, or compliance in the software lifecycle. The alignment is partial at best, as some agile and flow-based principles have superficial relevance to Shift Left, but the intent, terminology, and application are not tailored to this concept. The audience (technical/organizational strategists) is similar, but the depth of direct discussion on Shift Left is minimal to none.",
    "reasoning_summary": "This content does not directly address Shift Left Strategy. While some iterative and feedback-driven principles have superficial alignment, it lacks explicit or in-depth discussion of shifting processes left in software development (e.g., early testing/security).",
    "level": "Ignored"
  },
  "Coaching": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Coaching",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 85.92,
    "ai_mentions": 7.5,
    "ai_alignment": 9.2,
    "ai_depth": 8.8,
    "ai_intent": 8.7,
    "ai_audience": 8.9,
    "ai_signal": 8.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 86.0,
    "reasoning": "The content introduces and elaborates on the 'Kendall Coach' role, discussing responsibilities such as mentoring, facilitating learning, surfacing impediments, feedback loops, and stewarding organisational learning—closely matching Agile and DevOps coaching definitions. There is explicit mention and thorough discussion of coaching as guiding teams, supporting learning cycles, and enhancing collaborative practice, all with non-directive intent. Distinctions from managing are clear (the coach does not manage day-to-day work), and key coaching practices (reflection, feedback, enabling, stewardship, mentoring) feature prominently and at practical depth. While the main focus is on a broader framework for AI adoption, the coaching dimension is a central element, targeting practitioners, leaders, and teams within organisational contexts relevant to Agile and evidence-based work. Content is focused, up-to-date, and free from noise or contradiction on coaching topics.",
    "reasoning_summary": "The content has strong conceptual and practical alignment to coaching, with specific focus on the 'Kendall Coach' role guiding learning and collaboration. Fit to the Coaching category is high, as coaching is well-explained and integral to the framework.",
    "level": "Primary"
  },
  "Collective Intelligence": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Collective Intelligence",
    "calculated_at": "2025-09-17T23:12:33",
    "ai_confidence": 83.19,
    "ai_mentions": 5.7,
    "ai_alignment": 9.2,
    "ai_depth": 9.1,
    "ai_intent": 8.8,
    "ai_audience": 8.0,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 83.0,
    "reasoning": "Direct mentions of 'collective intelligence' are absent; however, the content discusses collective ownership, collaborative practices, and shared knowledge flows between humans with significant agency and AI systems/practices. The framework's core is about effective alignment and adaptive collaboration for AI adoption, addressing complex socio-technical challenges—consistent with the category's definition. Depth is high, with detailed roles (Coach, Lead, Champions) fostering shared understanding, cross-discipline feedback loops, and systemic learning. However, while the collaboration is explicit and heavily context-driven for AI adoption, the text rarely refers to AI agents as active team members, and concrete examples of emergent, human-AI joint outcomes are sparse (more of the operational scaffolding is covered than the direct human-AI teaming or joint problem-solving with autonomous or semi-autonomous AI agents as partners). Still, the spirit, mechanisms, and audience align tightly, making the fit strong but not maximal.",
    "reasoning_summary": "Content deeply aligns with collective intelligence by emphasizing collaborative, context-driven AI adoption and team roles. While it lacks explicit AI-as-team-member narratives, its focus on human-AI synergy and shared learning fits the category closely.",
    "level": "Primary"
  },
  "DevOps": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "DevOps",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 38.25,
    "ai_mentions": 0.5,
    "ai_alignment": 3.8,
    "ai_depth": 3.1,
    "ai_intent": 4.3,
    "ai_audience": 5.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content discusses a system of work for AI adoption, emphasizing flow, collaboration, feedback loops, accountability, and continuous improvement—superficially echoing some DevOps themes. However, it never directly references DevOps philosophy, culture, or practices. The framework is not positioned as a DevOps methodology or as integral to DevOps transformations; instead, it is an AI-specific adoption guide. While language such as 'flow', 'feedback', 'empirical', and 'collaboration' loosely resonates with DevOps, these are generic agile/system-thinking concepts that are not implemented through the lens of DevOps' integration of development, operations, and shared delivery. IT automation, 'shift left', observability as meant in DevOps, and cross-team (dev/ops/sec) accountability are not explicitly covered nor described in DevOps terms. The target audience is technical/decision-maker-adjacent but not DevOps-specific. Overall, fit is tangential and partial (general system-of-work and improvement themes) with little direct or deep alignment to the DevOps category.",
    "reasoning_summary": "The content focuses on AI adoption with some themes (flow, collaboration, feedback) that partially overlap with DevOps ideals, but does not discuss DevOps concepts directly or in depth; thus, alignment is partial and confidence is low.",
    "level": "Ignored"
  },
  "Revenue per Employee": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Revenue per Employee",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 6.2,
    "ai_mentions": 0.2,
    "ai_alignment": 1.8,
    "ai_depth": 1.6,
    "ai_intent": 1.5,
    "ai_audience": 0.7,
    "ai_signal": 0.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The content does not directly mention Revenue per Employee nor explore it as a metric. Its focus is on a framework for AI adoption, prioritisation, and context-setting. While evidence, inspection, and business outcomes are discussed, there is no tie to workforce efficiency, financial observability, or metric-based analysis like Revenue per Employee. Score reflects this poor alignment, depth, and relevance.",
    "reasoning_summary": "The content does not address Revenue per Employee or related workforce financial metrics. Its themes concern AI adoption frameworks and organisational learning, so fit with this category is minimal.",
    "level": "Ignored"
  },
  "Lean Startup": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Lean Startup",
    "calculated_at": "2025-09-17T23:12:33",
    "ai_confidence": 30.19,
    "ai_mentions": 0.5,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 3.7,
    "ai_audience": 6.3,
    "ai_signal": 5.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 30.0,
    "reasoning": "There are no direct mentions of Lean Startup or its core concepts (MVP, Build-Measure-Learn, pivoting, rapid validation, etc.). While the Kendall Guide uses some iterative and evidence-based principles, they are applied to the adoption of AI, emphasizing problem-first thinking, context, accountability, cadenced review events, and stakeholder alignment, but not in the explicit startup/entrepreneurial or product hypothesis/testing sense. Concepts like feedback loops and continuous improvement are present but framed broadly in an organizational/AI adoption context, not specifically for validating business model hypotheses or MVPs. The target audience (change leaders, AI stakeholders) partially overlaps but is not start-up or Lean-focused. Content is focused on its own framework, not Lean Startup methodology.",
    "reasoning_summary": "Content focuses on an evidence-based AI adoption framework, not Lean Startup methods. While some iterative and feedback concepts overlap, there is no direct or substantial alignment to Lean Startup's core practices or intent. Partial thematic relevance only.",
    "level": "Ignored"
  },
  "Beta Codex": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Beta Codex",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 34.67,
    "ai_mentions": 0.2,
    "ai_alignment": 4.1,
    "ai_depth": 3.9,
    "ai_intent": 3.95,
    "ai_audience": 5.3,
    "ai_signal": 6.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 35.0,
    "reasoning": "The content never directly mentions Beta Codex, nor does it refer to its principles or terminology. Its main theme is AI adoption through disciplined, context-driven, and adaptive approaches. While it briefly touches on ideas like collaboration, flow, iterativity, and decentralisation of some responsibilities (e.g., Context Champions, Opportunity Leads), it does so in a modern management context rather than specifically invoking Beta Codex’s decentralised, anti-hierarchical philosophy. The framework’s accountabilities still reinforce boundaries and structural roles, and there’s no overt critique of hierarchical management or explicit advocacy for the core Beta Codex worldview. The intended audience—involved in organisational transformation, learning, and adaptive work—somewhat overlaps with Beta Codex’s, but alignment is superficial: the framework does not foreground decentralisation or human-centric reorganisation. The unambiguous focus is AI problem-solving and delivery discipline, making any Beta Codex overlap incidental and not central.",
    "reasoning_summary": "No direct mention or explicit adoption of Beta Codex principles. While adaptive, flow- and learning-oriented language overlaps at surface, the content does not align with decentralised or anti-hierarchical philosophy. Fit is weak and mostly incidental.",
    "level": "Ignored"
  },
  "Technical Excellence": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Technical Excellence",
    "calculated_at": "2025-09-17T23:12:34",
    "ai_confidence": 37.233,
    "ai_mentions": 0.9,
    "ai_alignment": 4.2,
    "ai_depth": 4.7,
    "ai_intent": 5.3,
    "ai_audience": 7.3,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "There are no direct mentions of technical excellence or its typical topics (TDD, CI/CD, modular architecture, emergent design, etc.). The content focuses on a framework for AI adoption and process discipline, emphasizing clarity, context, collaboration, and continuous improvement, which tangentially align with some technical excellence principles (continuous improvement, discipline, flow), but it doesn't engage with the underlying engineering or technical practices central to the category. The depth is moderate regarding processes but shallow on technical quality or practices. The target audience overlaps with technical teams but is broader (strategic, leadership, management). The discussion is focused and relevant to its own topic but not tightly linked to technical excellence's key themes.",
    "reasoning_summary": "The content mainly discusses frameworks, discipline, and collaboration for AI adoption, not the technical practices or principles central to Technical Excellence. Fit is partial and mostly indirect, lacking explicit engineering focus.",
    "level": "Ignored"
  },
  "Empirical Process Control": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Empirical Process Control",
    "calculated_at": "2025-09-17T23:12:34",
    "ai_confidence": 88.6,
    "ai_mentions": 7.6,
    "ai_alignment": 9.2,
    "ai_depth": 8.8,
    "ai_intent": 9.1,
    "ai_audience": 8.4,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 89.0,
    "reasoning": "The Kendall Guide explicitly references empirical inspection, adaptation, evidence-based decision-making, and feedback loops — core to empirical process control. 'Inspect and adapt' and regular cadence events mirror Agile practices. Content discusses transparency (clarity), inspection (cadence, discovery), and adaptation (feedback and roadmap revisions). The audience (organisations, teams, management) matches Agile practitioners and change enablers. Depth is strong: practical accountabilities, events, and artefacts show active application, not just conceptual mentions. There are few direct uses of the term 'empirical process control,' but the underlying concepts are robust and central. There is minimal unrelated content, and all emphasis is on iterative, evidence-driven adaptation. There is no outdated/contradictory material, so no penalties are applied.",
    "reasoning_summary": "Content strongly aligns with empirical process control: it emphasises adaptation, transparency, and inspection via evidence-based feedback loops. The intent and approach match Agile/empirical practices, though explicit category mentions are limited.",
    "level": "Primary"
  },
  "Strategic Goals": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Strategic Goals",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 88.41,
    "ai_mentions": 7.1,
    "ai_alignment": 9.7,
    "ai_depth": 8.9,
    "ai_intent": 8.6,
    "ai_audience": 8.2,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 88.0,
    "reasoning": "The Kendall Guide consistently integrates strategic alignment, clarity of purpose, and long-term value into AI adoption, emphasizing frameworks, accountabilities, and events dedicated to aligning initiatives with organisational objectives. Concepts like Roadmap, Opportunity Backlog, and adaptive feedback loops tie AI adoption to business strategy, reflect priorities, and adapt based on evidence—mirroring the core tenets of the 'Strategic Goals' category. While strategic themes permeate the entire framework and explicit references to goals are frequent, a minor part of the content is procedural/operational. However, overall, the intentions, audience (organizational leaders, strategists), and depth are strongly aligned to the category definition, with minimal off-topic material or tangential noise.",
    "reasoning_summary": "Content thoroughly embeds and operationalizes strategic goals in AI adoption, linking long-term business objectives and agility with clear frameworks, accountabilities, and adaptive processes. Strong, direct fit with only minor focus on tactical execution.",
    "level": "Primary"
  },
  "Test Automation": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Test Automation",
    "calculated_at": "2025-09-17T23:12:24",
    "ai_confidence": 3.62,
    "ai_mentions": 0.0,
    "ai_alignment": 1.7,
    "ai_depth": 2.0,
    "ai_intent": 2.5,
    "ai_audience": 6.0,
    "ai_signal": 5.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 4.0,
    "reasoning": "The content describes the Kendall Framework, a system for AI adoption that emphasizes problem identification, context definition, disciplined collaboration, and evidence-based improvement. There are no explicit references or even implied discussions of test automation principles, frameworks, test types, CI/CD, or automation tools. The focus is entirely on organizational practices and accountabilities for adopting AI in a structured and collaborative manner. Its audience (technical strategists, leaders in AI adoption) could intersect with some audiences interested in test automation, but the actual content does not address or overlap with automated testing, its principles, or processes. Only a small conceptual and audience overlap occurs due to shared interest in evidence-based, iterative improvement.",
    "reasoning_summary": "Content fully focuses on AI adoption and organizational practices, with no coverage—direct or indirect—of test automation. No relevant frameworks, practices, or principles are mentioned. Fit with the Test Automation category is effectively absent.",
    "level": "Ignored"
  },
  "GitHub": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "GitHub",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 1.2,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.0,
    "ai_intent": 1.0,
    "ai_audience": 5.3,
    "ai_signal": 1.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 1.0,
    "reasoning": "The content is focused entirely on a framework for AI adoption, with no reference to GitHub or its functionalities. There are no direct mentions or implied use of GitHub's services, tools, or methodologies. The conceptual overlap is extremely minimal—generic collaboration and backlog terms are used, but they are not placed in a GitHub context and do not reference GitHub features. The depth is very low, as nothing is discussed about GitHub. The intent is clearly non-GitHub-specific, targeting those looking to improve AI adoption practices, possibly appealing in part to some technical audiences, but not those interested in GitHub per se. The content is focused (signal-to-noise), but not on the evaluated category.",
    "reasoning_summary": "This content discusses AI adoption frameworks, not GitHub. There are no mentions, no depth on GitHub practices, and the intent is unrelated to the GitHub category definition. Fit is extremely poor.",
    "level": "Ignored"
  },
  "Test Driven Development": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Test Driven Development",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 2.35,
    "ai_mentions": 0.2,
    "ai_alignment": 1.9,
    "ai_depth": 2.1,
    "ai_intent": 3.0,
    "ai_audience": 4.1,
    "ai_signal": 2.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content is a comprehensive guide for AI adoption focusing on organisational alignment, context, evidence-based practices, and roles. There is no mention of Test Driven Development (TDD), nor are TDD principles (such as the Red-Green-Refactor cycle, unit tests before code, or TDD patterns) discussed. The content instead attends to high-level workflows, accountabilities, and process discipline for AI, not software engineering technique or testing. Any overlaps in empirical inspection or adaptation are process-general and not specific to TDD. The intended audience (AI adoption leaders, organisational transformation coaches) partially overlaps with possible TDD practitioners but with different foci. Content contains no relevant TDD material.",
    "reasoning_summary": "Content covers a framework for AI adoption and organisational practices, not Test Driven Development or related principles. No TDD topics are mentioned. The fit for the category is extremely low and largely coincidental.",
    "level": "Ignored"
  },
  "One Engineering System": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "One Engineering System",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 24.48,
    "ai_mentions": 0.3,
    "ai_alignment": 2.4,
    "ai_depth": 2.3,
    "ai_intent": 2.1,
    "ai_audience": 8.2,
    "ai_signal": 7.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content explicitly discusses the Kendall Framework as a system of work for AI adoption, centering on clarity, accountability, and continuous improvement. However, it never references or aligns with the One Engineering System (1ES) framework, its principles, or its core aim of standardising and integrating engineering practices. The main focus is on AI problem-first adoption, context maintenance, and collaboration—these tangentially overlap with some of 1ES's themes (like collaboration and process discipline) but aren't fundamentally about unified engineering systems or their integration. Significant technical alignment with an engineering audience is present, but the topic and depth are about a separate, non-1ES-specific methodology. Thus, the confidence in this being a fit for the 'One Engineering System' category is very low.",
    "reasoning_summary": "The content does not discuss or reference One Engineering System (1ES) or its integration principles. It introduces a separate framework (Kendall) focused on AI adoption, making category alignment minimal and only tangential at best.",
    "level": "Ignored"
  },
  "Install and Configuration": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Install and Configuration",
    "calculated_at": "2025-09-17T23:12:21",
    "ai_confidence": 7.914,
    "ai_mentions": 0.2,
    "ai_alignment": 0.8,
    "ai_depth": 0.9,
    "ai_intent": 0.6,
    "ai_audience": 2.2,
    "ai_signal": 0.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content describes the Kendall Framework for AI adoption, emphasizing organisational processes, principles, roles, and high-level events. It offers no specific installation, setup, or configuration instructions for tools, software, or platforms. No direct mentions of 'install' or 'configuration' are present, nor are there step-by-step guides, technical requirements, or troubleshooting details. The audience is practitioners of business transformation or AI adoption, not directly those seeking technical implementation support. Though there is mention of artifacts such as repositories and backlogs, these refer to project/process artifacts, not technical configuration elements. Thus, the fit to 'Install and Configuration' is weak on all main dimensions.",
    "reasoning_summary": "This content is centered on organisational frameworks and roles for AI adoption, not on installing or configuring any software. It does not fit the 'Install and Configuration' category.",
    "level": "Ignored"
  },
  "Frequent Releases": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Frequent Releases",
    "calculated_at": "2025-09-17T23:12:40",
    "ai_confidence": 19.25,
    "ai_mentions": 0.3,
    "ai_alignment": 2.2,
    "ai_depth": 2.4,
    "ai_intent": 2.6,
    "ai_audience": 5.8,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The Kendall Guide focuses on frameworks for AI adoption, emphasising problem-first approaches, context, leadership roles, and feedback loops. It discusses iteration and cadence (quarterly/half-yearly cycles) for strategic review and adaptation, but nowhere does it directly mention software releases, release frequency, DevOps/CD, automation, or related tooling. The concepts of feedback, iteration, and continuous improvement are general and not tied to Frequent Releases as per the given classification, and the process cadence is quite slow compared to the continuous/incremental manner required by Frequent Releases. Overall, the fit is peripheral: some agile-adjacent practices are described, but the primary subject and intent do not align with Frequent Releases, either in direct focus or in deep discussion.",
    "reasoning_summary": "Content does not address Frequent Releases or related practices, tools, or metrics. Iterative improvement is discussed at a high level, but not in the context of software releases. Fit is vague and mostly unrelated.",
    "level": "Ignored"
  },
  "Unrealised Value": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Unrealised Value",
    "calculated_at": "2025-09-17T23:12:26",
    "ai_confidence": 77.25,
    "ai_mentions": 2.3,
    "ai_alignment": 8.9,
    "ai_depth": 8.1,
    "ai_intent": 8.2,
    "ai_audience": 7.4,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 77.0,
    "reasoning": "Direct mentions of 'unrealised value' are absent, and the term itself is not explicitly referenced. However, the content conceptually aligns well with identifying and prioritising opportunities, managing an 'Opportunity Backlog,' and using feedback loops to surface untapped AI applications—each mapping closely to exploring potential value (the essence of Unrealised Value). Depth is strong: the content explains roles, events, and artifacts for capturing new AI opportunities, enabling adaptive change, and prioritising value-adding work. The intent is aligned (helping organisations unlock additional AI-driven value through evidence-based collaboration and improvement), matching EBM themes. Audience is slightly broader than EBM practitioners, including technical and business leaders. Signal is high: most content focuses on value discovery and strategic adaptation, though a small part focuses on operational/role clarification. No penalties apply as the content is current, supportive, and matches the framing.",
    "reasoning_summary": "Content broadly aligns with 'Unrealised Value' via its focus on uncovering, prioritising, and realising AI opportunities. Lacks explicit terminology but strongly matches the category’s intent, strategies, and target audience.",
    "level": "Secondary"
  },
  "Product Validation": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Product Validation",
    "calculated_at": "2025-09-17T23:12:27",
    "ai_confidence": 60.9,
    "ai_mentions": 1.3,
    "ai_alignment": 6.5,
    "ai_depth": 6.1,
    "ai_intent": 5.4,
    "ai_audience": 7.2,
    "ai_signal": 8.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 61.0,
    "reasoning": "The content focuses on AI adoption frameworks and principles, emphasizing evidence-based decision-making, feedback loops, and prioritization. These elements overlap conceptually with some aspects of product validation (like feedback loops and learning cycles), but there is a lack of direct discussion of user testing, market fit, prototyping, or validating product ideas with real users. The artifacts and events described are process-oriented and align more with organizational alignment and opportunity management than specifically validating product ideas with end users. Few, if any, explicit mentions or detailed discussions are made about engaging real users to test or validate product hypotheses. The material is highly relevant to technical and leadership audiences, and it stays focused without significant digressions, but the primary purpose is not product validation as narrowly defined.",
    "reasoning_summary": "While the Kendall Guide stresses evidence, iteration, and feedback loops (paralleling some product validation themes), it does not focus directly on user-driven product idea validation. Fit to the category is partial but not strong.",
    "level": "Secondary"
  },
  "Lead Time": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Lead Time",
    "calculated_at": "2025-09-17T23:12:28",
    "ai_confidence": 6.4575,
    "ai_mentions": 0.4,
    "ai_alignment": 1.2,
    "ai_depth": 1.6,
    "ai_intent": 1.2,
    "ai_audience": 1.5,
    "ai_signal": 0.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The content on the Kendall Framework focuses on AI adoption strategy, prioritization, opportunity backlogs, feedback loops, and flow, but does not mention 'Lead Time' or closely related concepts like Cycle Time. While 'flow' and 'feedback' are discussed, these relate to information and learning, not temporal process efficiency as defined for Lead Time. No direct references or substantial discussion on measuring, tracking, or optimizing the time from initiation to delivery of work exist. Thus, alignment and depth scores are low, with only marginal partial fit for practitioners interested in process improvement. No outdated or undermining content was found.",
    "reasoning_summary": "Content centers on AI adoption frameworks, not Lead Time. Minimal conceptual overlap (flow, feedback) with no explicit or deep foundation in Lead Time as an observability/process efficiency metric. Only a partial, tangential fit.",
    "level": "Ignored"
  },
  "Project Management": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Project Management",
    "calculated_at": "2025-09-17T23:12:41",
    "ai_confidence": 75.15,
    "ai_mentions": 3.6,
    "ai_alignment": 8.6,
    "ai_depth": 7.9,
    "ai_intent": 7.2,
    "ai_audience": 7.0,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 75.0,
    "reasoning": "Direct mentions of 'project management' or related explicit terminology are sparse; the main terminology revolves around AI adoption, frameworks, and systems of work. However, there is significant conceptual overlap: the framework manages scope (via Opportunity Backlog and Roadmap), roles (Kendall Coach, Opportunity Lead, etc.), structured event cadences (mirroring project phases), prioritisation, stakeholder alignment, and continuous improvement, all of which resonate with core project management principles. The content addresses cross-cutting governance, reporting, and accountability. The depth is strong (framework, artifacts, events, defined accountabilities), though the focus is on AI adoption rather than traditional or generic project management. The intent is to support organisational adoption in a disciplined, evidence-based way, targeting audiences typically interested in project management but skewed tech/innovation. Signal is good but diluted by extensive focus on AI-context specifics. No penalties: it's contemporary, non-critical, and fully relevant. Confidence is moderate-to-high because the core practices are project management-oriented in an AI delivery domain, even if not labeled as such.",
    "reasoning_summary": "The content closely aligns with project management through structured roles, prioritisation, planning, and governance—albeit uniquely focused on AI adoption. The fit is partial: it covers PM themes deeply, but not in a general or methodology-specific way.",
    "level": "Secondary"
  },
  "Hybrid Agile": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Hybrid Agile",
    "calculated_at": "2025-09-17T23:12:30",
    "ai_confidence": 12.187,
    "ai_mentions": 0.3,
    "ai_alignment": 1.8,
    "ai_depth": 1.7,
    "ai_intent": 1.5,
    "ai_audience": 2.0,
    "ai_signal": 1.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content introduces a framework for AI adoption focused on problem-first approaches, clarity, iterative improvement, collaboration, and accountability. While some themes (empirical work, flow, roles, events, backlogs) are common in agile/adaptive systems, there is no explicit mention or discussion of Hybrid Agile, nor is there a critical analysis of blending agile and traditional project management. There are no references to command-and-control, challenges with hybridization, or the pitfalls typically addressed by the Hybrid Agile category. The intent is practical guidance for AI adoption, not critique or exploration of Hybrid Agile dysfunctions; any overlaps are generic and not category-specific.",
    "reasoning_summary": "This resource describes an AI adoption framework with some process/adaptive themes but does not discuss Hybrid Agile concepts, challenges, or key dysfunctions. Its focus is unrelated and fit to the Hybrid Agile category is minimal and incidental.",
    "level": "Ignored"
  },
  "Backlog Refinement": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Backlog Refinement",
    "calculated_at": "2025-09-17T23:12:41",
    "ai_confidence": 34.13,
    "ai_mentions": 2.8,
    "ai_alignment": 4.6,
    "ai_depth": 3.9,
    "ai_intent": 5.5,
    "ai_audience": 5.6,
    "ai_signal": 4.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 34.0,
    "reasoning": "The Kendall Guide's 'Opportunity Backlog' is somewhat conceptually similar to a backlog but diverges in purpose, mechanics, and audience from Agile backlog refinement. While prioritisation and some refinement are discussed, terms and practices (like Product Owner, sprints, user stories, acceptance criteria, Scrum) are absent. The focus is AI adoption strategy and organisational alignment. Collaboration and iterative learning have partial thematic overlap, but explicit alignment, events, and techniques relevant to Agile backlog refinement are not covered. Audience partially overlaps: practitioners in improvement roles, not Scrum teams. References to refinement are high-level and not deep or focused on Agile/Scrum methodology.",
    "reasoning_summary": "Content presents an AI adoption framework with an 'Opportunity Backlog', showing partial thematic overlap but lacking direct coverage of Agile Backlog Refinement. Concepts such as Scrum events, user stories, or backlog grooming are not present. Only a partial, indirect fit.",
    "level": "Ignored"
  },
  "Digital Transformation": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Digital Transformation",
    "calculated_at": "2025-09-17T23:12:31",
    "ai_confidence": 82.35,
    "ai_mentions": 3.4,
    "ai_alignment": 9.1,
    "ai_depth": 9.3,
    "ai_intent": 8.2,
    "ai_audience": 8.4,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 82.0,
    "reasoning": "The Kendall Guide frames a structured, organisation-wide approach for adopting AI with clear roles, feedback loops, and alignment between strategy and execution. While the term 'digital transformation' is not directly used, the framework’s focus on adopting emerging digital technology (AI), organisational change, collaboration, metrics, feedback-driven improvement, and business agility strongly aligns with the definition. It explores impact on culture, processes, and operational efficiency, with deep and practical discussion. The intent is to guide strategic, value-driven AI adoption, targeting the executives, managers, and change agents typically concerned with digital transformation. Some minor focus is on framework mechanics over large-scale transformation rhetoric, so signal is slightly reduced, but most areas show high fit. No penalties needed.",
    "reasoning_summary": "This content outlines a comprehensive, strategic framework for organisational AI adoption—matching digital transformation’s themes of technology-driven, evidence-based change and business agility, despite not naming the category. High alignment and depth.",
    "level": "Primary"
  },
  "Decision Theory": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Decision Theory",
    "calculated_at": "2025-09-17T23:12:41",
    "ai_confidence": 66.36,
    "ai_mentions": 2.7,
    "ai_alignment": 7.3,
    "ai_depth": 6.9,
    "ai_intent": 7.2,
    "ai_audience": 7.7,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 66.0,
    "reasoning": "Direct mentions of 'Decision Theory' or its formal terminology are absent; however, the framework hinges on evidence-based, adaptive decision-making in AI adoption. Several principles (empirical inspection, prioritisation under uncertainty, context-driven choices) resonate with decision theory concepts (uncertainty, outcomes, frameworks). The depth is moderate: the material focuses on practical process and team roles rather than rigorous exploration of probability, heuristics, or behavioural economics. The primary audience (AI/tech leaders, teams, organisational strategists) overlaps with those interested in decision science within the Agile/DevOps context. Most content is relevant to decision processes in uncertain environments but leans pragmatic and managerial, not academic or theoretical. The fit is partial—decision-making under uncertainty is central but the focus is practical adoption frameworks, not a direct or deep exposition of decision theory.",
    "reasoning_summary": "This content aligns with Decision Theory in intent and process (evidence-based, adaptive decisions under uncertainty) but lacks explicit, deep coverage of decision theory concepts. Fit is partial and practical, not direct or comprehensive.",
    "level": "Secondary"
  },
  "Tenet": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Tenet",
    "calculated_at": "2025-09-17T23:12:27",
    "ai_confidence": 92.43,
    "ai_mentions": 8.7,
    "ai_alignment": 9.9,
    "ai_depth": 9.7,
    "ai_intent": 9.5,
    "ai_audience": 9.2,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content provides a framework heavily structured around actionable guiding rules—'first principles'—which are explicitly described and prescriptive (e.g., 'Problem Before Solution', 'Continuous Improvement', 'Collaboration Sustains Value'). These match the definition of tenets, moving from high-level beliefs to concrete practices that direct behavior, especially in contexts relevant to Agile, Lean, and Evidence-Based Management. The framework’s application, roles/accountabilities, and events further operationalize these tenets. The content is targeted at practitioners and leaders seeking an actionable doctrine for AI adoption—fully aligned with the category. The only slight deduction in the 'signal' dimension is due to a few framing passages (e.g., philosophy/definition references), but these are minor. There is no outdated or critical tone; no penalties apply.",
    "reasoning_summary": "The content thoroughly defines and operationalizes actionable tenets guiding AI adoption, strongly aligning with the category's definition. Its intent, structure, and audience closely fit 'Tenet', with only minor general framing—fit is very strong.",
    "level": "Primary"
  },
  "Automated Testing": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Automated Testing",
    "calculated_at": "2025-09-17T23:12:33",
    "ai_confidence": 4.5,
    "ai_mentions": 0.2,
    "ai_alignment": 1.0,
    "ai_depth": 0.8,
    "ai_intent": 1.1,
    "ai_audience": 0.7,
    "ai_signal": 0.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 4.0,
    "reasoning": "The content extensively details an AI adoption framework focused on problem-first thinking, context, flow, and iterative improvement. While it discusses evidence-based and collaborative practices, there are no direct or explicit references to automated testing—its types, roles in CI/CD, tools, or relevant methodologies. The closest thematic alignments are around empirical inspection, adaptation, and feedback loops, but none specifically connect to testing automation or quality engineering. The intended audience is organizational leaders and teams adopting AI, not specifically testers or automation specialists. Virtually no discussion matches the category’s essential topics.",
    "reasoning_summary": "No direct or substantial link to automated testing. Focus is on AI adoption systems, not automation, frameworks, or CI/CD topics. Any overlap (evidence, learning loops) is generic, not testing-specific. Category fit is absent.",
    "level": "Ignored"
  },
  "Value Stream Mapping": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Value Stream Mapping",
    "calculated_at": "2025-09-17T23:12:44",
    "ai_confidence": 25.95,
    "ai_mentions": 0.2,
    "ai_alignment": 3.7,
    "ai_depth": 2.9,
    "ai_intent": 3.1,
    "ai_audience": 8.8,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 26.0,
    "reasoning": "The content does not mention Value Stream Mapping (VSM) directly and does not discuss its principles, tools, or mapping steps. While there are allusions to flow, value delivery, and lean-like practices (e.g., eliminating impediments to flow, continuous improvement), these remain at the conceptual level and are framed in the context of AI adoption rather than workflow visualization or process mapping. There is no discussion or illustration of mapping the end-to-end value stream, distinguishing value-added/non-value-added activities, use of VSM tools/artifacts, or integration with lean management approaches as defined in the category. The main intent is to outline a framework for AI adoption, not to teach or apply VSM or related techniques, though the audience is similar and some language overlaps.",
    "reasoning_summary": "Content describes an AI adoption framework with minor conceptual overlap to Lean but contains no direct or substantive discussion of Value Stream Mapping or its techniques. Fit is weak and mostly tangential, not aligned to the category definition.",
    "level": "Ignored"
  },
  "Artifact": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Artifact",
    "calculated_at": "2025-09-17T23:12:34",
    "ai_confidence": 79.98,
    "ai_mentions": 5.4,
    "ai_alignment": 8.9,
    "ai_depth": 7.4,
    "ai_intent": 8.0,
    "ai_audience": 8.2,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 80.0,
    "reasoning": "The content discusses three specific artifacts—Opportunity Backlog, Context Repository, and Roadmap—in detail and describes their roles within the Kendall Framework, aligning with the definition. However, artifacts are not the primary focus; much of the content covers roles, principles, and events in the framework. The artifacts section is explicit and substantial, discussing structure, purpose, and use in transparency, inspection, and adaptation, but is only one part of the overall piece. The rest largely details governance, accountabilities, and system-level practices. Audience and intent match artifact-related content yet are broadly targeted at organizational change. No outdated practices or category undermining observed; no penalties applied.",
    "reasoning_summary": "The content describes artifacts in the Kendall Framework explicitly and in detail, matching the Artifact category. However, artifacts are not the main focus, being only a moderate portion of a broader framework for AI adoption.",
    "level": "Secondary"
  },
  "Capability": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Capability",
    "calculated_at": "2025-09-17T23:12:28",
    "ai_confidence": 73.72,
    "ai_mentions": 3.7,
    "ai_alignment": 8.1,
    "ai_depth": 8.4,
    "ai_intent": 8.0,
    "ai_audience": 7.2,
    "ai_signal": 8.0,
    "ai_penalties_applied": true,
    "ai_penalty_points": 1,
    "ai_penalty_details": "Mentions penalized (-1): does not directly use 'capability/capabilities,' instead emphasizing 'framework, system of work' and 'practices.'",
    "final_score": 74.0,
    "reasoning": "The Kendall Guide frequently aligns conceptually with the Capability category by emphasizing systemic, enduring competencies for AI adoption, such as collaboration, continuous improvement, and flow. The depth of discussion is strong regarding sustainable and adaptive practices, learning loops, and embedding these habits, all reflecting capability-like themes. However, it does not explicitly use the word 'capability,' instead focusing on framework constructs, events, roles, and artifacts. While these indirectly foster organizational capability, the lack of direct references led to a lower 'Mentions' score and a –1 penalty on that dimension. The core intent, audience (change leaders, practitioners), and signal-to-noise are otherwise strong. Artifacts and roles are described, but typically in service of building systemic habits, not as isolated outputs/tools.",
    "reasoning_summary": "Content strongly aligns with the Capability category through its focus on enduring, systemic practices for value delivery and adaptation. Direct mentions are lacking, but its conceptual and practical treatment of capabilities is deep and well-targeted.",
    "level": "Secondary"
  },
  "Continuous Learning": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Continuous Learning",
    "calculated_at": "2025-09-17T23:12:34",
    "ai_confidence": 85.81,
    "ai_mentions": 7.4,
    "ai_alignment": 9.4,
    "ai_depth": 9.1,
    "ai_intent": 8.2,
    "ai_audience": 8.1,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 86.0,
    "reasoning": "The content repeatedly references themes central to continuous learning: empirical inspection, adaptation, and feedback loops. Roles (Kendall Coach, Opportunity Lead, Context Champions) all promote reflective practice, team learning, and knowledge sharing. It discusses regular feedback events, learning orientation, and explicit structures for inspection and adaptation—all signals of continuous learning per Agile/Lean/DevOps context. Direct categorical mentions are moderate but not explicit by name; the narrative focuses on learning as a core principle rather than just a surface mention. While rooted in AI adoption, the framework repeatedly emphasizes learning cycles, feedback, collaborative improvement, and experimental adaptation. The audience is practitioners and organisations in team-based, improvement-focused work. Only a modest proportion addresses non-learning artifacts. There is no evidence of contradictions, outdated practice, or off-topic tangents.",
    "reasoning_summary": "The content strongly aligns with Continuous Learning, discussing feedback loops, adaptation, team learning, and growth as core principles for AI adoption in Agile/Lean contexts. Fit is clear and substantial, with only moderate explicit naming.",
    "level": "Primary"
  },
  "Ethos": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Ethos",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 65.68,
    "ai_mentions": 3.2,
    "ai_alignment": 7.5,
    "ai_depth": 6.9,
    "ai_intent": 7.2,
    "ai_audience": 7.9,
    "ai_signal": 8.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 66.0,
    "reasoning": "The content identifies foundational principles for disciplined AI adoption (e.g., Problem Before Solution, Context Creates Meaning, Boundaries Enable Trust) and enshrines accountabilities (Kendall Coach) that operationalize clarity and evidence-based adaptation. However, explicit references to ethos as the underlying system-level driver are indirect—the focus is structured processes and principled accountabilities rather than overt discussion of beliefs shaping system behaviors. There is alignment in values-oriented, principle-driven method, but the conversation does not deeply examine ethos or distinguish it from ritual/compliance. The intended audience is change leaders, coaches, and technical/strategic practitioners; signal is focused but anchored on application, not deconstruction of ethos as such.",
    "reasoning_summary": "The content presents principled, system-level foundations and disciplined stances for AI adoption, aligning with ethos themes, but stops short of directly examining ethos as a distinct systemic force. Fit is partial, leaning toward relevant.",
    "level": "Secondary"
  },
  "Product Owner": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Product Owner",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 19.62,
    "ai_mentions": 1.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.1,
    "ai_intent": 2.4,
    "ai_audience": 7.4,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content focuses on the Kendall Framework's approach to AI adoption, outlining custom roles/accountabilities (Kendall Coach, Opportunity Lead, Context Champions) and associated artifacts. Although there are some indirect conceptual overlaps (e.g., opportunity backlog, prioritisation, accountability), the roles and terms are not equivalent to the Scrum Product Owner, nor do they reference Scrum or Agile directly in the context of Product Owner accountability. There are no explicit mentions of the Product Owner role, its responsibilities, or its Scrum context. The depth, intent, and main audience are only very loosely related through incidental alignment on topics such as prioritisation and value delivery, but the implementation is unique to the Kendall Framework, not Scrum/Product Owner. Signal-to-noise and audience scores are higher because practitioners interested in frameworks and backlogs may find relevance, but overall fit is weak and mostly coincidental, not intentional.",
    "reasoning_summary": "Content discusses Kendall Framework accountabilities, not Scrum's Product Owner role. Overlap on themes like prioritisation and value is incidental; there is no direct or substantial focus on Product Owner accountability.",
    "level": "Ignored"
  },
  "Test First Development": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Test First Development",
    "calculated_at": "2025-09-17T23:12:38",
    "ai_confidence": 11.68,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 1.3,
    "ai_intent": 1.2,
    "ai_audience": 4.0,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "There is no direct mention of Test First Development or its principles (e.g., test criteria before implementation, automated or manual test-first practices, TDD/ATDD, acceptance criteria, or feedback loops focusing on test-first). The Kendall Framework focuses on AI adoption through problem-first, context-driven, and evidence-based practices, but it does not advocate for defining acceptance/test criteria before implementation or emphasize testing as design or feedback. The concept of feedback loops appears, but these relate to strategic alignment and opportunity discovery, not to test-first design. The audience overlap is limited—both target practitioners and organisations, but from very different perspectives. Most of the content is relevant to its own context, not to Test First Development, with only superficial, coincidental conceptual overlap (feedback, evidence, iteration).",
    "reasoning_summary": "The content does not discuss Test First Development or its practices. It focuses on AI adoption via problem-first, context-driven, and evidence-based work, with only minor conceptual overlap (e.g., feedback), so fit is negligible.",
    "level": "Ignored"
  },
  "Cycle Time": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Cycle Time",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 11.6,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content describes the Kendall Framework for AI adoption, focusing on problem prioritization, flow, evidence-based decision-making, and collaboration. Although 'flow' and continuous improvement are discussed, Cycle Time is never directly mentioned nor explored as a work unit metric. The overall theme centers on strategic alignment, opportunity backlogs, context management, and roles/artifacts rather than on the granular measurement or analysis of work duration, workflow efficiency, or process improvement through Cycle Time. While the broad principle of 'flow' hints at efficiency, there are no explicit discussions, tools, methods, or examples relating to Cycle Time, nor any reference to its impact in Agile or DevOps contexts. Therefore, the conceptual, depth, and intent alignment to the Cycle Time category are low. Audience alignment is slightly higher as it targets organizational practitioners familiar with Agile-ish practices, but most signals remain off-topic for Cycle Time.",
    "reasoning_summary": "The content does not directly address Cycle Time, nor does it discuss measuring or improving work duration. Its focus is on AI adoption, prioritization, and flow, so fit to the 'Cycle Time' category is extremely limited.",
    "level": "Ignored"
  },
  "Product Strategy": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Product Strategy",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 87.29,
    "ai_mentions": 3.8,
    "ai_alignment": 9.5,
    "ai_depth": 8.9,
    "ai_intent": 9.4,
    "ai_audience": 8.1,
    "ai_signal": 8.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 87.0,
    "reasoning": "Direct usage of 'product strategy' language is limited; however, the framework extensively addresses vision, roadmapping, strategic alignment, opportunity prioritisation, and evidence-based adaptation. The discussion is deeply focused on strategy-oriented AI adoption (roadmaps, context, prioritisation). The content's main purpose, structure, and target (decision-makers, strategists, organisational leaders) are closely aligned with product strategy principles, though explicitly framed in the AI adoption context. Topics like roadmaps, backlogs, accountability, and evidence review are deeply discussed, indicating strong depth and alignment. Audience and signal are high but not perfect as implementation nuances and some supporting roles are mentioned.",
    "reasoning_summary": "The content deeply explores frameworks for AI adoption that focus on vision, roadmaps, prioritisation, and evidence-based strategy, making it a strong—though not explicit—fit for Product Strategy.",
    "level": "Primary"
  },
  "Agile Values and Principles": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agile Values and Principles",
    "calculated_at": "2025-09-17T23:12:34",
    "ai_confidence": 44.732,
    "ai_mentions": 0.7,
    "ai_alignment": 4.9,
    "ai_depth": 4.6,
    "ai_intent": 4.1,
    "ai_audience": 5.5,
    "ai_signal": 4.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 45.0,
    "reasoning": "The content describes the Kendall Framework for AI adoption emphasizing principles like collaboration, continuous improvement, iterative adaptation, stakeholder accountability, and value delivery—concepts that echo themes in Agile. However, there are no direct mentions of 'Agile,' the Agile Manifesto, or its core values/principles. Alignment is partial—many principles (e.g., inspect and adapt, flow, collaboration) resemble Agile philosophy, but the main focus is on a distinct system for AI, not on exploring Agile's foundational beliefs. The audience is similar (leaders, teams, coaches), and the intent is organizational improvement, yet the guide doesn't teach or explicitly contextualize 'Agile Values and Principles.' Discussion depth is moderate: first principles and mechanisms are explained, but not from an Agile perspective. Fit is partial, as the values overlap but the content doesn't fit squarely within the defined category.",
    "reasoning_summary": "The content aligns in part with Agile values (collaboration, inspect‑adapt, accountability), but it neither discusses Agile itself nor frames these principles as such. It is mainly an AI adoption framework with principles that echo Agile, making the category fit partial.",
    "level": "Tertiary"
  },
  "Agile Strategy": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agile Strategy",
    "calculated_at": "2025-09-17T23:12:35",
    "ai_confidence": 82.31,
    "ai_mentions": 3.6,
    "ai_alignment": 8.4,
    "ai_depth": 8.5,
    "ai_intent": 8.0,
    "ai_audience": 8.2,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 82.0,
    "reasoning": "The content details the Kendall Framework, a system of work for AI adoption that emphasizes adaptability, continuous improvement, stakeholder collaboration, and evidence-based decision-making—closely aligned with Agile Strategy principles. It discusses strategic alignment, feedback loops, iterative improvement, and leadership roles (e.g., Kendall Coach, Opportunity Lead) in enabling adaptive, value-focused AI adoption at scale. While 'Agile' isn't directly mentioned often, the practices and organizational focus reflect Agile strategic planning and delivery. The targeted audience aligns with strategists and leaders responsible for transformation. No penalties applied as the tone and references are current and affirming.",
    "reasoning_summary": "Substantially fits Agile Strategy via frameworks, adaptive planning, feedback, and value alignment—though 'Agile' is rarely named, the themes, audience, and strategic lens are a strong match. Partial fit due to lack of explicit Agile branding.",
    "level": "Primary"
  },
  "Current Value": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Current Value",
    "calculated_at": "2025-09-17T23:12:40",
    "ai_confidence": 49.97,
    "ai_mentions": 0.6,
    "ai_alignment": 5.7,
    "ai_depth": 5.2,
    "ai_intent": 5.9,
    "ai_audience": 6.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 50.0,
    "reasoning": "The content introduces a practical AI adoption framework focused on empirical, adaptive practices, context, and value flow. While it emphasizes evidence, feedback loops, and outcomes, it never directly discusses 'Current Value' as defined in Evidence-Based Management, nor does it specify measurement of customer satisfaction, revenue, or real-time value delivery metrics. The framework's artifacts and events suggest a general commitment to evidence-based prioritisation and adaptation, but do so abstractly. There is lack of explicit, deep, or measured discussion of Current Value as a distinct EBM focus area. The alignment and depth scores reflect that practical mechanisms for inspecting outcomes are implied but not elaborated in direct relation to Current Value. No penalties were applied, as there is no contradiction or outdated advice present.",
    "reasoning_summary": "While the Kendall Framework emphasizes evidence, adaptation, and value flow, it rarely directly mentions Current Value or discusses its measurement in an EBM sense. Connection is indirect; fit to the category is partial and not explicit.",
    "level": "Tertiary"
  },
  "Agile Planning": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agile Planning",
    "calculated_at": "2025-09-17T23:12:35",
    "ai_confidence": 69.45,
    "ai_mentions": 2.7,
    "ai_alignment": 7.6,
    "ai_depth": 7.9,
    "ai_intent": 7.3,
    "ai_audience": 7.7,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 69.0,
    "reasoning": "The Kendall Guide discusses a system of work for AI adoption grounded in adaptive, iterative practices and feedback loops—conceptually similar to Agile Planning—but it never directly mentions Agile, sprints, backlogs (beyond 'Opportunity Backlog'), or established Agile ceremonies. Its core focus is not teaching Agile Planning but enabling principled, evidence-based, collaborative adaptation. Key Agile Planning ideas such as prioritisation, cadence-based events, and backlogs are present; however, these are framed generically for AI adoption rather than in explicit Agile (Scrum/Kanban) terms. The depth is substantial for its intended process, with emphasis on empirical iteration, alignment, and value delivery—strong conceptual parallels to Agile Planning philosophies. Audiences overlap (practitioners, teams, strategists), and signal is focused, but the lack of explicit Agile terminology or references reduces Mention score. No outdatedness or negation is present, so no penalties applied.",
    "reasoning_summary": "The content aligns conceptually with Agile Planning via iterative, adaptive, feedback-driven practices, and use of backlogs and cadence. However, it lacks direct Agile references, making fit partial—not the primary category focus.",
    "level": "Secondary"
  },
  "Self Organisation": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Self Organisation",
    "calculated_at": "2025-09-17T23:12:41",
    "ai_confidence": 60.74,
    "ai_mentions": 1.5,
    "ai_alignment": 6.6,
    "ai_depth": 6.4,
    "ai_intent": 6.3,
    "ai_audience": 8.7,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 61.0,
    "reasoning": "The Kendall Guide emphasizes collaboration, collective ownership, continuous improvement, and team accountability, aligning conceptually with self-organisation principles. However, it primarily focuses on AI adoption processes rather than explicitly exploring self-organisation as its core theme. Explicit references to autonomy, empowered teams, or direct self-organisation terminology are limited, and much of the framework relies on designated roles and structured responsibilities, revealing only partial fit to the category definition. Still, the framework’s discussion of distributed responsibilities, feedback loops, and emphasis on learning does support a culture conducive to self-organisation, justifying moderate scores in alignment and depth, and high scores for audience and signal relevance.",
    "reasoning_summary": "Content moderately fits 'Self Organisation' via themes (accountability, collaboration, adaptation), but lacks explicit focus or depth on the topic; main intent is practical AI adoption, making the fit partial.",
    "level": "Secondary"
  },
  "Customer Retention": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Customer Retention",
    "calculated_at": "2025-09-17T23:12:43",
    "ai_confidence": 36.716,
    "ai_mentions": 0.7,
    "ai_alignment": 3.6,
    "ai_depth": 3.3,
    "ai_intent": 2.6,
    "ai_audience": 4.3,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The Kendall Guide focuses on AI adoption via clarity, adaptive planning, collaboration, and evidence-based improvement. While it discusses feedback loops and value delivery, its intent and depth emphasize organizational AI enablement, not direct customer retention. It lacks explicit or in-depth discussion of retention strategies, satisfaction measurement, or churn reduction. The core audience is technical/organizational practitioners, which partly overlaps with customer-centric roles, but the signal is diluted as retention is not a main or explicit focus.",
    "reasoning_summary": "The content centers on AI adoption and organizational clarity, not customer retention. Feedback loops and value delivery are mentioned, but retention strategy, measurement, or KPIs are not core themes. Partial audience alignment, but overall fit is weak.",
    "level": "Ignored"
  },
  "Flow Efficiency": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Flow Efficiency",
    "calculated_at": "2025-09-17T23:12:44",
    "ai_confidence": 43.49,
    "ai_mentions": 2.7,
    "ai_alignment": 5.3,
    "ai_depth": 4.7,
    "ai_intent": 5.2,
    "ai_audience": 7.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "Direct references to 'flow' appear mainly in the context of information, decisions, and value—not specifically throughput or work item flow. The core focus is AI adoption, prioritisation, and context management, not optimising throughput in the value stream. There is mention of flow-based thinking and visibility of information/decision flow, but with little detail on bottleneck identification, WIP limits, or specific flow efficiency metrics. The framework targets organisational and team audiences consistent with flow efficiency topics, but its practical mechanics center on clarity, opportunities, feedback, and learning loops rather than targeted throughput optimisation. The intent and discussion are only loosely aligned with flow efficiency as defined.",
    "reasoning_summary": "Content references 'flow' (of information, decisions, value) and hints at continuous improvement but lacks substantive focus on throughput optimisation, bottlenecks, or flow metrics. Fit to Flow Efficiency is partial, conceptual, and not primary.",
    "level": "Tertiary"
  },
  "Scrum": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Scrum",
    "calculated_at": "2025-09-17T23:12:35",
    "ai_confidence": 7.9,
    "ai_mentions": 0.2,
    "ai_alignment": 1.7,
    "ai_depth": 2.1,
    "ai_intent": 1.2,
    "ai_audience": 1.6,
    "ai_signal": 1.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content thoroughly describes the Kendall Framework as a system of work for AI adoption, focusing on principles, roles, events, and artifacts. While there are conceptual echoes of empirical inspection, adaptation, and iterative improvement, the discussion and terminology are specific to Kendall, not Scrum. There are no direct mentions or references to Scrum, its roles, events, or artifacts. Team dynamics, framework structure, and continuous improvement are covered but outside Scrum's context or practice. The content targets change leaders, coaches, and AI practitioners, overlapping slightly with Scrum-style audiences, but the fit is incidental and not intended. The only notable alignment is general process improvement and adaptive practice, which are too generic to be considered strong evidence of Scrum relevance.",
    "reasoning_summary": "This content describes the Kendall Framework for AI adoption, with minimal conceptual overlap to Scrum (e.g., iterative, adaptive practices) but no direct relevance. It does not match Scrum's main topics, terminology, or intent; fit is negligible.",
    "level": "Ignored"
  },
  "Lean": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Lean",
    "calculated_at": "2025-09-17T23:12:38",
    "ai_confidence": 44.35,
    "ai_mentions": 2.2,
    "ai_alignment": 5.6,
    "ai_depth": 5.2,
    "ai_intent": 6.5,
    "ai_audience": 7.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 44.0,
    "reasoning": "The Kendall Guide details a system for AI adoption focused on prioritisation, flow, collaboration, empirical inspection, and continuous improvement. While these concepts overlap with Lean themes (e.g., reduction of waste, continuous improvement, flow), the content never explicitly references Lean, its principles, or Lean-specific tools like Kanban, 5S, or value stream mapping. The terms 'lean management' and 'flow' are present but are not contextualised using classical Lean literature or terminology. The main focus remains on AI adoption strategies. Audience and intent are partially aligned (aimed at practitioners, with value-focused purpose), but a direct and thorough engagement with Lean is absent.",
    "reasoning_summary": "The content discusses AI adoption with some Lean-adjacent concepts (flow, improvement, value focus) but lacks direct Lean references or tools. Fit is partial and indirect—the content does not primarily discuss Lean.",
    "level": "Tertiary"
  },
  "Philosophy": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Philosophy",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 87.1,
    "ai_mentions": 6.2,
    "ai_alignment": 9.4,
    "ai_depth": 8.8,
    "ai_intent": 8.6,
    "ai_audience": 8.3,
    "ai_signal": 7.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 87.0,
    "reasoning": "The content directly discusses foundational principles (first principles) and values behind the Kendall Framework, focusing on 'problem before solution,' context, accountability, learning, and continuous improvement—all core philosophical concepts. It references systems thinking, empirical inspection, and adaptation, steering away from technical implementation and detailed tools. Terms such as 'principled,' 'evidence-based,' and 'collaboration' underscore alignment with the philosophy of organisational methods such as Agile and Lean. However, while there are explicit theoretical references and clear philosophical framing, some sections lean toward procedural structures (roles, events, and artifacts), slightly diluting depth and conceptual focus. Still, the intent, audience, and main themes match the Philosophy category well; the primary aim is shaping mindsets and foundational approaches, not mechanics. No penalties applied as the content is current and supports, not contradicts, the category.",
    "reasoning_summary": "This content robustly fits the Philosophy category, exploring foundational principles, evidence-based thinking, and cultural elements guiding AI adoption. A minor procedural lean reduces conceptual purity, but the primary intent and themes are philosophical.",
    "level": "Primary"
  },
  "Azure Pipelines": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Azure Pipelines",
    "calculated_at": "2025-09-17T23:12:41",
    "ai_confidence": 2.2,
    "ai_mentions": 0.1,
    "ai_alignment": 0.7,
    "ai_depth": 0.5,
    "ai_intent": 0.2,
    "ai_audience": 0.4,
    "ai_signal": 1.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content is entirely focused on the Kendall Guide for AI adoption and never mentions Azure Pipelines or its concepts. There are no discussions of CI/CD, pipeline configuration, automation, or Azure-specific DevOps practices. The focus is on AI frameworks, organisational structure, and collaborative decision-making. Although some terminology like 'flow', 'backlog', and 'coach' overlap with Agile or DevOps lexicon, these are used generically and not in any Azure Pipelines context. There are no tangential allusions that might tie to Azure Pipelines content, nor is the audience addressed as Azure DevOps practitioners.",
    "reasoning_summary": "This content does not mention or discuss Azure Pipelines or related concepts. It is about AI adoption frameworks, with no overlap in topic, intent, or audience with the Azure Pipelines category. The fit is nonexistent.",
    "level": "Ignored"
  },
  "Accountability": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Accountability",
    "calculated_at": "2025-09-17T23:12:43",
    "ai_confidence": 90.35,
    "ai_mentions": 9.3,
    "ai_alignment": 9.7,
    "ai_depth": 9.4,
    "ai_intent": 9.0,
    "ai_audience": 8.7,
    "ai_signal": 8.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 90.0,
    "reasoning": "The content explicitly defines formal accountabilities for key roles (Kendall Coach, Opportunity Lead, Context Champion) and discusses how each is accountable for specific outcomes rather than just tasks. Outcome ownership, alignment, and adaptation are frequent themes. It also details how these accountabilities structure the flow of information, decisions, and value, matching the category's focus on structural accountability in work systems. Events and artifacts further reinforce accountability by clarifying ownership and feedback mechanisms flowing from objective evidence. The discussion deeply explores accountability's function in alignment, learning, and adaptation within complex environments, clearly targeting practitioners of modern work systems. Minor signal dilution occurs due to some context-setting and introductory content, but the overall content stays highly focused and relevant.",
    "reasoning_summary": "This content fits the 'Accountability' category exceptionally well. It details role-based outcome ownership, systemic accountabilities, and how explicit accountabilities enable adaptation and alignment in AI work systems.",
    "level": "Primary"
  },
  "Organisational Agility": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Organisational Agility",
    "calculated_at": "2025-09-17T23:12:43",
    "ai_confidence": 88.97,
    "ai_mentions": 3.9,
    "ai_alignment": 9.7,
    "ai_depth": 9.3,
    "ai_intent": 9.5,
    "ai_audience": 8.7,
    "ai_signal": 9.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 89.0,
    "reasoning": "The Kendall Guide content is strongly aligned with Organisational Agility. While it is focused on AI adoption, it is framed as an organisational system of work grounded in adaptive, collaborative, and empirical practices—core themes of agility. Concepts such as empirical inspection/adaptation, cross-functional collaboration, continuous improvement, prioritisation and structured learning, and alignment with strategic objectives are thoroughly explored. Formal agile or agility language occurs indirectly, with some direct references (e.g., 'adaptive,' 'flow,' 'iteration,' 'continuous improvement,' 'inspect and adapt,' 'collaboration'), giving a moderate explicit mentions score. The depth of discussion and conceptual alignment are high, as the guide addresses leadership roles, cadence, feedback loops, systemic barriers to flow, and culture-building. The intended audience includes organisational leaders, teams, and strategists interested in adaptive, evidence-based transformation—matching the typical audience for organisational agility topics. Signal-to-noise is very high: discussion is focused, practical, and avoids tangential or filler content. There are no indications of outdated, critical, or anti-agility positions. Thus, the confidence rating is highly positive and the fit is strong, even if agility per se is often implied rather than overtly named.",
    "reasoning_summary": "Content fits strongly: it details adaptive frameworks, collaborative practices, and continuous improvement for organisational AI adoption, aligning clearly with principles of organisational agility even though the term is mostly implied, not named.",
    "level": "Primary"
  },
  "Customer Feedback Loops": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Customer Feedback Loops",
    "calculated_at": "2025-09-17T23:12:46",
    "ai_confidence": 61.651,
    "ai_mentions": 4.3,
    "ai_alignment": 6.7,
    "ai_depth": 7.1,
    "ai_intent": 6.5,
    "ai_audience": 8.2,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 62.0,
    "reasoning": "The content occasionally references feedback loops, organizational learning, and adaptive improvement—especially in the 'Opportunity & Context Sourcing Event' and recurring references to empirical inspection and adaptation. However, customer/end-user feedback as a sustained, explicit practice is not central here: the framework emphasizes evidence, inspection, and adaptation cycles largely internal to the organization, prioritization backlogs, and context management. Feedback mechanisms are described in terms of 'learning' and 'adaptation loops,' but there's limited discussion of gathering feedback directly from customers or mechanisms/materials for collecting, analyzing, or implementing external user feedback. Most of the looped feedback centers on internal strategy, leadership alignment, and cross-team learning (e.g., 'deliberate feedback,' 'reflection across discovery cycles'), so the conceptual alignment and discussion depth are moderate, but not highly concentrated or explicit per the strict definition. Audience and signal are relatively strong due to overlap with Agile/Lean teams. No penalties for outdatedness or tone.",
    "reasoning_summary": "The Kendall Guide mentions feedback loops and adaptive learning but focuses on internal organizational feedback, not direct customer feedback mechanisms. Fit with 'Customer Feedback Loops' is partial and only tangentially supports the category’s strict definition.",
    "level": "Secondary"
  },
  "Decision Making": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Decision Making",
    "calculated_at": "2025-09-17T23:12:45",
    "ai_confidence": 94.85,
    "ai_mentions": 9.2,
    "ai_alignment": 9.7,
    "ai_depth": 9.8,
    "ai_intent": 9.6,
    "ai_audience": 9.4,
    "ai_signal": 9.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 95.0,
    "reasoning": "The content directly and repeatedly refers to evidence-based decision-making, prioritisation, collaborative alignment, feedback loops, and structured frameworks for informing choices—core elements in the 'Decision Making' category definition. It describes roles (Kendall Coach, Opportunity Lead, Context Champions) and events (Opportunity & Context Sourcing) facilitating collaborative, data-driven decision processes. Discussion of artifacts like the Opportunity Backlog and Context Repository further underscores a commitment to structured, empirical decision practice. No penalties apply as content is current, supportive, and closely aligned with category framing.",
    "reasoning_summary": "The content deeply explores evidence-based and collaborative decision-making. It aligns tightly with the category definition, focusing on structured, empirical, and adaptive processes for organisational choices. Fit is highly direct and complete.",
    "level": "Primary"
  },
  "Product Management": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Product Management",
    "calculated_at": "2025-09-17T23:12:26",
    "ai_confidence": 62.58,
    "ai_mentions": 2.4,
    "ai_alignment": 7.1,
    "ai_depth": 6.7,
    "ai_intent": 6.2,
    "ai_audience": 7.8,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 63.0,
    "reasoning": "The Kendall Guide centers on guiding AI adoption within organisations by focusing on aligning purpose, context, and opportunities—paralleling some strategic product management concepts (like prioritisation, stakeholder alignment, evidence-based decision making, and roadmapping). Roles such as Opportunity Lead and Context Champions resemble strategic aspects of product management, particularly around backlog management and ensuring alignment with intent. Artifacts such as Opportunity Backlog and Roadmap further parallel product management activities. However, the content is ultimately framed around a unique 'AI adoption' system, not the explicit domain of end-to-end product management. It does not directly name 'Product Management' or use related terminology, nor does it discuss established product management methodologies or frameworks in detail. The audience and depth align partially, but most core themes are for a wider AI strategy/collaboration/innovation context rather than product management per se. Thus, fit is moderate, grounded in overlapping strategic and adaptive practices but not a primary or explicit focus.",
    "reasoning_summary": "This content partially fits Product Management through shared themes like prioritisation and evidence-based decisions, but it is fundamentally about AI adoption frameworks, not product management as a primary focus.",
    "level": "Secondary"
  },
  "Product Discovery": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Product Discovery",
    "calculated_at": "2025-09-17T23:12:26",
    "ai_confidence": 73.41,
    "ai_mentions": 2.9,
    "ai_alignment": 8.1,
    "ai_depth": 8.4,
    "ai_intent": 7.2,
    "ai_audience": 7.7,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 73.0,
    "reasoning": "The content describes a framework (Kendall Guide) for AI adoption that strongly focuses on problem identification, opportunity prioritisation, stakeholder context, and regular discovery events. These align well with product discovery principles (e.g., clarifying context, prioritizing features/opportunities, continuous feedback, collaboration). However, the term 'product discovery' is not directly referenced and the explicit techniques for user research, customer interviews, or prototyping are less evident, resulting in lower scores for direct mention and partial alignment. The main audience is practitioners and strategists engaged in AI/product adoption and organisational improvement, with clear evidence of facilitating discovery phases, feedback loops, and iterative learning. Nearly all content is relevant, with some generic systems/management lens. No penalties are applied as the content is current, positive, and fits the framing.",
    "reasoning_summary": "Content substantially matches Product Discovery through its focus on problem discovery, prioritisation, feedback cycles, and stakeholder alignment, yet does not directly mention 'product discovery' or specific research techniques. Fit is strong but not absolute.",
    "level": "Secondary"
  },
  "Mentoring": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Mentoring",
    "calculated_at": "2025-09-17T23:12:26",
    "ai_confidence": 53.89,
    "ai_mentions": 3.2,
    "ai_alignment": 6.8,
    "ai_depth": 6.4,
    "ai_intent": 6.0,
    "ai_audience": 7.3,
    "ai_signal": 6.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 54.0,
    "reasoning": "The content explicitly mentions mentoring, coaching, and accountability, especially in the Kendall Coach role, focusing on guiding teams and developing organisational learning. However, mentoring is a supporting aspect, not the dominant theme; the main focus remains on the AI adoption framework, principles, and systemic workflows. Broad audience relevance, but primary purpose isn't mentoring-centric, and depth on the mentoring process isn’t sustained throughout the text. No outdated or negative elements requiring penalties.",
    "reasoning_summary": "Mentoring and coaching are discussed via the Kendall Coach and Context Champions roles, but the overall focus is on a system for AI adoption, not mentoring itself. Fit is partial; relevant but not dominant.",
    "level": "Tertiary"
  },
  "Liberating Structures": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Liberating Structures",
    "calculated_at": "2025-09-17T23:12:26",
    "ai_confidence": 6.99,
    "ai_mentions": 0.05,
    "ai_alignment": 0.6,
    "ai_depth": 0.5,
    "ai_intent": 0.7,
    "ai_audience": 2.0,
    "ai_signal": 2.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content does not mention Liberating Structures by name or describe any of its specific facilitation techniques. While concepts like collaboration, facilitation, cadence, and feedback loops are present, these are general principles also found in many Agile frameworks. There is significant detail about roles, events, and artifacts in the context of the Kendall Framework for AI adoption, but there is no reference to using Liberating Structures or their methods (e.g., 1-2-4-All) in facilitation. The intent is related to structured collaboration, but without specifics linking it to Liberating Structures. The audience could feasibly overlap with those interested in facilitation, but the focus here is on AI adoption rather than team facilitation methods. Thus, fit is very weak.",
    "reasoning_summary": "Content does not reference or discuss Liberating Structures or their methods. Overlaps with facilitation in general, but lacks any evidence of the category's core techniques or direct intent. Fit with category is extremely weak and almost absent.",
    "level": "Ignored"
  },
  "Competence": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Competence",
    "calculated_at": "2025-09-17T23:12:26",
    "ai_confidence": 65.82,
    "ai_mentions": 3.5,
    "ai_alignment": 7.7,
    "ai_depth": 6.9,
    "ai_intent": 6.2,
    "ai_audience": 9.1,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 66.0,
    "reasoning": "Direct references to competence are minimal; terms like 'competence', 'skills', or 'capability' are not explicitly used. Conceptually, the framework touches some related elements—such as learning, improvement, coaching, and accountability—which partially align with competence as a foundational principle. Accountability roles (e.g., Coach, Opportunity Lead, Context Champion) focus on learning, guidance, and enabling feedback loops, suggesting a competence-related intent but not making it the core theme. The depth is moderate: continuous improvement, learning, empirical inspection, and adaptation are woven through the framework but mainly in the context of process effectiveness and organisational clarity rather than explicit skill or professional development. Intent matches indirectly: the content is about adaptive AI adoption frameworks and mentions mentoring and learning, but its main aim is not the systematic development or demonstration of competence. The audience is mostly practitioners, leaders, and organisations—matching the likely target for competence content. The bulk of the content is focused, with little off-topic material. No penalties for outdatedness or tone are warranted.",
    "reasoning_summary": "Content partially fits the competence category through focus on learning, coaching, and improvement, but does not center on explicit competence or professional skill development. Alignment is moderate; direct mentions are few. Fit is partial, not primary.",
    "level": "Secondary"
  },
  "Value Delivery": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Value Delivery",
    "calculated_at": "2025-09-17T23:12:31",
    "ai_confidence": 85.3,
    "ai_mentions": 6.3,
    "ai_alignment": 9.2,
    "ai_depth": 9.0,
    "ai_intent": 8.1,
    "ai_audience": 8.4,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 85.0,
    "reasoning": "The content closely aligns with 'Value Delivery' by focusing on how organisations can iteratively deliver value via AI adoption, guided by principles such as problem-first thinking, continuous improvement, collaboration, and empirical inspection/adaptation. The framework's outcomes emphasise alignment, prioritisation, and adaptive feedback loops—key topics of the category. There are explicit references to value flow, stakeholder accountability, and maintaining a purposeful, evidence-based approach. Value delivery is discussed both conceptually and with practical artifacts (backlog, roadmap, feedback loops). Audience is management and practitioners in agile/modern work. Direct category terms—'value' and 'value delivery'—are referenced, but not excessively; thus, the 'mentions' score is moderate. Depth, alignment, and intent are strong, though not every section is exclusively about value delivery per se (some is about context management and process design), which slightly tempers 'signal' and 'intent.' No penalty is needed.",
    "reasoning_summary": "Content demonstrates strong conceptual and procedural alignment with Value Delivery, emphasising adaptive, iterative, and evidence-based practices to maximise value in AI adoption. Fit is clear but not exhaustive; some parts relate to context or process.",
    "level": "Primary"
  },
  "Value Stream Management": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Value Stream Management",
    "calculated_at": "2025-09-17T23:12:32",
    "ai_confidence": 47.48,
    "ai_mentions": 1.2,
    "ai_alignment": 5.7,
    "ai_depth": 5.9,
    "ai_intent": 4.9,
    "ai_audience": 5.3,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 47.0,
    "reasoning": "The content never directly mentions 'Value Stream Management' and is focused on a framework for AI adoption. There is some conceptual overlap: the emphasis on clarity, flow of information, continuous improvement, stakeholder alignment, and minimising waste resembles VSM principles. Artifacts like backlogs, feedback loops, and adaptive roadmaps are structurally similar to VSM tools, and terms like 'flow of value' are used. However, the intent is not to discuss value stream mapping, waste elimination in end-to-end processes, or VSM frameworks—these are mentioned obliquely or only in service to AI problem-solving. The target audience (change leaders, coaches, strategists) partially overlaps with VSM, but the context is AI adoption, not enterprise value stream optimisation. The discussion is more about adopting AI systems with disciplined clarity, not managing the flow of value as a stream across the business. The signal-to-noise ratio is moderate because value flow is discussed as an attribute, not a core practice.",
    "reasoning_summary": "This content addresses AI adoption using concepts like flow, alignment, and continuous improvement, echoing aspects of Value Stream Management, but the primary focus is not VSM and direct references are absent. Partial thematic fit but not a direct category match.",
    "level": "Tertiary"
  },
  "Agentic Software Delivery": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agentic Software Delivery",
    "calculated_at": "2025-09-17T23:12:33",
    "ai_confidence": 44.0,
    "ai_mentions": 1.3,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 5.2,
    "ai_audience": 3.9,
    "ai_signal": 3.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 44.0,
    "reasoning": "The content focuses on a framework for AI adoption emphasizing context, accountability, evidence-based learning, and flow. However, it does not discuss autonomous AI agents, agentic delivery patterns, or detailed technical integration of context-aware agents in software delivery. While there is alignment in principles such as feedback loops, context, and collaboration, the content lacks explicit mention of agentic software delivery, agency in AI, or agent-human collaboration as described in the category. Audience is somewhat aligned (organizational leaders in AI and software), but not directly technical engineering teams. The level of depth in outcome focus and context is notable, but agentic themes are largely implicit.",
    "reasoning_summary": "This content aligns methodologically with some agentic delivery principles (context, feedback, adaptive learning) but lacks direct focus on AI agents, their integration, or agentic patterns in software delivery. Fit is partial and somewhat tangential.",
    "level": "Tertiary"
  },
  "Definition of Done": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Definition of Done",
    "calculated_at": "2025-09-17T23:12:32",
    "ai_confidence": 9.8,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.6,
    "ai_intent": 1.0,
    "ai_audience": 2.2,
    "ai_signal": 1.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content very briefly references accountability, artifacts, and work completion criteria, but never discusses or mentions Definition of Done (DoD), its purpose, or characteristics. The focus is on AI adoption systems, not Agile completeness standards. Team roles, quality criteria, Sprint concepts, or DoD best practices are not present. The content aligns with process discipline and outcomes but not DoD itself. No penalties were needed as there is no outdated or negative framing.",
    "reasoning_summary": "The content does not fit the 'Definition of Done' category. It addresses AI adoption frameworks, not DoD principles, criteria, or practices. There is at most a remote conceptual overlap, but no substantive or explicit DoD relevance.",
    "level": "Ignored"
  },
  "Time to Market": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Time to Market",
    "calculated_at": "2025-09-17T23:12:37",
    "ai_confidence": 24.67,
    "ai_mentions": 0.7,
    "ai_alignment": 2.5,
    "ai_depth": 3.2,
    "ai_intent": 2.5,
    "ai_audience": 6.0,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 25.0,
    "reasoning": "The content details an AI adoption system-of-work, prioritising clarity, prioritisation, learning, collaboration, and evidence. While it briefly references 'flow of value' and 'continuous improvement', it never explicitly mentions 'Time to Market' or related core metrics. The framework is oriented toward problem-first prioritisation of AI initiatives but does not specifically address the acceleration of delivery from idea to market or techniques/metrics to improve that speed. Its audience overlaps practitioners and strategists suitable for EBM, but actual alignment and depth on Time to Market are low: discussion is at the framework and process level, not about delivery speed, measurement, or reduction of time to deliver value. There is no case study, metric, or targeted strategy for Time to Market. Thus, confidence is low, despite reasonable focus and relevance of the target audience.",
    "reasoning_summary": "This content introduces an AI adoption framework focused on prioritisation, clarity, and evidence-based decision-making, but makes only passing reference to flow and does not meaningfully address Time to Market concepts or metrics. Fit is partial but mostly tangential.",
    "level": "Ignored"
  },
  "Social Technologies": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Social Technologies",
    "calculated_at": "2025-09-17T23:12:38",
    "ai_confidence": 90.83,
    "ai_mentions": 6.4,
    "ai_alignment": 9.7,
    "ai_depth": 9.3,
    "ai_intent": 9.2,
    "ai_audience": 8.5,
    "ai_signal": 8.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 91.0,
    "reasoning": "The Kendall Guide deeply discusses a framework to facilitate AI adoption in organisations by fostering collaboration, collective ownership, transparency, feedback loops, and continuous improvement—directly aligning with the core meaning of 'Social Technologies'. The content explores distributed accountabilities (Coach, Opportunity Lead, Context Champions), highly collaborative processes (events, artifacts), and empirical adaptation, promoting value delivery through structured social frameworks rather than technical tools. While it does not use the exact phrase 'social technologies' frequently, it extensively addresses the category’s focus (self-organisation, adaptability, value delivery, organisational learning). The intended audience (practitioners, organisational leaders, teams) matches the category, and the content maintains a high signal-to-noise ratio. No penalties are needed as the content is current and wholly supports the framing.",
    "reasoning_summary": "The content strongly fits 'Social Technologies': it details a collaborative, adaptive organisational framework supporting self-organisation, continuous improvement, and value delivery, with clear intent and depth matching the category definition.",
    "level": "Primary"
  },
  "System Configuration": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "System Configuration",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 19.47,
    "ai_mentions": 1.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.4,
    "ai_intent": 2.0,
    "ai_audience": 5.4,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content describes a framework for AI adoption focused on organisational decision-making, clarity, accountability, and context management. No explicit or significant focus on configuring hardware/software, automation, monitoring, or tools directly related to system configuration. While there is mention of context repositories and opportunity backlogs, these serve as organisational artefacts for prioritisation, not system-level setup or maintenance practices relevant to the category. Depth and intent do not align with practices like configuration management, integration, or maintenance discussed in the category definition.",
    "reasoning_summary": "The framework is about organisational AI adoption, not system configuration. No substantial coverage of system setup, tools, automation, or best practices relevant to system configuration. Fit is minimal and mostly indirect.",
    "level": "Ignored"
  },
  "Acceptance Test Driven Development": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Acceptance Test Driven Development",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 6.426,
    "ai_mentions": 0.2,
    "ai_alignment": 1.0,
    "ai_depth": 1.1,
    "ai_intent": 0.8,
    "ai_audience": 1.0,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The Kendall Guide content does not mention Acceptance Test Driven Development (ATDD) directly, nor does it discuss its principles, techniques, or key topics such as acceptance criteria, defining acceptance tests, or the collaborative development approach central to ATDD. The framework is focused on AI adoption, business strategy, context management, and organisational learning. While there is mention of collaboration, opportunity backlogs, and evidence-based practices, these elements are generic organisational concepts and not specific to ATDD or acceptance test design. Audience alignment is minimal, as the content targets AI strategists and organisational leaders, not practitioners or teams implementing acceptance tests. No penalties apply since the content is not outdated nor satirical. The resulting confidence score reflects the lack of explicit or conceptual fit to ATDD.",
    "reasoning_summary": "Content is entirely focused on AI adoption frameworks and organisational context, not on Acceptance Test Driven Development. No mention or substantive alignment with ATDD concepts, making category fit highly unlikely.",
    "level": "Ignored"
  },
  "Professional Scrum": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Professional Scrum",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 45.4,
    "ai_mentions": 0.3,
    "ai_alignment": 5.9,
    "ai_depth": 6.2,
    "ai_intent": 5.0,
    "ai_audience": 5.3,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 45.0,
    "reasoning": "Direct mentions of Professional Scrum are entirely absent, so the Direct Mentions score is very low. While the content shares some conceptual alignment with Professional Scrum principles—such as empiricism, accountability, evidence-based decision making, iterative improvement, clearly defined roles, and disciplined delivery—the terminology, framing, and overall application are distinct and specific to AI adoption rather than Scrum. Depth and signal are moderate because the text demonstrates rigor around professional, evidence-driven frameworks and values, paralleling (but not directly discussing) Scrum's intent. However, the primary audience, terminology, and overall context are AI and organisational transformation, not Scrum practitioners or Professional Scrum environments, so intent and audience scores are middling. The content does not contain outdated or contradictory material, so no penalties were applied. The confidence score reflects a partial, indirect fit—it is methodologically similar in parts, but does not address Professional Scrum directly or use its language.",
    "reasoning_summary": "Content expresses evidence-based, professional, and iterative principles overlapping with Professional Scrum ethos, but is focused on AI adoption—not Scrum. Fit is partial and indirect; explicit Scrum context, values, or constructs are missing.",
    "level": "Tertiary"
  },
  "Team Collaboration": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Team Collaboration",
    "calculated_at": "2025-09-17T23:12:38",
    "ai_confidence": 86.46,
    "ai_mentions": 6.2,
    "ai_alignment": 9.1,
    "ai_depth": 9.3,
    "ai_intent": 8.4,
    "ai_audience": 8.2,
    "ai_signal": 8.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 86.0,
    "reasoning": "The content repeatedly highlights collaboration, collective ownership, and cross-team alignment—core to Team Collaboration. Sections on accountabilities, events, and artifacts (e.g., Opportunity Backlogs and Context Champions) reveal substantial depth in structuring collaborative practices. The intent is to enable and support effective teamwork in AI adoption, targeting practitioners and leaders in Agile/DevOps contexts. Explicit references to shared understanding, feedback loops, alignment, and coaching further strengthen conceptual fit. While 'Team Collaboration' is not named verbatim, all relevant themes are well addressed and the framework builds on the enhancement of collaboration within teams and across disciplines. No penalties apply; content is recent, positive, and methodologically aligned.",
    "reasoning_summary": "Collaboration and shared ownership are central throughout the framework, with deep discussion of collaborative roles, events, and artifacts relevant to Agile/DevOps. The content strongly aligns with Team Collaboration despite not always using the term.",
    "level": "Primary"
  },
  "Team Performance": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Team Performance",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 76.83,
    "ai_mentions": 4.3,
    "ai_alignment": 8.5,
    "ai_depth": 8.4,
    "ai_intent": 7.1,
    "ai_audience": 7.3,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 77.0,
    "reasoning": "The Kendall Guide discusses a system of work focused on AI adoption at the organisational and team levels, with notable emphasis on roles (Kendall Coach, Opportunity Lead, Context Champions), systemic constraints, alignment, and feedback loops. The guide covers system-level accountabilities, structures, rhythms, empiricism, impediment handling, and improvement patterns, all of which align well with team performance themes such as delivery systems, throughput, learning, and adaptation. However, its primary framing revolves around AI adoption strategy rather than solely focusing on team delivery capability, and performance metrics or in-depth delivery analytics are not the centerpiece. Some content is also directed at organizational leaders and cross-team alignment, making audience and intent only partially team-focused. Mentions of team performance in the explicit sense are limited.",
    "reasoning_summary": "Strong alignment with team-system themes (roles, flow, feedback) and factors impacting team effectiveness, but content is AI adoption-centric. Team performance is covered incidentally, so the fit is substantial but not direct or primary.",
    "level": "Secondary"
  },
  "Increment": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Increment",
    "calculated_at": "2025-09-17T23:12:22",
    "ai_confidence": 21.69,
    "ai_mentions": 0.6,
    "ai_alignment": 2.3,
    "ai_depth": 2.2,
    "ai_intent": 2.7,
    "ai_audience": 5.0,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 22.0,
    "reasoning": "The content describes the Kendall Guide—a system for AI adoption focusing on organizational alignment, problem solving, and adaptive processes. Although it uses terms like 'iteration,' 'cadence,' and 'feedback loops,' it makes no direct reference to Increment as the tangible, usable output at the end of an iteration as defined in Agile or Scrum. Artifacts discussed (Opportunity Backlog, Context Repository, Roadmap) facilitate clarity and prioritization but are not working software increments. No discussion explores value delivery via potentially releasable working software or the specific role of the Increment within Scrum. The intent is to provide a guiding framework for adopting AI, not to operationalize or discuss Increment in the Scrum sense. Audience alignment is moderate: while practitioners may overlap, the focus is on organizational workflows, not software iteration. There is no significant outdatedness or contradiction present.",
    "reasoning_summary": "Content describes an AI adoption framework focusing on opportunities, context, and workflows—not Increments as working software. Lacks discussion of Increment delivery or its Scrum/Agile role. Weak and indirect fit to the Increment category.",
    "level": "Ignored"
  },
  "Change Management": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Change Management",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 73.38,
    "ai_mentions": 3.3,
    "ai_alignment": 8.2,
    "ai_depth": 7.6,
    "ai_intent": 7.2,
    "ai_audience": 8.1,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 73.0,
    "reasoning": "Direct references to 'change management' are absent ('mentions' low), but the Kendall Guide robustly aligns with core change management concepts in Agile: focus on adaptive learning, stakeholder engagement, leadership accountabilities, evidence-based adaptation, and organisational alignment. Depth is substantial due to detailed discussion on roles, artifacts, and events supporting transition and continuous improvement. The primary intent is to support meaningful AI adoption within organisations—closely tied to process and mindset change, but not exclusively about the mechanics of change management itself. The target audience (org leaders, team coaches, execs, strategists) is well-aligned. Most content is concentrated on transition strategies and stakeholder roles versus pure AI tech. Overall, this is a strong partial fit: high on alignment/depth/intent, but with only implicit, not explicit, category references.",
    "reasoning_summary": "Content aligns deeply with change management principles in Agile contexts (roles, adaptive cycles, stakeholder focus) but lacks direct mentions and is framed around AI adoption, not change management per se; a strong, but indirect, fit.",
    "level": "Secondary"
  },
  "Asynchronous Development": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Asynchronous Development",
    "calculated_at": "2025-09-17T23:12:28",
    "ai_confidence": 16.09,
    "ai_mentions": 0.7,
    "ai_alignment": 2.2,
    "ai_depth": 2.1,
    "ai_intent": 1.8,
    "ai_audience": 5.0,
    "ai_signal": 4.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "The Kendall Guide focuses on AI adoption, structured collaboration, and evidence-based decision-making, but does not discuss asynchronous development principles, distributed teams, or asynchronous collaboration tools/practices. While there is mention of flow, cadence, and events, these refer to strategic/operational cycles (e.g., quarterly reviews) rather than asynchronous team interaction. There are no direct or explicit references to asynchronous work, tools enabling it, or challenges particular to asynchronous development. The audience might conceptually overlap (tech teams or strategists) but the core topic is not aligned.",
    "reasoning_summary": "This content centers on AI adoption frameworks and collaboration but lacks discussion of asynchronous development or distributed team practices; fit with the category is minimal and mostly incidental.",
    "level": "Ignored"
  },
  "Employee Engagement": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Employee Engagement",
    "calculated_at": "2025-09-17T23:12:28",
    "ai_confidence": 35.14,
    "ai_mentions": 0.5,
    "ai_alignment": 4.2,
    "ai_depth": 4.4,
    "ai_intent": 4.1,
    "ai_audience": 4.8,
    "ai_signal": 3.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 35.0,
    "reasoning": "The Kendall Guide focuses on AI adoption frameworks, prioritization, context, and adaptive collaboration. While there are ideas like collaboration, context champions, and feedback loops, these are presented as components of efficient organizational process and AI implementation, not as strategies specifically intended to address or enhance employee engagement, motivation, or commitment. There is little direct or indirect discussion of concepts like motivation, recognition, reward, satisfaction, or psychological drivers of engagement. The audience is organizational practitioners but more concerned with system/process optimization than human engagement aspects. Minimal surface alignment is noted where facilitation, coaching, and cross-team alignment are discussed, but these are not explored at the depth or intent required for this category.",
    "reasoning_summary": "Content addresses collaboration and feedback in AI adoption, but does not focus on employee motivation or engagement. Human aspects are byproducts, not core themes. Misalignment with Employee Engagement is clear; fit is tangential and shallow.",
    "level": "Ignored"
  },
  "Trend Analysis": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Trend Analysis",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 39.85,
    "ai_mentions": 1.2,
    "ai_alignment": 4.3,
    "ai_depth": 3.7,
    "ai_intent": 5.0,
    "ai_audience": 5.2,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 40.0,
    "reasoning": "The content provides a thorough practical system for AI adoption focused on problem-first principles, context, evidence, and structured decision-making. However, while it explores adaptive practices and periodic review, it lacks direct discussion or case analysis of trends, trend identification, or analysis of shifts within Agile, DevOps, or business agility. The framework's focus is on framework-driven adoption and alignment, not on analyzing industry or process trends. There are indirect overlaps, such as themes of feedback, adaptation, and learning, but without specific attention to trend monitoring or analysis techniques relevant to the category definition. No penalties; the content is current and does not contradict the framing.",
    "reasoning_summary": "Though adaptive and evidence-based, the content does not directly analyze trends in Agile, DevOps, or business agility. Fit is partial at best: themes overlap but trend analysis per se is not discussed.",
    "level": "Ignored"
  },
  "Continuous Improvement": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Continuous Improvement",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 86.08,
    "ai_mentions": 7.3,
    "ai_alignment": 9.2,
    "ai_depth": 8.8,
    "ai_intent": 8.1,
    "ai_audience": 8.0,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 86.0,
    "reasoning": "The content repeatedly references key practices of Continuous Improvement such as empirical inspection, feedback loops, inspect-and-adapt cycles, and learning orientation. One of the core principles is explicitly labeled 'Continuous Improvement.' The framework applies iterative, evidence-based adaptation to AI adoption, emphasizing organizational learning, reflection, and adaptation at regular cadences—strongly matching the category definition. There is substantial depth in describing both philosophy and practical mechanisms (roles, events, artifacts) supporting continuous, incremental progress. Audience and intent align with practitioners and decision-makers interested in adaptive, evidence-based approaches. Minor deductions are unnecessary; the content is current and positive about the topic.",
    "reasoning_summary": "The Kendall Guide deeply integrates continuous improvement through explicit principles, iterative cadences, and feedback loops, consistently aligning in intent, audience, and focus with the category definition.",
    "level": "Primary"
  },
  "Deployment Strategies": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Deployment Strategies",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 13.33,
    "ai_mentions": 1.0,
    "ai_alignment": 2.2,
    "ai_depth": 2.8,
    "ai_intent": 1.7,
    "ai_audience": 2.1,
    "ai_signal": 2.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content does not explicitly discuss deployment methodologies or the transition of software into production. Its central focus is AI adoption strategy, prioritisation, stakeholder roles, and context management, rather than deployment techniques like blue-green deployments, canary releases, or continuous deployment. Terminology and intent are not related to software deployment risk management, rollout models, or infrastructure automation. The themes target AI adoption and organisational change rather than practitioners looking for effective deployment strategies. Only tangential artifacts like 'Roadmap' appear, but not in a deployment context.",
    "reasoning_summary": "Content focuses on AI adoption and organisational strategy, not on software deployment methodologies. Core topics like blue-green, canary, or rolling updates are absent. Minimal to no fit with 'Deployment Strategies'.",
    "level": "Ignored"
  },
  "Framework": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Framework",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 93.17,
    "ai_mentions": 9.4,
    "ai_alignment": 9.7,
    "ai_depth": 9.3,
    "ai_intent": 9.1,
    "ai_audience": 9.4,
    "ai_signal": 9.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 93.0,
    "reasoning": "The content explicitly and repeatedly refers to the Kendall Framework as a structured methodology for AI adoption. It covers its definition, principles, application, accountabilities, events, artifacts, and summary—going beyond basic description to present an actionable, flexible system and integration possibilities. All core framework topics are present: purpose, implementation, accountabilities, practices, adaptation, and events. The audience (organizations, teams) and the intent (practical guidance for structured improvement/adoption) clearly match the category. No off-topic material, criticism, or outdatedness is present. No dimension merited a penalty as the piece is current, practical, and tightly focused. High confidence is justified.",
    "reasoning_summary": "This content thoroughly explains the Kendall Framework as a structured, adaptive system for AI adoption. It is fully aligned with the Framework category, covering principles, application, roles, and events. The fit is clear, direct, and confident.",
    "level": "Primary"
  },
  "Evidence Based Management": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Evidence Based Management",
    "calculated_at": "2025-09-17T23:12:32",
    "ai_confidence": 76.34,
    "ai_mentions": 6.7,
    "ai_alignment": 8.3,
    "ai_depth": 7.7,
    "ai_intent": 8.0,
    "ai_audience": 7.2,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 76.0,
    "reasoning": "The content frequently references evidence-based, empirical, and outcome/prioritization concepts (e.g., 'empirical inspection and adaptation,' 'evidence-informed prioritisation,' 'evidence review of outcomes'), showing strong alignment. It promotes cycles of inspect/adapt and includes feedback loops, roadmaps, and measurable prioritization, which maps directly to EBM practices (empirical decision-making, outcome management, etc). While there are no direct references to key EBM metrics (Current Value, Time to Market, etc.), the guide does stay focused on using evidence and feedback to inform management and decision-making in AI adoption. The discussion is deep, especially on system flow, continuous improvement, and alignment of opportunities with evidence and learning, and is targeted to organizational/leadership roles that match the EBM audience. No notable penalty factors: the tone, concepts, and relevance are contemporary and aligned.",
    "reasoning_summary": "Content is strongly aligned with Evidence-Based Management via emphasis on empirical decision-making, feedback loops, adaptive strategy, and evidence-driven prioritisation, but lacks explicit use of standard EBM metrics or direct EBM framework titles. Fit is substantial but not exhaustive.",
    "level": "Secondary"
  },
  "Entrepreneurship": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Entrepreneurship",
    "calculated_at": "2025-09-17T23:12:43",
    "ai_confidence": 51.06,
    "ai_mentions": 2.3,
    "ai_alignment": 5.4,
    "ai_depth": 5.6,
    "ai_intent": 5.2,
    "ai_audience": 7.5,
    "ai_signal": 6.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 51.0,
    "reasoning": "Direct mentions of entrepreneurship are minimal; it's briefly included as one of many intended audiences. The framework's core is about AI adoption processes in organizations—problem-first orientation, value delivery, and adaptive learning—paralleling qualities like innovation, risk-taking, and value-creation, but rarely links them to entrepreneurship specifically. There is moderate conceptual overlap with principles relevant to entrepreneurs (e.g., identifying opportunities, stakeholder accountability, and iterative adaptation). However, most discussion is organizational, not explicitly about starting/sustaining new businesses or entrepreneurial ecosystems. The audience fit is partial since entrepreneurs are listed but not directly targeted. No dimension is strongly met; surface-level fit is present but lacks depth or focus on entrepreneurial process itself.",
    "reasoning_summary": "Content is tangentially relevant to entrepreneurship through value, opportunity, and adaptation themes, but mainly targets broader AI adoption in organizations. Entrepreneurship is not its core focus; fit is partial and not deeply developed.",
    "level": "Tertiary"
  },
  "Technical Debt": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Technical Debt",
    "calculated_at": "2025-09-17T23:12:34",
    "ai_confidence": 10.19,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.25,
    "ai_intent": 0.7,
    "ai_audience": 4.1,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content does not mention technical debt or related concepts. It focuses on AI adoption, frameworks for problem-solving, and organisational context and collaboration. There are no discussions on code maintenance, debt trade-offs, or remediation strategies.",
    "reasoning_summary": "This content is not about technical debt. Its topic, themes, and intent focus on AI adoption frameworks and organisational strategy, lacking any direct or indirect relevance to technical debt.",
    "level": "Ignored"
  },
  "Organisational Change": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Organisational Change",
    "calculated_at": "2025-09-17T23:12:35",
    "ai_confidence": 83.99,
    "ai_mentions": 6.3,
    "ai_alignment": 8.1,
    "ai_depth": 8.7,
    "ai_intent": 8.2,
    "ai_audience": 7.8,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 84.0,
    "reasoning": "The content does not directly name 'organisational change' but closely describes a framework for changing how organisations adopt AI with strong alignment to change management principles: adaptive learning, leadership accountabilities, feedback loops, and organisational learning. It discusses roles and events for aligning teams, prioritising opportunities, integrating evidence-based practices, and fostering a culture of adaptation and collaboration. The depth and breadth are strong, with process descriptions, responsibilities, and cultural aspects included. The intent is clearly to guide org-wide change in the way AI is adopted and operationalised. While primarily targeting strategists, executives, and transformation leads, its coverage is slightly more geared toward practitioners involved in the change process, rather than only C-level leadership. Some room for a more explicit tie-in to classic change frameworks (ADKAR, Kotter) or resistance management, and more direct use of 'organisational change' language keeps this just short of the highest mark.",
    "reasoning_summary": "This framework thoroughly guides AI adoption as an organisational change process. It strongly fits the category via focus on adaptive learning, roles, feedback, and evidence. This is a high-confidence but not perfect match due to less explicit mention.",
    "level": "Primary"
  },
  "Agile Product Management": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agile Product Management",
    "calculated_at": "2025-09-17T23:12:43",
    "ai_confidence": 75.16,
    "ai_mentions": 2.8,
    "ai_alignment": 8.3,
    "ai_depth": 7.7,
    "ai_intent": 7.1,
    "ai_audience": 7.6,
    "ai_signal": 6.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 75.0,
    "reasoning": "Direct references to Agile Product Management are absent; the term is never named and Agile is only loosely alluded to through concepts like iteration, backlogs, prioritization, evidence-based adaptation, and stakeholder alignment. However, many framework elements—like the Opportunity Backlog, Roadmap, feedback loops, metrics-driven adaptation, and collaborative events—reflect strong conceptual and procedural alignment with Agile Product Management, even though framed around AI adoption. Roles such as 'Opportunity Lead' and 'Context Champion' fulfill analogous functions to a Product Owner and supporting product team. The discussion of stakeholder engagement, incremental learning, and continuous improvement further reinforce fit. The audience (change leaders, coaches, teams adopting AI) parallels Agile product leaders, but the explicit focus is AI, not general product management. Depth is substantial, discussing processes, roles, key events, and artifacts in detail with a recurring emphasis on value delivery and adaptability. Signal remains high, but a minority of the piece is general framework philosophy or background. No evidence of outdatedness or contradicting the category; all practices described are current and adaptive. Penalties are not applied due to tone, date, or content conflicts. Overall, while not core Agile Product Management per se, this guide meaningfully overlaps by importing Agile product strategies into the AI adoption context.",
    "reasoning_summary": "Content aligns well with Agile Product Management principles (prioritization, feedback, value, roles), though focused on AI adoption. Concepts, depth, and intent match the category, despite low direct mention. Overall, it is a strong but slightly tangential fit.",
    "level": "Secondary"
  },
  "Market Adaptability": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Market Adaptability",
    "calculated_at": "2025-09-17T23:12:36",
    "ai_confidence": 81.687,
    "ai_mentions": 5.3,
    "ai_alignment": 8.5,
    "ai_depth": 7.8,
    "ai_intent": 8.2,
    "ai_audience": 8.0,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 82.0,
    "reasoning": "The Kendall Guide introduces a structured framework for AI adoption emphasizing adaptability, continuous improvement, collaboration, feedback loops, and alignment of opportunities to strategic context. While 'market adaptability' is not directly mentioned, the core principles—problem-first thinking, flow, empirical inspection, feedback, and resilience—align conceptually. The guide lays out deep, practice-oriented mechanisms (cadences, roles, backlogs) for organisational responsiveness, echoing Agile/Lean values. It is targeted at organisations and practitioners seeking adaptive, evidence-based AI implementation. There is a strong focus on adaptation, learning, and continuous feedback. However, market responsiveness—in terms of explicit competitive pressure, market shifts, or customer focus—is only implicit, not foregrounded, keeping the depth and mentions scores just below top marks. No outdated material or contradictory tone identified.",
    "reasoning_summary": "Content aligns well with Market Adaptability, focusing on adaptive structures, feedback, and continuous improvement for AI adoption, though explicit connections to market shifts or competition are implicit rather than direct.",
    "level": "Primary"
  },
  "Personal": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Personal",
    "calculated_at": "2025-09-17T23:12:37",
    "ai_confidence": 13.576,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 1.9,
    "ai_intent": 2.3,
    "ai_audience": 4.5,
    "ai_signal": 4.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content explains a practical, organisation-wide framework (the Kendall Guide) for AI adoption. It offers procedural guidance, defines roles, and describes organisational practices and artifacts. There are no personal stories, anecdotes, or subjective insights from individuals—neither reflections by the author nor first-person perspectives. All discussions are framed at the organisational and framework/application level. Occasional attribution (e.g., references to Drucker or 'Nigel’s lens') are theoretical/philosophical and not personal experiences. The intended audience is professionals implementing AI, not individuals sharing personal journeys relating to Agile, Scrum, or similar themes.",
    "reasoning_summary": "The content is organisational and procedural, providing no personal experiences or reflections. It lacks subjective or anecdotal discussion; thus, it only marginally fits the 'Personal' category.",
    "level": "Ignored"
  },
  "Hypothesis Driven Development": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Hypothesis Driven Development",
    "calculated_at": "2025-09-17T23:12:45",
    "ai_confidence": 54.8,
    "ai_mentions": 0.7,
    "ai_alignment": 6.5,
    "ai_depth": 6.8,
    "ai_intent": 7.2,
    "ai_audience": 8.1,
    "ai_signal": 7.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content never directly mentions 'hypothesis' or the specific language of Hypothesis Driven Development, resulting in a very low 'mentions' score. However, it shows partial conceptual overlap: principles like 'evidence-based decision-making', 'empirical inspection and adaptation', and 'feedback loops' echo parts of hypothesis-driven work. Importantly, the framework does not clearly discuss formulating falsifiable hypotheses, running product experiments, or metrics/KPIs as described in the category. Instead, it focuses more on prioritisation, context definition, and alignment, with adaptation cycles informed by evidence but not explicit experimentation. The 'depth' and 'intent' scores reflect the partial but indirect relevance—the framework supports some foundational thinking found in hypothesis-driven development (like learning cycles), but does not make experimentation or hypothesis testing explicit nor central. Audience and signal scores are higher as it targets change agents and practitioners in evidence-based AI work, with minimal off-topic information, but the central theme remains framework adoption and alignment over strict experimentation.",
    "reasoning_summary": "The content supports evidence-based decision-making and adaptive learning, loosely resembling hypothesis-driven development. However, it lacks explicit mention of hypotheses or experimentation, so fit with the category is moderate but indirect.",
    "level": "Tertiary"
  },
  "Complexity Thinking": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Complexity Thinking",
    "calculated_at": "2025-09-17T23:12:40",
    "ai_confidence": 42.422,
    "ai_mentions": 1.1,
    "ai_alignment": 4.7,
    "ai_depth": 5.1,
    "ai_intent": 4.3,
    "ai_audience": 6.5,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The Kendall Guide references systems thinking, flow, feedback loops, and adaptation, all adjacent to complexity principles, but never directly mentions complexity science, Cynefin, or Stacey. Alignment and depth are modest: the framework promotes adaptivity and iterative learning, which are compatible with complexity thinking, but it avoids explicit references to emergence, non-linearity, or complexity frameworks. Discussion remains at the organisational method level, emphasizing clarity, context, and evidence-based practices for AI, but doesn't explore non-linear, emergent behaviours or explicitly tie its practices to complexity science. Audience fit is solid, as it targets strategists and practitioners interested in adaptation and flow. Overall, the fit is partial—with mild conceptual similarities but lacking direct discussion or terminology from complexity thinking. No penalties apply.",
    "reasoning_summary": "The content aligns with adaptive, flow- and feedback-based practices but lacks explicit reference to complexity thinking, frameworks, or theory. Connection is partial and implicit; it's not a direct or deep fit for 'Complexity Thinking'.",
    "level": "Tertiary"
  },
  "Cell Structure Design": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Cell Structure Design",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 16.983,
    "ai_mentions": 0.4,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.1,
    "ai_audience": 5.7,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 17.0,
    "reasoning": "The content comprehensively presents the Kendall Framework for AI adoption, focused on principles of clarity, adaptability, and accountability. There is no direct mention of Cell Structure Design, Niels Pfläging, Beta Codex, nor core concepts like autonomous cells or decentralisation. While there are thematic overlaps around distributed accountabilities and adaptive learning, these are implemented within traditional framework and role boundaries, without reference to network-based, cell-like organisational design. The depth relates strongly to the Kendall Framework itself; any overlap with Cell Structure Design is coincidental and not explicit or intentional. Audience (leaders, teams, coaches) slightly aligns with strategic change, hence the higher audience/signal scores, but the topic remains outside Cell Structure Design.",
    "reasoning_summary": "This content does not address Cell Structure Design. It details a framework for AI adoption with only superficial thematic parallels to decentralised work. No direct or implicit focus on Beta Codex, cells, or networked organisational structure.",
    "level": "Ignored"
  },
  "Common Goals": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Common Goals",
    "calculated_at": "2025-09-17T23:12:48",
    "ai_confidence": 83.382,
    "ai_mentions": 6.6,
    "ai_alignment": 8.9,
    "ai_depth": 8.7,
    "ai_intent": 7.7,
    "ai_audience": 8.2,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 83.0,
    "reasoning": "The Kendall Guide discusses alignment, shared purpose, collaboration, and structured goal-setting within organisational AI adoption. It strongly aligns with the spirit of 'Common Goals'—purpose, objectives, accountability, and alignment are recurring themes. While the term 'Common Goals' is not directly mentioned, the guide's focus on aligning opportunities, context, and objectives with overall strategy—alongside accountability roles and shared events—maps directly to the category's core. Depth is high: it provides specific mechanisms (Opportunity Backlog, Sourcing Events) for maintaining strategic alignment. Audience is leaders and practitioners in frameworks akin to Agile/DevOps. Signal-to-noise is strong; minor deductions as not all elements are literally goal-definition, but all reinforce alignment. No penalties for outdatedness; content is current and supportive.",
    "reasoning_summary": "Content thoroughly covers principles and practices that align teams to shared objectives and outcomes, mapping well to the 'Common Goals' category even if terms aren't explicit. Themes of alignment, accountability, and strategic intent are strong and clear.",
    "level": "Primary"
  },
  "Business Agility": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Business Agility",
    "calculated_at": "2025-09-17T23:12:44",
    "ai_confidence": 82.799,
    "ai_mentions": 4.8,
    "ai_alignment": 9.6,
    "ai_depth": 9.3,
    "ai_intent": 8.7,
    "ai_audience": 8.2,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 83.0,
    "reasoning": "The content focuses on a framework for AI adoption grounded in adaptive, evidence-based, iterative, and collaborative practices—core tenets of business agility. It covers empirical inspect-adapt cycles, learning, opportunity alignment, and leadership roles like coaching and context management. Themes of purpose-driven adaptation, responsive prioritization, value delivery, and continuous improvement closely align with business agility principles. While 'business agility' isn't explicitly named, the discussion thoroughly explores relevant concepts, such as alignment with objectives, resilience, team collaboration, and feedback loops. The target audience (organizational leaders, teams) matches business agility stakeholders. Most material directly supports the definition, though primary focus is on AI adoption rather than agility in broad organizational contexts, so a few points are docked for scope. No outdated or critical tone identified.",
    "reasoning_summary": "Content strongly aligns with business agility through its focus on adaptive, evidence-based AI adoption, organizational learning, and team collaboration. Fit is high—core themes match the category definition, though explicit use of the term is minimal.",
    "level": "Primary"
  },
  "Application Lifecycle Management": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Application Lifecycle Management",
    "calculated_at": "2025-09-17T23:12:41",
    "ai_confidence": 37.54,
    "ai_mentions": 0.4,
    "ai_alignment": 3.2,
    "ai_depth": 3.5,
    "ai_intent": 3.3,
    "ai_audience": 4.8,
    "ai_signal": 5.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The Kendall Guide focuses on AI adoption, prioritization, and decision-making frameworks within organizations but does not reference or detail application lifecycle stages, application maintenance, ALM tools, or governance practices directly tied to Application Lifecycle Management. While there are surface similarities (structured artifacts, roles, events, iterative feedback), they serve the AI opportunity discovery/adoption process—not the full management of software application lifecycles per the category definition. The depth and concepts around context, backlogs, and roadmaps are closer to strategic AI initiative management rather than end-to-end application lifecycle management. Audience overlap exists (leaders, practitioners), but key ALM topics (deployment, maintenance, retirement, ALM metrics, compliance) are missing. No penalties for outdated content or tone.",
    "reasoning_summary": "Content centers on AI adoption and opportunity management, not ALM. Lacks explicit discussion of the application lifecycle, governance, or tools for managing software from inception to retirement. Only a partial, surface-level overlap exists.",
    "level": "Ignored"
  },
  "Troubleshooting": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Troubleshooting",
    "calculated_at": "2025-09-17T23:12:42",
    "ai_confidence": 29.67,
    "ai_mentions": 0.5,
    "ai_alignment": 2.7,
    "ai_depth": 3.1,
    "ai_intent": 3.9,
    "ai_audience": 6.0,
    "ai_signal": 5.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 30.0,
    "reasoning": "Direct mentions of 'troubleshooting' or related terminology are virtually absent. The framework is aimed at AI adoption and organisational alignment, placing its themes in problem identification, prioritisation, and process improvement. While issues, impediments, and blockers are briefly referenced, there is no sustained discussion on diagnosing or resolving technical faults, bugs, or system failures. The practical focus is on structuring opportunities and learning cycles, not on stepwise resolution of malfunctions. The audience is technical and managerial, matching the category partially. Overall, troubleshooting is at best a minor, tangential theme, rather than a direct or sustained topic. No penalty adjustments apply as the text is current and not contrary in tone.",
    "reasoning_summary": "The content primarily discusses an AI adoption framework, not troubleshooting. While it occasionally mentions impediments and blockers, it lacks direct or in-depth focus on identifying or resolving technical issues. Only a loose, partial fit to the category.",
    "level": "Ignored"
  },
  "Scaling": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Scaling",
    "calculated_at": "2025-09-17T23:12:48",
    "ai_confidence": 34.95,
    "ai_mentions": 1.4,
    "ai_alignment": 3.9,
    "ai_depth": 4.6,
    "ai_intent": 3.7,
    "ai_audience": 5.2,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 35.0,
    "reasoning": "The Kendall Guide focuses on structured AI adoption, prioritisation, and adaptive learning at the organisational level but lacks explicit or consistent references to scaling frameworks or the coordination of multiple teams. While there are some cross-team alignment and role-defining elements (e.g., Opportunity Lead, Kendall Coach) and references to flow, inspection, adaptation, and feedback loops, the content primarily aims to onboard and guide organisations in adopting AI effectively—not to address the complexities of scaling agile or DevOps across teams. There are no direct mentions of scaling frameworks (e.g., SAFe, LeSS) or specific strategies for managing dependencies or integration among multiple teams, and the discussion of alignment and structure is generic and does not substantively address scaling. Audience is partially aligned (practitioners and leaders), and signal relates loosely to optimising flow, but little is discussed about scaling complexity, cross-team coordination mechanisms, or metrics for delivery at scale.",
    "reasoning_summary": "The content focuses on organisational AI adoption with elements of flow and alignment but lacks substantive discussion on methodologies or frameworks for scaling agile practices. Only a partial and indirect fit with the scaling category.",
    "level": "Ignored"
  },
  "Modern Source Control": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Modern Source Control",
    "calculated_at": "2025-09-17T23:12:48",
    "ai_confidence": 2.91,
    "ai_mentions": 0.3,
    "ai_alignment": 1.2,
    "ai_depth": 2.1,
    "ai_intent": 3.0,
    "ai_audience": 4.0,
    "ai_signal": 3.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content is focused on a framework for AI adoption, emphasizing problem-first thinking, context, collaboration, and evidence-based improvement. None of the key topics of Modern Source Control—such as version control systems, branching strategies, or code review—are mentioned directly or conceptually. While the ideas of collaboration, backlog, and artifacts appear, these are used in the context of AI opportunity management, not code or source control. The primary audience and purpose do not align; practitioners of version control would not find relevant guidance here, as tool, workflow, or system references are absent. Any overlap is minimal and incidental.",
    "reasoning_summary": "The content does not address Modern Source Control. Its focus is on AI adoption methodologies, not version control, collaboration workflows, or technical practices related to source control. The fit is minimal and indirect.",
    "level": "Ignored"
  },
  "Evidence Based Leadership": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Evidence Based Leadership",
    "calculated_at": "2025-09-17T23:12:24",
    "ai_confidence": 87.67,
    "ai_mentions": 7.3,
    "ai_alignment": 9.4,
    "ai_depth": 8.9,
    "ai_intent": 8.1,
    "ai_audience": 8.4,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 88.0,
    "reasoning": "The content explicitly references evidence-based, empirical, and adaptive decision-making throughout. Framework roles (Coach, Opportunity Lead) focus on aligning decisions to empirical review cycles, KPIs, and feedback loops are mentioned in events and artifacts, and terms like 'empirical inspection and adaptation' recur. The main purpose is to improve leadership and collaboration using structured, evidence-backed processes. The audience (leaders and organisations adopting AI) matches the category. Discussion is detailed on how evidence, feedback loops, and structured inspection connect to leadership choices. No outdated or critical tone. Partial overlap exists with Agile/system thinking, but the primary frame is evidence-based leadership in AI adoption.",
    "reasoning_summary": "Strong match: The content centers on frameworks, roles, events, and artifacts enabling empirical, evidence-based leadership decisions in AI adoption, with clear feedback loops and structured learning. Minor overlap with Agile/system approaches but category fit predominates.",
    "level": "Primary"
  },
  "Portfolio Management": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Portfolio Management",
    "calculated_at": "2025-09-17T23:12:25",
    "ai_confidence": 77.62,
    "ai_mentions": 2.8,
    "ai_alignment": 8.7,
    "ai_depth": 7.9,
    "ai_intent": 8.1,
    "ai_audience": 7.6,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 78.0,
    "reasoning": "The content provides a detailed framework for AI adoption prioritising strategic alignment, context, flow, and empirical improvement. It features explicit mechanisms (e.g., Opportunity Backlog, Roadmap, prioritisation, alignment of initiatives) that largely map to portfolio management in an AI context. The audience includes organisational leaders, strategists, and those responsible for aligning AI initiatives to business goals. There is no explicit or frequent mention of 'portfolio management' as a term, thus the score is low for direct mentions, but the Opportunity Backlog and Roadmap closely mirror portfolio-level practices. The depth of discussion around alignment, prioritisation, feedback cadences, and strategic intent is substantial. The content is focused with little extraneous information, but the primary focus is AI adoption, not universal portfolio management, so minor reservations remain around depth and audience fit.",
    "reasoning_summary": "Strong fit: Framework describes prioritisation, alignment, and adaptive oversight of multiple AI initiatives—core to portfolio management—even without explicit labeling. Focus is AI portfolios; depth and intent closely match the category.",
    "level": "Secondary"
  },
  "Platform Engineering": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Platform Engineering",
    "calculated_at": "2025-09-17T23:12:24",
    "ai_confidence": 17.691,
    "ai_mentions": 0.2,
    "ai_alignment": 2.7,
    "ai_depth": 2.5,
    "ai_intent": 3.2,
    "ai_audience": 4.3,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "Direct mentions of platform engineering or its key terms (IDP, internal platforms, self-service) are absent. The content focuses exclusively on a framework for AI adoption, its events, roles, and artifacts, not on enabling developer platforms or standardising delivery tooling. Conceptually, the framework emphasises clarity, collaboration, and continuous improvement—ideas adjacent to platform engineering—but their application is for guiding organisational AI adoption/decision-making, not designing or operating developer-centric platforms. The intended audience includes decision-makers and teams adopting AI, not platform engineers. While some overlap exists in fostering structure and flow, themes such as automation, internal developer platforms, and technical enablement are missing. Therefore, fit for the Platform Engineering category is weak and incidental.",
    "reasoning_summary": "The content is about an AI adoption framework, not platform engineering. No direct mentions or substantial conceptual links to internal platforms, IDPs, or developer enablement. Alignment with platform engineering is weak and largely incidental.",
    "level": "Ignored"
  },
  "Continuous Delivery": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Continuous Delivery",
    "calculated_at": "2025-09-17T23:12:24",
    "ai_confidence": 18.76,
    "ai_mentions": 0.3,
    "ai_alignment": 2.1,
    "ai_depth": 2.6,
    "ai_intent": 1.9,
    "ai_audience": 6.2,
    "ai_signal": 3.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "This content centers on an AI adoption framework, focusing on prioritisation, context, collaboration, and evidence-based adaptation. While it emphasizes iterative learning and adaptive planning, it does not discuss Continuous Delivery principles, automation, or software release cycles. There are no explicit or substantive references to building or deploying software in short, reliable cycles, nor do the artifacts or events described correspond to continuous integration or delivery pipelines. The iterative and feedback themes weakly align to CD values, but the main focus is AI program governance, not software delivery practice.",
    "reasoning_summary": "Content focuses on AI adoption strategy and evidence-based prioritization, with only incidental overlap (e.g., adaptive iteration) to Continuous Delivery. Core delivery principles, automation, and deployment are not present. Fit is minimal.",
    "level": "Ignored"
  },
  "Sprint Review": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Sprint Review",
    "calculated_at": "2025-09-17T23:12:24",
    "ai_confidence": 3.97,
    "ai_mentions": 0.2,
    "ai_alignment": 1.4,
    "ai_depth": 2.6,
    "ai_intent": 1.6,
    "ai_audience": 6.2,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 4.0,
    "reasoning": "The content describes the Kendall Guide for AI adoption, focusing on principles, roles, events, and artifacts unique to that framework. There is no mention of Scrum, sprints, or the Sprint Review. No events or artifacts map to or are analogous with the Sprint Review or its practices. Although it mentions review cycles, feedback, and inspection and adaptation in general terms, these are not framed within Scrum, and do not align with the Sprint Review event as defined. The audience overlaps with Agile/leadership practitioners, but nothing in the content targets Sprint Review participants or objectives.",
    "reasoning_summary": "The Kendall Guide discusses an AI adoption framework, not Sprint Reviews. No Scrum topics, events, or roles are mentioned, so fit is very weak. Only superficial overlap in concepts like review cycles or feedback exists, making fit partial and unclear.",
    "level": "Ignored"
  },
  "Organisational Psychology": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Organisational Psychology",
    "calculated_at": "2025-09-17T23:12:30",
    "ai_confidence": 51.27,
    "ai_mentions": 1.2,
    "ai_alignment": 6.9,
    "ai_depth": 5.7,
    "ai_intent": 6.2,
    "ai_audience": 7.1,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 51.0,
    "reasoning": "The Kendall Guide focuses on enabling effective AI adoption in organisations, with emphasis on clarity, collaboration, accountability, and feedback loops. While it discusses roles (coaches, champions), collaboration, and learning, its framing is around process governance rather than psychological principles or theories central to Organisational Psychology. There are some implicit connections to behaviour (e.g., collective ownership, reflection, engagement), but direct exploration of motivational, leadership, conflict, or team dynamic theories is largely absent. The audience aligns with leaders and organisational change agents, consistent with the intended category, and the narrative is clear and focused, but it stays at a process and systems level rather than deeply engaging with psychological constructs.",
    "reasoning_summary": "Partial fit: The content relates to organisational collaboration, learning, and roles, but focuses on frameworks and process, not core psychological theories or principles. Alignment with Organisational Psychology is present but indirect and limited.",
    "level": "Tertiary"
  },
  "Scrum Master": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Scrum Master",
    "calculated_at": "2025-09-17T23:12:31",
    "ai_confidence": 5.9,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.4,
    "ai_intent": 1.0,
    "ai_audience": 6.0,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The content does not mention Scrum, Scrum Master, or its accountabilities. The focus is entirely on the Kendall Framework for AI adoption, with roles like Kendall Coach, Opportunity Lead, and Context Champion that, while sharing some conceptual similarities (coaching, enabling flow, transparency), never reference Scrum roles or responsibilities directly or indirectly. Alignment, depth, and intent scores are extremely low: any conceptual overlap (like supporting teams, supporting learning, or impediment removal) is superficial and not linked to Scrum, making fit to 'Scrum Master' category highly tenuous. Audience is slightly higher since parts of the content do target change facilitators, but overall, relevance is negligible.",
    "reasoning_summary": "Content never references Scrum or the Scrum Master role. Roles and concepts are unique to the Kendall Framework and only superficially resemble Scrum accountabilities. No evidence the topic purpose matches 'Scrum Master'.",
    "level": "Ignored"
  },
  "Definition of Ready": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Definition of Ready",
    "calculated_at": "2025-09-17T23:12:31",
    "ai_confidence": 9.35,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 0.7,
    "ai_intent": 0.7,
    "ai_audience": 2.5,
    "ai_signal": 1.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The Kendall Guide does not directly mention or discuss Definition of Ready. While there are concepts of clarity, backlog, and readiness of opportunities (especially in roles and artifacts such as Opportunity Backlog), these are heavily contextualized for AI adoption, not Agile DoR. No criteria for 'ready' backlog items or their actionable state for sprint execution are outlined. The guide instead emphasizes prioritization, alignment, and continuous improvement of AI initiatives. The only minor alignment is with the clarity and refinement of items in a backlog, but without the specific standards or checklists central to DoR. Audience (practitioners/team) and a mild backlog focus provide the only small overlap. Overall, the content is almost completely off-topic regarding DoR.",
    "reasoning_summary": "Content does not address Definition of Ready; backlog clarity/prioritization is referenced, but not readiness. Topic, intent, and themes do not align with DoR. Fit is minimal and mostly circumstantial.",
    "level": "Ignored"
  },
  "Enterprise Agility": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Enterprise Agility",
    "calculated_at": "2025-09-17T23:12:23",
    "ai_confidence": 83.38,
    "ai_mentions": 4.2,
    "ai_alignment": 9.3,
    "ai_depth": 8.7,
    "ai_intent": 9.0,
    "ai_audience": 8.8,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 83.0,
    "reasoning": "The content presents the Kendall Framework as a system-of-work for AI adoption at an organisational level. It details structured roles, artefacts, cadences, and feedback loops to foster adaptation, continuous improvement, and alignment across teams and leadership. Practices like cross-team alignment, system-wide accountabilities (Coach, Opportunity Lead), strategic backlogs, and regular inspect-and-adapt events indicate an enterprise-wide approach, well-aligned with Enterprise Agility's focus on adaptability and scaling agile beyond teams. While direct mentions of 'enterprise agility' or frameworks like SAFe/LeSS are absent, the conceptual machinery, intent, and audience clearly target leaders seeking to drive change and responsiveness at organisational scale. The depth is strong, and the purpose is clearly not just team-level but enterprise transformation of AI adoption behaviors. Signal is high; only a minor score reduction for absence of direct category language.",
    "reasoning_summary": "The Kendall Framework content describes scalable, adaptable, and collaborative AI adoption practices for organisations. Its themes, roles, cadences, and focus are highly aligned to enterprise agility, despite minimal direct mentions. Strong category fit.",
    "level": "Primary"
  },
  "Experimentation": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Experimentation",
    "calculated_at": "2025-09-17T23:12:23",
    "ai_confidence": 61.95,
    "ai_mentions": 2.7,
    "ai_alignment": 7.9,
    "ai_depth": 7.4,
    "ai_intent": 6.3,
    "ai_audience": 8.2,
    "ai_signal": 8.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 62.0,
    "reasoning": "Direct references to experimentation, hypothesis, or systematic testing are absent. However, the framework repeatedly focuses on empirical inspection, adaptation, feedback loops, opportunity backlogs, evidence-driven prioritization, and learning orientation—central to experimentation in agile. The application resembles evidence-based and iterative methodologies, aligned closely with experimental approaches but stops short of explicit hypothesis-driven language or structured testing methods (e.g., A/B testing, hypothesis formulation, result analysis). Depth and audience fit are strong, with a practitioner-leaning, agile-oriented audience and sustained discussion of learning and adaptation. However, without explicit experimentation terminology or techniques, the fit is partial but substantial.",
    "reasoning_summary": "The content lacks explicit experimentation or hypothesis-driven language but is strongly aligned conceptually—focused on evidence, feedback, adaptation, and learning loops within agile. Fit is partial, with good depth, audience, and intent alignment.",
    "level": "Secondary"
  },
  "Product Delivery": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Product Delivery",
    "calculated_at": "2025-09-17T23:12:23",
    "ai_confidence": 51.48,
    "ai_mentions": 2.2,
    "ai_alignment": 6.9,
    "ai_depth": 6.6,
    "ai_intent": 6.2,
    "ai_audience": 7.3,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 51.0,
    "reasoning": "The content focuses on a framework for AI adoption emphasizing problem-first approaches, context, collaboration, and continuous improvement. While practices such as prioritization, feedback loops, roadmaps, and disciplined delivery are discussed, the main focus is adoption strategy and organisational alignment rather than the core end-to-end methodologies of product delivery. There are no explicit references to software engineering, testing, deployment, or agile/DevOps-specific delivery processes, and while artifacts like Roadmap and Backlog overlap with delivery, they are framed in the context of AI opportunity evaluation rather than delivering working software to customers. The target audience (organisational leaders, teams, coaches) aligns decently, and the signal is strong, but depth on product delivery practices is clearly partial.",
    "reasoning_summary": "Framework discusses AI adoption with artifacts/practices (roadmap, backlog, feedback loops) that partially overlap with product delivery, but lacks explicit focus on the software delivery lifecycle or core delivery practices. Partial fit; intent is adoption strategy.",
    "level": "Tertiary"
  },
  "Azure DevOps": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Azure DevOps",
    "calculated_at": "2025-09-17T23:12:23",
    "ai_confidence": 4.7,
    "ai_mentions": 0.0,
    "ai_alignment": 1.4,
    "ai_depth": 0.8,
    "ai_intent": 1.2,
    "ai_audience": 0.9,
    "ai_signal": 0.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 5.0,
    "reasoning": "The content never mentions Azure DevOps, nor does it discuss any of its tools, features, or methodologies. It provides a framework for AI adoption at an organisational level with conceptual overlap (e.g., backlogs, roadmaps, coaching, flow, and evidence-based management), but none are explicitly or implicitly tied to Azure DevOps. The intended audience may overlap with those interested in Azure DevOps (organisational change, tech leadership, and practitioners), but the substance is not relevant to Azure DevOps-specific tooling or practices. All six dimensions score very low; mentions are zero because Azure DevOps is never referenced. The overall fit is minimal and mostly coincidental.",
    "reasoning_summary": "The content is about a generic AI adoption framework and never references Azure DevOps. While there are faint conceptual overlaps with Agile or DevOps practices, it is entirely unrelated to Azure DevOps tooling, methods, or focus.",
    "level": "Ignored"
  },
  "Team Motivation": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Team Motivation",
    "calculated_at": "2025-09-17T23:12:24",
    "ai_confidence": 42.61,
    "ai_mentions": 1.8,
    "ai_alignment": 4.1,
    "ai_depth": 4.3,
    "ai_intent": 4.0,
    "ai_audience": 6.2,
    "ai_signal": 5.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "Direct mentions of Team Motivation are minimal; the document doesn't use the term, nor does it explicitly discuss motivation, engagement, or psychological safety per se. The alignment emerges mainly from indirect emphasis on collaboration, collective ownership, coaching, and feedback loops (e.g., 'cultivating feedback loops', 'collective ownership'). Elements like the 'Kendall Coach' role and shared accountabilities support engagement and learning orientation. However, the primary focus is on structured AI adoption and accountability, not specifically on team motivation strategies. Motivation-related themes are present but not explored with great depth or as a main topic. Intent is practical/adoption-focused, not strictly motivational. The audience includes teams and organizations, so there is moderate overlap. The content's signal is fairly high in terms of relevance to collaboration and some team dynamic practices, but explicit links to motivation are weak.",
    "reasoning_summary": "Content touches on collaboration, ownership, and learning, offering some indirect links to team motivation, but its core is AI adoption structure. Team motivation is not the main topic nor explored in depth. Fit with category is partial and indirect.",
    "level": "Tertiary"
  },
  "Lean Thinking": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Lean Thinking",
    "calculated_at": "2025-09-17T23:12:31",
    "ai_confidence": 58.783,
    "ai_mentions": 2.1,
    "ai_alignment": 6.85,
    "ai_depth": 7.35,
    "ai_intent": 6.8,
    "ai_audience": 7.2,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 59.0,
    "reasoning": "The content does not explicitly mention Lean Thinking, Lean, or its canonical principles or tools. However, its focus on flow, waste reduction (implicit via streamlining adoption), empirical feedback, continuous improvement, and disciplined collaboration shows conceptual overlap, especially with themes like value, inspection/adaptation, feedback loops, and flow. There's a moderate fit in depth and audience (organizational leaders/practitioners), though most references are indirect. The main purpose is helping organizations adopt AI through structured, evidence-based, flow-oriented systems, similar to Lean's ethos. Direct lean-specific tools, terminology, and explicit lean framing are missing, reducing the direct mentions score and lowering overall confidence despite conceptual alignment.",
    "reasoning_summary": "Content aligns conceptually with Lean Thinking via focus on flow, value, feedback, and continuous improvement, but lacks explicit Lean references or tools. Fit is partial and mostly indirect, with moderate depth and strong audience alignment.",
    "level": "Tertiary"
  },
  "Customer Satisfaction": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Customer Satisfaction",
    "calculated_at": "2025-09-17T23:12:30",
    "ai_confidence": 23.57,
    "ai_mentions": 0.4,
    "ai_alignment": 2.6,
    "ai_depth": 2.3,
    "ai_intent": 3.1,
    "ai_audience": 6.6,
    "ai_signal": 5.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content centers on a framework for AI adoption focused on context, opportunity, and evidence-based iterative work. While it references stakeholder needs, value delivery, and feedback loops, these are not discussed in terms of customer satisfaction as defined. There is no direct mention of measuring, improving, or prioritizing customer happiness or experience. Concepts like Opportunity Backlog and continuous improvement could tangentially support satisfaction, but the framework is aimed at strategic clarity and disciplined AI delivery. The audience aligns moderately with Agile/DevOps/Lean practitioners, but the fit to the customer satisfaction category is mostly indirect.",
    "reasoning_summary": "The content mainly addresses disciplined AI adoption, not customer satisfaction. While it emphasizes value and stakeholder alignment, it doesn’t directly or deeply explore customer experience, measurement, or satisfaction practices.",
    "level": "Ignored"
  },
  "Agile Frameworks": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agile Frameworks",
    "calculated_at": "2025-09-17T23:12:29",
    "ai_confidence": 60.029,
    "ai_mentions": 2.5,
    "ai_alignment": 7.2,
    "ai_depth": 6.6,
    "ai_intent": 7.3,
    "ai_audience": 6.0,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 60.0,
    "reasoning": "The Kendall Guide proposes a framework for AI adoption that shares some conceptual overlap with Agile frameworks: it emphasizes iteration, adaptation, continuous improvement, feedback loops, accountabilities, and collaboration. However, it does not directly mention or compare Agile frameworks (such as Scrum, Kanban, XP, Lean), nor are Agile principles or values explicitly cited or analyzed. The subject is an AI-specific management framework rather than one derived from or systematically compared to Agile frameworks. While its concepts might resonate with Agile practitioners (e.g., inspect-and-adapt, backlog management), the primary focus remains on the unique Kendall system, not on Agile frameworks per se. Hence, while there is moderate thematic alignment and depth, direct reference and intent toward the Agile Frameworks category are limited.",
    "reasoning_summary": "Content primarily introduces the Kendall Framework for AI adoption. While conceptually similar to Agile practices, it does not explicitly discuss, compare, or reference Agile frameworks, so the category fit is partial and indirect.",
    "level": "Tertiary"
  },
  "Scrum Team": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Scrum Team",
    "calculated_at": "2025-09-17T23:12:30",
    "ai_confidence": 7.6,
    "ai_mentions": 0.3,
    "ai_alignment": 1.1,
    "ai_depth": 0.9,
    "ai_intent": 0.5,
    "ai_audience": 2.1,
    "ai_signal": 1.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content is entirely about the Kendall Framework, a method for adopting AI, and does not mention or focus on Scrum Teams or their specific accountabilities. The framework defines its own distinct roles (Kendall Coach, Opportunity Lead, Context Champions) and artifacts, which differ fundamentally from the structure and roles of the Scrum Team (Scrum Master, Product Owner, Developers). There is no substantive overlap in theme, intent, or purpose with the Scrum Team as defined in the Scrum Guide. While the content does mention concepts like 'teams,' 'collaboration,' and 'accountability,' these are generic and not specific to Scrum Team as an accountability. The intended audience and context are more general, targeting organizations approaching AI, rather than practitioners focused on Scrum Teams.",
    "reasoning_summary": "This content is about the Kendall Framework for AI adoption, not Scrum Team accountability. Roles, events, and purpose are unrelated to Scrum. Any overlap is generic (e.g., collaboration) and not specific to the Scrum Team as defined in the Scrum Guide.",
    "level": "Ignored"
  },
  "Lean Principles": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Lean Principles",
    "calculated_at": "2025-09-17T23:12:33",
    "ai_confidence": 74.203,
    "ai_mentions": 3.3,
    "ai_alignment": 7.8,
    "ai_depth": 7.5,
    "ai_intent": 7.0,
    "ai_audience": 8.1,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 74.0,
    "reasoning": "The Kendall Guide content does not explicitly mention Lean or its main terminology (e.g., Muda, 5S), but its themes—such as continuous improvement, flow of value/information, collaboration, and empirical inspection—conceptually align with Lean Principles. The framework is iterative and seeks to maximise value in AI adoption while advocating adaptation and learning (Kaizen spirit). Despite these parallels, direct connection to Lean and its unique toolset is minimal, and there's little evidence of using Lean vocabulary or methodologies directly. The content's focus is on a specific AI-adoption framework, not explicitly Lean. Depth and alignment are moderate, intent is supportive but not targeted solely at Lean audiences. No penalties apply.",
    "reasoning_summary": "The content partially aligns with Lean Principles by emphasising flow, adaptation, and continuous improvement, but it lacks explicit references to Lean or its core tools. The fit is moderate, primarily conceptual and indirect rather than direct.",
    "level": "Secondary"
  },
  "Artificial Intelligence": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Artificial Intelligence",
    "calculated_at": "2025-09-17T23:12:31",
    "ai_confidence": 93.3,
    "ai_mentions": 9.7,
    "ai_alignment": 9.4,
    "ai_depth": 9.1,
    "ai_intent": 9.3,
    "ai_audience": 9.0,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 93.0,
    "reasoning": "The content directly and frequently mentions AI, explicitly focusing on adoption frameworks grounded in problem-first, iterative, evidence-based approaches. It is conceptually aligned with applying AI to organizational work, including aspects relevant to Agile and DevOps (empirical inspection, adaptiveness, context-driven collaboration), although it does not reference these practices by name. The depth is substantial—covering framework principles, roles, events, and artifacts, all centered on disciplined AI usage in teams and organizations. The audience is practitioners, coaches, and leaders implementing AI in a structured way—very close to the intended category audience. The signal-to-noise ratio is high, with nearly all content focused on practical AI adoption governance. No penalties are warranted, as there are no outdated practices or negative tone.",
    "reasoning_summary": "The content is a thorough framework for structuring AI adoption in organizations, prioritizing evidence, clarity, and adaptive practices. It strongly fits the category, though references to Agile/DevOps are implicit, not explicit.",
    "level": "Primary"
  },
  "Throughput": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Throughput",
    "calculated_at": "2025-09-17T23:12:36",
    "ai_confidence": 18.625,
    "ai_mentions": 0.7,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 1.8,
    "ai_audience": 3.1,
    "ai_signal": 2.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content presents the Kendall Framework for AI adoption and focuses on organisational clarity, empirical ways of working, flow of information, and adaptive learning. While 'flow' and 'feedback loops' are mentioned several times, these refer to information and decision flow—not the metric of throughput as defined. There is no explicit or substantive discussion on throughput as a delivery metric, nor any related analysis, forecasting, or visualisation. The primary intent is guiding AI adoption processes, not managing, analysing, or reporting on throughput. Thus, apart from some conceptual tangents (e.g., reference to 'flow of priorities' or 'impediments to flow'), it does not align with the strict criteria of the throughput category.",
    "reasoning_summary": "Content is focused on AI adoption frameworks, with only tangential references to flow. It does not analyse or discuss throughput as a delivery metric, so it does not match the 'Throughput' category definition.",
    "level": "Ignored"
  },
  "Agile Transformation": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agile Transformation",
    "calculated_at": "2025-09-17T23:12:35",
    "ai_confidence": 37.6,
    "ai_mentions": 0.8,
    "ai_alignment": 4.7,
    "ai_depth": 4.2,
    "ai_intent": 4.1,
    "ai_audience": 5.9,
    "ai_signal": 5.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content outlines the Kendall Framework, a structured approach for AI adoption emphasising collaboration, empirical inspection, adaptation, feedback loops, and continuous improvement. These concepts intersect with Agile practices but do not explicitly or directly discuss Agile transformation, its values, or frameworks. There are no occurrences of 'Agile,' nor explicit reference to Agile methodologies, transformation strategies, or cultural change management as defined by the category. Some intent and mindset overlap with Agile (e.g., inspect–adapt, feedback loops, collaborative roles), but the framework is focused on AI adoption rather than organisational Agile transformation. The content may appeal to audiences considering transformation or adaptive work, but it is not written for Agile transformation practitioners specifically.",
    "reasoning_summary": "While the Kendall Framework shares some values with Agile (adaptation, feedback, collaboration), it is about AI adoption, not Agile Transformation. It lacks direct references, depth, and clear intent matching the category.",
    "level": "Ignored"
  },
  "Product Backlog": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Product Backlog",
    "calculated_at": "2025-09-17T23:12:33",
    "ai_confidence": 19.12,
    "ai_mentions": 2.3,
    "ai_alignment": 2.8,
    "ai_depth": 2.4,
    "ai_intent": 2.5,
    "ai_audience": 4.6,
    "ai_signal": 3.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content centers on the Kendall Framework for AI adoption, introducing novel concepts such as the 'Opportunity Backlog' but does not mention or discuss the Product Backlog in Agile/Scrum. There is minimal conceptual overlap—the Opportunity Backlog, while superficially similar in being a prioritized list, is not equivalent in role, structure, or intent to the Product Backlog as defined in Agile frameworks. Terminology, artifacts, and practices described are custom to the Kendall system and not purposefully about Agile backlog management or Product Backlog practices. There is only brief incidental relevance regarding disciplined prioritization, but the depth, alignment, and directness are too low for a meaningful category fit. The core audience is also AI/strategy adopters, not Agile/Scrum practitioners.",
    "reasoning_summary": "Content does not discuss the Product Backlog or Agile backlog practices. References to 'Opportunity Backlog' are unrelated to Product Backlog. Minimal overlap; category fit is weak and incidental at best.",
    "level": "Ignored"
  },
  "Internal Developer Platform": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Internal Developer Platform",
    "calculated_at": "2025-09-17T23:12:37",
    "ai_confidence": 12.35,
    "ai_mentions": 0.3,
    "ai_alignment": 1.2,
    "ai_depth": 1.1,
    "ai_intent": 1.0,
    "ai_audience": 5.8,
    "ai_signal": 2.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content centers on a framework for AI adoption (the Kendall Guide) focused on process, prioritization, and organizational clarity, not on Internal Developer Platforms. There are no direct or indirect references to IDP concepts—no mention of developer self-service, developer platforms, or tools to streamline the software delivery lifecycle. While some artifacts (like backlog or repository) echo Agile/DevOps terms, they are not discussed in the organizational or technical context of IDPs and relate strictly to organizational AI adoption workflow. The underlying audience (organizations, leaders, teams) partly overlaps with IDP interests, but the theme, purpose, and detailed subject matter do not fit the category.",
    "reasoning_summary": "Content is unrelated to Internal Developer Platforms. It describes a general AI adoption framework, lacking any discussion of platform concepts, architectures, or practices that fit the IDP category.",
    "level": "Ignored"
  },
  "Deployment Frequency": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Deployment Frequency",
    "calculated_at": "2025-09-17T23:12:37",
    "ai_confidence": 11.512,
    "ai_mentions": 0.3,
    "ai_alignment": 1.3,
    "ai_depth": 1.458,
    "ai_intent": 1.43,
    "ai_audience": 3.14,
    "ai_signal": 2.05,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content is focused on a framework for AI adoption, emphasizing prioritization, context, feedback loops, and adaptive improvement. While some practices (e.g., cadence, feedback loops, iteration) overlap conceptually with Agile/DevOps, there is no direct or substantive mention of deployment or release practices, nor focus on software release intervals or frequency. The audience may include technical/organizational practitioners, but the discussion is not framed around deployment frequency optimization. Fit is minimal, with only generic process improvement themes relating indirectly.",
    "reasoning_summary": "Content focuses on AI adoption process, prioritization, and learning—not on deployment frequency. It does not discuss release intervals, CI/CD, or related Agile/DevOps deployment practices. Fit to the category is minimal and mostly tangential.",
    "level": "Ignored"
  },
  "Agentic Engineering": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agentic Engineering",
    "calculated_at": "2025-09-17T23:12:37",
    "ai_confidence": 85.43,
    "ai_mentions": 2.7,
    "ai_alignment": 9.2,
    "ai_depth": 8.5,
    "ai_intent": 9.0,
    "ai_audience": 8.1,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 85.0,
    "reasoning": "The Kendall Guide offers a system of work for AI adoption that closely aligns with Agentic Engineering principles: it emphasizes problem-first, context-driven, evidence-based decision-making, collaboration, accountability, feedback loops, and the integration of ethical AI. Roles such as the Kendall Coach and Context Champions reinforce autonomy and feedback-driven adaptation. Artifacts (Opportunity Backlog, Context Repository) and events (regular cadence, empirical inspection) map to continuous value delivery and systemic observability. However, although agency, adaptation, and ethical integration are implicit, there is limited direct reference to 'Agentic Engineering' as a term or an explicit discourse about maximizing human/AI agency as the primary theme, which lowers the mentions score. The guide is highly relevant for practitioners, technical team leads, and organizations adopting AI, but slightly broadens context to general AI adoption frameworks, resulting in marginally lower depth and audience alignment scores. No outdated or critical content is present, so no penalties were applied.",
    "reasoning_summary": "This content strongly fits Agentic Engineering, thoroughly addressing agency, adaptive feedback, and ethical AI integration in engineering systems. The main theme matches the category definition, though it lacks explicit category naming, making fit very high but not absolute.",
    "level": "Primary"
  },
  "Working Software": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Working Software",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 17.31,
    "ai_mentions": 0.7,
    "ai_alignment": 2.4,
    "ai_depth": 2.3,
    "ai_intent": 2.6,
    "ai_audience": 5.4,
    "ai_signal": 4.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 17.0,
    "reasoning": "The content outlines a framework for AI adoption, discussing principles, roles, events, and artifacts like backlogs and roadmaps. It does not explicitly mention 'Working Software', nor does it discuss delivered or incrementing software, quality, or customer value in terms of tangible outputs. Its artifacts are managerial (opportunity backlog, context repo, roadmap) rather than working software artifacts. The themes center around decision frameworks, collaboration, prioritization, and flow, rather than building or delivering working software increments. Thus, conceptual and topical fit are low while audience/intent have some overlap with those who care about software delivery, explaining the low confidence score.",
    "reasoning_summary": "This content focuses on managerial processes, context, and prioritization in AI adoption—not on the creation or delivery of working software as an increment or finished output. Little alignment exists with the 'Working Software' category.",
    "level": "Ignored"
  },
  "Transparency": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Transparency",
    "calculated_at": "2025-09-17T23:12:37",
    "ai_confidence": 74.2,
    "ai_mentions": 4.9,
    "ai_alignment": 8.6,
    "ai_depth": 8.2,
    "ai_intent": 7.8,
    "ai_audience": 7.0,
    "ai_signal": 7.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 74.0,
    "reasoning": "The content discusses visibility of information (flow of information, artefacts like Opportunity Backlog and Context Repository) and team/accountability structures that promote clarity, alignment, and inspection. Transparency is referenced directly (Context Champions 'promote transparency'), but is a supporting, not primary, theme. Emphasis on regular feedback loops, event cadence, and artefact visibility aligns with Transparency, but the core topic is AI adoption systems. Thus, fit is substantial but partial.",
    "reasoning_summary": "Transparency appears as a supporting principle, with practices promoting openness, artefact visibility, and aligned accountabilities. However, transparency is not the main theme but woven within broader framework guidance for AI adoption. Fit is partial but meaningful.",
    "level": "Secondary"
  },
  "Collaboration Tools": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Collaboration Tools",
    "calculated_at": "2025-09-17T23:12:41",
    "ai_confidence": 48.382,
    "ai_mentions": 2.5,
    "ai_alignment": 5.8,
    "ai_depth": 6.2,
    "ai_intent": 4.7,
    "ai_audience": 5.1,
    "ai_signal": 5.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 48.0,
    "reasoning": "The Kendall Guide discusses collaboration as a value and enabler (e.g., 'collaborative practices', 'collective ownership'), and references artifacts and events designed to promote alignment and information flow. However, the content is not focused on specific collaboration tools or platforms, their features, or integrations with Agile methodologies. There are no direct mentions of digital platforms (Slack, Jira, etc.), tool comparisons, or explicit guidance on the use of such tools in Agile teams. Instead, collaboration is framed as a principle, and the guide focuses on a framework for AI adoption using collaborative values and roles. There is some conceptual overlap with the goals of collaboration tools (improving alignment, visibility, information flow), but not at the level of actual tools, practices, or comparative discussion required by the category definition.",
    "reasoning_summary": "The content promotes collaboration as a value but does not discuss specific collaboration tools or their practical use in Agile environments. Its focus is a framework, not tools; thus, fit with the 'Collaboration Tools' category is partial and indistinct.",
    "level": "Tertiary"
  },
  "Leadership": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Leadership",
    "calculated_at": "2025-09-17T23:12:42",
    "ai_confidence": 69.89,
    "ai_mentions": 4.2,
    "ai_alignment": 7.1,
    "ai_depth": 7.4,
    "ai_intent": 6.3,
    "ai_audience": 7.0,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 70.0,
    "reasoning": "Leadership is not repeatedly or explicitly named outside of references to accountabilities and roles (e.g., Coach, Lead, Champion)—more emphasis is on frameworks and systems. Conceptual fit is moderate: it prescribes roles with accountability, mentoring, and alignment functions that align partly with Agile/DevOps leadership, such as promoting collaboration, feedback loops, and adaptation. However, the discussion is primarily about structuring an AI adoption framework rather than deeply exploring leadership philosophies or leadership impact. Depth regarding 'Leadership' per se is limited—leadership aspects are introduced but subsumed within broader guidance. The intent is mainly guidance on work systems, with some alignment to audience interested in organisational leadership but also practitioners. Much of the content describes processes, practices, and artifacts, not focused analysis of leadership behaviors or development, keeping the signal-to-noise ratio moderate for this category.",
    "reasoning_summary": "Content describes roles and accountabilities relevant to leadership in AI adoption, with some coaching and alignment themes. However, leadership is not its main focus, and discussion of leadership topics is moderate, making fit partial rather than primary.",
    "level": "Secondary"
  },
  "Technical Mastery": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Technical Mastery",
    "calculated_at": "2025-09-17T23:12:43",
    "ai_confidence": 42.32,
    "ai_mentions": 1.7,
    "ai_alignment": 4.7,
    "ai_depth": 4.5,
    "ai_intent": 4.2,
    "ai_audience": 4.8,
    "ai_signal": 6.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The Kendall Guide focuses on organisational frameworks for AI adoption, emphasising disciplines like context, evidence-based prioritisation, and collaborative processes. There is minimal mention of software craftsmanship, code quality, or explicit technical practices. While some nods to engineering excellence (such as 'modern engineering' and 'sustainable outcomes') and artifacts (repositories, backlogs) exist, the depth and focus are not substantially technical. Most content addresses management, decision workflows, and leadership roles in AI opportunity selection, with little direct discussion of architecture, code, DevOps, or refactoring. Therefore, the fit for Technical Mastery is partial and somewhat tangential.",
    "reasoning_summary": "The content is mostly organisational and management-focused for AI adoption. It offers limited overlap with Technical Mastery, rarely addressing core software craftsmanship or development practices, resulting in only a partial category fit.",
    "level": "Tertiary"
  },
  "Method": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Method",
    "calculated_at": "2025-09-17T23:12:44",
    "ai_confidence": 91.2,
    "ai_mentions": 8.4,
    "ai_alignment": 9.6,
    "ai_depth": 9.2,
    "ai_intent": 8.8,
    "ai_audience": 8.3,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 91.0,
    "reasoning": "The content thoroughly describes the Kendall Framework as a structured, step-by-step system guiding AI adoption. It defines clear procedures (problem-first, events, artifacts, accountabilities, iterative improvement), uses method-focused language, and offers depth in execution. There are direct references to structured practices, cadences, feedback loops, and specific roles—matching 'Method' as defined. The narrative’s purpose is to guide practical application and workflow, not tools or philosophies. Audience is organizational practitioners, and the writing remains focused on the method of adoption, yielding a high method fit. No penalties; all concepts are current and align positively with the category.",
    "reasoning_summary": "The content provides detailed procedural guidance for AI adoption, specifying structured steps, roles, events, and artifacts. Its purpose and audience closely match the 'Method' category, with strong direct and conceptual alignment and depth.",
    "level": "Primary"
  },
  "Behaviour Driven Development": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Behaviour Driven Development",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 13.55,
    "ai_mentions": 0.3,
    "ai_alignment": 1.6,
    "ai_depth": 1.7,
    "ai_intent": 1.2,
    "ai_audience": 2.4,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The Kendall Guide focuses on AI adoption through problem-first, collaborative, and evidence-based approaches. While there is mention of clarity, context, stakeholder alignment, collaboration, and feedback loops, there are no explicit or implicit references to Behaviour Driven Development (BDD), its principles, tools, or methodologies. The content does not discuss user stories, acceptance criteria, or BDD-style scenarios, nor does it reference BDD frameworks or practices. Any thematic similarity (such as collaboration or context) is generic and not specific to BDD. The audience (those working on AI adoption and organisational change) could overlap with those interested in BDD, but the content itself is not tailored to BDD practitioners nor does it further that discipline. Signal-to-noise is relatively low in BDD terms as the piece is nearly all off-topic for the requested category.",
    "reasoning_summary": "Content outlines an AI adoption framework, not BDD. No explicit or substantive connection to BDD principles, practices, or tools. Any overlap is incidental and generic. Does not fit BDD category.",
    "level": "Ignored"
  },
  "Discipline": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Discipline",
    "calculated_at": "2025-09-17T23:12:45",
    "ai_confidence": 91.46,
    "ai_mentions": 9.1,
    "ai_alignment": 9.7,
    "ai_depth": 9.2,
    "ai_intent": 9.3,
    "ai_audience": 9.0,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 91.0,
    "reasoning": "The content consistently frames the Kendall Framework as a system of work guided by discipline, explicitly mentioning discipline and discussing the shared principles, methodologies, accountabilities, governance roles, and continuous improvement mechanisms foundational to a discipline. It aligns strongly with key topics such as structure, principles, ethical considerations, and systemic approach to professional conduct and decision-making. The depth is high—the guide not only defines discipline but details how it is enacted via governance roles, artifacts, feedback loops, and cadenced events. The intent is to inform and guide organisational actors seeking a disciplined approach to AI. The targeted audience are practitioners, strategists, and leaders responsible for adoption at an organisational scale. Most content is tightly relevant, with very little tangential or filler material. No penalty applies, as the tone, framing, and concepts are current and entirely compatible with the category.",
    "reasoning_summary": "Content extensively and directly addresses discipline in AI adoption. It articulates principles, governance, roles, learning, and structure, fully aligning with the Discipline category’s definition and intent. Fit is strong, systemic, and clear.",
    "level": "Primary"
  },
  "Ability to Innovate": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Ability to Innovate",
    "calculated_at": "2025-09-17T23:12:39",
    "ai_confidence": 62.91,
    "ai_mentions": 2.6,
    "ai_alignment": 7.7,
    "ai_depth": 6.9,
    "ai_intent": 8.2,
    "ai_audience": 7.5,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 63.0,
    "reasoning": "The content focuses on a framework for AI adoption that emphasizes empirical learning, adaptation, feedback loops, and structures to support collaboration and context-driven outcomes. These mechanisms (inspect-and-adapt, learning cycles, opportunity backlogs, feedback events) are strongly aligned with fostering innovation as defined in Agile/DevOps/EBM. However, the content rarely directly references innovation. Instead, it discusses enablers and practices (e.g., continuous improvement, problem-first thinking, learning orientation) that underpin innovation without naming it, and does not explicitly cover innovation-specific metrics or case studies. The target audience (organizations adopting AI with adaptive practices) matches the innovation context, and the material is focused on relevant topics with minimal off-topic content. The lack of explicit discussion of innovation, metrics, or case examples limits the depth and directness.",
    "reasoning_summary": "Content aligns well with mechanisms that enable innovation (learning, adaptation) but rarely explicitly mentions innovation or relevant metrics, so fit is strong but indirect. Discussion is focused, with intent and audience matching the innovation context.",
    "level": "Secondary"
  },
  "Agentic Agility": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Agentic Agility",
    "calculated_at": "2025-09-17T23:12:40",
    "ai_confidence": 78.68,
    "ai_mentions": 3.6,
    "ai_alignment": 8.1,
    "ai_depth": 7.8,
    "ai_intent": 8.0,
    "ai_audience": 7.7,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 79.0,
    "reasoning": "Direct mentions of 'Agentic Agility' are absent, and the phrase 'agency' appears only as 'accountability' and 'intentionality.' However, there is strong conceptual alignment: the framework emphasizes intentional, adaptive action within organizations adopting AI, focusing on outcome alignment, empirical inspection, adaptation, and accountability. The roles ('Kendall Coach,' 'Opportunity Lead,' 'Context Champion') clearly map to mechanisms fostering agency and sustained agility. Discussion of feedback loops, learning orientation, continuous improvement, collaboration, ownership, and alignment with evolving goals further demonstrates depth. The content is aimed at those involved in implementing agile, adaptive approaches in complex environments, ensuring audience alignment. The narrative is on-topic with little filler, yielding a high signal-to-noise ratio, but absence of explicit 'agency' language or direct reference to 'Agentic Agility' prevents a perfect score.",
    "reasoning_summary": "The content closely matches Agentic Agility themes (intentional action, accountability, adaptive learning in socio-technical contexts). Lacks explicit 'agency' or 'Agentic Agility' terms but is conceptually strong and relevant; minor gap limits top score.",
    "level": "Secondary"
  },
  "First Principal": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "First Principal",
    "calculated_at": "2025-09-17T23:12:42",
    "ai_confidence": 77.65,
    "ai_mentions": 7.2,
    "ai_alignment": 8.6,
    "ai_depth": 7.9,
    "ai_intent": 7.5,
    "ai_audience": 8.0,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 78.0,
    "reasoning": "The content has an explicit section labeled 'First Principles of the Kendall Framework' and articulates foundational truths guiding system design, directly aligning with the definition. The principles are described as fundamental and non-negotiable within the Kendall context (e.g., Problem Before Solution, Boundaries Enable Trust, etc.) and are applied to guide decisions, structure, and accountabilities. However, while these are labeled as 'first principles,' they are presented within the custom context of Kendall (not canonical Lean, Scrum, or DevOps) and not cross-referenced to foundational theorists of those disciplines. The discussion is substantial but largely anchored to one framework's articulation of first principles rather than the broader, cross-framework theme implied by the category, slightly limiting depth. The intent is well aligned: to establish non-derivable, systemic constraints guiding AI adoption and delivery. The audience (organisational leaders, practitioners involved in systems of work) is suitable. There is moderate but not total alignment to the canonical scope of immutable first principles in Lean, Agile, or DevOps, although the principles do serve a similar foundational function in this new domain.",
    "reasoning_summary": "Clearly identifies and discusses 'first principles' within the Kendall Framework, aligning with the category's scope, though application is confined to a novel system versus canonical Lean, Agile, or DevOps contexts. Fit is strong but not universal for the category.",
    "level": "Secondary"
  },
  "Miscellaneous": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Miscellaneous",
    "calculated_at": "2025-09-17T23:12:43",
    "ai_confidence": 21.982,
    "ai_mentions": 0.0,
    "ai_alignment": 2.2,
    "ai_depth": 1.6,
    "ai_intent": 2.7,
    "ai_audience": 6.1,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 22.0,
    "reasoning": "There are no direct mentions of 'Miscellaneous' or its allied topics. The Kendall Guide presents a new system for AI adoption, describing practices, roles, events, and artifacts. While it adopts some concepts like empirical inspection, flow, and adaptation, these are couched within its proprietary framework and not in reference to Agile, Scrum, DevOps, Lean, or EBM directly. The overall depth is high regarding the proprietary system but not as it relates to Miscellaneous—its focus is clear and theme is heavily methodological, making it too specific to fit cleanly in Miscellaneous. The intended audience could overlap with those interested in business agility, but the approach is narrowly about Kendall. Signal-to-noise is moderate: content is comprehensive, but not tangent or filler. Thus, overall category fit for Miscellaneous is low, as content aligns more with a unique framework than catch-all or non-aligned material.",
    "reasoning_summary": "Content outlines a proprietary AI adoption framework. It does not align with Miscellaneous—themes, intent, and specificity place it outside the 'catch-all' nature of the category. Fit is mostly absent except for partial relevance to business agility audience.",
    "level": "Ignored"
  },
  "Definition of Workflow": {
    "resourceId": "ktBQKAhD6RZ",
    "category": "Definition of Workflow",
    "calculated_at": "2025-09-17T23:12:45",
    "ai_confidence": 40.82,
    "ai_mentions": 1.8,
    "ai_alignment": 4.1,
    "ai_depth": 4.4,
    "ai_intent": 4.2,
    "ai_audience": 6.2,
    "ai_signal": 6.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 41.0,
    "reasoning": "The Kendall Guide outlines a system of work and process for AI adoption, featuring artifacts, events, and accountabilities. It references 'flow' in information and value but does not explicitly define or discuss 'Definition of Workflow' per Kanban/agile theory: lacking entry/exit criteria, WIP limits, or visual workflow concepts. There are some thematic overlaps (focus on flow, adaptability, inspect-and-adapt rhythms), yet core elements of Definition of Workflow—explicit agreements and policies governing the flow of work—are not present or named. Audience and intent partially align as the guide is for practitioners seeking clearer process, but not specific to Kanban or agile workflow explication.",
    "reasoning_summary": "Content describes a process framework for AI adoption emphasizing flow and adaptation, but does not explicitly discuss or define 'Definition of Workflow' per Kanban/agile principles. Only partial thematic overlap; fit is weak and indirect.",
    "level": "Tertiary"
  },
  "Product Operating Model": {
    "resourceId": "ktBQKAhD6RZ",
    "itemId": "ktBQKAhD6RZ",
    "category": "Product Operating Model",
    "calculated_at": "2025-11-24T18:57:02",
    "ai_confidence": 84.5,
    "ai_mentions": 6.3,
    "ai_alignment": 9.4,
    "ai_depth": 9.0,
    "ai_intent": 8.9,
    "ai_audience": 8.8,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 84.0,
    "reasoning": "The content describes the Kendall Framework—a system of work for AI adoption—which aligns with the design, roles, processes, governance, and structures for implementing AI across an organization. It covers frameworks for accountabilities, defined roles (Kendall Coach, AI Lead, Context Controller/Owner), artifacts (Opportunity Backlog, Context Repository, Roadmap), and key events that foster alignment, collaboration, prioritization, and evidence-based adaptation. The discussion closely maps to an 'AI Product Operating Model', a subcategory explicitly included in the definition. While the term 'Product Operating Model' is not repeatedly mentioned by name, the entire document addresses the model's core purpose—structuring how organizations align strategy, decision-making, cross-functional collaboration, feedback loops, and governance to deliver value via AI solutions. The content targets leaders, coaches, and teams involved in organization-wide change and continuous improvement—matching the target audience. Depth and alignment are both strong, with thorough explanations of how elements fit into a structured model for AI adoption. No penalties apply: there is nothing outdated, contradictory, or satirical, and practices discussed are current. Signal-to-noise ratio is high, with nearly the entire piece devoted to the model's components and application.",
    "reasoning_summary": "This content strongly fits the 'Product Operating Model' category, offering detailed frameworks, governance, roles, events, and artifacts for AI adoption. It matches the scope, depth, intent, and audience outlined in the classification definition.",
    "level": "Primary"
  },
  "Operating Model": {
    "resourceId": "ktBQKAhD6RZ",
    "itemId": "ktBQKAhD6RZ",
    "category": "Operating Model",
    "calculated_at": "2025-11-24T18:57:07",
    "ai_confidence": 83.39,
    "ai_mentions": 7.4,
    "ai_alignment": 9.1,
    "ai_depth": 8.7,
    "ai_intent": 8.1,
    "ai_audience": 8.6,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 83.0,
    "reasoning": "The Kendall Guide describes a 'system of work' for organizations adopting AI, aligning closely with operating model concepts: it defines accountabilities (Kendall Coach, AI Lead, Context Owner), workflows (Opportunity Backlog, Context Repository, Roadmap), governance structures (discovery cadences, sourcing events), and mechanisms for alignment between strategy and execution. The content thoroughly explains how an organization can structure AI adoption, focusing on value flow, empirical adaptation, and sustained learning. Direct use of the term 'operating model' is minimal, but the 'system of work' framing, management accountabilities, and organizational constructs map strongly to the operating model category, especially in the context of an AI Product Operating Model. Audience targeting (organizational leaders, teams, strategists) further increases fit. Superficiality is avoided; though explicit foundational theories are more implicit than cited, systems thinking and organizational effectiveness principles are clearly present.",
    "reasoning_summary": "The content details a system of work for AI adoption that defines accountabilities, workflows, and governance at an organizational scale. Its structure and intent strongly align with operating model principles, despite limited explicit use of the term.",
    "level": "Primary"
  },
  "AI Product Operating Model": {
    "resourceId": "ktBQKAhD6RZ",
    "itemId": "ktBQKAhD6RZ",
    "category": "AI Product Operating Model",
    "calculated_at": "2025-11-24T18:56:19",
    "ai_confidence": 92.68,
    "ai_mentions": 8.2,
    "ai_alignment": 9.6,
    "ai_depth": 9.7,
    "ai_intent": 9.0,
    "ai_audience": 8.5,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 93.0,
    "reasoning": "The content holistically describes a framework for operationalizing AI adoption at the organizational level, focusing on unique AI product governance, cross-functional roles, artifacts (e.g., opportunity backlog, context repository), events, and workflows, mirroring an AI Product Operating Model. It addresses lifecycle, accountability, value-stream integration, and iterative approaches (inspect and adapt cycles) fully aligned with the category’s scope. While the exact phrase 'AI Product Operating Model' is not heavily repeated, the content frequently references operating model-like constructs, such as end-to-end management, role definitions, continuous improvement, and governance of AI product delivery. It goes beyond surface-level guidance to supply actionable practices and role architectures, targeting practitioners, leaders, and strategists involved in AI product operationalization. No penalties are warranted—the information is current and the tone actively upholds the value and rigor of operating models for AI.",
    "reasoning_summary": "The guide proposes a comprehensive, role-focused framework for implementing AI across organizations, closely aligning with the AI Product Operating Model category by addressing lifecycle, governance, workflow, and continuous improvement.",
    "level": "Primary"
  }
}