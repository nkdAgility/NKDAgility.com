{
  "Kanban": {
    "resourceId": "oRStCAqLAY4",
    "category": "Kanban",
    "calculated_at": "2025-08-07T06:10:46",
    "ai_confidence": 7.6,
    "ai_mentions": 0.0,
    "ai_alignment": 0.3,
    "ai_depth": 0.2,
    "ai_intent": 0.5,
    "ai_audience": 0.8,
    "ai_signal": 0.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content provides an in-depth discussion of using generative AI to automate tagging and categorization in a blog site via Hugo and PowerShell scripts. It discusses taxonomy theory and its technical implementation but does not mention, reference, or discuss the Kanban methodology, its practices, key topics (e.g., visualizing work flow, WIP limits, Kanban boards), or its context in Lean or Agile. The only reference to 'Kanban' is in the context of choosing blog categories (e.g., 'Kanban' among others), not the methodology itself. There is no conceptual alignment or substantive discussion of Kanban principles; the depth, intent, and signal to Kanban are negligible.",
    "reasoning_summary": "This content does not discuss Kanban practices, principles, or methodology. Its focus is on AI-driven content categorization, not Kanban. 'Kanban' appears only as an example of a blog category, with no topical relevance.",
    "level": "Ignored"
  },
  "DevOps": {
    "resourceId": "oRStCAqLAY4",
    "category": "DevOps",
    "calculated_at": "2025-08-07T07:05:49",
    "ai_confidence": 16.52,
    "ai_mentions": 0.4,
    "ai_alignment": 2.6,
    "ai_depth": 1.9,
    "ai_intent": 1.7,
    "ai_audience": 3.6,
    "ai_signal": 1.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 17.0,
    "reasoning": "The content focuses on using AI and PowerShell scripting to automate tags and categories in a Hugo blog, emphasizing automation, auditability, and human oversight. While there is a passing mention of the author's background including DevOps, there are no direct discussions of DevOps principles, cultural values, or practices. Automation and version control are discussed, which are tangential to DevOps, but without specific alignment to DevOps philosophy, feedback loops, flow efficiency, or shared accountability within software delivery pipelines. The primary audience is content managers or technical bloggers optimizing website taxonomy, not DevOps professionals. Thus, the fit is weak, with only superficial and indirect conceptual overlap.",
    "reasoning_summary": "The content centers on AI-driven content classification and blog management, not DevOps. While automation and some practices overlap with DevOps tools, there is no substantial discussion or intent aligning with core DevOps principles. Fit is minimal and indirect.",
    "level": "Ignored"
  },
  "Product Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Management",
    "calculated_at": "2025-08-07T07:05:58",
    "ai_confidence": 42.1,
    "ai_mentions": 1.9,
    "ai_alignment": 4.7,
    "ai_depth": 5.2,
    "ai_intent": 3.8,
    "ai_audience": 3.4,
    "ai_signal": 3.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "Direct references to 'Product Management' or its frameworks are absent. The content focuses on using generative AI and scripting to automate tagging and categorisation of blog content in Hugo, with a strong emphasis on technical architecture and automation processes. Although there are elements discussing strategy around taxonomy restructuring and editorial consistency, these are more about content management and optimisation than the strategic alignment of customer needs, business objectives, and technical capabilities. Product development, user-centric alignment, or cross-functional team strategies—core to the Product Management category—are only lightly touched, chiefly as side-effects of improved taxonomy. The target audience appears to be technically inclined individuals—site owners or developers—instead of product managers or strategists. The discussion is thorough but mostly operational or technical, not focused on product management methodologies or frameworks.",
    "reasoning_summary": "The content mainly discusses technical automation of content tagging/categorisation using AI, not product management strategy. Strategic alignment, customer needs, or business goals are handled only superficially and not in the intended context of Product Management.",
    "level": "Tertiary"
  },
  "Scrum": {
    "resourceId": "oRStCAqLAY4",
    "category": "Scrum",
    "calculated_at": "2025-08-07T07:06:02",
    "ai_confidence": 19.73,
    "ai_mentions": 2.1,
    "ai_alignment": 2.5,
    "ai_depth": 2.2,
    "ai_intent": 2.9,
    "ai_audience": 3.0,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "Direct mention of 'Scrum' is present when the author shares their career background, but the content does not discuss Scrum practices, roles, or implementation in any substantive way. References to taxonomies and categorization include 'Scrum' as an example, but there is no meaningful exploration or analysis of Scrum itself. The main focus is on automation of tagging and content management using generative AI and scripting tools for a personal blog. Audience alignment and intent are weakly in-range only for those interested in content management or AI-driven classification, not Scrum practitioners. No dimension merits penalties, but the overall fit with the Scrum category is tenuous, partial, and almost incidental.",
    "reasoning_summary": "Scrum is mentioned only briefly as a background context and as an example of a category, with no in-depth discussion or alignment. The focus is automation of tagging using AI, not Scrum principles or practices. Fit with the category is minimal and incidental.",
    "level": "Ignored"
  },
  "Product Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Development",
    "calculated_at": "2025-08-07T09:26:07",
    "ai_confidence": 58.9,
    "ai_mentions": 3.9,
    "ai_alignment": 6.8,
    "ai_depth": 7.2,
    "ai_intent": 5.5,
    "ai_audience": 6.3,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 59.0,
    "reasoning": "The content discusses designing a technical classification and automation system for blog post tagging and categorisation using generative AI and PowerShell, with principles of human oversight and systematic auditability. While terms such as 'Product Development' and closely related concepts appear (e.g., iterative improvement, risk mitigation, evidence-based assessment), the piece is largely focused on the automation and editorial process for content management on a personal blog rather than directly addressing product development methodology or practices for delivering customer-facing products. There is occasional alignment to practices (e.g., alignment, continuous improvement, validation, traceability), but the primary audience is technical and editorial system creators, not product managers or cross-functional product teams. The themes partially overlap with product development (especially around process, automation, iterative refinement, evidence-based reasoning, and integration of feedback), but discussion of actual product delivery, customer outcome measurement, or strategic alignment to business goals is limited. The content is well-structured and ties in some lean, DevOps, and agile-adjacent concepts, but does not directly engage with product development lifecycle or processes as defined by the category.",
    "reasoning_summary": "The piece aligns partially with Product Development via iterative automation, traceability, and process improvement. However, it centers on blog content management, not delivering user-facing products or formal product development practices. Fit is partial but not primary.",
    "level": "Tertiary"
  },
  "Leadership": {
    "resourceId": "oRStCAqLAY4",
    "category": "Leadership",
    "calculated_at": "2025-08-07T09:26:11",
    "ai_confidence": 37.2,
    "ai_mentions": 0.8,
    "ai_alignment": 3.3,
    "ai_depth": 3.9,
    "ai_intent": 2.3,
    "ai_audience": 4.6,
    "ai_signal": 4.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on the author's technical and editorial overhaul of a blog's tagging, category structure, and AI-powered automation with a heavy emphasis on technical execution, traceability, and content management. While 'leadership' is referenced subtextually (through themes like accountability, responsibility, and human oversight vs. automation), there is little to no direct mention or in-depth discussion of leadership roles, models, adaptive strategies, or organizational/team dynamics relating to leadership. References to human accountability are primarily in the context of system correctness and editorial control vs. broader organizational or agile leadership principles. The audience seems to be individual practitioners or technical content managers, not leaders or executives focused on business agility. The intent and scope remain centered on system architecture and workflow, not leadership practice or philosophy.",
    "reasoning_summary": "The content describes technical and editorial automation, emphasizing human control and accountability but does not directly discuss leadership concepts, roles, or frameworks. Fit to the 'Leadership' category is incidental and indirect.",
    "level": "Ignored"
  },
  "Lean": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lean",
    "calculated_at": "2025-08-07T09:26:19",
    "ai_confidence": 23.45,
    "ai_mentions": 0.7,
    "ai_alignment": 2.1,
    "ai_depth": 2.7,
    "ai_intent": 2.4,
    "ai_audience": 2.1,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "The content primarily discusses the automation of blog tagging and classification using generative AI and PowerShell, focusing on technical workflow optimization, human oversight, and traceability of tagging decisions. While there are references to process improvement, transparency, and waste reduction in a very general sense, there are no explicit or implicit mentions of Lean principles, value stream mapping, waste elimination methods (such as the Seven Wastes), Lean tools, or Lean continuous improvement practices. The central theme is around content management automation and AI/human collaboration—not value creation or Lean methodologies. The alignment, depth, and mentions around Lean are minimal; any overlap is coincidental or secondary, not intentional.",
    "reasoning_summary": "This content does not fit the Lean category: it centers on AI-driven tagging workflows, not Lean principles. Lean concepts are absent both explicitly and thematically except for general process efficiency, which is non-specific and not Lean-focused.",
    "level": "Ignored"
  },
  "Engineering Excellence": {
    "resourceId": "oRStCAqLAY4",
    "category": "Engineering Excellence",
    "calculated_at": "2025-08-07T09:26:15",
    "ai_confidence": 73.95,
    "ai_mentions": 4.7,
    "ai_alignment": 7.7,
    "ai_depth": 7.2,
    "ai_intent": 7.5,
    "ai_audience": 7.9,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 74.0,
    "reasoning": "The content describes leveraging AI and scripting to automate and improve tag/category management in a Hugo blog, with strong tooling, clear processes, auditability, human oversight, automation, and quality control. It demonstrates technical process improvement and insightful reflections on operational efficiency—key tenets of modern software practices. The solution emphasizes traceability, validation layers, code reviews, and continuous improvement, all relevant to Engineering Excellence. However, there are only indirect and infrequent explicit mentions of the category or its core themes like code quality, collaborative engineering, or CI/CD. The depth is notable with some discussion of architecture, process, and practical approaches, but primary focus is on content management and classification, not core software engineering deliverables or team best practices. The audience is technical practitioners, but content is centered on pragmatic technical productivity for blog management, not wider software product engineering. The signal is strong due to practical insights, but low direct linkage to core Engineering Excellence topics slightly reduces overall scores. No obsolescence or contradictory tone detected.",
    "reasoning_summary": "Strong on automation, process, and auditability, with deep technical focus, but fits Engineering Excellence only partially. Most content centers on blog content classification, not core software engineering practices. Relevant but indirect fit.",
    "level": "Secondary"
  },
  "Technical Leadership": {
    "resourceId": "oRStCAqLAY4",
    "category": "Technical Leadership",
    "calculated_at": "2025-08-07T07:05:53",
    "ai_confidence": 31.73,
    "ai_mentions": 1.1,
    "ai_alignment": 3.9,
    "ai_depth": 4.6,
    "ai_intent": 3.3,
    "ai_audience": 3.8,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 32.0,
    "reasoning": "The content focuses primarily on the technical implementation of AI-driven tagging and categorization for a personal blog using Hugo and PowerShell. While there is some mention of 'Technical Leadership' as a category label and nods to broader editorial strategy, there is almost no substantive discussion of the key topics for technical leadership outlined in the classification (e.g., servant leadership, team guidance, DevOps practices, mentoring, agile facilitation, or decision-making alignment). The piece is instead instructional/personal and technical; it targets technical implementers and independent creators, rather than leaders of development teams. It lacks depth on leadership themes, with its intent centered more on automation and technical process than on guiding or leading teams or processes as a technical leader would. Audience fit is partial at best, and connections to technical leadership principles are tenuous and indirect.",
    "reasoning_summary": "The article is a technical walkthrough of automating blog classification using AI; 'Technical Leadership' appears mainly as a content label, not a substantive theme. Core category topics (leadership, team guidance, agile practice) are mostly absent.",
    "level": "Ignored"
  },
  "Agile Strategy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Strategy",
    "calculated_at": "2025-08-07T11:24:02",
    "ai_confidence": 41.45,
    "ai_mentions": 0.4,
    "ai_alignment": 4.4,
    "ai_depth": 4.9,
    "ai_intent": 3.7,
    "ai_audience": 6.5,
    "ai_signal": 6.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 41.0,
    "reasoning": "The content primarily focuses on using generative AI and scripts for refining content tagging and categorization in a personal blog. While it discusses strategic thinking around taxonomies, classification, and human/AI collaboration, there is minimal direct reference or alignment with organizational Agile Strategy as defined (no mention of organizational vision, agile scaling, long-term value delivery, or integrating agile principles into business strategy). The content's strategy relates more to editorial/site management than organizational agile strategy. Audience and depth are moderate due to insights on process and philosophy, but fit remains partial.",
    "reasoning_summary": "Content discusses internal taxonomies and AI-enhanced classification, not organizational Agile Strategy. Strategy is at a technical/editorial level, lacking core Agile Strategy themes. Only partial fit due to superficial thematic overlap.",
    "level": "Tertiary"
  },
  "Lean Startup": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lean Startup",
    "calculated_at": "2025-08-07T11:24:02",
    "ai_confidence": 18.96,
    "ai_mentions": 0.4,
    "ai_alignment": 2.7,
    "ai_depth": 2.6,
    "ai_intent": 3.1,
    "ai_audience": 4.0,
    "ai_signal": 3.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content—a detailed reflection on using generative AI to automate and improve tagging and categorization (in Hugo)—does not mention 'Lean Startup', MVPs, build-measure-learn cycles, validated learning, rapid experimentation, or startup-centric metrics. Its theme centers on content management automation and technical workflow improvement, with no reference to Lean Startup principles or entrepreneurial learning. No penalties applied. The audience is technical practitioners, but not particularly startup innovators seeking Lean methodology guidance. Accordingly, all scores are low.",
    "reasoning_summary": "This is a technical post about AI-driven blog categorization, not Lean Startup. No Lean principles, MVPs, or iterative validated learning are present. Does not fit the category beyond a general spirit of improvement and feedback.",
    "level": "Ignored"
  },
  "Backlog Refinement": {
    "resourceId": "oRStCAqLAY4",
    "category": "Backlog Refinement",
    "calculated_at": "2025-08-07T11:24:02",
    "ai_confidence": 11.0,
    "ai_mentions": 0.0,
    "ai_alignment": 2.3,
    "ai_depth": 2.6,
    "ai_intent": 0.9,
    "ai_audience": 2.1,
    "ai_signal": 2.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 11.0,
    "reasoning": "There are no direct mentions or thematic treatment of Backlog Refinement as practiced in Agile/Scrum. The content focuses on automating blog categorization/tagging with AI and PowerShell, which is unrelated to backlog clarity, prioritization, or refinement. Though classification, curation, and validation terms appear, they're applied to content taxonomies, not Agile backlogs. There's no discussion of user stories, prioritization for development teams, product owners, or impact on sprint planning—topics central to backlog refinement. The audience appears to be technical content creators or site admins, not Agile practitioners. Any overlap (e.g., use of 'categories', 'classification', 'prioritisation') is superficial and not about Agile teams. Thus, the fit is extremely low.",
    "reasoning_summary": "This content does not fit Backlog Refinement. It addresses AI-powered blog taxonomy, not Agile practices, user stories, or backlog management. No direct or conceptual alignment with backlog refinement or Scrum processes.",
    "level": "Ignored"
  },
  "Product Backlog": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Backlog",
    "calculated_at": "2025-08-07T11:23:39",
    "ai_confidence": 10.5,
    "ai_mentions": 0.2,
    "ai_alignment": 1.0,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 3.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content extensively discusses methods and automation to improve blog tagging and categorization but makes no direct reference to the concept, structure, or processes of a Product Backlog in Agile or Scrum. It focuses on site taxonomy, discoverability, and AI-powered content classification, not backlog management, refinement, prioritization, or relevant tooling. While the audience might overlap with technical practitioners, there is no substantive alignment with Product Backlog practices, key topics, or purpose as defined in the category. Any overlap is purely superficial (e.g., the use of prioritized lists for categories/tags), not conceptual.",
    "reasoning_summary": "Content is about AI-driven blog tagging/categorization, not Product Backlog. No mentions, concepts, or practices aligned with Agile backlog management. Only minor overlap in audience; otherwise, fit is negligible.",
    "level": "Ignored"
  },
  "Continuous Integration": {
    "resourceId": "oRStCAqLAY4",
    "category": "Continuous Integration",
    "calculated_at": "2025-09-05T03:29:12",
    "ai_confidence": 19.83,
    "ai_mentions": 0.4,
    "ai_alignment": 2.1,
    "ai_depth": 2.6,
    "ai_intent": 2.3,
    "ai_audience": 4.2,
    "ai_signal": 3.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content focuses extensively on generative AI and scripting for blog post classification, not on Continuous Integration (CI). There is only a mention in passing of 'CI/CD' as a tag example, but no exploration of CI principles, tools, workflows, or best practices. While the technical audience could overlap, the purpose, examples, and thematic alignment remain about automation for taxonomy management rather than code integration or collaborative repository management. The depth is limited to content tagging and site automation, with no discussion of code merges, automated testing, CI tools, or related CI pillars, resulting in low alignment and confidence for the CI category.",
    "reasoning_summary": "Content is about AI-powered content classification, not CI. Minimal mention of CI, with no substantive discussion on integration practices or relevant tools. Intent, topic, and examples do not fit the CI category, so confidence is low and fit is incidental at best.",
    "level": "Ignored"
  },
  "Scrum Values": {
    "resourceId": "oRStCAqLAY4",
    "category": "Scrum Values",
    "calculated_at": "2025-09-17T23:12:33",
    "ai_confidence": 9.7,
    "ai_mentions": 0.2,
    "ai_alignment": 0.4,
    "ai_depth": 0.3,
    "ai_intent": 0.3,
    "ai_audience": 1.1,
    "ai_signal": 0.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content is a technical case study on using generative AI and scripting to automate content classification in a blog CMS. It discusses general editorial principles, automation processes, governance, human vs. AI roles, and related technology, but makes no direct or indirect mention of Scrum Values or their principles (Commitment, Courage, Focus, Openness, Respect). There is only a passing reference to Scrum as one of many career experiences and no thematic alignment, depth, or intent relevant to the Scrum Values category. The content is not aimed at Scrum practitioners but rather technical and editorial process audiences.",
    "reasoning_summary": "Content is focused on technical AI-enhanced classification, not Scrum Values. No mentions or relevant discussion of Scrum Values or their intent; audience, purpose, and alignment are unrelated. Fit with the category is extremely low.",
    "level": "Ignored"
  },
  "Lean Principles": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lean Principles",
    "calculated_at": "2025-10-01T16:42:18",
    "ai_confidence": 30.47,
    "ai_mentions": 0.8,
    "ai_alignment": 3.6,
    "ai_depth": 3.9,
    "ai_intent": 2.8,
    "ai_audience": 6.5,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 30.0,
    "reasoning": "The content describes a technical workflow for automating blog classification and auditability using AI and scripting. While it references process improvement, continuous quality, and some audit/review logic reminiscent of Lean's focus on value and transparency, it does not directly mention Lean, its principles, or signature topics like waste reduction, flow, Kaizen, or Lean tools. The focus is on automation, explainability, and human/AI collaboration for site content; any connection to Lean is tangential at best, possibly echoing continuous improvement in approach only. The depth goes into system architecture, not Lean thinking, and the intent is more about efficient digital content management than about Lean methods. Thus, the fit is marginal.",
    "reasoning_summary": "The content is centered on AI-driven tag and category management in a blog, not Lean Principles. Any overlap is incidental, lacking direct references or sustained discussion of Lean concepts. Overall, the fit with Lean Principles is weak and indirect.",
    "level": "Ignored"
  },
  "Definition of Done": {
    "resourceId": "oRStCAqLAY4",
    "category": "Definition of Done",
    "calculated_at": "2025-10-01T16:58:30",
    "ai_confidence": 9.2,
    "ai_mentions": 0.0,
    "ai_alignment": 2.2,
    "ai_depth": 1.9,
    "ai_intent": 1.5,
    "ai_audience": 2.5,
    "ai_signal": 1.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content focuses exclusively on generative AI, tagging, and content classification within a static site/blogging context (Hugo, PowerShell, OpenAI). There is no mention of the Definition of Done (DoD), nor any discussion of its criteria, importance, or use in Agile/Scrum. While there are references to quality, accountability, and transparency (e.g., keeping human review, applying audit trails), these relate to editorial content management—not the DoD as defined in Agile. The intended audience is clearly content publishers and technical implementers of AI content workflows, not Agile/Scrum practitioners discussing DoD. Minimal conceptual overlap and no explicit or implicit discussion mean the fit is extremely weak.",
    "reasoning_summary": "This content does not discuss the Definition of Done or its related concepts. It focuses on AI-driven tagging and categorization for blogs, with no Agile/Scrum or DoD relevance. Fit with the category is negligible.",
    "level": "Ignored"
  },
  "Estimation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Estimation",
    "calculated_at": "2025-10-01T16:58:45",
    "ai_confidence": 18.5,
    "ai_mentions": 0.7,
    "ai_alignment": 2.1,
    "ai_depth": 2.7,
    "ai_intent": 1.5,
    "ai_audience": 5.6,
    "ai_signal": 4.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content is a detailed account of leveraging generative AI and automation for blog post tagging and categorization within Hugo. While terms like 'classification,' 'scoring,' and 'confidence' appear—which superficially resemble some estimation concepts—there is no discussion, direct or indirect, of estimation in Agile or Scrum contexts. The focus is on automated taxonomy management, auditability, and editorial control. No Agile estimation techniques, empirical forecasting, or related frameworks are mentioned. The only tangential similarity is the numeric scoring of tag classification, but this is neither intended for nor referencing backlog or effort estimation practices. The target audience overlaps with tech practitioners but not with Agile teams seeking estimation mastery.",
    "reasoning_summary": "Content does not address Agile/Scrum estimation. Numeric scoring here refers to content classification, not team estimation. No conceptual or practical fit with the Estimation category. Fit is minimal and only incidental due to superficial numeric similarities.",
    "level": "Ignored"
  },
  "Service Level Expectation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Service Level Expectation",
    "calculated_at": "2025-10-01T16:57:29",
    "ai_confidence": 2.6,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.4,
    "ai_intent": 1.0,
    "ai_audience": 4.2,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content focuses on generative AI-powered tagging and category automation for a personal blog, detailing technical implementation and benefits around traceability and editorial control. There is no discussion, mention, or application of Service Level Expectation (SLE) as defined within Agile, Scrum, or Kanban practices. The closest conceptual overlap involves procedural transparency and quality control for automated classification, which is distantly analogous to some Agile principles but has no explicit or implicit connection to SLE, its calculation, its role in workflow predictability, or any cited authoritative Agile sources. No penalties were applied, as the content is current and neutral in tone.",
    "reasoning_summary": "The content does not address Service Level Expectation (SLE) in Agile, Scrum, or Kanban contexts. It focuses strictly on AI-driven content classification, with no conceptual overlap or topical relevance to SLE.",
    "level": "Ignored"
  },
  "Test Automation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Test Automation",
    "calculated_at": "2025-10-01T16:57:24",
    "ai_confidence": 34.32,
    "ai_mentions": 0.7,
    "ai_alignment": 2.6,
    "ai_depth": 3.3,
    "ai_intent": 2.9,
    "ai_audience": 4.0,
    "ai_signal": 3.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 34.0,
    "reasoning": "The content describes automating blog tag/category assignment using generative AI and PowerShell in Hugo, focusing on content discovery and editorial curation rather than software testing automation. There is extensive discussion of process automation, auditability, and quantitative measurement. However, there are no mentions or exploration of core Test Automation topics such as software/app testing, test frameworks, automated test types (unit/integration), QA strategy, or CI/CD pipelines in a testing sense. While the methodology features multi-factor scoring, penalties, and repeatable logic (which conceptually resemble aspects of test automation), these are applied to content management rather than software testing. The intended audience is more general tech or content engineering, not specifically testers or automation engineers. The fit with Test Automation is therefore partial at best, with most references outside the category definition.",
    "reasoning_summary": "The content centers on automating content tagging/categorization using AI, not software test automation. While it uses automation concepts, it doesn't address automated software testing, making it a poor fit for the Test Automation category.",
    "level": "Ignored"
  },
  "Time to Market": {
    "resourceId": "oRStCAqLAY4",
    "category": "Time to Market",
    "calculated_at": "2025-10-01T16:58:35",
    "ai_confidence": 28.19,
    "ai_mentions": 0.7,
    "ai_alignment": 2.7,
    "ai_depth": 2.9,
    "ai_intent": 2.4,
    "ai_audience": 4.8,
    "ai_signal": 4.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 28.0,
    "reasoning": "The content focuses almost entirely on using generative AI and scripting to automate blog taxonomy (tags, categories, concepts) for better site management, discoverability, and editorial consistency. There is no explicit mention of 'Time to Market', nor are any of its key EBM-aligned metrics (lead time, cycle time, delivery speed) discussed. While it does describe improvements in workflow and efficiency, these relate to site maintenance and classification, not the rapid delivery of value to external customers or markets. Audience partially overlaps (technical, process-minded) but not with Time to Market’s focus (Agile/DevOps delivery leads). There is only a tangential conceptual fit via automation, with very shallow indirect relevance. No penalties were needed.",
    "reasoning_summary": "Content details AI-driven automation for content tagging, not Time to Market. No direct or substantive discussion of delivery speed, market readiness, or related EBM metrics. Only a minor tangential fit via workflow automation. Very weak match to category.",
    "level": "Ignored"
  },
  "Behaviour Driven Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Behaviour Driven Development",
    "calculated_at": "2025-10-01T16:57:18",
    "ai_confidence": 13.29,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.5,
    "ai_intent": 1.3,
    "ai_audience": 6.2,
    "ai_signal": 6.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content focuses on leveraging generative AI and scripting for automating blog tagging and categorisation, with substantial emphasis on editorial control, automation, technical workflow, and AI-human agency boundaries. There are no direct mentions of Behaviour Driven Development (BDD), nor is there any discussion of BDD principles, practices, tools, frameworks, or stakeholder collaboration as defined in the classification. While there is an underlying concern with clarity and traceability in classification (superficially similar to BDD’s concern with clarity in requirements), this is not tied to behaviour-driven approaches, user stories, or acceptance criteria. The intent and main themes are squarely about content management automation, not BDD. The content is technically detailed and aimed at content managers or technically oriented bloggers, not primarily those practicing or interested in BDD.",
    "reasoning_summary": "Content is unrelated to Behaviour Driven Development; its focus is on AI-powered content tagging, not aligning development processes with business objectives via BDD. No direct or conceptual fit; any overlap is coincidental and minimal.",
    "level": "Ignored"
  },
  "Remote Working": {
    "resourceId": "oRStCAqLAY4",
    "category": "Remote Working",
    "calculated_at": "2025-10-01T16:57:34",
    "ai_confidence": 11.73,
    "ai_mentions": 0.6,
    "ai_alignment": 1.6,
    "ai_depth": 1.2,
    "ai_intent": 1.2,
    "ai_audience": 3.1,
    "ai_signal": 1.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content primarily focuses on leveraging generative AI and automation (with human oversight) to improve tagging and categorization in a personal blog system. It discusses the technical implementation, philosophy of editorial control, and architecture for content classification, including using PowerShell and OpenAI. There is no direct reference to remote working or distributed Agile teams. The discussion is about personal content curation and automation, not remote team collaboration, Agile ceremonies, or tools for remote Agile work. There are no relevant examples, strategies, tools, or cultural practices related to remote working or Agile in remote environments.",
    "reasoning_summary": "The content is about AI-driven blog post classification and technical workflow automation, with no significant relevance to remote working in Agile contexts. No alignment with remote collaboration, distributed teams, or related challenges.",
    "level": "Ignored"
  },
  "Customer Satisfaction": {
    "resourceId": "oRStCAqLAY4",
    "category": "Customer Satisfaction",
    "calculated_at": "2025-10-01T16:58:50",
    "ai_confidence": 18.15,
    "ai_mentions": 0.7,
    "ai_alignment": 2.8,
    "ai_depth": 2.4,
    "ai_intent": 1.6,
    "ai_audience": 4.5,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content focuses on leveraging generative AI to improve the tagging and categorisation process for a personal blog. While it discusses classification quality, editorial control, and technical automation, there are no direct mentions or substantive exploration of customer satisfaction, its measurement, or practices to enhance end-user happiness. The target audience is practitioners interested in automation and content management, not explicitly those focused on customer outcomes or satisfaction theories in Agile or DevOps contexts. Alignment with the defined category is incidental at best—discoverability and editorial standards may impact UX, but 'customer satisfaction' as a discipline is neither named nor explored.",
    "reasoning_summary": "Content focuses on AI-based classification for blog management, not on measuring or enhancing customer satisfaction. No direct or substantial references to customer satisfaction principles, intent, or methods from Agile or DevOps. Fit is minimal and tangential.",
    "level": "Ignored"
  },
  "Pragmatic Thinking": {
    "resourceId": "oRStCAqLAY4",
    "category": "Pragmatic Thinking",
    "calculated_at": "2025-10-01T16:57:26",
    "ai_confidence": 82.25,
    "ai_mentions": 4.8,
    "ai_alignment": 8.7,
    "ai_depth": 8.3,
    "ai_intent": 8.6,
    "ai_audience": 8.2,
    "ai_signal": 8.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 82.0,
    "reasoning": "The content thoroughly details the practical application of AI to automate tagging, categorization, and taxonomy transformation in a complex, evolving blog system. While Pragmatic Thinking is not directly named, the post exemplifies this category through real-world, experience-based problem-solving, combining automation (generative AI, scripting in PowerShell/C#) with essential human validation and iterative learning. It showcases adaptability, the intertwining of automation with accountability, and lessons learned in a genuinely complex, legacy environment — all core to pragmatic thinking as defined. Concrete case study elements are present (site migration, taxonomy overhaul, audit trails), and substantial discussion is given to why each approach was chosen and its practical outcomes. The intent is to inform and empower practitioners (editors, process consultants, tech leads) with focus and relevance, robustly matching the audience. Only lesser direct naming/explicit mentions prevents a higher 'mentions' score, but all other dimensions are high. No out-of-date concepts or negative tone warranting penalties.",
    "reasoning_summary": "The content strongly fits 'Pragmatic Thinking' via practical, experience-driven AI automation of complex workflows, with a clear focus on real-world application, adaptability, and accountability. Intent, depth, and alignment are especially strong; naming is less direct.",
    "level": "Primary"
  },
  "Software Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Software Development",
    "calculated_at": "2025-10-01T16:57:24",
    "ai_confidence": 68.209,
    "ai_mentions": 4.5,
    "ai_alignment": 6.9,
    "ai_depth": 7.8,
    "ai_intent": 6.8,
    "ai_audience": 7.3,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content focuses on using generative AI and PowerShell scripting to automate classification and tagging in a Hugo blog. It covers automation, version control (using GitHub), traceable workflows, and technical architecture, which partially aligns with software development practices like automation, version control, code modularity, and quality assurance. However, its primary aim is to automate content management tasks rather than discuss software development process, engineering methodology, or SDLC directly. While it references scripting, JSON formatting, auditability, and repo management, these are applied in a content operations context (blog tagging) more than in substantive software engineering contexts. There is evidence of SD practices (e.g., auditing, modular scripts, PRs), but these support content management rather than being the core subject. The intended audience seems moderately technical (blog maintainers, developers), with a high technical signal. The depth is solid regarding automation and architecture, but less so on software development frameworks, patterns, or methodologies. No penalties are applied as the content is current, non-satirical, and not contradictory.",
    "reasoning_summary": "Content concerns automating Hugo blog classification using AI and scripts—showing some overlap with software development (automation, scripting, repo usage), but focuses on content ops, not SD methods. Fit is partial, mainly via technical implementation.",
    "level": "Secondary"
  },
  "Continuous Delivery": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Continuous Delivery",
    "calculated_at": "2025-10-31T18:34:17",
    "ai_confidence": 26.436,
    "ai_mentions": 1.3,
    "ai_alignment": 2.0,
    "ai_depth": 2.5,
    "ai_intent": 2.1,
    "ai_audience": 3.2,
    "ai_signal": 2.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 26.0,
    "reasoning": "The content focuses on automating and improving blog post categorisation using generative AI and PowerShell scripts. There are passing mentions of concepts like versioning, automation, and incremental improvements, but the main discussion is unrelated to Continuous Delivery as defined. No detailed discussion of CD principles, automated deployment pipelines, or feedback loops is present. Audience (technical implementers) may overlap somewhat, but the intent and substance revolve around content management automation, not software delivery cycles.",
    "reasoning_summary": "Content discusses AI-powered content classification, not Continuous Delivery. Automation is present but not in the CD sense. Minimal conceptual overlap and intent; fit is weak and mostly incidental.",
    "level": "Ignored"
  },
  "Company as a Product": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Company as a Product",
    "calculated_at": "2025-10-31T18:34:17",
    "ai_confidence": 20.06,
    "ai_mentions": 0.2,
    "ai_alignment": 2.3,
    "ai_depth": 2.7,
    "ai_intent": 2.8,
    "ai_audience": 6.6,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "There are no direct mentions of 'Company as a Product' or related frameworks. The content describes transforming a personal blog's tagging and categorisation using AI. While it discusses systematic, measurable approaches and references concepts like alignment with user needs and transparency, it is focused narrowly on individual content management rather than treating an organisation as a product. There is little to no discussion of organisational transformation, cross-functional teams, or customer-facing strategic objectives at the company level. The audience is more technical implementers or site owners than executive strategists. Thus, most dimensions score low for explicit relevance.",
    "reasoning_summary": "This content focuses on improving personal website tagging and categorisation using AI and oversight. It does not address organisational design or company-level strategies as per the Company as a Product category, resulting in a low confidence fit.",
    "level": "Ignored"
  },
  "Agile Values and Principles": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Agile Values and Principles",
    "calculated_at": "2025-10-31T18:34:17",
    "ai_confidence": 12.48,
    "ai_mentions": 0.6,
    "ai_alignment": 1.2,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 1.1,
    "ai_signal": 1.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content focuses on leveraging generative AI, PowerShell, and data structures to automate and improve blog tagging and classification in Hugo. It explores editorial strategy, human vs. AI agency, and technical approaches. While there are references to the thematic role of values (e.g., agency, accountability, traceability) and some domains like 'Scrum' are mentioned as an editorial category, there is no discussion or even indirect engagement with the Agile Manifesto, its principles, Agile values, or the core beliefs outlined in the classification definition. The closest alignment is the general notion of human agency and learning from reflection, but these ideas are operational/technical rather than conceptual discussions of Agile. The content is technology/process-centered, with virtually no overlap with the true core of Agile Values and Principles.",
    "reasoning_summary": "This content does not fit the 'Agile Values and Principles' category. It focuses on AI-driven classification for blog management, not on Agile beliefs, principles, or manifesto topics. Any fit is incidental or minimal.",
    "level": "Ignored"
  },
  "Market Adaptability": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Market Adaptability",
    "calculated_at": "2025-10-31T18:34:17",
    "ai_confidence": 33.08,
    "ai_mentions": 0.4,
    "ai_alignment": 2.8,
    "ai_depth": 3.2,
    "ai_intent": 2.2,
    "ai_audience": 5.5,
    "ai_signal": 5.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content primarily covers the technical automation of blog tagging and classification using AI and scripting, focusing on editorial consistency, traceability, and content management process improvements. While there are tangential mentions of process evolution (e.g., moving from DevOps/Scrum to consultancy and taxonomy intent changes), there is no substantial or direct discussion about strategies for market adaptability, organisational agility, or specific methodologies (Agile, Lean, DevOps) in a market-responsive context. The target audience overlaps with technical and process-oriented readers, but the main themes are technical optimisation and content management, not adaptation to market change. The fit is mostly tangential and does not meet the core requirements of the category.",
    "reasoning_summary": "Content is focused on using AI and scripts for editorial tagging and content management, not on strategies for adapting to market shifts or competitive pressures. Minimal direct alignment with Market Adaptability; fit is weak and mostly tangential.",
    "level": "Ignored"
  },
  "Agile Product Operating Model": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Agile Product Operating Model",
    "calculated_at": "2025-10-31T18:34:17",
    "ai_confidence": 35.35,
    "ai_mentions": 0.4,
    "ai_alignment": 3.8,
    "ai_depth": 3.2,
    "ai_intent": 2.6,
    "ai_audience": 5.7,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 35.0,
    "reasoning": "The content is a detailed narrative on deploying generative AI and scripting to optimize blog tagging and categorization in Hugo. It emphasizes automation, human oversight, and explainability in content management workflows. While it considers operational models and reflects on evolving from manual to automated classification, there is only a tangential overlap with the APOM: the content does not discuss transitioning from projects to products, principles of APOM, product operating models, or how agile and product management interlink at an organizational level. There is no mention of business/technology roadmaps, EBM, Scrum integration, value optimization, or supporting structures for product-centric agility. The intent and depth focus on content categorization frameworks and AI system oversight, not the principles or applications of an Agile Product Operating Model.",
    "reasoning_summary": "Content focuses on AI-driven content classification in Hugo, not Agile Product Operating Models. No substantive discussion on APOM principles, transition from project to product, or organizational agility. Fit is only tangential and not core.",
    "level": "Ignored"
  },
  "Product Discovery": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Product Discovery",
    "calculated_at": "2025-10-31T18:34:23",
    "ai_confidence": 24.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.3,
    "ai_depth": 2.8,
    "ai_intent": 2.1,
    "ai_audience": 7.2,
    "ai_signal": 5.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 25.0,
    "reasoning": "The content focuses on automating site tagging and categorisation using generative AI and PowerShell, with an emphasis on workflow, classification strategy, technical scripts, and governance. While it discusses improving discoverability and aligning tags/categories with user needs, these topics are addressed from a content management and technical automation viewpoint, not from a Product Discovery perspective as defined (identifying customer needs, validating ideas, feature discovery, user research, MVP, etc.). There are no direct or indirect discussions around user research, customer feedback, product feature definition, or validation frameworks. Some fleeting alignment exists in improving user experience/discoverability, but overall, the content does not address the core methods, audience, or intent associated with Product Discovery. The audience is more technical (content managers, automation practitioners) versus strategists or those seeking to understand customer needs for new product features.",
    "reasoning_summary": "The content primarily details technical automation for tagging/categorisation, not product discovery. It lacks focus on user research, feature validation, or understanding customer needs. Alignment with 'Product Discovery' is minimal and mostly tangential.",
    "level": "Ignored"
  },
  "Entrepreneurship": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Entrepreneurship",
    "calculated_at": "2025-10-31T18:34:24",
    "ai_confidence": 27.92,
    "ai_mentions": 0.3,
    "ai_alignment": 2.6,
    "ai_depth": 3.5,
    "ai_intent": 2.8,
    "ai_audience": 4.3,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 28.0,
    "reasoning": "The content focuses on the technical and workflow aspects of using generative AI and PowerShell for blog post classification and site tagging. There is no explicit mention of entrepreneurship or its core concepts such as innovation, risk-taking in business, value creation, or strategies for building ventures. While the author demonstrates initiative and problem-solving, these are not framed within the entrepreneurial process. The audience skews toward technical practitioners interested in automation and content management, not entrepreneurs or those seeking guidance on entrepreneurship. As such, both the direct and conceptual links to entrepreneurship are weak and incidental.",
    "reasoning_summary": "Content details AI-powered blog tagging strategies but does not discuss entrepreneurship, innovation, or business-building. Its purpose and audience are technical, not entrepreneurial. Fit with the category is marginal at best, with only indirect relevance.",
    "level": "Ignored"
  },
  "Hypothesis Driven Development": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Hypothesis Driven Development",
    "calculated_at": "2025-10-31T18:34:26",
    "ai_confidence": 31.45,
    "ai_mentions": 0.7,
    "ai_alignment": 3.3,
    "ai_depth": 3.7,
    "ai_intent": 2.8,
    "ai_audience": 5.2,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 31.0,
    "reasoning": "The content gives a detailed account of using generative AI and PowerShell to automate content tagging with human oversight but does not discuss hypothesis formulation, conducting experiments, validated learning, or iterative experimentation based on data. While there are mentions of automation, traceability, and improvement cycles, these relate to engineering workflows rather than the hypothesis-driven experimentation integral to Hypothesis Driven Development. No explicit reference is made to hypothesis testing, metrics for validation, or learning loops; the themes are oriented to technical implementation, not structured product discovery or validated learning. The potential audience is somewhat aligned (technical/process practitioners), but the majority of content is off-topic regarding the precise definition of Hypothesis Driven Development.",
    "reasoning_summary": "Content focuses on AI-driven tagging automation and workflow, not hypothesis creation or experiments. Lacks key elements of Hypothesis Driven Development such as validated learning or empirical product experiments. Fit is weak and mostly tangential.",
    "level": "Ignored"
  },
  "Digital Transformation": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Digital Transformation",
    "calculated_at": "2025-10-31T18:34:37",
    "ai_confidence": 67.9,
    "ai_mentions": 3.7,
    "ai_alignment": 6.8,
    "ai_depth": 7.3,
    "ai_intent": 6.0,
    "ai_audience": 7.5,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content centers on applying generative AI and automation (PowerShell, OpenAI) to overhaul a personal blog's tagging, categorization, and governance process. While it discusses leveraging digital tools to significantly enhance workflow, traceability, and editorial efficiency—principles associated with Digital Transformation—the focus is narrowly on optimizing individual content management rather than organizational business transformation. It lacks discussion on wider strategic or cultural shifts, change management, or direct business agility impact. There are some overlaps—such as the narrative of automation, measurable improvement, and blending AI with human oversight—but these reside at the level of technical enablement for a specific process, not enterprise-scale transformation. The intended audience aligns (practitioners, strategists), and the explanation is thorough, but the context remains mostly personal/technical over strategic/organizational.",
    "reasoning_summary": "Content broadly aligns (AI, automation, measurable improvement), but focuses on personal technical workflow, not business-wide digital transformation. Fit is partial: shares methods, not full strategic scope of the category.",
    "level": "Secondary"
  },
  "Shift Left Strategy": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Shift Left Strategy",
    "calculated_at": "2025-10-31T18:34:38",
    "ai_confidence": 18.84,
    "ai_mentions": 0.2,
    "ai_alignment": 2.3,
    "ai_depth": 2.1,
    "ai_intent": 2.5,
    "ai_audience": 7.0,
    "ai_signal": 5.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content describes applying generative AI to automate tagging and categorisation of a blog using Hugo, along with PowerShell scripting and a metrics-driven approach for content management. While the author emphasises early, automated, and auditable decisions within their process, these are related to editorial and metadata workflows rather than shifting quality controls (testing, security, compliance) earlier in software development. There are no direct mentions or focused discussions of the Shift Left Strategy or its principles as it applies within software development lifecycles. The intent is to showcase technical, traceable automation for content management, not to discuss software quality assurance, compliance, or defect prevention. Audience alignment is moderate because the technical depth could appeal to practitioners, but the main theme is content management automation, not software lifecycle improvement. Relevance to the Shift Left Strategy is minimal and mostly coincidental; no penalty applied because there is no outdated or contradictory content.",
    "reasoning_summary": "Content is about AI-powered automation in blog tagging and categorisation, not integrating testing, security, or compliance earlier in development, so it is only minimally aligned with Shift Left Strategy. Fit is mostly unrelated and coincidental.",
    "level": "Ignored"
  },
  "Azure Repos": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Azure Repos",
    "calculated_at": "2025-11-10T14:44:01",
    "ai_confidence": 1.9,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.2,
    "ai_intent": 0.3,
    "ai_audience": 3.0,
    "ai_signal": 1.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content focuses on using generative AI and PowerShell to automate tagging and categorization of blog content on Hugo, with some discussion of using GitHub for version control. There is no explicit or implicit reference to Azure Repos, its features, or its role in source control, CI/CD, or related DevOps practices. The single mention of versioning and pull requests is in a generic GitHub context and unrelated to Azure Repos. The audience, while technical, is not targeted toward Azure Repos users nor does the content address Azure Repos-specific best practices, integration, or functionalities. The content is almost entirely off-topic for this category.",
    "reasoning_summary": "Content is unrelated to Azure Repos; no mention or discussion of its features, practices, or integration. Focus is on AI-driven classification in Hugo and GitHub—not Azure Repos. Fit for category is minimal to none.",
    "level": "Ignored"
  },
  "Team Collaboration": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Team Collaboration",
    "calculated_at": "2025-11-10T14:44:27",
    "ai_confidence": 19.97,
    "ai_mentions": 0.7,
    "ai_alignment": 2.7,
    "ai_depth": 2.9,
    "ai_intent": 2.2,
    "ai_audience": 6.3,
    "ai_signal": 5.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content is focused on using AI and scripting to automate blog tagging and categorization. There are no direct mentions or substantive discussion of teamwork, shared ownership, communication, or team collaboration within Agile, Scrum, or DevOps. While the technical audience could overlap with those interested in team collaboration, this piece is almost entirely about individual content management and automation processes. Although it references transparency, auditability, and controlled oversight, these are framed as aspects of individual accountability, not as components of collaborative team dynamics. No examples or strategies for improving team collaboration, trust-building, cross-functionality, or team performance are given.",
    "reasoning_summary": "The content does not discuss team collaboration, dynamics, or practices within Agile, Scrum, or DevOps. It focuses on individual automation and content management, not teamwork. Category fit is minimal and largely tangential.",
    "level": "Ignored"
  },
  "Agile Product Management": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Agile Product Management",
    "calculated_at": "2025-11-10T14:43:57",
    "ai_confidence": 33.9,
    "ai_mentions": 0.4,
    "ai_alignment": 3.5,
    "ai_depth": 3.2,
    "ai_intent": 2.6,
    "ai_audience": 5.1,
    "ai_signal": 3.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 34.0,
    "reasoning": "The content primarily discusses leveraging generative AI and PowerShell scripts to automate tag/category management for improved discoverability and editorial consistency in a personal blog using Hugo. While themes like editorial curation, classification strategy, and AI-assisted optimization are explored in-depth, there is minimal, indirect overlap with the principles of Agile Product Management as defined (i.e., product vision alignment, backlog prioritization, continuous delivery, stakeholder collaboration, customer feedback incorporation). The article mentions some experience with DevOps and Scrum, and alludes to concepts like value and strategy at a taxonomic level, but does not focus on product value maximization, product ownership, or agile delivery. The target audience seems to be technical content site maintainers rather than Agile product practitioners. Signal is diluted by technical implementation details unrelated to product management under an agile philosophy.",
    "reasoning_summary": "The content focuses on automating website tagging/categorization using AI, not on agile product management. Only minimal, tangential overlap exists with the category’s themes. Intent and audience do not primarily align; fit is low and mostly incidental.",
    "level": "Ignored"
  },
  "Large Scale Agility": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Large Scale Agility",
    "calculated_at": "2025-11-10T14:44:31",
    "ai_confidence": 16.69,
    "ai_mentions": 0.3,
    "ai_alignment": 2.4,
    "ai_depth": 1.8,
    "ai_intent": 2.1,
    "ai_audience": 4.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 17.0,
    "reasoning": "The content discusses the use of generative AI and scripting to automate tagging and categorization for a personal blog, emphasizing process transparency and human oversight. There is no mention or coverage of large-scale agile frameworks (SAFe, LeSS, Nexus), nor does the discussion address enterprise-level scaling, cross-team alignment, or agile transformation at organizational scale. The discussion is grounded in individual site management and content classification practices, not in principles or practices of scaling Agile methodologies. The intended audience appears to be technical content managers or individual practitioners automating workflows, not executives, agile coaches, or enterprise strategists. There is minimal relevance to the concerns of Large Scale Agility, with only a loose conceptual overlap in process improvement and automated workflows at a very small scale.",
    "reasoning_summary": "Content does not fit 'Large Scale Agility.' It focuses on single-site automation and tagging, with no references to scaling agile practices, enterprise frameworks, or cross-team collaboration. Only minimal overlap in process improvement at a non-enterprise scale.",
    "level": "Ignored"
  },
  "Engineering Practices": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Engineering Practices",
    "calculated_at": "2025-11-10T14:44:02",
    "ai_confidence": 46.1,
    "ai_mentions": 1.8,
    "ai_alignment": 4.3,
    "ai_depth": 5.7,
    "ai_intent": 5.2,
    "ai_audience": 7.1,
    "ai_signal": 5.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 46.0,
    "reasoning": "The content focuses on automating content tagging and categorization in a Hugo-based blog using AI and PowerShell scripts. While it demonstrates automation, scripting, and technical rigor, the primary theme is not core Agile engineering practices like clean code, TDD, CI/CD, or pair programming. The process practices mentioned pertain more to content management, not foundational software engineering principles. The target audience is technical, and PowerShell scripting suggests some engineering overlap, but the main purpose is not advancing or exemplifying Agile engineering practices as defined in the category. Some techniques (e.g., script automation, auditability, using GitHub for code reviews) have peripheral relevance to engineering best practices, justifying mid-range depth/intention scores, but overall the fit is partial.",
    "reasoning_summary": "Content is about automating content classification and auditability using scripts and AI—not core Agile engineering practices. While it uses automation and technical rigor, it does not address clean code, TDD, CI/CD, or refactoring directly; fit is partial and peripheral.",
    "level": "Tertiary"
  },
  "Customer Feedback Loops": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Customer Feedback Loops",
    "calculated_at": "2025-11-10T14:44:30",
    "ai_confidence": 16.389,
    "ai_mentions": 0.7,
    "ai_alignment": 2.6,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 5.2,
    "ai_signal": 3.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "This content details automating blog post classification using AI and PowerShell in Hugo. While it mentions integrating 'human oversight' and reviewing results, none of this refers to collecting, analysing, or acting on customer/user feedback. The discussion centers on internal editorial consistency, automation, and content strategy, not mechanisms for input from users or feeding end-user/customer insight into development or improvement. There is reference to alignment with 'user needs' at a broad category design level, but this is distinct from genuine customer feedback loop mechanisms as defined by the category. Audience alignment to website managers is partial but tangential to those focused on customer feedback loops.",
    "reasoning_summary": "The content focuses on AI-driven internal tagging and classification with human oversight, not on collecting or integrating customer or user feedback. There is little conceptual or practical overlap with customer feedback loop processes.",
    "level": "Ignored"
  },
  "Troubleshooting": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Troubleshooting",
    "calculated_at": "2025-11-10T14:44:35",
    "ai_confidence": 30.44,
    "ai_mentions": 0.7,
    "ai_alignment": 2.4,
    "ai_depth": 2.0,
    "ai_intent": 2.2,
    "ai_audience": 3.1,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 30.0,
    "reasoning": "The content focuses on how generative AI and PowerShell scripts automate tagging and categorisation for a blog, with strong emphasis on content architecture, automate/manual workflow, and classification auditability—not technical troubleshooting. There are passing mentions of pain points in legacy systems (e.g., updating old categories/tags), but no substantive exploration of issue diagnosis, tools or techniques for resolving system or software problems, or methodologies for systematic troubleshooting. The intent is tied to automation, editorial consistency, and transparent workflows, not identification or resolution of technical faults. The audience is somewhat technical but not clearly targeting troubleshooters or those seeking diagnosis/resolution of system issues. Most of the text is descriptive rather than problem-solving, and no troubleshooting case studies or frameworks are presented.",
    "reasoning_summary": "Content centers on automating and improving blog tagging/categorisation, not diagnosing or resolving system issues. No substantive troubleshooting concepts, techniques, or practices are explored. Fit for the 'Troubleshooting' category is minimal and mostly incidental.",
    "level": "Ignored"
  },
  "Agile Leadership": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Agile Leadership",
    "calculated_at": "2025-11-10T14:44:36",
    "ai_confidence": 24.05,
    "ai_mentions": 0.2,
    "ai_alignment": 2.9,
    "ai_depth": 2.6,
    "ai_intent": 2.7,
    "ai_audience": 3.0,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content exclusively details a technical system for automated content classification using generative AI and scripting, focused on tagging, categorisation, traceability, and process automation. Leadership in an Agile context, including team empowerment, organisational change, or fostering Agile culture, is neither discussed nor implied in a relevant way. There are brief references to processes, accountability, and human/AI collaboration, but these revolve around editorial decisions rather than any leadership behaviours, roles, or frameworks aligned with Agile Leadership. The primary audience is technical practitioners or site owners interested in automation, not Agile leaders. Signal is moderately relevant to technical leadership/automation, not to Agile Leadership specifically.",
    "reasoning_summary": "Content centers on automating tagging/classification with generative AI for blogs, not on leadership roles, empowerment, or Agile culture. Minimal conceptual and audience overlap with Agile Leadership—fit is weak and mostly indirect.",
    "level": "Ignored"
  },
  "Revenue per Employee": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Revenue per Employee",
    "calculated_at": "2025-11-10T14:44:05",
    "ai_confidence": 9.65,
    "ai_mentions": 0.1,
    "ai_alignment": 0.7,
    "ai_depth": 0.8,
    "ai_intent": 0.3,
    "ai_audience": 3.2,
    "ai_signal": 0.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content meticulously describes the use of generative AI for automated tagging and categorisation in a personal blog using Hugo, PowerShell, and human oversight. However, it does not mention or discuss the Revenue per Employee metric, its calculation, interpretation, or use as a financial observability signal. There is no financial benchmarking, workforce efficiency analysis, or mention of organisational throughput. The main focus is entirely on AI-supported content classification rather than empirical financial or workforce metrics. The only tangential link is a vague parallel—multi-factor scoring—but there is no direct or meaningful thematic connection. The audience is technical but not financial or executive. All scoring dimensions reflecting relevance are extremely low.",
    "reasoning_summary": "This content does not fit the Revenue per Employee category; it never references financial metrics, workforce efficiency, or related analysis. Its focus is solely on AI-driven content classification, not organisational financial performance.",
    "level": "Ignored"
  },
  "Trend Analysis": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Trend Analysis",
    "calculated_at": "2025-11-10T14:44:06",
    "ai_confidence": 26.01,
    "ai_mentions": 0.6,
    "ai_alignment": 2.4,
    "ai_depth": 2.5,
    "ai_intent": 1.8,
    "ai_audience": 2.7,
    "ai_signal": 2.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 26.0,
    "reasoning": "The content details a technical case study on automating blog categorisation using generative AI and PowerShell, focusing on editorial taxonomy improvements, automation, and human oversight. There are some passing mentions of shifts in classification strategies and future intentions to track classification shifts over time, but there is little focus on analysing historical or emerging trends in Agile, DevOps, or business agility frameworks as defined by the category. The primary aim is process optimisation at the site level, not strategic trend identification or informing organisational decision-making. Trend-related signals (like mentioning the intent to track classification shifts) are brief and undeveloped, and examples given pertain specifically to the author's blog infrastructure. Thus, the fit is marginal at best. The content is notably more relevant to automation, AI-assistance, or classification tooling than to formal trend analysis.",
    "reasoning_summary": "Content is focused on AI-enabled tagging/categorisation automation, with only brief future-oriented references to tracking classification shifts. It does not analyse trends in Agile, DevOps, or business agility. Fit to Trend Analysis category is very low.",
    "level": "Ignored"
  },
  "Azure Pipelines": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Azure Pipelines",
    "calculated_at": "2025-11-24T18:56:45",
    "ai_confidence": 20.5,
    "ai_mentions": 1.3,
    "ai_alignment": 2.8,
    "ai_depth": 2.2,
    "ai_intent": 2.6,
    "ai_audience": 5.7,
    "ai_signal": 3.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content briefly mentions 'Azure Pipelines' as an example of a tag but does not discuss Azure Pipelines or any related CI/CD practices, concepts, or implementation details. The main subject is the use of generative AI and PowerShell for blog tag/category management in Hugo, which is unrelated to Azure Pipelines. There is no exploration of configuration, management, integration, or best practices for Azure Pipelines; the audience, purpose, and depth all align with content classification automation, not CI/CD pipelines on Azure. Scores are low in all areas except partial audience overlap, as technical readers might also be interested in Azure, but the topic itself is not a fit.",
    "reasoning_summary": "Does not fit the Azure Pipelines category—only an incidental mention as a tag. No discussion of Azure Pipelines usage, concepts, or configuration. Focus is on AI-driven site content classification, not CI/CD or DevOps pipelines.",
    "level": "Ignored"
  },
  "Change Management": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Change Management",
    "calculated_at": "2025-11-24T18:56:45",
    "ai_confidence": 36.66,
    "ai_mentions": 1.4,
    "ai_alignment": 3.1,
    "ai_depth": 3.6,
    "ai_intent": 2.4,
    "ai_audience": 3.5,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on using generative AI and scripting to automate tagging and categorisation in a personal blog built with Hugo. While it discusses improving and iterating editorial taxonomies and introduces transparent decision processes, these efforts pertain to local content workflow, not organisational change. There are no explicit references to change management practices, strategies for fostering adaptability within teams, resistance management, or aligning transformations with Agile/DevOps principles. Any alignment is superficial, as the article is chiefly about automation, technical implementation, and responsible AI use for content classification. The audience is mainly developers or solo content managers, not organisational stakeholders. Thus, the match to 'Change Management' is weak and mostly incidental.",
    "reasoning_summary": "The content is about technical automation and responsible AI use for tagging, not about organisational change. There is minimal conceptual or audience overlap with Change Management; fit is incidental rather than intentional.",
    "level": "Ignored"
  },
  "Asynchronous Development": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Asynchronous Development",
    "calculated_at": "2025-11-24T18:56:45",
    "ai_confidence": 18.41,
    "ai_mentions": 0.3,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 2.2,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content provides a deep dive into using AI and automation with PowerShell to improve tagging and classification on a Hugo blog. While it discusses technical automation, auditability, and technical workflow improvements, it does not mention nor meaningfully align with the principles, practices, or challenges of asynchronous development. There is no exploration of distributed or asynchronous team collaboration, no discussion of asynchronous tools or workflows relevant to team-based software development, and the audience focus is on solo site management and technical implementation, not cross-timezone teamwork. The match to asynchronous development is almost entirely absent except for some brief allusions to automation and version control which could, in an extremely broad sense, play minor supporting roles in asynchronous contexts, but these are not the intent nor focus of this piece.",
    "reasoning_summary": "Content focuses on AI-driven tagging automation and site management, not asynchronous development. No relevant discussion of remote teamwork, asynchronous practices, workflows, or principles. Only superficial technical overlap; category fit is poor.",
    "level": "Ignored"
  },
  "Lead Time": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Lead Time",
    "calculated_at": "2025-11-24T19:11:47",
    "ai_confidence": 6.6,
    "ai_mentions": 0.3,
    "ai_alignment": 0.7,
    "ai_depth": 0.7,
    "ai_intent": 1.1,
    "ai_audience": 2.0,
    "ai_signal": 1.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content extensively covers generative AI for site tagging/classification, using metrics for content fit and auditability. However, it never references Lead Time, nor discusses process efficiency, delivery speed, or flow metrics central to the Lead Time category. Audience, intent, and depth are all unrelated to measuring or optimising Lead Time; any reference to metrics is strictly for content classification, not workflow delivery.",
    "reasoning_summary": "Content focuses solely on automated content categorisation using AI, not Lead Time. No substantive links to delivery timelines, flow metrics, or process efficiency. No fit with the Lead Time category definition.",
    "level": "Ignored"
  },
  "Install and Configuration": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Install and Configuration",
    "calculated_at": "2025-11-24T18:56:45",
    "ai_confidence": 20.32,
    "ai_mentions": 1.7,
    "ai_alignment": 2.6,
    "ai_depth": 2.4,
    "ai_intent": 2.8,
    "ai_audience": 5.1,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content centers on using AI and PowerShell to automate tagging and categorization in Hugo. While it includes technical details (tools, scripting, data flows), it does not provide step-by-step installation or configuration instructions for Hugo, PowerShell, or the AI integration. There are no explicit guides or troubleshooting on software setup, security, or best configuration practices. The focus is on architecture, workflow, and the human/AI process for classification rather than how to install or configure software components. Audience alignment is moderate because practitioners interested in scripting or automation may find value, but the content is conceptual/architectural, not directly a resource for install/configuration tasks. The signal to noise is low for this category as most content is about process and results, not technical setup.",
    "reasoning_summary": "Content describes architecture, automation, and workflow design for AI-powered blog classification in Hugo, not installation or configuration processes. Fit with the category is low due to lack of detailed setup instructions or configuration guidance.",
    "level": "Ignored"
  },
  "Automated Testing": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Automated Testing",
    "calculated_at": "2025-11-24T18:58:55",
    "ai_confidence": 28.72,
    "ai_mentions": 0.6,
    "ai_alignment": 3.7,
    "ai_depth": 3.6,
    "ai_intent": 3.4,
    "ai_audience": 3.2,
    "ai_signal": 2.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 29.0,
    "reasoning": "The content details the automation of blog post tagging and classification, leveraging generative AI and PowerShell scripts for content management in Hugo. While extensively discussing automation, data pipelines, audit trails, classification logic, and human oversight, there is no meaningful mention or discussion of software Automated Testing practices, types (unit, integration, functional), tools, CI/CD, or related quality measures. Automated processes described are for metadata assignment and content management, not for software test automation. The intent, themes, and audience (content managers and AI practitioners) diverge from Automated Testing's core domain.",
    "reasoning_summary": "Content is about automating site tagging/classification using AI and scripting, not about software Automated Testing. No coverage of test types, frameworks, or quality practices; themes and intent do not fit the category beyond the concept of automation itself.",
    "level": "Ignored"
  },
  "Product Delivery": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Product Delivery",
    "calculated_at": "2025-11-24T18:56:47",
    "ai_confidence": 37.36,
    "ai_mentions": 0.7,
    "ai_alignment": 2.2,
    "ai_depth": 2.9,
    "ai_intent": 1.1,
    "ai_audience": 3.0,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study about automating blog post classification using generative AI and PowerShell within a static site workflow. It does not directly discuss software product delivery practices, integrating planning, development, testing, deployment, or customer value delivery. Although concepts like automation, tagging, categories, and auditability are discussed, they are scoped to personal content management—not the broader product delivery context described by the category. There is only the faintest overlap (e.g., mentions of CI/CD, DevOps—as tags—but not as process discussion), and no treatment of product team collaboration, release management, or feedback loops. The target audience is technical/content managers rather than practitioners in software product delivery. The signal-to-noise ratio for the category is low; most material focuses on AI-powered metadata handling rather than the delivery of usable software products.",
    "reasoning_summary": "Content focuses on automating content classification for a blog using AI, not software product delivery. Only minimal peripheral overlap (e.g., DevOps as a tag) appears—core product delivery themes are absent. Low fit with the category.",
    "level": "Ignored"
  },
  "Definition of Ready": {
    "resourceId": "oRStCAqLAY4",
    "category": "Definition of Ready",
    "calculated_at": "2025-05-07T12:53:39",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.0,
    "ai_depth": 1.2,
    "ai_intent": 0.8,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There are no direct mentions of the Definition of Ready (DoR), nor is there any discussion of DoR criteria, its role in Agile, or related practices. The main focus is on information architecture (tags, categories, concepts), automation, auditability, and human oversight in content classification. While the content does discuss the importance of clarity, traceability, and editorial standards in classification, these are not framed in the context of backlog item readiness or Agile sprint planning. The audience is technical practitioners, which partially overlaps with the DoR category, but the intent and substance are not aligned. The signal-to-noise ratio is moderate, as the content is focused but off-topic for DoR. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence that this content fits under 'Definition of Ready' is very low.",
    "level": "Ignored"
  },
  "Organisational Agility": {
    "resourceId": "oRStCAqLAY4",
    "category": "Organisational Agility",
    "calculated_at": "2025-05-07T12:53:45",
    "ai_confidence": 41.7,
    "ai_mentions": 0.7,
    "ai_alignment": 4.2,
    "ai_depth": 4.8,
    "ai_intent": 3.9,
    "ai_audience": 5.2,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content is a detailed technical case study of using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There is a strong focus on automation, data architecture, technical scripting, and the integration of AI with human oversight for editorial control. While the post discusses concepts such as adaptability, continuous improvement, and the blending of automation with human judgment, these are framed in the context of personal content management rather than organisational strategy or agility. There are no direct mentions of 'Organisational Agility' or explicit references to agile methodologies, leadership, or organisational structures. The main ideas and depth are technical and operational, not strategic or cultural as required by the category. The intent is to inform technical practitioners or bloggers about automating classification, not to guide organisations in becoming more agile. The audience is more technical than executive or organisational, and the signal-to-noise ratio is moderate, with most content focused on implementation details rather than agility principles. No penalties were applied as the content is current and not critical of agility, but overall, the fit with 'Organisational Agility' is weak, resulting in a low confidence score.",
    "level": "Tertiary"
  },
  "Test First Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Test First Development",
    "calculated_at": "2025-05-07T12:53:50",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.5,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of Test First Development, nor are its principles, practices, or key topics discussed. The main focus is on classification, automation, human oversight, and auditability in content management, not on defining success criteria before implementation or on testing practices (manual or automated). The only tangential overlap is the mention of 'penalty and validation rules' and 'deterministic enforcement,' which are generic quality control mechanisms, not Test First practices. The audience is technical, but the subject matter is not aligned with Test First Development. The signal-to-noise ratio is moderate, as the content is focused but off-topic for this category. No penalties were applied, as the content is not outdated or critical of the category. Overall, the confidence score is very low, reflecting the lack of relevance to Test First Development.",
    "level": "Ignored"
  },
  "Social Technologies": {
    "resourceId": "oRStCAqLAY4",
    "category": "Social Technologies",
    "calculated_at": "2025-05-07T12:53:57",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.2,
    "ai_audience": 5.0,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily details the technical and architectural process of automating blog post tagging and categorisation using generative AI and PowerShell scripts. While there are some conceptual overlaps with Social Technologies—such as the emphasis on transparency, traceability, and the blend of AI suggestions with human oversight—these are not the main focus. The content does not directly discuss frameworks or methodologies that promote collaboration, collective intelligence, or self-organisation within teams or organisations. There is no explicit mention of Social Technologies or their key topics (e.g., team dynamics, emergent problem-solving, or organisational culture). The audience is likely technical practitioners interested in automation and content management, which only partially overlaps with the Social Technologies category. The discussion of human vs. AI agency and the importance of accountability does touch on relevant themes, but the depth and intent are more technical and process-oriented than socially transformative. The signal-to-noise ratio is moderate, as most content is focused on technical implementation rather than social frameworks. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score reflects that while there are some tangential connections, the content does not substantially fit under Social Technologies.",
    "level": "Tertiary"
  },
  "Flow Efficiency": {
    "resourceId": "oRStCAqLAY4",
    "category": "Flow Efficiency",
    "calculated_at": "2025-05-07T12:54:03",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 7.1,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts, with an emphasis on human oversight and auditability. There are no direct mentions of 'Flow Efficiency' or its key concepts such as value stream throughput, bottleneck elimination, WIP limits, or Lean/Agile flow metrics. The main ideas revolve around information architecture, technical implementation, and responsible AI use in content management, which are not conceptually aligned with the optimisation of work throughput or flow efficiency. The depth of discussion is substantial regarding classification automation and technical strategy, but not in relation to flow efficiency. The intent is to inform about AI-driven classification, not to address flow efficiency. The audience (technical practitioners, site owners) partially overlaps with those interested in flow efficiency, but the content is not targeted at Lean/Agile or DevOps process optimisation. The signal-to-noise ratio is high for its actual topic, but almost none of the content is relevant to flow efficiency. No penalties were applied as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Flow Efficiency' is very low.",
    "level": "Ignored"
  },
  "Deployment Frequency": {
    "resourceId": "oRStCAqLAY4",
    "category": "Deployment Frequency",
    "calculated_at": "2025-05-07T12:54:08",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of deployment frequency, nor are there discussions about optimising software deployment intervals, CI/CD, or Agile/DevOps release practices. The main themes are content management, classification, automation, and human oversight in editorial workflows. While there are tangential references to DevOps and process consulting in the author's background, these are not explored in the context of deployment frequency. The audience is technical, but the subject matter is not aligned with the deployment frequency category. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant topic. No penalties were applied, as the content is not outdated or critical of the category. Overall, the confidence score is very low, reflecting the lack of relevance to Deployment Frequency.",
    "level": "Ignored"
  },
  "Scaling": {
    "resourceId": "oRStCAqLAY4",
    "category": "Scaling",
    "calculated_at": "2025-05-07T12:54:14",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 5.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo-based static site. There is no direct mention of scaling frameworks (e.g., SAFe, LeSS, Nexus), nor are there discussions about coordinating multiple teams, cross-team collaboration, or enterprise-level alignment. The main themes are technical automation, editorial consistency, and human-AI collaboration for content management, which are unrelated to the complexities of scaling Agile practices. The depth of discussion is substantial for its own topic (content classification automation), but not for scaling as defined. The intent is to inform practitioners about AI-driven content management, not to address scaling challenges. The audience is technical (developers, site maintainers), which partially overlaps with scaling audiences, but the focus is not on enterprise or multi-team coordination. The signal-to-noise ratio is moderate, as the content is focused but not on the scaling category. No penalties were applied as the content is current and not critical of the scaling category. Overall, the confidence that this content fits under 'Scaling' is very low.",
    "level": "Ignored"
  },
  "Artificial Intelligence": {
    "resourceId": "oRStCAqLAY4",
    "category": "Artificial Intelligence",
    "calculated_at": "2025-05-07T12:54:23",
    "ai_confidence": 91.7,
    "ai_mentions": 8.7,
    "ai_alignment": 9.6,
    "ai_depth": 9.3,
    "ai_intent": 9.2,
    "ai_audience": 8.8,
    "ai_signal": 9.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content directly and repeatedly references Artificial Intelligence (AI), specifically generative AI and OpenAI, as the core technology enabling the transformation of site tagging and categorisation. The main theme is the integration of AI into a software development workflow (Hugo static site generator, PowerShell scripting), with a strong focus on automation, human oversight, and transparent audit trails. The discussion is highly aligned with the category definition: it explores how AI is used to automate and improve content classification, describes technical architecture, and details the blend of AI-driven suggestions with human validation. The depth is substantial, covering architectural decisions, data structures, validation logic, and future enhancements, all within the context of AI's role in software process improvement. The intent is clearly to inform practitioners about responsible, effective AI integration in a technical workflow, matching the category's purpose. The audience is technical (developers, DevOps, process consultants), which fits the category's target. The signal-to-noise ratio is high, with nearly all content focused on the application of AI in this context. No penalties are warranted: the content is current, constructive, and does not contradict the category's framing. Overall, the confidence score is very high due to the explicit, in-depth, and relevant discussion of AI's application in software development processes.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the category, as it thoroughly explores how AI—specifically generative models—enhances content classification within a technical workflow. It details the integration of AI with development tools, highlights automation balanced by human oversight, and is clearly aimed at a technical audience, making it highly relevant and informative for practitioners in this space."
  },
  "Value Stream Mapping": {
    "resourceId": "oRStCAqLAY4",
    "category": "Value Stream Mapping",
    "calculated_at": "2025-05-07T12:54:28",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 5.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of Value Stream Mapping (VSM), nor are its principles, steps, or techniques discussed. The main ideas revolve around content classification, automation, and editorial oversight, which are not conceptually aligned with VSM's focus on visualising and optimising the flow of value in a process. The depth of discussion is substantial regarding AI-driven classification and technical architecture, but none of this relates to mapping or improving value streams. The intent is to inform about AI-powered content management, not VSM. The audience is technical, which partially overlaps with VSM practitioners, but the subject matter is not relevant to those seeking VSM insights. The signal-to-noise ratio is moderate, as the content is focused but off-topic for this category. No penalties were applied, as the content is current and not critical of VSM. Overall, the confidence score is very low, reflecting the lack of relevance to Value Stream Mapping.",
    "level": "Ignored"
  },
  "Market Share": {
    "resourceId": "oRStCAqLAY4",
    "category": "Market Share",
    "calculated_at": "2025-05-07T12:54:33",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of 'market share' or any explicit discussion of strategies, methodologies, or metrics related to increasing a product's market presence or competitive advantage. The main themes are technical automation, editorial consistency, and human-AI collaboration for content management. While there is a brief mention of promoting some tags to categories 'for marketing purposes,' this is not explored in the context of market share, competitive analysis, or audience expansion. The depth of discussion is focused on technical implementation, not on market positioning or share. The intended audience is technical practitioners interested in automation and content management, not strategists or executives focused on market share. The signal-to-noise ratio is moderate, as the content is highly relevant to its own topic but not to the 'Market Share' category. No penalties were applied, as the content is current and does not contradict the category's framing, but the overall fit is very low.",
    "level": "Ignored"
  },
  "Technical Excellence": {
    "resourceId": "oRStCAqLAY4",
    "category": "Technical Excellence",
    "calculated_at": "2025-05-07T12:54:39",
    "ai_confidence": 54.7,
    "ai_mentions": 1.2,
    "ai_alignment": 5.8,
    "ai_depth": 5.5,
    "ai_intent": 5.0,
    "ai_audience": 6.2,
    "ai_signal": 6.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content is a detailed technical case study of using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. While it demonstrates strong technical practices (automation, auditability, modular scripting, validation layers, and human-in-the-loop oversight), it does not directly discuss or reference the concept of 'Technical Excellence' as defined (i.e., high-level engineering practices like TDD, CI/CD, modular architecture, or emergent design in the context of software delivery). There are no explicit mentions of 'Technical Excellence' or its core topics; the focus is on content management, classification, and responsible AI use, not on improving software engineering practices or product quality at a systemic level. The technical depth is solid, and the audience is technical, but the alignment with the category is partial and indirect. The signal-to-noise ratio is good, with most content relevant to the technical implementation, but the main intent is not to explore or advocate for technical excellence as a discipline. No penalties were applied, as the content is current and not critical or satirical. The final confidence score reflects that, while the post is technically sophisticated, it only partially aligns with the specific meaning of 'Technical Excellence' as defined.",
    "level": "Tertiary"
  },
  "Transparency": {
    "resourceId": "oRStCAqLAY4",
    "category": "Transparency",
    "calculated_at": "2025-05-07T12:54:45",
    "ai_confidence": 91.7,
    "ai_mentions": 8.2,
    "ai_alignment": 9.4,
    "ai_depth": 9.1,
    "ai_intent": 9.0,
    "ai_audience": 8.7,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content directly and repeatedly references transparency, both in explicit language (e.g., 'transparent audit trails', 'traceable and explainable', 'records all inputs, outputs, penalties, and decisions for transparency') and in the design of the technical system. The main theme is the creation of a transparent, auditable, and accountable classification process for blog content using AI and PowerShell, with human oversight. The discussion goes beyond surface mentions, detailing how transparency is achieved through logging, audit trails, deterministic validation, and human review. The intent is strongly aligned: the author aims to make classification decisions visible, explainable, and reviewable, which is the core of the Transparency category. The audience is technical practitioners and process consultants, matching the category's typical readership. The signal-to-noise ratio is high, with most content focused on transparency, auditability, and accountability, though there is some tangential discussion of technical implementation details. No penalties are applied, as the content is current, positive, and fully aligned with the category. The final confidence score reflects the strong, multi-dimensional fit with Transparency.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the Transparency category, as it centres on making AI-driven classification processes open, explainable, and auditable. It thoroughly discusses mechanisms like audit trails, logging, and human oversight, ensuring decisions are visible and accountable. The technical focus and clear intent to foster transparency make it highly relevant for practitioners interested in transparent systems."
  },
  "Ability to Innovate": {
    "resourceId": "oRStCAqLAY4",
    "category": "Ability to Innovate",
    "calculated_at": "2025-05-07T12:54:50",
    "ai_confidence": 54.7,
    "ai_mentions": 2.6,
    "ai_alignment": 5.8,
    "ai_depth": 6.2,
    "ai_intent": 5.5,
    "ai_audience": 6.0,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content describes the use of generative AI and automation to improve blog post tagging and categorisation, with a focus on technical implementation, auditability, and human oversight. While there are elements of process improvement and the adoption of new technology (AI, PowerShell scripting), the discussion is primarily about content management and workflow optimisation for a personal blog. There is no direct mention of 'Ability to Innovate' as a value area, nor are there explicit references to innovation metrics, learning cycles, or frameworks for measuring innovation in an organisational context. The main ideas align partially with the category in that the author is innovating their own workflow, but the depth of discussion is technical and operational rather than strategic or organisational. The intent is to share a technical solution rather than to explore or enhance organisational innovation capacity. The audience is likely technical practitioners interested in automation and AI, which partially overlaps with the category's audience, but the focus is not on business agility or innovation management. The content is focused and relevant to its own topic, but only tangentially touches on the broader themes of innovation as defined in Evidence-Based Management. No penalties were applied as the content is current, constructive, and not contradictory to the category's framing.",
    "level": "Tertiary"
  },
  "Cross Functional Teams": {
    "resourceId": "oRStCAqLAY4",
    "category": "Cross Functional Teams",
    "calculated_at": "2025-05-07T12:54:56",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.5,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of cross-functional teams, nor any discussion of their structure, benefits, or role in Agile. The main themes are automation, AI-human collaboration, and technical architecture for content management. While the author briefly references their own career path (including DevOps and Scrum), this is only to provide context for evolving taxonomies and does not discuss team composition, collaboration, or cross-functional practices. The depth of discussion is focused entirely on technical implementation, not on team dynamics or cross-functional collaboration. The intent is to inform technical practitioners about AI-driven classification, not to explore or exemplify cross-functional teams. The audience is technical (developers, site owners, automation enthusiasts), which partially overlaps with Agile practitioners but is not specifically targeted at those interested in cross-functional teams. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the category. Overall, the content does not fit the 'Cross Functional Teams' category, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Platform Engineering": {
    "resourceId": "oRStCAqLAY4",
    "category": "Platform Engineering",
    "calculated_at": "2025-05-07T12:55:02",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.5,
    "ai_intent": 2.8,
    "ai_audience": 4.1,
    "ai_signal": 3.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site. While it discusses internal automation, scripting, and technical architecture, it does not directly mention or explore platform engineering, Internal Developer Platforms (IDPs), or the core principles of platform engineering such as standardised tooling, self-service developer platforms, or lifecycle automation for application development. The main intent is to describe a personal workflow for content management, not to inform or support platform engineering practitioners. The audience is more aligned with technical bloggers or site maintainers rather than platform engineers. There are only tangential overlaps, such as automation and traceability, but these are not framed within the context of platform engineering. The signal-to-noise ratio is moderate, with most content focused on the specific use case rather than broader platform engineering concepts. No penalties were applied as the content is current and not critical or satirical. Overall, the confidence score is low, reflecting the lack of direct relevance to the Platform Engineering category.",
    "level": "Ignored"
  },
  "Organisational Psychology": {
    "resourceId": "oRStCAqLAY4",
    "category": "Organisational Psychology",
    "calculated_at": "2025-05-07T12:55:08",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 2.0,
    "ai_audience": 3.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and scripting to automate blog post tagging and categorisation in Hugo. There are no direct mentions of organisational psychology, nor are any of its core concepts (motivation, leadership, team dynamics, psychological safety, etc.) discussed. The main focus is on technical architecture, automation, and editorial workflow, not on psychological principles or theories within organisations. The intent is to inform technically-minded readers about automation and content management, not to explore psychological factors in organisational settings. While there is some mention of human oversight and accountability, these are framed in terms of editorial control and system reliability, not in the context of organisational behaviour or psychology. The audience is technical practitioners, not organisational psychologists or those interested in workplace psychology. The signal-to-noise ratio is moderate, as the content is focused but entirely off-topic for this category. No penalties were applied, as the tone is neutral and the content is current, but the overall fit is extremely low.",
    "level": "Ignored"
  },
  "Agile Philosophy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Philosophy",
    "calculated_at": "2025-05-07T12:55:14",
    "ai_confidence": 23.7,
    "ai_mentions": 0.4,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and scripting to automate blog post tagging and categorisation in Hugo. There is a strong focus on automation, data architecture, technical implementation, and the balance between AI and human oversight. While the author briefly mentions their background, including experience with Scrum and process consulting, there are no direct references to Agile Philosophy, the Agile Manifesto, or its principles. The discussion of 'Concepts' as high-level thematic anchors (e.g., Philosophy, Practices, Methods, Values, Strategy) is generic and not specifically tied to Agile Philosophy. The main ideas revolve around content management, automation, and responsible AI use, not the foundational values or mindset of Agile. The depth of discussion is technical and operational, not philosophical. The intended audience is technical practitioners interested in automation and AI for content management, not those seeking insight into Agile Philosophy. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied, as the content is current and not satirical or critical of Agile. Overall, the confidence that this content fits under 'Agile Philosophy' is low, as it does not address the core meaning or key topics of the category.",
    "level": "Ignored"
  },
  "Product Strategy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Strategy",
    "calculated_at": "2025-05-07T12:55:20",
    "ai_confidence": 27.6,
    "ai_mentions": 0.7,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 3.2,
    "ai_audience": 4.1,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 28.0,
    "reasoning": "The content is a detailed technical case study on automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo site. It focuses on technical architecture, scripting, data structures, and the process of integrating AI for content classification, with strong emphasis on human oversight and auditability. There are no direct mentions of 'Product Strategy' or its core concepts such as vision formulation, roadmapping, market analysis, or alignment with organisational goals. The main ideas revolve around content management, automation, and editorial consistency, which are operational and technical rather than strategic. The depth of discussion is high for technical implementation but not for product strategy methodologies or frameworks. The intent is to inform technical practitioners or site owners about automating classification, not to guide product strategists. The audience is more technical/editorial than executive or strategic. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied as the content is current and not satirical or critical of the category. Overall, the confidence score is low, reflecting that the content does not fit the 'Product Strategy' category.",
    "level": "Ignored"
  },
  "Collaboration Tools": {
    "resourceId": "oRStCAqLAY4",
    "category": "Collaboration Tools",
    "calculated_at": "2025-05-07T12:55:27",
    "ai_confidence": 19.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 5.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve tagging and categorisation of blog posts in Hugo. While it discusses workflow automation, technical architecture, and the integration of AI for content management, it does not directly address or reference collaboration tools as defined by the category. There are no explicit mentions of platforms like Slack, Teams, Trello, or Jira, nor is there discussion of features or practices that enhance team communication or coordination within Agile teams. The main intent is to describe a personal technical solution for content classification, not to inform or support Agile team collaboration. The audience is more technical (developers, site owners, automation enthusiasts) rather than Agile practitioners seeking collaboration solutions. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant topic. Overall, the content does not fit the 'Collaboration Tools' category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Deployment Strategies": {
    "resourceId": "oRStCAqLAY4",
    "category": "Deployment Strategies",
    "calculated_at": "2025-05-07T12:55:35",
    "ai_confidence": 13.7,
    "ai_mentions": 0.6,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.1,
    "ai_audience": 4.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. It details the technical and editorial strategies for classification, human oversight, and auditability, but does not discuss deployment methodologies or practices. There are no direct mentions of deployment strategies such as blue-green deployments, canary releases, rolling updates, infrastructure as code, or risk management in software releases. The conceptual alignment is very low, as the main ideas revolve around content management and classification automation, not software deployment. The depth of discussion is substantial for its own topic but not for deployment strategies. The intent is to inform about AI-driven classification, not deployment. The audience is technical, which slightly overlaps with the deployment strategies audience, but the focus is not on deployment practitioners. The signal-to-noise ratio is moderate, as the content is focused but off-topic for this category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is very low, reflecting the lack of relevance to deployment strategies.",
    "level": "Ignored"
  },
  "Decision Making": {
    "resourceId": "oRStCAqLAY4",
    "category": "Decision Making",
    "calculated_at": "2025-05-07T12:55:41",
    "ai_confidence": 67.6,
    "ai_mentions": 2.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.5,
    "ai_audience": 7.0,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content provides a detailed account of using generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo, with a strong emphasis on human oversight, auditability, and transparent reasoning. While the term 'decision making' is not directly mentioned, the post repeatedly discusses the process of making classification decisions, blending AI suggestions with deterministic, human-validated rules. This aligns conceptually with structured, evidence-based decision-making, especially in the context of content management. The architecture described includes penalty logic, validation, and audit trails, all of which are relevant to evidence-based methodologies. The discussion of quantitative, multi-factor assessment and the explicit separation of AI's tactical role from human strategic accountability further reinforce alignment with the category. However, the primary focus is on technical implementation and workflow automation rather than a deep exploration of decision-making frameworks or cognitive biases. The audience is technical practitioners interested in automation and content management, which partially overlaps with the intended audience for decision-making methodologies. The content is focused and relevant, with minimal off-topic material, but the lack of direct references to decision-making frameworks or explicit discussion of evidence-based management principles limits the depth and directness of the fit. No penalties were applied, as the content is current, constructive, and does not contradict the category's framing.",
    "level": "Secondary"
  },
  "Team Performance": {
    "resourceId": "oRStCAqLAY4",
    "category": "Team Performance",
    "calculated_at": "2025-05-07T12:55:46",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.7,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study about automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo site. There are no direct mentions of 'team performance' or related delivery capability at the team level. The main focus is on content management, automation, and editorial consistency for a personal blog, not on evaluating or improving team outcomes, delivery metrics, or systemic team behaviours. While the author references concepts like 'classification', 'auditability', and 'systemic validation', these are applied to content workflows, not to team dynamics or throughput. The audience is primarily technical practitioners interested in automation and AI integration for content management, not those seeking to understand or improve team performance. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the 'Team Performance' category. There is no evidence of outdated practices or contradictory tone, so no penalties are applied. Overall, the content does not align with the definition or key topics of 'Team Performance', resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Professional Scrum": {
    "resourceId": "oRStCAqLAY4",
    "category": "Professional Scrum",
    "calculated_at": "2025-05-07T12:55:54",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 3.5,
    "ai_intent": 4.0,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. While the author briefly mentions their background, including experience with Scrum and process consulting, the main focus is on the architecture, scripting, and auditability of the classification system. There is a strong emphasis on human accountability versus AI agency, which conceptually aligns with some Professional Scrum values (e.g., accountability, transparency), but these are not discussed in the context of Scrum or its ethos. The term 'Scrum' appears only in passing as part of the author's career history and in example tags/categories, not as a subject of discussion. There is no exploration of Scrum values, empiricism, technical excellence in the Scrum sense, or the philosophy of Professional Scrum. The intent is to inform technical practitioners about AI-powered content management, not to discuss or promote Professional Scrum. The audience is technical (blog owners, developers, automation enthusiasts), not specifically Scrum professionals. The signal-to-noise ratio is moderate: the content is focused, but not on Professional Scrum. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Professional Scrum' is low, as it does not address the ethos, principles, or practices of Professional Scrum in any substantive way.",
    "level": "Ignored"
  },
  "Sociotechnical Systems": {
    "resourceId": "oRStCAqLAY4",
    "category": "Sociotechnical Systems",
    "calculated_at": "2025-05-07T12:56:00",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.2,
    "ai_audience": 6.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily describes the technical and process-oriented implementation of generative AI and scripting to automate blog post tagging and categorisation, with a strong emphasis on human oversight and auditability. While there are some indirect references to the interplay between technology (AI, scripting, automation) and human roles (editorial control, accountability, validation), these are framed in the context of an individual’s workflow rather than organisational structures or team dynamics. There is no explicit mention of sociotechnical systems, nor are there direct discussions of organisational culture, team effectiveness, or the integration of social and technical aspects within a broader organisational context. The main audience appears to be technical practitioners or solo content managers, not those focused on organisational or team-level sociotechnical concerns. The content is focused and relevant to automation and responsible AI use in content management, but it does not deeply explore the theoretical or practical aspects of sociotechnical systems as defined in the category. Therefore, the confidence score is low, reflecting only a partial and incidental alignment with the sociotechnical systems category.",
    "level": "Tertiary"
  },
  "Competence": {
    "resourceId": "oRStCAqLAY4",
    "category": "Competence",
    "calculated_at": "2025-05-07T12:56:07",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.0,
    "ai_audience": 6.2,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily details the technical implementation of generative AI and PowerShell scripts to automate tagging and categorisation in a Hugo-based blog. While it demonstrates a high level of technical skill and process improvement, direct mentions of 'competence' as defined in Agile, Scrum, DevOps, or Lean contexts are absent. There is some conceptual overlap: the author discusses continuous improvement, traceability, and the importance of human oversight and accountability, which are tangentially related to competence. However, the main focus is on automation, data architecture, and workflow optimisation, not on the development or inspection of professional skills, mastery, or fostering a culture of competence. The depth of discussion around competence is limited, with only indirect references to quality, validation, and responsible use of AI. The intent is more about technical enablement and process transparency than about competence as a foundational principle. The audience is technical practitioners, which aligns somewhat, but the content is not tailored to those seeking to understand or develop competence in the professional sense. The signal-to-noise ratio is moderate, as much of the content is technical detail rather than discussion of competence. Overall, the confidence score reflects that while there are minor thematic connections, the content does not substantively address the core meaning of the 'Competence' category.",
    "level": "Tertiary"
  },
  "Azure DevOps": {
    "resourceId": "oRStCAqLAY4",
    "category": "Azure DevOps",
    "calculated_at": "2025-05-07T12:56:12",
    "ai_confidence": 7.2,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 0.5,
    "ai_audience": 0.7,
    "ai_signal": 0.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. It discusses scripting, data architecture, and human-AI collaboration for content management. There is a single, passing mention of 'Azure Pipelines' as an example tag, but no substantive discussion of Azure DevOps services, tools, or practices. The main focus is on Hugo, OpenAI, PowerShell, and content classification workflows, not on Azure DevOps or its ecosystem. The audience is technical, but not specifically Azure DevOps practitioners. The signal-to-noise ratio is high for the actual topic (AI-driven classification), but almost zero for Azure DevOps. No penalties were applied, as the content is current and not critical of Azure DevOps. Overall, the confidence that this content fits under the 'Azure DevOps' category is extremely low.",
    "level": "Ignored"
  },
  "Azure Boards": {
    "resourceId": "oRStCAqLAY4",
    "category": "Azure Boards",
    "calculated_at": "2025-05-07T12:56:18",
    "ai_confidence": 7.2,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 0.5,
    "ai_audience": 2.0,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There are no direct mentions of Azure Boards, nor any discussion of its features, best practices, or integration with Agile project management. The conceptual alignment is extremely low, as the main ideas revolve around content management, AI-driven classification, and technical scripting, not Agile project tracking or Azure DevOps. The depth of discussion is high for its own topic but not for Azure Boards, so the score is minimal. The intent is to inform about AI-powered content classification, not to support or inform Azure Boards users. The audience is technical, but not the specific practitioner audience for Azure Boards. The signal-to-noise ratio is low for this category, as nearly all content is off-topic. No penalties were applied, as the content is not outdated or satirical, but the confidence score is extremely low due to the lack of relevance.",
    "level": "Ignored"
  },
  "One Engineering System": {
    "resourceId": "oRStCAqLAY4",
    "category": "One Engineering System",
    "calculated_at": "2025-05-07T12:56:24",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 8.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate and improve tagging and categorisation in a personal Hugo-based blog. There are no direct mentions of 'One Engineering System' (1ES) or its principles, nor is there any discussion of standardising or integrating software development practices across teams, which is central to the 1ES category. The main focus is on individual workflow automation, data architecture for content classification, and the blend of AI and human oversight for editorial control. While the technical depth is high and the audience is technical, the alignment with 1ES is weak: the content does not address cross-team integration, unified engineering processes, or organisational standardisation. The signal-to-noise ratio is moderate, as the content is focused but not on the 1ES topic. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence score is low, reflecting that the content does not fit the 'One Engineering System' category.",
    "level": "Ignored"
  },
  "Metrics and Learning": {
    "resourceId": "oRStCAqLAY4",
    "category": "Metrics and Learning",
    "calculated_at": "2025-05-07T12:56:29",
    "ai_confidence": 54.7,
    "ai_mentions": 2.2,
    "ai_alignment": 5.8,
    "ai_depth": 6.1,
    "ai_intent": 5.5,
    "ai_audience": 6.0,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content primarily details the technical implementation of generative AI and PowerShell scripts to automate tagging and categorisation in a Hugo-based blog. While it references the use of data, automation, and audit trails, direct mentions of 'metrics' or 'learning' in the context of Agile, DevOps, or continuous improvement are minimal. The main focus is on content management, classification architecture, and technical scripting, rather than on collecting, analysing, or leveraging metrics for iterative learning or evidence-based management. There are some conceptual overlaps, such as the use of quantitative, multi-factor assessment and the mention of tracking classification shifts and dashboards as future enhancements, which touch on metrics and feedback loops. However, these are not the central themes, and the discussion does not deeply explore continuous improvement methodologies, feedback mechanisms, or the impact of metrics on team or organisational behaviour. The intent is more about technical enablement and editorial control than fostering learning cycles or evidence-based decision-making. The audience is technical and process-oriented, which partially aligns, and the content is focused with little off-topic material. No penalties were applied as the content is current and not contradictory. Overall, the fit with 'Metrics and Learning' is moderate but not strong, resulting in a mid-range confidence score.",
    "level": "Tertiary"
  },
  "Project Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Project Management",
    "calculated_at": "2025-05-07T12:56:34",
    "ai_confidence": 54.7,
    "ai_mentions": 1.2,
    "ai_alignment": 5.7,
    "ai_depth": 5.9,
    "ai_intent": 5.5,
    "ai_audience": 6.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content primarily details the technical and editorial process of automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo site. While it references concepts such as 'technical strategy', 'process consultant', 'auditability', and 'workflow', these are discussed in the context of content management and automation, not project management methodologies or practices. There are no direct mentions of project management, its principles, or its methodologies (e.g., Waterfall, Agile, PRINCE2). The alignment score reflects that some themes—such as process improvement, traceability, and human oversight—are tangentially relevant to project management, but the main focus is on technical implementation for content classification. The depth score is moderate, as the discussion is thorough but not about project management itself. The intent is to inform about a technical solution for content management, not to guide or support project management practitioners. The audience is likely technical (developers, site owners, automation enthusiasts) rather than project managers or those interested in project delivery. The signal-to-noise ratio is decent, with most content focused on the described system, but little of it is directly relevant to project management. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low-to-moderate, reflecting that while there are some process and oversight themes, the content does not substantively fit under the 'Project Management' category.",
    "level": "Tertiary"
  },
  "Cycle Time": {
    "resourceId": "oRStCAqLAY4",
    "category": "Cycle Time",
    "calculated_at": "2025-05-07T12:56:39",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 1.2,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of 'Cycle Time' or any discussion of measuring the time taken to complete units of work from initiation to completion. The main themes revolve around content management, classification systems, automation, and human oversight, which do not conceptually align with the definition or key topics of Cycle Time in Agile or DevOps contexts. The depth of discussion is substantial, but it is entirely centred on classification and editorial workflows, not workflow efficiency or time-based metrics. The intent is to inform about technical strategies for content classification, not to address Cycle Time or related metrics. The audience is technical (blog maintainers, developers, automation practitioners), which partially overlaps with the Cycle Time category's audience, but the content is not relevant to their interests regarding Cycle Time. The signal-to-noise ratio is moderate, as the content is focused but off-topic for Cycle Time. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence that this content fits under 'Cycle Time' is very low.",
    "level": "Ignored"
  },
  "Personal": {
    "resourceId": "oRStCAqLAY4",
    "category": "Personal",
    "calculated_at": "2025-05-07T12:56:45",
    "ai_confidence": 91.7,
    "ai_mentions": 7.8,
    "ai_alignment": 9.5,
    "ai_depth": 9.2,
    "ai_intent": 9.0,
    "ai_audience": 8.7,
    "ai_signal": 8.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content is a detailed, first-person narrative describing the author's journey in transforming their blog's tagging and categorisation system using generative AI and PowerShell. It is rich in personal anecdotes (e.g., 'I moved my blog...', 'I realised pretty quickly...', 'I've been very impressed...'), reflections on challenges (legacy content, WordPress pain points), and subjective insights into the impact of automation and AI on their workflow. The main ideas are deeply aligned with the 'Personal' category, as the author shares their unique perspective and lessons learned, rather than providing a technical manual or generalised analysis. The discussion is thorough, covering motivations, technical architecture, process, and future plans, all through a personal lens. The intent is to share an individual experience and offer advice to others considering similar approaches, which fits the category's purpose. The audience is likely practitioners or content managers interested in personal stories of digital transformation, closely matching the category's target. The content is focused, with minimal off-topic material, and maintains a high signal-to-noise ratio. No penalties were applied, as the content is current, positive, and does not contradict the category's framing. The final confidence score is high, reflecting the strong conceptual and narrative fit with the 'Personal' category.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the 'Personal' category, as it centres on the author's own experiences and reflections while revamping their blog with generative AI and PowerShell. The narrative is subjective, sharing lessons learned and personal insights, making it relevant for readers interested in individual journeys rather than general technical guides."
  },
  "Internal Developer Platform": {
    "resourceId": "oRStCAqLAY4",
    "category": "Internal Developer Platform",
    "calculated_at": "2025-05-07T12:56:52",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.7,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site workflow. There is no direct mention of Internal Developer Platforms (IDPs), nor is there any discussion of their definition, purpose, architecture, or role in software development lifecycles. The main themes revolve around content management, automation, and human-in-the-loop AI validation for editorial processes, not the creation or operation of an IDP. While there are some technical details about scripting, data architecture, and automation, these are specific to personal content management and do not align with the broader, team-oriented, and process-streamlining goals of an IDP. The intended audience appears to be individual technical practitioners interested in content automation, not platform engineers or teams building internal platforms. The signal-to-noise ratio is moderate, as the content is focused but off-topic for the IDP category. No penalties were applied, as the content is not outdated or critical of the IDP concept, but the overall fit is weak, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Agnostic Agile": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agnostic Agile",
    "calculated_at": "2025-05-07T12:57:03",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 3.2,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There are no direct mentions of Agnostic Agile, its principles, or its thought leaders. The main themes revolve around automation, human oversight, and transparent audit trails in content management, not agile philosophy or context-driven agility. While there is a general emphasis on context, traceability, and ethical use of AI, these are not explicitly tied to Agnostic Agile or its unique philosophy. The depth of discussion is focused on technical implementation rather than agile methodologies or their adaptation. The intent is to inform about a technical solution for content classification, not to discuss or promote Agnostic Agile. The audience is technical practitioners interested in automation and content management, not specifically agile professionals or strategists. The signal-to-noise ratio is moderate, as the content is focused but not on the Agnostic Agile topic. No penalties were applied, as the content is current and not critical or satirical. Overall, the content does not fit the Agnostic Agile category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Hybrid Agile": {
    "resourceId": "oRStCAqLAY4",
    "category": "Hybrid Agile",
    "calculated_at": "2025-05-07T12:57:08",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 1.8,
    "ai_intent": 1.2,
    "ai_audience": 2.0,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of Hybrid Agile, nor is there any discussion of blending traditional project management with agile delivery practices. The main themes are automation, AI-human collaboration, traceability, and technical architecture for content management. There is no analysis of Hybrid Agile frameworks, no critique of command-and-control structures, and no exploration of agile role accountability in a hybrid context. The intent is to inform technical practitioners about AI-driven classification, not to examine the pitfalls or challenges of Hybrid Agile. The audience is technical (blog owners, developers, automation enthusiasts), not those interested in project management methodologies. The signal-to-noise ratio is high for its actual topic, but almost entirely irrelevant to Hybrid Agile. No penalties were applied as the content is current and does not contradict the category's framing, but the fit is extremely weak, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Scrum Team": {
    "resourceId": "oRStCAqLAY4",
    "category": "Scrum Team",
    "calculated_at": "2025-05-07T12:57:13",
    "ai_confidence": 13.7,
    "ai_mentions": 0.4,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 2.1,
    "ai_signal": 1.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. While the author briefly mentions their career progression from web developer through DevOps and Scrum to process consultant, there is no substantive discussion of the Scrum Team as an accountability in the Scrum framework. The only direct reference to 'Scrum' is as an example of a category or tag, not as a subject of analysis. There is no exploration of Scrum Team structure, responsibilities, self-management, or accountability boundaries. The main focus is on technical architecture, automation, and editorial workflow, not on Scrum Team concepts. The intended audience is technical practitioners interested in automation and content management, not specifically Scrum Team members or those seeking to understand Scrum Team accountability. The signal-to-noise ratio is low for this category, as nearly all content is off-topic with respect to the Scrum Team. Therefore, the confidence score is very low, reflecting only a minimal, incidental connection.",
    "level": "Ignored"
  },
  "Operational Practices": {
    "resourceId": "oRStCAqLAY4",
    "category": "Operational Practices",
    "calculated_at": "2025-05-07T12:57:19",
    "ai_confidence": 67.7,
    "ai_mentions": 2.6,
    "ai_alignment": 7.7,
    "ai_depth": 7.9,
    "ai_intent": 7.2,
    "ai_audience": 7.8,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content provides a detailed account of using generative AI and PowerShell scripting to automate and improve the tagging and categorisation process for a Hugo-based blog. While it does not directly mention 'Operational Practices' or use the terminology of Agile, DevOps, or Lean frameworks, it does describe practical strategies for process optimisation, automation, and workflow improvement—core aspects of operational practices. The technical architecture, auditability, and human-in-the-loop validation reflect a focus on operational efficiency and quality. The discussion is thorough, covering the rationale, data architecture, technical implementation, and future enhancements, which demonstrates depth. The main intent is to share a practical, repeatable approach to improving content management operations, aligning with the category's purpose. The audience is primarily technical practitioners interested in automation, workflow optimisation, and responsible AI use, which fits the operational practices audience. However, the content is somewhat specialised (focused on blog management rather than broader organisational operations) and does not explicitly reference Agile, DevOps, or Lean, which lowers the direct mentions score. The signal-to-noise ratio is high, with most content relevant to the process and its improvement. Overall, the content is a strong but not perfect fit for 'Operational Practices', meriting a moderate-to-high confidence score.",
    "level": "Secondary"
  },
  "Sensemaking": {
    "resourceId": "oRStCAqLAY4",
    "category": "Sensemaking",
    "calculated_at": "2025-05-07T12:57:24",
    "ai_confidence": 36.7,
    "ai_mentions": 0.4,
    "ai_alignment": 3.2,
    "ai_depth": 3.6,
    "ai_intent": 2.8,
    "ai_audience": 4.1,
    "ai_signal": 3.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a technical case study on using generative AI and scripting to automate blog post tagging and categorisation. There are no direct mentions of 'sensemaking' or its frameworks (e.g., Cynefin), nor is there explicit discussion of interpreting complexity or organisational decision-making. The main focus is on technical automation, data architecture, and workflow improvements, not on understanding or navigating complex environments. While there is some conceptual overlap—such as the need for human oversight, traceability, and the blending of machine suggestions with human judgment—these are framed in the context of content management, not organisational sensemaking. The audience is primarily technical practitioners interested in automation and AI integration, not strategists or leaders focused on sensemaking. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. Overall, the content does not substantially align with the definition or intent of the 'Sensemaking' category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Organisational Physics": {
    "resourceId": "oRStCAqLAY4",
    "category": "Organisational Physics",
    "calculated_at": "2025-05-07T12:57:31",
    "ai_confidence": 36.7,
    "ai_mentions": 0.4,
    "ai_alignment": 3.2,
    "ai_depth": 3.7,
    "ai_intent": 2.8,
    "ai_audience": 4.1,
    "ai_signal": 4.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There are no direct mentions of 'Organisational Physics' or explicit references to systems thinking, organisational dynamics, or related terminology. The main focus is on technical implementation, automation, and editorial workflow, not on understanding or influencing organisational systems or behaviour. While there are some tangential overlaps—such as the mention of 'agency' (AI vs. human), layered classification, and the need for traceability and feedback—these are framed in the context of content management, not organisational dynamics. The depth of discussion is high for technical architecture and process automation, but not for systems thinking or organisational behaviour. The intent is to inform technical practitioners about automating content classification, not to explore or apply Organisational Physics principles. The audience is technical (bloggers, developers, automation enthusiasts), not strategists or organisational theorists. The signal-to-noise ratio is good for its actual topic, but almost entirely off-topic for Organisational Physics. No penalties were applied, as the content is current and not satirical or critical of the category. Overall, the confidence that this content fits under 'Organisational Physics' is low, as it does not address the category's core themes or audience.",
    "level": "Ignored"
  },
  "Continuous Learning": {
    "resourceId": "oRStCAqLAY4",
    "category": "Continuous Learning",
    "calculated_at": "2025-05-07T12:57:37",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.0,
    "ai_audience": 6.2,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily details the technical implementation of generative AI and PowerShell scripts to automate blog post tagging and categorisation in Hugo, with a strong emphasis on human oversight, auditability, and transparent decision-making. While there are some tangential connections to Continuous Learning—such as the author's reflection on lessons learned, the iterative improvement of classification systems, and the mention of learning from experience—these are not the main focus. The content does not directly discuss growth mindset, team knowledge sharing, feedback loops, or the creation of a learning culture within Agile, DevOps, or Lean environments. There are no explicit or frequent mentions of 'Continuous Learning' or its key principles. The depth of discussion around learning is limited and mostly incidental to the technical narrative. The intent is to inform about a technical solution, not to foster or explore continuous learning practices. The audience is technical (blog maintainers, developers, automation enthusiasts), which partially overlaps with the Continuous Learning category, but the content is not tailored to teams or practitioners seeking to improve learning culture. The signal-to-noise ratio is moderate: while the content is focused, its relevance to Continuous Learning is low. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting that the content does not substantially fit under the 'Continuous Learning' category.",
    "level": "Tertiary"
  },
  "Value Stream Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Value Stream Management",
    "calculated_at": "2025-05-07T12:57:42",
    "ai_confidence": 19.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.4,
    "ai_intent": 2.0,
    "ai_audience": 1.8,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content focuses on the use of generative AI and scripting to automate and improve the tagging and categorisation of blog posts within a static site generator (Hugo). While it discusses process optimisation, automation, and the reduction of manual labour, these are applied specifically to content management and classification, not to the broader organisational flow of value as defined by Value Stream Management (VSM). There are no direct mentions of VSM, nor are its principles, techniques, or metrics discussed. The main themes are technical automation, AI-human collaboration, and editorial consistency, which are not conceptually aligned with VSM's focus on optimising end-to-end value delivery, minimising organisational waste, or aligning work with customer outcomes. The depth of discussion is substantial for content classification and AI integration, but not for VSM. The intent is to inform about technical improvements in content management, not to address value streams or business agility. The audience is technical (blog owners, developers, content managers), not the typical VSM audience (process consultants, business strategists, Lean/Agile practitioners). The content is focused and relevant to its own topic, but not to VSM. No penalties were applied as the content is current and not critical of the VSM framing. Overall, the confidence that this content fits under Value Stream Management is very low.",
    "level": "Ignored"
  },
  "Sprint Review": {
    "resourceId": "oRStCAqLAY4",
    "category": "Sprint Review",
    "calculated_at": "2025-05-13T14:02:22",
    "ai_confidence": 7.2,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 0.5,
    "ai_audience": 1.0,
    "ai_signal": 0.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog tagging and categorisation in Hugo. While it references Scrum and related terms in passing, there are no direct or indirect mentions of Sprint Review, nor any discussion of its purpose, process, or best practices. The main focus is on content management automation, not Scrum events. Thus, the content does not align with the Sprint Review category.",
    "reasoning_summary": "This content is about automating blog categorisation with AI and PowerShell, not about Sprint Reviews. It doesn't mention or discuss Sprint Review concepts, so it doesn't fit the category.",
    "level": "Ignored"
  },
  "Team Motivation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Team Motivation",
    "calculated_at": "2025-05-07T12:58:04",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 3.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of team motivation, nor are there discussions of engagement, ownership, psychological safety, or other motivational dynamics within agile teams. The main focus is on technical architecture, automation, and editorial control, not on team dynamics or motivation. The only tangentially related aspect is the mention of human oversight and accountability, but this is framed in the context of content management, not team motivation. The audience is technical practitioners interested in automation and content management, not those seeking strategies for motivating agile teams. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant category. Overall, the content does not align with the 'Team Motivation' category, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Technical Mastery": {
    "resourceId": "oRStCAqLAY4",
    "category": "Technical Mastery",
    "calculated_at": "2025-05-07T12:58:10",
    "ai_confidence": 91.7,
    "ai_mentions": 7.8,
    "ai_alignment": 9.5,
    "ai_depth": 9.2,
    "ai_intent": 9.0,
    "ai_audience": 9.1,
    "ai_signal": 9.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content provides a detailed, technical walkthrough of automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts, with a strong emphasis on software engineering best practices. Direct mentions of 'technical architecture', 'data information architecture', and explicit breakdowns of scripts, modules, and validation logic demonstrate a clear focus on software craftsmanship and engineering excellence. The discussion covers maintainability, traceability, auditability, and the integration of AI with deterministic, human-controlled validation—core concerns of technical mastery. The depth is substantial, with architectural diagrams, code examples, and a nuanced explanation of penalty and validation layers. The intent is to inform and guide practitioners on building robust, high-quality automation systems, aligning perfectly with the category. The audience is clearly technical, targeting engineers, architects, and advanced practitioners interested in automation, DevOps, and content management systems. The signal-to-noise ratio is very high, with minimal digression and a strong focus on technical implementation and lessons learned. No penalties were applied, as the content is current, constructive, and fully aligned with the category definition. The final confidence score reflects the strong, multi-dimensional fit with 'Technical Mastery'.",
    "level": "Primary",
    "reasoning_summary": "This content is an excellent fit for the 'Technical Mastery' category. It offers a thorough, practical guide to automating blog post tagging with generative AI and PowerShell, focusing on best practices, architecture, and validation. The technical depth, clear audience targeting, and actionable insights make it highly relevant for engineers and architects seeking robust automation solutions."
  },
  "Organisational Culture": {
    "resourceId": "oRStCAqLAY4",
    "category": "Organisational Culture",
    "calculated_at": "2025-05-07T12:58:16",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of organisational culture, nor does the content discuss cultural factors, leadership, team dynamics, or the impact of culture on agility or transformation. The main focus is on technical architecture, automation, and editorial workflow, with some discussion of human oversight and accountability in AI systems. While the author briefly references their evolving role (from developer to consultant) and the importance of human agency, these are not explored in the context of organisational culture or its influence on Agile, DevOps, or business agility. The audience is primarily technical practitioners interested in automation and content management, not those seeking insights on organisational culture. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the content does not align with the Organisational Culture category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Agile Planning Tools": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Planning Tools",
    "calculated_at": "2025-05-07T12:58:24",
    "ai_confidence": 13.7,
    "ai_mentions": 0.4,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 1.5,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve blog post tagging and categorisation in Hugo, with an emphasis on technical architecture, data structures, and human oversight. There is no direct mention of Agile Planning Tools, nor are any specific tools (e.g., Jira, Trello, Asana) or Agile planning methodologies discussed. The main themes revolve around content management, automation, and classification, not Agile frameworks or planning processes. While the author references their background in DevOps and Scrum, these are only mentioned in passing to provide context for the evolution of their taxonomy, not as a discussion of Agile planning or tools. The audience is technical, but the content is not targeted at Agile practitioners or teams seeking to improve Agile planning. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the Agile Planning Tools category. No penalties were applied, as the content is current and not satirical or critical of the category. Overall, the content does not fit the 'Agile Planning Tools' category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Customer Retention": {
    "resourceId": "oRStCAqLAY4",
    "category": "Customer Retention",
    "calculated_at": "2025-05-07T12:58:31",
    "ai_confidence": 18.7,
    "ai_mentions": 0.3,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 5.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of customer retention, nor are there references to strategies, methodologies, or metrics for maintaining user engagement or minimising churn. The main focus is on internal content management, editorial consistency, and automation, not on delivering continuous value to customers or enhancing user experience in a way that aligns with customer retention goals. While the improved discoverability and editorial standards could indirectly benefit users, the discussion is not framed around customer needs, feedback loops, or retention strategies. The audience is technical (blog owners, developers, automation practitioners), which partially overlaps with those interested in customer retention, but the content is not targeted at retention strategists or customer experience professionals. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Customer Retention' is very low.",
    "level": "Ignored"
  },
  "Release Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Release Management",
    "calculated_at": "2025-05-07T12:58:37",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses technical automation, classification, and version control in the context of content management, it does not directly address or mention release management as defined (i.e., planning, scheduling, and controlling software releases). There are no explicit references to release management practices, CI/CD, release scheduling, or coordination between development and operations. The main intent is to describe a workflow for content classification and auditability, not software delivery or release processes. The audience is technical but more aligned with content managers, bloggers, or site maintainers rather than release managers or DevOps practitioners. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. Overall, the content only tangentially touches on concepts (e.g., version control, automation) that are adjacent to release management, resulting in a low confidence score for this category.",
    "level": "Ignored"
  },
  "Lean Thinking": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lean Thinking",
    "calculated_at": "2025-05-07T12:58:44",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 3.2,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripting to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses workflow optimisation, automation, and the reduction of manual labour, it does not directly mention Lean Thinking or its core principles (such as value, value stream, flow, pull, perfection, or waste elimination). There are no explicit references to Lean tools (e.g., 5S, Kanban, JIT), nor is there a discussion of Lean leadership, value stream mapping, or continuous improvement in the Lean sense. The main intent is to share a technical solution for content management, not to explore or advocate Lean Thinking. The audience is technical (blog owners, developers, automation practitioners), which partially overlaps with Lean audiences, but the content is not tailored to Lean practitioners or strategists. The signal-to-noise ratio is moderate, as the content is focused on its technical topic but not on Lean. No penalties were applied, as the content is current and not critical of Lean. Overall, the confidence that this content fits under the 'Lean Thinking' category is very low.",
    "level": "Ignored"
  },
  "Evidence Based Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Evidence Based Management",
    "calculated_at": "2025-05-07T12:58:53",
    "ai_confidence": 38.7,
    "ai_mentions": 0.6,
    "ai_alignment": 4.2,
    "ai_depth": 4.7,
    "ai_intent": 3.8,
    "ai_audience": 5.1,
    "ai_signal": 5.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and scripting to automate and improve the tagging and categorisation of blog posts in Hugo. There is a strong focus on automation, traceability, and the blending of AI suggestions with human oversight, including the use of penalty logic and transparent audit trails. However, there are no direct mentions of Evidence-Based Management (EBM) or its key terminology. The main conceptual alignment is with data-driven classification and the use of empirical, multi-factor scoring to inform content categorisation, which is somewhat adjacent to EBM's emphasis on empirical decision-making. The depth of discussion is high regarding technical implementation, but it does not explore EBM's core topics such as Current Value, Time to Market, Ability to Innovate, Unrealised Value, or outcome management. The intent is to inform technical practitioners about automating content management, not to discuss or promote EBM as a management approach. The audience is technical (developers, site owners, automation enthusiasts), which only partially overlaps with EBM's typical audience of managers and strategists. The signal-to-noise ratio is good, with focused, relevant content, but the relevance to EBM is tangential at best. No penalties were applied, as the content is current and does not contradict the EBM framing. Overall, while there are elements of empirical, data-driven decision-making, the content does not fit well under the Evidence-Based Management category.",
    "level": "Ignored"
  },
  "Current Value": {
    "resourceId": "oRStCAqLAY4",
    "category": "Current Value",
    "calculated_at": "2025-05-07T12:59:02",
    "ai_confidence": 19.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 6.2,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content focuses on the technical implementation of generative AI and PowerShell scripts to automate tagging and categorisation in a Hugo-based blog. There is no direct mention of 'Current Value' as defined in Evidence-Based Management, nor are there references to its key metrics (customer satisfaction, revenue impact, performance feedback) or its role in Agile, DevOps, or Lean methodologies. The main themes are automation, traceability, and editorial control in content management, not the real-time assessment of value delivered to customers or organisations. While the content does discuss quantitative assessment and confidence scoring, these are applied to content classification accuracy, not to measuring product or service value. The audience is technical practitioners interested in automation and AI for content management, which only partially overlaps with the intended audience for Current Value discussions. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant category. No penalties were applied, as the content is not outdated or critical of the category. Overall, the confidence score is low, reflecting minimal alignment with the Current Value category.",
    "level": "Ignored"
  },
  "Beta Codex": {
    "resourceId": "oRStCAqLAY4",
    "category": "Beta Codex",
    "calculated_at": "2025-05-07T12:59:08",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.7,
    "ai_audience": 7.1,
    "ai_signal": 6.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of Beta Codex or its foundational theories, nor is there any explicit discussion of decentralised, adaptive, or human-centric organisational design. The main focus is on technical automation, data architecture, and the balance between AI and human oversight in editorial workflows. While there are some tangential themes (e.g., human accountability, adaptive systems, transparency), these are framed in the context of content management and AI governance, not organisational design or Beta Codex principles. The audience is technical practitioners interested in automation and content management, not those seeking insight into Beta Codex or decentralised organisational models. The signal-to-noise ratio is high for its intended topic, but almost none of the content aligns with the Beta Codex category. Therefore, the confidence score is very low, reflecting only minimal incidental overlap (such as the mention of 'adaptive systems' and human agency) but no substantive fit.",
    "level": "Ignored"
  },
  "Increment": {
    "resourceId": "oRStCAqLAY4",
    "category": "Increment",
    "calculated_at": "2025-05-07T12:59:19",
    "ai_confidence": 7.7,
    "ai_mentions": 0.0,
    "ai_alignment": 0.2,
    "ai_depth": 0.2,
    "ai_intent": 0.2,
    "ai_audience": 0.5,
    "ai_signal": 0.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content is a detailed technical narrative about using generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. It focuses on data architecture, automation, auditability, and the blending of AI and human oversight for content classification. There are no direct mentions of 'Increment' as defined in Scrum or Agile, nor is there any discussion of delivering working software, iterative value delivery, or the role of increments in Agile methodologies. The main ideas, technical depth, and intent are all centred on content management and classification, not on the concept of Increment. The audience is technical, but not in the context of Agile software delivery. The signal-to-noise ratio is high for its actual topic, but entirely off-topic for the Increment category. Therefore, the confidence score is extremely low, reflecting only the most remote conceptual overlap (e.g., the idea of iterative improvement in classification, which is not the same as software increments).",
    "level": "Ignored"
  },
  "Liberating Structures": {
    "resourceId": "oRStCAqLAY4",
    "category": "Liberating Structures",
    "calculated_at": "2025-05-07T12:59:25",
    "ai_confidence": 7.2,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 0.5,
    "ai_audience": 0.7,
    "ai_signal": 0.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of Liberating Structures, nor any references to specific facilitation techniques, methods, or the toolkit itself. The conceptual alignment is extremely weak: while the post discusses structuring information and improving editorial processes, it does not address team facilitation, engagement, or collaborative methods as defined by Liberating Structures. The depth of discussion is focused entirely on technical automation, not on facilitation or group process. The intent is to inform about AI-driven content management, not to support or inform practitioners of Liberating Structures. The audience is technical (bloggers, developers, automation enthusiasts), not facilitators, Scrum Masters, or Agile Coaches. The signal-to-noise ratio is high for its own topic, but nearly zero for the Liberating Structures category. No penalties were applied, as the content is not outdated or critical of the category. Overall, the confidence score is extremely low, reflecting the near-total absence of relevant content for the Liberating Structures category.",
    "level": "Ignored"
  },
  "Modern Source Control": {
    "resourceId": "oRStCAqLAY4",
    "category": "Modern Source Control",
    "calculated_at": "2025-05-07T12:59:31",
    "ai_confidence": 36.7,
    "ai_mentions": 2.2,
    "ai_alignment": 3.8,
    "ai_depth": 3.5,
    "ai_intent": 3.7,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content primarily discusses the use of generative AI and PowerShell scripts to automate and improve tagging and categorisation in a Hugo-based blog. While there is a brief mention of using GitHub for versioning, branching, and pull requests, these are not the focus of the article. The main themes revolve around content management, automation, and AI-driven classification, not modern source control practices or methodologies. There is no in-depth exploration of version control systems, branching strategies, code review processes, or related best practices. The audience is more aligned with technical content managers or developers interested in automation and AI, rather than practitioners seeking guidance on modern source control. The signal-to-noise ratio is moderate, as the only relevant mention is the use of GitHub for code versioning, which is not elaborated upon. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting the tangential and minimal relevance to the 'Modern Source Control' category.",
    "level": "Ignored"
  },
  "Technical Debt": {
    "resourceId": "oRStCAqLAY4",
    "category": "Technical Debt",
    "calculated_at": "2025-05-07T12:59:38",
    "ai_confidence": 23.6,
    "ai_mentions": 0.7,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses the challenges of managing legacy content, categories, and tags, and the pain of updating them in previous platforms, it does not directly mention or explore the concept of technical debt as defined (i.e., the accumulation of suboptimal code or design decisions that hinder sustainable development). There are no explicit references to technical debt, nor is there a discussion of its types, measurement, impact on velocity, or remediation strategies. The main themes are automation, AI-human collaboration, and content management, not the management or implications of technical debt. The audience is technical (blog maintainers, developers), but the focus is on content classification and workflow automation rather than codebase health or long-term maintainability. The signal-to-noise ratio is moderate, as the content is focused but not on the technical debt topic. No penalties were applied, as the content is current and not satirical or critical of the category. Overall, the confidence that this content fits under 'Technical Debt' is low.",
    "level": "Ignored"
  },
  "Business Agility": {
    "resourceId": "oRStCAqLAY4",
    "category": "Business Agility",
    "calculated_at": "2025-05-07T12:59:44",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.8,
    "ai_intent": 3.5,
    "ai_audience": 4.1,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of 'business agility' or its core principles. The main focus is on technical automation, data architecture, and workflow optimisation for content management, not on organisational adaptability, leadership, or agile transformation. While some concepts (automation, adaptability, traceability) are tangentially relevant to business agility, they are discussed strictly in the context of personal site management, not organisational change or market responsiveness. The depth of discussion is strong for technical implementation but shallow regarding business agility concepts. The intended audience is technical practitioners interested in AI-driven content management, not business leaders or strategists. The signal-to-noise ratio is high for its actual topic but low for business agility relevance. No penalties were applied, as the content is current and not critical of the category. Overall, the content does not fit well under 'Business Agility,' resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Miscellaneous": {
    "resourceId": "oRStCAqLAY4",
    "category": "Miscellaneous",
    "calculated_at": "2025-05-07T12:59:59",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 5.3,
    "ai_intent": 4.5,
    "ai_audience": 5.0,
    "ai_signal": 5.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content is a detailed technical narrative about automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo site. It focuses on the architecture, scripting, and process of integrating AI for content management, with strong emphasis on human oversight and auditability. \n\nDirect Mentions (1.2): The term 'Miscellaneous' is not mentioned, nor is there any explicit reference to the category. The content is highly specific to technical implementation and personal workflow, not to general or catch-all discussions.\n\nConceptual Alignment (4.8): While the content is tangentially related to business agility (in the sense of improving workflows and content management), it does not fit the core meaning of 'Miscellaneous' as defined. It is not a general discussion, anecdote, or non-framework-aligned reflection; rather, it is a technical case study with clear objectives and methods.\n\nDepth of Discussion (5.3): The discussion is deep and thorough, but it is focused on technical architecture, scripting, and process, not on miscellaneous or off-framework topics. The depth is in the technical domain, not in the catch-all or non-specific area the category describes.\n\nIntent / Purpose Fit (4.5): The main intent is to inform and share a technical solution for content classification, not to provide a general, non-framework-aligned discussion. The purpose is not aligned with the 'Miscellaneous' category, which is for content that does not fit elsewhere.\n\nAudience Alignment (5.0): The audience is technical practitioners interested in automation, AI integration, and content management, which only partially overlaps with the broad audience for 'Miscellaneous' (which could include non-technical or general business agility readers).\n\nSignal-to-Noise Ratio (5.2): The content is focused and relevant to its technical topic, but not to the 'Miscellaneous' category. There is little off-topic or filler content, but the focus is not on the catch-all or non-framework-aligned discussions the category is meant for.\n\nNo penalties were applied, as the content is current, not satirical, and does not contradict the category's framing. Overall, the confidence score is low, reflecting that while the content is not a fit for any specific Agile, Scrum, DevOps, Lean, or EBM category, it is also not a strong fit for 'Miscellaneous' as defined, since it is a technical case study rather than a general or non-framework-aligned discussion.",
    "level": "Tertiary"
  },
  "Complexity Thinking": {
    "resourceId": "oRStCAqLAY4",
    "category": "Complexity Thinking",
    "calculated_at": "2025-05-07T13:00:06",
    "ai_confidence": 23.7,
    "ai_mentions": 0.4,
    "ai_alignment": 2.2,
    "ai_depth": 2.7,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the technical and process-oriented transformation of blog post tagging and categorisation using generative AI and PowerShell scripting. There are no direct mentions of complexity science, complexity thinking, or related frameworks such as Cynefin, emergence, non-linear dynamics, or organisational uncertainty. The main ideas revolve around automation, human oversight, and transparent audit trails in content management, which are not conceptually aligned with the core meaning of Complexity Thinking. While the author discusses the increasing complexity of managing large numbers of tags and categories, this is in the colloquial sense of 'complicated' rather than engaging with complexity theory or its principles. The depth of discussion is substantial regarding technical implementation but does not explore complexity science concepts. The intent is to inform about AI-driven classification and workflow improvements, not to discuss or apply complexity thinking. The audience is likely technical practitioners interested in automation and content management, not those seeking insights into complexity science or organisational dynamics. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the Complexity Thinking category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting the lack of direct or conceptual fit with Complexity Thinking.",
    "level": "Ignored"
  },
  "Site Reliability Engineering": {
    "resourceId": "oRStCAqLAY4",
    "category": "Site Reliability Engineering",
    "calculated_at": "2025-05-07T13:00:13",
    "ai_confidence": 23.7,
    "ai_mentions": 0.4,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripting to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses automation, auditability, and technical architecture, there are no direct mentions of Site Reliability Engineering (SRE) or its core principles as defined by Google. The main themes revolve around content management, editorial consistency, and leveraging AI for classification, not the reliability, scalability, or performance of production systems. The technical depth is substantial but is applied to content workflows rather than system reliability. The intent is to inform about AI-driven content classification, not SRE practices. The audience is technical but more aligned with content managers, developers, or automation enthusiasts than SRE practitioners. The signal-to-noise ratio is moderate, with most content focused on the described system but not on SRE. No penalties were applied as the content is current and not satirical or critical of SRE. Overall, the content does not fit the SRE category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Frequent Releases": {
    "resourceId": "oRStCAqLAY4",
    "category": "Frequent Releases",
    "calculated_at": "2025-05-07T13:00:23",
    "ai_confidence": 23.6,
    "ai_mentions": 0.7,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo-based static site. There is no direct mention of 'Frequent Releases' or related practices such as Continuous Delivery, Continuous Deployment, or DevOps-driven release automation. The main themes are content classification, AI-human collaboration, and technical architecture for metadata management. While there are tangential references to automation, scripting, and version control (e.g., GitHub, PRs), these are in service of content management, not software release frequency or incremental delivery to users. The audience is technical, but the subject matter is not aligned with the principles, best practices, or metrics of frequent software releases. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence score is low due to minimal conceptual overlap and lack of direct relevance.",
    "level": "Ignored"
  },
  "Strategic Goals": {
    "resourceId": "oRStCAqLAY4",
    "category": "Strategic Goals",
    "calculated_at": "2025-05-07T13:00:33",
    "ai_confidence": 38.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 4.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and scripting to automate and improve blog post tagging and categorisation in Hugo. While it discusses the architecture, data model, and process improvements, it does not directly address or reference strategic goals, long-term objectives, or business agility in the sense defined by the category. There is some conceptual overlap in the sense that the author is seeking to improve editorial consistency, traceability, and scalability, which could be seen as supporting broader site management objectives. However, these are operational and tactical improvements rather than strategic ones. The main focus is on technical implementation, automation, and human oversight, not on aligning organisational strategy with agile principles or fostering competitive advantage. The audience is primarily technical practitioners and site owners, not strategists or executives. The signal-to-noise ratio is moderate, as the content is focused but not on the strategic level required. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence that this content fits under 'Strategic Goals' is low, as it is much more about operational tactics and technical execution than about defining or achieving long-term strategic objectives.",
    "level": "Ignored"
  },
  "Enterprise Agility": {
    "resourceId": "oRStCAqLAY4",
    "category": "Enterprise Agility",
    "calculated_at": "2025-05-07T13:00:43",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 4.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study of using generative AI and PowerShell to automate and improve tagging and categorisation for a personal blog using Hugo. There is a strong focus on automation, auditability, and the blend of AI and human oversight in content management. However, there are no direct mentions of 'Enterprise Agility' or its frameworks (e.g., SAFe, LeSS), nor is there any discussion of organisational agility, leadership, or change management at the enterprise level. The main ideas are about technical implementation, data architecture, and responsible AI use in a solo or small-scale editorial context, not about scaling agility across an organisation. The depth is high for the technical topic, but not for enterprise agility. The intent is to inform technical practitioners or bloggers, not enterprise leaders or strategists. The audience is more technical and individual than organisational. The signal-to-noise ratio is good for the topic, but the topic itself is not aligned with enterprise agility. No penalties were applied as the content is current and not critical or satirical. Overall, the confidence that this content fits under 'Enterprise Agility' is low, as it does not address the broader organisational, cultural, or leadership aspects required by the category.",
    "level": "Ignored"
  },
  "Working Software": {
    "resourceId": "oRStCAqLAY4",
    "category": "Working Software",
    "calculated_at": "2025-05-07T13:00:49",
    "ai_confidence": 19.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 6.0,
    "ai_signal": 5.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content is a detailed technical case study about automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site. While it thoroughly discusses automation, scripting, and the architecture of a classification system, it does not directly mention or focus on 'working software' as defined in the Agile/Scrum context. There are no explicit references to working software as an artifact, nor is there discussion of iterative delivery, increments, or value delivery to customers through software. The main intent is to describe a content management automation process, not to deliver or discuss working, high-quality software increments. The audience is technical and the content is focused, but the conceptual alignment and depth regarding 'working software' are low. The signal-to-noise ratio is moderate, as the content is relevant to automation and scripting but not to the core category. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence that this content fits under 'Working Software' is low.",
    "level": "Ignored"
  },
  "Agile Transformation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Transformation",
    "calculated_at": "2025-05-07T13:00:57",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.1,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. While the author briefly mentions their background, including experience with DevOps and Scrum, there are no direct or explicit references to Agile Transformation, its principles, or organisational change. The main focus is on technical automation, data architecture, and human-AI collaboration for content management. There is no discussion of Agile frameworks, change management, leadership in transformation, or organisational agility. The audience is primarily technical practitioners interested in automation and content management, not those seeking guidance on Agile Transformation. The signal-to-noise ratio is moderate, as the content is focused but not on the relevant category. No penalties were applied, as the content is current and not critical of Agile. Overall, the content does not fit the Agile Transformation category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Experimentation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Experimentation",
    "calculated_at": "2025-05-07T13:01:05",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.6,
    "ai_intent": 2.8,
    "ai_audience": 4.1,
    "ai_signal": 3.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. While it thoroughly discusses automation, classification, and the integration of AI with human oversight, it does not directly or indirectly address experimentation as defined by the category. There are no explicit or implicit references to hypothesis-driven approaches, systematic testing of ideas, or validation of assumptions within Agile workflows. The main focus is on technical implementation, data architecture, and process automation, not on running experiments, analysing results, or iterating based on findings. The audience is technical (developers, site maintainers), which partially overlaps with the experimentation category, but the intent and depth are not aligned with experimentation in Agile. The signal-to-noise ratio is moderate, as the content is focused but not on the target topic. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence score is low, reflecting the lack of conceptual and direct alignment with the Experimentation category.",
    "level": "Ignored"
  },
  "Systems Thinking": {
    "resourceId": "oRStCAqLAY4",
    "category": "Systems Thinking",
    "calculated_at": "2025-05-07T13:01:12",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.8,
    "ai_intent": 3.5,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on the technical and process aspects of automating blog post classification using generative AI and scripting, with an emphasis on human oversight and auditability. There are no direct mentions of 'Systems Thinking' or its foundational principles, nor are there references to its key tools (e.g., causal loop diagrams, system dynamics) or frameworks (e.g., Cynefin, Soft Systems Methodology). While the author describes a multi-level classification structure (concepts, categories, tags) and discusses interconnectedness in the context of taxonomy, this is primarily a data architecture and automation discussion, not a holistic analysis of organisational systems or complex interdependencies as defined by Systems Thinking. The intent is to inform technical practitioners about AI-driven content management, not to explore or apply Systems Thinking methodologies. The audience is technical (bloggers, developers, process consultants), which partially overlaps with Systems Thinking practitioners, but the content is not tailored to strategists or organisational change agents. The signal-to-noise ratio is moderate: the content is focused, but its relevance to Systems Thinking is tangential at best. No penalties were applied, as the content is current and not critical of the category. Overall, the confidence score is low, reflecting minimal conceptual alignment and depth regarding Systems Thinking.",
    "level": "Ignored"
  },
  "Product Validation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Validation",
    "calculated_at": "2025-05-07T13:01:19",
    "ai_confidence": 23.7,
    "ai_mentions": 0.4,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 8.1,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts, with an emphasis on technical architecture, data structures, and human oversight. There are no direct mentions of product validation or its key methodologies (user testing, market fit, prototyping, customer feedback loops, A/B testing, Lean Startup, or evidence-based management). The main conceptual alignment is weak: while the content discusses validation in the sense of ensuring accurate classification and traceability, this is about metadata and content management, not validating product ideas with real users or market needs. The depth of discussion is substantial, but it is technical and process-oriented, not about product validation practices. The intent is to inform technical practitioners about automating content classification, not to explore or teach product validation. The audience is technical (developers, site owners), which partially overlaps with product validation practitioners, but the focus is not on product validation. The signal-to-noise ratio is high, as the content is focused and relevant to its own topic, but not to product validation. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence score is low, reflecting that the content does not fit the 'Product Validation' category.",
    "level": "Ignored"
  },
  "Agile Planning": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Planning",
    "calculated_at": "2025-05-07T13:01:25",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.8,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of Agile Planning, nor are Agile methodologies, principles, or practices discussed. The main focus is on information architecture, automation, and human-AI collaboration for content management. While the author briefly references their background in DevOps and Scrum, these are only mentioned in passing and not explored in the context of Agile Planning. The content does not discuss sprints, backlogs, iterative planning, or any Agile frameworks or ceremonies. The intent is to inform technical practitioners about automating classification, not to guide or support Agile Planning. The audience is technical (blog owners, developers, automation enthusiasts), not specifically Agile practitioners or planners. The signal-to-noise ratio is moderate, as the content is focused but not on the Agile Planning topic. No penalties were applied, as the content is current and not critical of Agile. Overall, the content has minimal conceptual overlap with Agile Planning, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Open Space Agile": {
    "resourceId": "oRStCAqLAY4",
    "category": "Open Space Agile",
    "calculated_at": "2025-05-07T13:01:32",
    "ai_confidence": 13.7,
    "ai_mentions": 0.0,
    "ai_alignment": 2.0,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.2,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of Open Space Agile or Open Space Technology, nor are there references to Agile transformation, psychological safety, co-creation, or emergence as defined in the category. The main themes are automation, human oversight, and technical architecture for content management, which do not conceptually align with Open Space Agile. The depth of discussion is high, but it is focused entirely on AI-driven classification and workflow automation, not on organisational agility or collaborative change processes. The intent is to inform technical practitioners about AI-powered content management, not to discuss or promote Open Space Agile. The audience is technical (blog owners, developers, automation enthusiasts), not those interested in Agile transformation or organisational change. The signal-to-noise ratio is high for its own topic, but almost entirely off-topic for Open Space Agile. No penalties were applied, as the content is not outdated or critical of the category, but the confidence score is very low due to a lack of relevance.",
    "level": "Ignored"
  },
  "Portfolio Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Portfolio Management",
    "calculated_at": "2025-05-07T13:01:48",
    "ai_confidence": 18.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 1.8,
    "ai_audience": 6.0,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate tagging and categorisation of blog posts in Hugo. There are no direct mentions of portfolio management, nor are its core concepts (such as strategic alignment of projects, investment prioritisation, value stream optimisation, or portfolio-level risk management) discussed. The main focus is on content classification, metadata management, and technical automation, not on managing a portfolio of projects or aligning execution with organisational strategy. The depth of discussion is substantial, but it is entirely about content management and AI-assisted classification, not portfolio management. The intent is to inform technical practitioners about automating editorial workflows, not to address portfolio management concerns. The audience is technical (blog owners, developers, automation enthusiasts), which only partially overlaps with the typical portfolio management audience (executives, strategists, PMO leads). The signal-to-noise ratio is high for its actual topic, but almost none of the content is relevant to portfolio management. Therefore, the confidence that this content fits under the 'Portfolio Management' category is very low.",
    "level": "Ignored"
  },
  "Decision Theory": {
    "resourceId": "oRStCAqLAY4",
    "category": "Decision Theory",
    "calculated_at": "2025-05-07T13:01:57",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.1,
    "ai_intent": 3.5,
    "ai_audience": 5.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content primarily focuses on the technical and process aspects of automating blog post tagging and categorisation using generative AI and PowerShell scripts. There is a strong emphasis on workflow automation, data architecture, and the integration of AI for classification, with human oversight and auditability. While the post discusses 'classification decisions', 'penalty logic', and 'probabilistic suggestions', these are framed in the context of content management and technical implementation, not as an exploration of decision theory as defined (i.e., the study of decision-making under uncertainty, heuristics, probability, or behavioural economics). There are no direct mentions of decision theory, nor are its core concepts (such as heuristics, risk assessment, or decision-making frameworks) discussed in depth. The intent is to inform technical practitioners about automating editorial processes, not to analyse or improve decision-making under uncertainty. The audience is technical (bloggers, developers, site maintainers), which only partially overlaps with the typical decision theory audience. The signal-to-noise ratio is moderate, as the content is focused but not on decision theory. No penalties were applied, as the content is current and not contradictory. Overall, the confidence score is low, reflecting only a tangential and superficial connection to decision theory through the use of terms like 'decision', 'penalty', and 'probabilistic', but without substantive alignment to the category.",
    "level": "Ignored"
  },
  "Empirical Process Control": {
    "resourceId": "oRStCAqLAY4",
    "category": "Empirical Process Control",
    "calculated_at": "2025-05-07T13:02:07",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.2,
    "ai_audience": 6.0,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily focuses on the technical and architectural implementation of generative AI and scripting to automate tagging and categorisation in a Hugo-based blog. While there are some tangential references to transparency, auditability, and human oversight—concepts that are adjacent to empirical process control—the content does not directly discuss empirical process control, its principles, or its application within Agile, Scrum, or related frameworks. There are no explicit mentions of empirical process control, nor are its core practices (transparency, inspection, adaptation) explored in depth or within the context of Agile methodologies. The main intent is to share a technical solution for content management, not to inform or guide on empirical process control. The audience is technical practitioners, which partially overlaps with the category, but the signal-to-noise ratio is moderate as most of the content is about automation, scripting, and AI integration rather than empirical process control. No penalties were applied as the content is current and not critical of the category. Overall, the confidence score is low, reflecting only a loose conceptual alignment and minimal direct relevance to the category.",
    "level": "Tertiary"
  },
  "Application Lifecycle Management": {
    "resourceId": "oRStCAqLAY4",
    "category": "Application Lifecycle Management",
    "calculated_at": "2025-05-07T13:02:15",
    "ai_confidence": 36.7,
    "ai_mentions": 0.8,
    "ai_alignment": 3.2,
    "ai_depth": 3.7,
    "ai_intent": 3.0,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site. While it discusses lifecycle-like processes (e.g., migration, automation, auditability, and maintenance of content metadata), it does not directly address the management of software applications across their full lifecycle as defined by Application Lifecycle Management (ALM). There are no explicit mentions of ALM, its methodologies, or its core practices such as application governance, compliance, or risk management. The technical depth is substantial but is centred on content management and classification automation, not on application lifecycle stages or ALM tools/frameworks. The intent is to inform about a content classification system, not to guide or support ALM practitioners. The audience is technical but more aligned with content managers, site owners, or automation enthusiasts rather than ALM professionals. The signal-to-noise ratio is moderate, as the content is focused but not on the ALM topic. No penalties were applied as the content is current and not satirical or critical of ALM. Overall, the confidence score is low, reflecting that the content is tangential and does not fit the ALM category.",
    "level": "Ignored"
  },
  "Daily Scrum": {
    "resourceId": "oRStCAqLAY4",
    "category": "Daily Scrum",
    "calculated_at": "2025-05-07T13:02:20",
    "ai_confidence": 7.2,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.3,
    "ai_intent": 0.5,
    "ai_audience": 1.0,
    "ai_signal": 0.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. While the author briefly mentions their background, including experience with Scrum, there are no direct or indirect references to the Daily Scrum event, its structure, purpose, or best practices. The main focus is on content management, automation, and AI-human collaboration for editorial workflows. There is no discussion of Scrum events, team meetings, or agile ceremonies. The intended audience is technical practitioners interested in automation and content management, not specifically Scrum teams or Daily Scrum participants. The signal-to-noise ratio is high for its actual topic, but entirely unrelated to the Daily Scrum category. Therefore, the confidence score is extremely low, reflecting only the faintest possible conceptual overlap (the author's background in Scrum) and no substantive relevance to the Daily Scrum category.",
    "level": "Ignored"
  },
  "Agile Frameworks": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agile Frameworks",
    "calculated_at": "2025-05-07T13:02:26",
    "ai_confidence": 18.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.0,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 5.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. While there are brief references to Agile-related terms (e.g., 'Scrum', 'process consultant', 'Technical Leadership', 'Product Development'), these are only mentioned as examples of categories or tags within the author's taxonomy. There is no substantive discussion of Agile frameworks, their principles, comparative analysis, implementation challenges, or organisational impact. The main focus is on automation, data architecture, and human-AI collaboration in content management, not on Agile frameworks themselves. The audience is technical and process-oriented, which partially overlaps with Agile practitioners, but the content is not targeted at those seeking insights into Agile frameworks. The signal-to-noise ratio is moderate, as most content is relevant to the technical automation topic, not Agile frameworks. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence that this content fits under 'Agile Frameworks' is very low.",
    "level": "Ignored"
  },
  "Minimum Viable Product": {
    "resourceId": "oRStCAqLAY4",
    "category": "Minimum Viable Product",
    "calculated_at": "2025-05-07T13:02:35",
    "ai_confidence": 23.85,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 8.0,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate and improve tagging and categorisation in a Hugo-based blog. There is no direct mention of 'Minimum Viable Product' (MVP), nor is the concept of MVP, as defined in the classification, discussed or implied. The main focus is on automation, AI-human collaboration, and content management workflows, not on building or iterating a product to test market assumptions. While the content does discuss iterative improvement and technical strategies, these are in the context of site taxonomy and classification, not MVP development or validation. The audience (technical practitioners, developers) overlaps with those interested in MVPs, but the subject matter is not aligned. The signal-to-noise ratio is high, as the content is focused and relevant to its stated purpose, but that purpose is not MVP-related. No penalties were applied, as the content is current and not critical of the MVP concept. Overall, the confidence that this content fits under the 'Minimum Viable Product' category is very low.",
    "level": "Ignored"
  },
  "Test Driven Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Test Driven Development",
    "calculated_at": "2025-05-07T13:02:41",
    "ai_confidence": 8.7,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.5,
    "ai_intent": 1.0,
    "ai_audience": 1.2,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content does not mention Test Driven Development (TDD) directly or indirectly. Its focus is on using generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo, with an emphasis on human oversight and auditability. There are no references to the TDD cycle, writing tests before code, or any TDD-related practices, tools, or challenges. The main intent is to describe a technical workflow for content classification, not software development methodology. The audience is technical, but not specifically practitioners of TDD. The signal-to-noise ratio is low for this category, as all discussion is off-topic with respect to TDD. No penalties were applied, as the content is not outdated or critical of TDD; it is simply unrelated.",
    "level": "Ignored"
  },
  "Common Goals": {
    "resourceId": "oRStCAqLAY4",
    "category": "Common Goals",
    "calculated_at": "2025-05-07T13:02:49",
    "ai_confidence": 36.85,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.6,
    "ai_intent": 3.0,
    "ai_audience": 4.1,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a detailed technical case study about automating blog post tagging and categorisation using generative AI and PowerShell scripts. It focuses on improving editorial consistency, discoverability, and traceability in content management. While the post discusses alignment of tags and categories and the importance of human accountability versus AI agency, it does not directly address the concept of Common Goals as defined in Agile or DevOps contexts. There are no explicit mentions of Common Goals, nor is there substantive discussion of aligning strategy with execution, shared objectives, or frameworks like OKRs. The main intent is technical process improvement for personal content management, not organisational goal alignment. The audience is technical (bloggers, developers, automation enthusiasts), which partially overlaps with the category's audience but is not a direct match. The signal-to-noise ratio is moderate, as the content is focused but not on the core topic of Common Goals. Overall, the content only tangentially touches on themes of alignment and accountability, resulting in a low confidence score for this category.",
    "level": "Ignored"
  },
  "Agentic Agility": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agentic Agility",
    "calculated_at": "2025-05-07T13:02:59",
    "ai_confidence": 67.2,
    "ai_mentions": 3.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.0,
    "ai_audience": 7.5,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 67.0,
    "reasoning": "The content provides a detailed account of integrating generative AI into a blog's classification workflow, with a strong emphasis on maintaining human oversight and accountability. There are explicit references to agency, such as the statement that 'AI systems have agency, but it is limited to tactical optimisation' and that 'AI here has no editorial authority.' The distinction between human and AI agency is discussed, aligning with the Agentic Agility category's focus on intentional, adaptive action and the importance of accountability. The content explores the mechanisms by which AI suggestions are validated and controlled by deterministic, human-authored rules, which resonates with the category's themes of agency, adaptive action, and the interplay between human and AI roles. However, the primary focus is on technical implementation and workflow automation, with Agentic Agility serving as a supporting concept rather than the central theme. The discussion of agency is meaningful and non-trivial, but it is not the main subject; rather, it is woven into the broader narrative about responsible AI use in content management. The audience is technical practitioners interested in automation, AI, and workflow optimisation, which aligns well with the intended audience for Agentic Agility. The content is focused and relevant, with minimal off-topic material. No penalties were applied, as the content is current, respectful of the category's framing, and does not reference obsolete practices. The confidence score reflects a strong but not primary alignment with Agentic Agility, acknowledging the depth and relevance of the agency discussion while recognising that it is not the sole or dominant focus.",
    "level": "Secondary"
  },
  "Mentoring": {
    "resourceId": "oRStCAqLAY4",
    "category": "Mentoring",
    "calculated_at": "2025-05-07T13:03:05",
    "ai_confidence": 18.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 6.2,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of mentoring, coaching, or related concepts. The main themes are technical automation, data architecture, and workflow optimisation, not the development of skills, behaviours, or leadership in Agile or Scrum contexts. While the author briefly references their own professional journey (from web developer to process consultant), this is background and not a discussion of mentoring or professional growth strategies. The intent is to inform technically-minded readers about a classification system, not to provide guidance or coaching for agile professionals. The audience is likely technical practitioners or content managers, not those seeking mentoring or leadership development. The signal-to-noise ratio is moderate, as the content is focused but entirely off-topic for the mentoring category. No penalties were applied, as the content is current and not critical or satirical. Overall, the content does not fit the 'Mentoring' category, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Unrealised Value": {
    "resourceId": "oRStCAqLAY4",
    "category": "Unrealised Value",
    "calculated_at": "2025-05-07T13:03:12",
    "ai_confidence": 23.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 8.0,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and PowerShell to automate and improve blog post tagging and categorisation in Hugo. There are no direct mentions of 'Unrealised Value' or Evidence-Based Management, nor are the core concepts of identifying untapped organisational value, market demand, or innovation potential discussed. The main focus is on technical implementation, workflow automation, and editorial control, not on measuring or strategising around potential value capture. While the content is thorough and well-aligned for a technical or practitioner audience, its intent and depth are not relevant to the Unrealised Value category. The only tangential alignment is in the improvement of content discoverability, which could, in a very broad sense, relate to unlocking value, but this is not framed or explored in the context of Unrealised Value as defined. The signal-to-noise ratio is moderate, as the content is focused but not on the target topic. No penalties were applied, as the content is current and not critical or satirical. Overall, the confidence that this content fits the 'Unrealised Value' category is very low.",
    "level": "Ignored"
  },
  "Throughput": {
    "resourceId": "oRStCAqLAY4",
    "category": "Throughput",
    "calculated_at": "2025-05-07T13:03:21",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 4.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on the use of generative AI and PowerShell scripts to automate and improve the tagging and categorisation of blog posts in Hugo. There is no direct mention of 'throughput' as a delivery metric, nor is there any discussion of measuring, analysing, or visualising the number of work items completed over time. The main themes are automation, classification, editorial consistency, and human oversight in content management. While there is some technical depth regarding the architecture and process, none of it aligns with the core meaning of 'Throughput' as defined in the classification. The intent is to inform about AI-driven classification, not to discuss delivery metrics or system performance. The audience is technical (bloggers, developers, content managers), but not specifically those interested in throughput as a metric. The signal-to-noise ratio is moderate, as the content is focused but not relevant to the 'Throughput' category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence that this content fits under 'Throughput' is very low.",
    "level": "Ignored"
  },
  "Evidence Based Leadership": {
    "resourceId": "oRStCAqLAY4",
    "category": "Evidence Based Leadership",
    "calculated_at": "2025-05-07T13:03:27",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.8,
    "ai_depth": 4.5,
    "ai_intent": 4.0,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content is a detailed technical case study on using generative AI and scripting to automate and improve blog post tagging and categorisation, with a strong emphasis on human oversight, auditability, and transparent decision-making. While it discusses the use of empirical, data-driven methods (such as multi-factor scoring, penalty logic, and audit trails) to inform content management decisions, it does not directly address leadership or organisational decision-making. There are no explicit mentions of 'Evidence Based Leadership' or its core frameworks (e.g., Evidence-Based Management, KPIs for leadership, or leadership case studies). The main audience appears to be technical practitioners or content managers rather than organisational leaders. The intent is to share a technical solution for content classification, not to inform or enhance leadership practices. However, the content does touch on some principles that are adjacent to evidence-based leadership, such as the importance of traceability, accountability, and data-driven decision-making, but these are applied to content management rather than leadership. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the content is only tangentially related to Evidence Based Leadership, resulting in a low-to-moderate confidence score.",
    "level": "Tertiary"
  },
  "Working Agreements": {
    "resourceId": "oRStCAqLAY4",
    "category": "Working Agreements",
    "calculated_at": "2025-05-07T13:03:31",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 2.0,
    "ai_audience": 3.0,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on automating blog post tagging and categorisation using generative AI and PowerShell scripts. There are no direct mentions of 'working agreements' or related team norms, nor is there any discussion of team collaboration principles, Agile/Scrum working agreements, or methods for establishing team norms. The main focus is on technical architecture, automation, and editorial control, not on team-based agreements or collaborative practices. The audience is technical practitioners interested in automation and content management, not teams seeking to improve collaboration through working agreements. The signal-to-noise ratio is low for this category, as nearly all content is off-topic for 'Working Agreements.' No penalties were applied, as the content is not outdated or satirical, but the fit is extremely weak, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Employee Engagement": {
    "resourceId": "oRStCAqLAY4",
    "category": "Employee Engagement",
    "calculated_at": "2025-05-07T13:03:37",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 4.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of employee engagement, nor are there discussions of motivation, commitment, team dynamics, or any of the psychological or social aspects central to the Employee Engagement category. The main themes are technical automation, data architecture, and workflow optimisation, with a focus on content management rather than people management. The depth of discussion is substantial, but it is entirely technical and process-oriented, not aligned with employee engagement concepts. The intended audience is technical practitioners interested in automation and AI integration, not HR professionals, leaders, or those focused on team motivation. The signal-to-noise ratio is high for its technical purpose, but nearly all content is off-topic for Employee Engagement. No penalties were applied, as the content is current and not satirical or critical of the category. The low confidence score reflects the near-total lack of relevance to Employee Engagement.",
    "level": "Ignored"
  },
  "Lean Product Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Lean Product Development",
    "calculated_at": "2025-05-07T13:03:42",
    "ai_confidence": 36.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.2,
    "ai_depth": 3.7,
    "ai_intent": 3.5,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on the use of generative AI and scripting to automate and improve the tagging and categorisation of blog posts in Hugo. While it discusses process optimisation, automation, and continuous improvement in content management, it does not directly mention Lean Product Development or its core principles. There are no explicit references to Lean Thinking, waste elimination, value stream mapping, or customer feedback loops as applied to product development. The main ideas are more aligned with technical automation, editorial workflow, and responsible AI use rather than Lean Product Development. The depth of discussion is substantial regarding technical architecture and process, but not in the context of Lean Product Development. The intent is to inform about a technical solution for content classification, not to educate or guide on Lean Product Development practices. The audience is likely technical practitioners interested in automation and AI, which partially overlaps with Lean audiences but is not a direct match. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied as the content is current and does not contradict the category, but overall, the fit is weak, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Psychological Safety": {
    "resourceId": "oRStCAqLAY4",
    "category": "Psychological Safety",
    "calculated_at": "2025-05-07T13:03:47",
    "ai_confidence": 8.7,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.4,
    "ai_intent": 0.6,
    "ai_audience": 0.8,
    "ai_signal": 0.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of 'psychological safety' or any of its synonyms. The main themes are automation, AI-human collaboration, data architecture, and technical implementation. While there is a brief emphasis on human oversight, accountability, and transparency, these are framed in the context of content management and responsible AI use, not in terms of fostering a psychologically safe environment for teams. There is no discussion of team dynamics, risk-taking, open communication, or any of the key topics outlined in the psychological safety category definition. The intended audience is technical practitioners interested in automation and AI, not those seeking guidance on psychological safety in teams. The content is highly focused on its technical subject, with no tangential or off-topic material, but it is not relevant to psychological safety. Therefore, the confidence score is extremely low, reflecting only the most remote conceptual overlap (e.g., human accountability), which is incidental and not aligned with the category.",
    "level": "Ignored"
  },
  "Value Delivery": {
    "resourceId": "oRStCAqLAY4",
    "category": "Value Delivery",
    "calculated_at": "2025-05-07T13:03:51",
    "ai_confidence": 38.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.9,
    "ai_intent": 3.8,
    "ai_audience": 5.2,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content primarily details the technical and editorial process of automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo static site. Direct mentions of 'value delivery' or its synonyms are absent, and the focus is on content management, automation, and traceability rather than on strategies for delivering value to customers in Agile, Scrum, or DevOps contexts. While there are tangential references to improving discoverability, editorial consistency, and reducing manual labour, these are framed as benefits to the site owner and readers, not as part of a structured value delivery methodology. The discussion of iterative improvement and auditability is technical and process-oriented, not explicitly tied to customer value or business agility. The audience appears to be technical practitioners interested in automation and content management, not specifically those focused on value delivery in Agile or DevOps. The signal-to-noise ratio is moderate, as the content is focused but not on the target category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting the lack of direct relevance to the Value Delivery category.",
    "level": "Ignored"
  },
  "Self Organisation": {
    "resourceId": "oRStCAqLAY4",
    "category": "Self Organisation",
    "calculated_at": "2025-05-07T13:03:57",
    "ai_confidence": 38.7,
    "ai_mentions": 0.7,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 5.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content primarily focuses on the technical and architectural implementation of generative AI and scripting to automate blog post tagging and categorisation. There is a strong emphasis on human oversight, accountability, and the distinction between AI agency and human decision-making. While these themes tangentially touch on concepts like autonomy and responsibility, which are relevant to self-organisation, the discussion is not situated within the context of team dynamics, Agile, or Scrum frameworks. There are no direct mentions of self-organisation, nor are there explorations of fostering team autonomy, leadership support for self-organising teams, or Agile principles. The main audience appears to be technical practitioners interested in automation and content management, not specifically those seeking to understand or implement self-organisation in teams. The depth of discussion around self-organisation is minimal; any alignment is incidental rather than intentional. The signal-to-noise ratio is moderate, as the content is focused but not on the self-organisation topic. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting the lack of direct relevance to the 'Self Organisation' category.",
    "level": "Ignored"
  },
  "Cell Structure Design": {
    "resourceId": "oRStCAqLAY4",
    "category": "Cell Structure Design",
    "calculated_at": "2025-05-07T13:04:04",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 2.0,
    "ai_audience": 3.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell to automate tagging and categorisation in a personal blog using Hugo. There are no direct mentions of Cell Structure Design, the Beta Codex, or any of the core principles or terminology associated with the category. The conceptual alignment is extremely weak: while the content discusses decentralisation of decision-making between AI and human oversight, this is in the context of content classification, not organisational design or autonomous cells. The depth of discussion is focused entirely on technical implementation, not on organisational models or network-based structures. The intent is to inform about AI-powered content management, not to explore or advocate for Cell Structure Design. The audience is technical (bloggers, developers, automation enthusiasts), not organisational designers or strategists. The signal-to-noise ratio is low for this category, as nearly all content is off-topic. No penalties were applied, as the content is not outdated or critical of the category, but the fit is extremely poor, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Acceptance Test Driven Development": {
    "resourceId": "oRStCAqLAY4",
    "category": "Acceptance Test Driven Development",
    "calculated_at": "2025-05-07T13:04:09",
    "ai_confidence": 7.6,
    "ai_mentions": 0.0,
    "ai_alignment": 0.3,
    "ai_depth": 0.2,
    "ai_intent": 0.5,
    "ai_audience": 0.5,
    "ai_signal": 0.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content is a detailed technical case study about using generative AI and PowerShell scripts to automate and improve tagging and categorisation in a Hugo-based blog. There are no direct mentions of Acceptance Test Driven Development (ATDD), nor are there references to acceptance criteria, stakeholder collaboration, or any of the core principles or practices of ATDD. The main focus is on content classification, automation, and human oversight in the context of blog management, not software feature development or acceptance testing. The audience is technical, but not specifically practitioners of ATDD or related methodologies. The signal-to-noise ratio is high for its actual topic, but entirely unrelated to ATDD. No penalties were applied as the content is not outdated or critical of ATDD; it is simply off-topic. The extremely low confidence score reflects the near-total lack of relevance to the ATDD category.",
    "level": "Ignored"
  },
  "Coaching": {
    "resourceId": "oRStCAqLAY4",
    "category": "Coaching",
    "calculated_at": "2025-05-07T13:04:14",
    "ai_confidence": 19.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 6.2,
    "ai_signal": 6.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of coaching, nor are there references to coaching techniques, roles, or mindsets. The main themes are automation, classification, technical architecture, and human oversight in content management. While the author discusses the importance of human accountability and oversight, this is framed in the context of editorial control and responsible AI use, not in the context of coaching, mentoring, or facilitating growth in teams or individuals. The audience is technical practitioners interested in automation and content management, not those seeking guidance on coaching practices. The signal-to-noise ratio is high for its intended topic, but the content is almost entirely unrelated to coaching as defined. No penalties were applied, as the content is current and not critical or satirical. The low confidence score reflects the near-total lack of conceptual or practical overlap with the Coaching category.",
    "level": "Ignored"
  },
  "Windows": {
    "resourceId": "oRStCAqLAY4",
    "category": "Windows",
    "calculated_at": "2025-05-07T13:04:19",
    "ai_confidence": 23.35,
    "ai_mentions": 2.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.7,
    "ai_audience": 6.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "Direct mentions of Windows are minimal: the only explicit reference is the author's statement 'I'm a Windows user and have been for years, so I wrote all of the scripting in PowerShell.' This is a passing mention and not a focus of the content. Conceptual alignment is weak; the main themes are about automating blog post classification using generative AI, Hugo, and PowerShell, not about Windows OS installation, configuration, troubleshooting, or management. The depth of discussion regarding Windows is negligible—the content does not explore Windows-specific features, issues, or best practices. The intent is to share a technical workflow for content classification, not to inform or support users in managing Windows environments. The audience is technical, which partially overlaps with the Windows category, but the focus is on content creators and automation enthusiasts rather than Windows administrators or users. The signal-to-noise ratio is low for the Windows category, as the vast majority of the content is off-topic for Windows. No penalties were applied, as the content is not outdated or satirical. Overall, the confidence score is low, reflecting the lack of substantive connection to the Windows category.",
    "level": "Ignored"
  },
  "GitHub": {
    "resourceId": "oRStCAqLAY4",
    "category": "GitHub",
    "calculated_at": "2025-05-07T13:04:26",
    "ai_confidence": 13.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.0,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 2.5,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a detailed technical narrative about automating blog post tagging and categorisation in Hugo using generative AI and PowerShell. There is a single, brief mention of GitHub: 'all of my code is in GitHub where it can be versioned, branched, and reviewed with a PR.' However, this is a passing reference and not a focus of the discussion. The main themes are automation, AI integration, scripting, and content management, not GitHub's services, features, or best practices. There is no exploration of GitHub Actions, CI/CD, collaboration features, or project management within GitHub. The audience is technical, but the content is not aimed at GitHub practitioners or those seeking GitHub-specific guidance. The signal-to-noise ratio is low for the GitHub category, as nearly all content is off-topic for this classification. No penalties were applied, as the content is current and not critical of GitHub, but the confidence score is very low due to minimal relevance.",
    "level": "Ignored"
  },
  "Organisational Change": {
    "resourceId": "oRStCAqLAY4",
    "category": "Organisational Change",
    "calculated_at": "2025-05-07T13:04:35",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content is a detailed technical case study about automating blog post tagging and categorisation using generative AI and PowerShell scripts within a Hugo-based static site. It focuses on the architecture, data structures, and workflow for classification, with an emphasis on human oversight and auditability. \n\nDirect Mentions (0.6): There are no explicit references to 'Organisational Change' or its frameworks, nor are there direct mentions of change management, agility, or related terminology. The only tangential connection is the use of the word 'transformation' in the context of site management, not organisational transformation.\n\nConceptual Alignment (2.2): The main ideas revolve around technical automation, AI-assisted classification, and editorial workflow improvements for a personal blog. While there is a process of change (moving platforms, improving workflows), it is not organisational in scope or intent. There is no discussion of organisational agility, resilience, or change management methodologies.\n\nDepth of Discussion (2.5): The content is thorough in its technical depth but does not explore organisational change concepts, frameworks, or practices. The discussion is limited to the technical and editorial domain, not organisational transformation.\n\nIntent / Purpose Fit (2.0): The primary intent is to share a technical solution for content management, not to inform or support organisational change initiatives. Any overlap is incidental and not the main purpose.\n\nAudience Alignment (3.1): The target audience is technical practitioners, bloggers, and developers interested in automation and AI for content management, not organisational leaders, change agents, or strategists.\n\nSignal-to-Noise Ratio (2.8): The content is focused and relevant to its technical topic, but almost none of it is relevant to organisational change. The signal for the evaluated category is very low.\n\nNo penalties were applied, as the content is current, not satirical, and does not contradict the category's framing. Overall, the confidence score is low, reflecting that the content does not fit the 'Organisational Change' category beyond a superficial, coincidental process improvement.",
    "level": "Ignored"
  },
  "Scrum Master": {
    "resourceId": "oRStCAqLAY4",
    "category": "Scrum Master",
    "calculated_at": "2025-05-07T13:04:43",
    "ai_confidence": 13.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.0,
    "ai_depth": 1.8,
    "ai_intent": 2.0,
    "ai_audience": 2.5,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. While the author briefly mentions their career progression, including a period working with Scrum and process consulting, there is no substantive discussion of the Scrum Master accountability, its responsibilities, or its systemic impact. The only direct reference to 'Scrum' is in a list of categories and tags, and 'Scrum Mastery' appears as an example tag, but neither is explored in any depth. The main focus is on technical architecture, automation, and editorial workflow, not on the Scrum Master role or its unique accountability within Scrum. The audience is primarily technical content managers or developers, not Scrum Masters or those interested in Scrum Mastery as a discipline. The signal-to-noise ratio for the Scrum Master category is low, as nearly all content is off-topic for this classification. No penalties were applied, as the content is current and does not contradict the category's framing, but the confidence score is very low due to minimal relevance.",
    "level": "Ignored"
  },
  "System Configuration": {
    "resourceId": "oRStCAqLAY4",
    "category": "System Configuration",
    "calculated_at": "2025-05-07T13:04:49",
    "ai_confidence": 41.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.2,
    "ai_intent": 3.5,
    "ai_audience": 5.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content primarily discusses the use of generative AI and PowerShell scripting to automate and improve the tagging and categorisation of blog posts within a Hugo static site. While there are technical details about scripting, automation, and data architecture, the focus is on content classification, editorial consistency, and workflow optimisation for content management—not on system configuration as defined (i.e., setup and integration of software/hardware for optimal performance, configuration management, or system reliability). There are some tangential overlaps, such as automation practices (PowerShell scripts, audit trails, version control), but these are applied to content metadata rather than system-level configuration. The audience is technical, but the main intent is not to inform about system configuration tools, methodologies, or best practices. Direct mentions of system configuration are absent, and the conceptual alignment is limited. The depth of discussion is substantial for content classification and automation, but not for system configuration. The signal-to-noise ratio is moderate, as the content is focused but not on the evaluated category. No penalties were applied, as the content is current and does not contradict the category's framing. Overall, the confidence score is low, reflecting that the content does not fit well under 'System Configuration' despite some technical overlap.",
    "level": "Tertiary"
  },
  "Continuous Improvement": {
    "resourceId": "oRStCAqLAY4",
    "category": "Continuous Improvement",
    "calculated_at": "2025-05-07T13:04:55",
    "ai_confidence": 67.6,
    "ai_mentions": 2.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.0,
    "ai_audience": 7.5,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "Direct mentions of 'Continuous Improvement' or its synonyms are minimal; the term itself is not explicitly referenced, and the focus is on technical automation and AI-driven classification. However, the conceptual alignment is moderately strong: the content describes an ongoing, iterative process of improving blog tagging and categorisation, leveraging automation, empirical feedback (audit trails, penalty logic), and human oversight. These are core aspects of continuous improvement, though the framing is more about technical optimisation than explicit process or team effectiveness. The depth of discussion is solid, with detailed explanations of architecture, validation, and future enhancements, but it is primarily technical rather than process-oriented. The intent is to share a method for improving a system over time, which fits the spirit of continuous improvement, though the main purpose is not to advocate for continuous improvement as a discipline. The audience is technical practitioners and content managers, which partially overlaps with the typical audience for continuous improvement (e.g., process consultants, agile teams). The signal-to-noise ratio is high, with most content relevant to the described system and its evolution. No penalties are applied, as the content is current, constructive, and not critical of the category. Overall, while the content embodies many principles of continuous improvement (iteration, feedback, measurable enhancement), it does so in a technical, site-specific context rather than as a primary subject, resulting in a moderate confidence score.",
    "level": "Secondary"
  },
  "Forecasting": {
    "resourceId": "oRStCAqLAY4",
    "category": "Forecasting",
    "calculated_at": "2025-05-07T13:05:04",
    "ai_confidence": 18.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 1.8,
    "ai_audience": 6.0,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a technical case study on using generative AI and PowerShell to automate blog post tagging and categorisation in Hugo. There are no direct mentions of 'Forecasting' or related Agile/Scrum forecasting practices. The main themes are automation, classification, and content management, not empirical prediction, delivery timelines, or risk management. While the content discusses data-driven classification and the use of metrics for validation, these are not in the context of forecasting outcomes or optimising value delivery as defined in the category. The depth of discussion is substantial but focused on technical implementation, not forecasting methodologies. The intent is to inform practitioners about AI-powered classification, not to support or explore forecasting in Agile/Scrum. The audience (technical practitioners) partially overlaps with the category, but the signal-to-noise ratio is moderate since the content is highly relevant to automation and classification, not forecasting. No penalties were applied as the content is current and not critical of the category. Overall, the confidence score is low, reflecting minimal conceptual overlap with the 'Forecasting' category.",
    "level": "Ignored"
  },
  "Product Owner": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Owner",
    "calculated_at": "2025-05-07T13:05:12",
    "ai_confidence": 13.7,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 5.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is a technical case study about using generative AI and PowerShell to automate tagging and categorisation in a Hugo-based blog. There is no direct mention of the Product Owner role or its accountability within Scrum or Agile frameworks. The only tangential reference is the author's career path, which briefly mentions moving through DevOps and Scrum to process consulting, but this is not elaborated upon and does not discuss Product Owner responsibilities, decision-making, or stakeholder management. The main themes are automation, human oversight, and technical architecture for content classification, not maximising product value or backlog prioritisation. The audience is technical practitioners interested in automation and content management, not specifically Product Owners or those interested in their accountability. The signal-to-noise ratio is low for the Product Owner category, as nearly all content is off-topic for this classification. No penalties were applied, as the content is not outdated or satirical, but the confidence score is very low due to lack of relevance.",
    "level": "Ignored"
  },
  "Practice": {
    "resourceId": "oRStCAqLAY4",
    "category": "Practice",
    "calculated_at": "2025-05-10T13:04:07",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.1,
    "ai_intent": 3.5,
    "ai_audience": 6.2,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on automating blog tagging and categorisation using generative AI and PowerShell, with an emphasis on technical implementation, auditability, and human oversight. While it references 'practices' in the context of classification and editorial standards, it does not discuss repeatable team techniques or actionable habits that improve team effectiveness, as defined by the Practice category. There are no direct mentions of key practices like retrospectives, TDD, or Kanban. The main audience is technical implementers, but the discussion is about system architecture and automation, not about team practices. The depth is moderate regarding automation and classification, but not on actionable team practices. The signal is somewhat diluted by technical details unrelated to Practice as defined.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Philosophy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Philosophy",
    "calculated_at": "2025-05-10T13:04:18",
    "ai_confidence": 54.7,
    "ai_mentions": 2.2,
    "ai_alignment": 5.7,
    "ai_depth": 5.9,
    "ai_intent": 5.5,
    "ai_audience": 7.1,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "Direct mentions of 'Philosophy' are minimal, appearing only as an example within a taxonomy structure, not as a discussion topic. The content's main focus is on technical implementation, automation, and editorial workflow, with only tangential references to philosophical concepts (e.g., human vs. AI agency, accountability). While there is some conceptual overlap—such as the distinction between human and AI roles, and the idea of foundational 'Concepts'—these are not explored in depth as philosophical frameworks. The depth of discussion is primarily technical and procedural, not theoretical. The intent is to inform about a technical solution, not to explore or advocate for philosophical underpinnings. The audience is likely to include strategists and technical leaders, which aligns somewhat with the Philosophy category, but the content is not targeted at those seeking philosophical discourse. The signal-to-noise ratio is high, as the content is focused and well-structured, but the focus is not on Philosophy. No penalties were applied as the content is current and not critical of the category.",
    "reasoning_summery": null,
    "level": "Tertiary"
  },
  "Capability": {
    "resourceId": "oRStCAqLAY4",
    "category": "Capability",
    "calculated_at": "2025-05-10T13:04:35",
    "ai_confidence": 41.6,
    "ai_mentions": 1.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.9,
    "ai_intent": 4.2,
    "ai_audience": 5.1,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and scripting. While it references 'capability' in a general sense and discusses building a robust, auditable classification system, it does not directly address organisational or team capabilities as defined in the category. The main themes are technical implementation, automation, and editorial control, not the enduring competencies or systemic capabilities that empower teams or organisations. There is some conceptual overlap in the sense of building a sustainable, repeatable process, but the discussion is largely about tooling, workflow, and personal site management. The audience is technical practitioners, but the depth and alignment with the Capability category are limited.",
    "reasoning_summery": null,
    "level": "Tertiary"
  },
  "Principle": {
    "resourceId": "oRStCAqLAY4",
    "category": "Principle",
    "calculated_at": "2025-05-10T13:04:49",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.1,
    "ai_intent": 3.5,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a technical case study on using generative AI and scripting to automate blog tagging and categorisation. While it references concepts like accountability, human oversight, and transparent decision-making, these are discussed as operational practices rather than as explicit, actionable principles guiding team behaviour. There is no direct or in-depth discussion of Agile, Lean, or DevOps principles, nor are foundational beliefs or guiding rules for decision-making explored. The main focus is on technical implementation, workflow automation, and system architecture, not on the principles that shape team conduct or decision-making. The audience is technical, but the content is not intended to teach or discuss principles as defined by the category. Any alignment is incidental and not the main purpose.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Framework": {
    "resourceId": "oRStCAqLAY4",
    "category": "Framework",
    "calculated_at": "2025-05-10T13:04:56",
    "ai_confidence": 23.7,
    "ai_mentions": 1.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 2.1,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on using generative AI and scripting to automate tagging and categorisation in a personal blog, with a strong emphasis on technical implementation, human oversight, and auditability. While it references categories such as 'Scrum' and 'Kanban' as examples of editorial groupings, it does not discuss frameworks themselves, their principles, implementation strategies, or adaptation. There is no exploration of Agile, DevOps, or Lean frameworks, nor any comparison, best practices, or case studies related to frameworks. The main intent is to describe a technical solution for content classification, not to inform or guide on frameworks. The audience is primarily technical implementers interested in automation, not those seeking guidance on frameworks. The signal-to-noise ratio is low for the Framework category, as the content is focused on automation and AI, not frameworks.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Model": {
    "resourceId": "oRStCAqLAY4",
    "category": "Model",
    "calculated_at": "2025-05-10T13:05:05",
    "ai_confidence": 41.7,
    "ai_mentions": 2.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.9,
    "ai_intent": 4.5,
    "ai_audience": 5.1,
    "ai_signal": 5.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content focuses on the technical implementation of generative AI and scripting to automate tagging and categorisation in a blog, with a strong emphasis on workflow, automation, and human oversight. While it introduces a multi-level classification structure (Concepts, Categories, Tags) and discusses the architecture for AI-driven classification, it does not directly discuss or analyse conceptual models as defined in the category (e.g., Cynefin, Three Ways of DevOps, Lean Startup, Kanban flow models). The closest alignment is the mention of 'Concepts' as thematic anchors, but these are not explored as models for organisational decision-making or systems thinking. The main intent is technical enablement and process improvement, not the exploration or application of models in Agile, DevOps, or Lean contexts. The audience is technical practitioners interested in automation and content management, which partially overlaps with the category's audience but is not a direct match. The signal-to-noise ratio is moderate, with some relevant discussion of classification structures but little focus on models as conceptual frameworks.",
    "reasoning_summery": null,
    "level": "Tertiary"
  },
  "Observability": {
    "resourceId": "oRStCAqLAY4",
    "category": "Observability",
    "calculated_at": "2025-05-10T13:05:11",
    "ai_confidence": 36.7,
    "ai_mentions": 0.8,
    "ai_alignment": 3.2,
    "ai_depth": 3.7,
    "ai_intent": 3.5,
    "ai_audience": 4.1,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on using generative AI and scripting to automate and improve tagging and categorisation in a static site generator (Hugo). While it discusses technical automation, auditability, and transparency, it does not directly address observability as defined (measuring and understanding internal system states via metrics, logs, or traces). There are no explicit mentions of observability, nor does the content explore its principles, tools, or impact on team or business outcomes. The main audience is technical practitioners, but the topic is content management automation, not observability in software systems. The signal-to-noise ratio is moderate, as the content is focused but not on the target category.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Accountability": {
    "resourceId": "oRStCAqLAY4",
    "category": "Accountability",
    "calculated_at": "2025-05-10T13:05:22",
    "ai_confidence": 67.7,
    "ai_mentions": 4.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.0,
    "ai_audience": 6.2,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content directly discusses the distinction between AI agency and human accountability, explicitly stating that AI cannot 'own accountability' and that humans retain outcome ownership. It references accountability as a structural mechanism (e.g., 'deterministic enforcement', 'humans set direction and own accountability'), aligning with the category's definition. However, the main focus is on technical implementation of AI-driven classification and workflow automation, with accountability as a supporting theme rather than the central topic. The discussion of accountability is thoughtful and non-superficial, but not deeply explored in the context of organisational design or role-specific accountabilities. The audience is technical practitioners interested in automation and content management, which partially overlaps with the category's target. The content is focused, with minimal off-topic material, but the primary intent is not to analyse accountability as a work system mechanism. No penalties are warranted as the content is current and not critical of the accountability concept.",
    "reasoning_summery": null,
    "level": "Secondary"
  },
  "Strategy": {
    "resourceId": "oRStCAqLAY4",
    "category": "Strategy",
    "calculated_at": "2025-05-10T13:05:28",
    "ai_confidence": 67.2,
    "ai_mentions": 3.7,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.5,
    "ai_audience": 7.0,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 67.0,
    "reasoning": "The content references 'technical strategy' and discusses high-level decisions about structuring site classification, blending automation with human oversight, and aligning taxonomies for editorial consistency. It describes a multi-layered classification system (concepts, categories, tags) and the rationale for these choices, which aligns with strategic thinking. However, the primary focus is on technical implementation and process improvement, not on organisational or business strategy. The discussion of 'Strategy' as a concept is present but not deeply explored in the context of organisational goal alignment or leadership. The audience is likely technical practitioners or site owners, not executive strategists. The content is focused and relevant, but the strategic dimension is more about system design than classic organisational strategy.",
    "reasoning_summery": null,
    "level": "Secondary"
  },
  "Discipline": {
    "resourceId": "oRStCAqLAY4",
    "category": "Discipline",
    "calculated_at": "2025-05-10T13:05:35",
    "ai_confidence": 54.7,
    "ai_mentions": 2.2,
    "ai_alignment": 5.8,
    "ai_depth": 6.1,
    "ai_intent": 5.5,
    "ai_audience": 6.0,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content focuses on the technical and editorial process of automating blog post classification using generative AI and PowerShell, with an emphasis on human oversight and traceability. While it references concepts like editorial standards, classification systems, and the importance of consistent principles, it does not directly discuss the systemic application, maturation, or governance of professional disciplines such as Agile, DevOps, or Lean. The main thrust is on workflow automation and content management, not on the evolution or characteristics of a discipline. There are some conceptual overlaps (e.g., continuous improvement, structured methodologies), but these are incidental rather than central. The audience is technical and process-oriented, but the discussion remains at the level of tooling and editorial practice rather than discipline theory or governance.",
    "reasoning_summery": null,
    "level": "Tertiary"
  },
  "Artifact": {
    "resourceId": "oRStCAqLAY4",
    "category": "Artifact",
    "calculated_at": "2025-05-10T13:05:47",
    "ai_confidence": 23.7,
    "ai_mentions": 0.7,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 2.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and scripting, with an emphasis on workflow, traceability, and editorial control. While it discusses the structure and management of tags, categories, and concepts, these are not formal Agile, Scrum, Lean, or DevOps artifacts as defined in the classification. There are no direct mentions of artifacts in the Agile sense, nor is there exploration of their role in transparency, empirical control, or evidence-based decision-making. The discussion is technical and process-oriented but does not align with the core meaning of 'Artifact' in Agile or Lean systems.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Tool": {
    "resourceId": "oRStCAqLAY4",
    "category": "Tool",
    "calculated_at": "2025-05-10T13:05:55",
    "ai_confidence": 87.7,
    "ai_mentions": 8.2,
    "ai_alignment": 9.1,
    "ai_depth": 8.7,
    "ai_intent": 8.5,
    "ai_audience": 8.0,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 88.0,
    "reasoning": "The content provides a detailed, technical account of integrating generative AI and PowerShell scripts to automate tagging and categorisation in Hugo, a static site generator. It directly discusses the use, architecture, and workflow impact of specific tools (Hugo, PowerShell, OpenAI, GitHub), aligning with the Tool category. The discussion is deep, covering implementation, auditability, and future enhancements, and is aimed at practitioners interested in workflow automation and tool integration. The content is highly focused, with minimal off-topic material, and the intent is to inform and guide on tool-based solutions for content management. No penalties were applied as the content is current, constructive, and fits the category well.",
    "reasoning_summery": null,
    "level": "Primary"
  },
  "Method": {
    "resourceId": "oRStCAqLAY4",
    "category": "Method",
    "calculated_at": "2025-05-10T13:06:04",
    "ai_confidence": 54.7,
    "ai_mentions": 2.2,
    "ai_alignment": 5.7,
    "ai_depth": 5.3,
    "ai_intent": 5.0,
    "ai_audience": 6.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content primarily details a technical workflow for automating blog post classification using generative AI and PowerShell scripts. While it references structured procedures (e.g., multi-layer classification, audit trails, penalty logic), these are not discussed as formal 'methods' in the Agile, Lean, or DevOps sense. There is some conceptual overlap with methodical approaches (e.g., deterministic validation, iterative improvements), but the main focus is on tooling, automation, and technical implementation rather than on step-by-step methods for process improvement or delivery. The audience is technical and process-oriented, but the discussion of 'method' is indirect and not central. The signal is strong for automation and classification, but only tangential for the Method category as defined.",
    "reasoning_summery": null,
    "level": "Tertiary"
  },
  "Tenet": {
    "resourceId": "oRStCAqLAY4",
    "category": "Tenet",
    "calculated_at": "2025-05-10T13:06:11",
    "ai_confidence": 36.7,
    "ai_mentions": 1.2,
    "ai_alignment": 3.8,
    "ai_depth": 4.1,
    "ai_intent": 3.5,
    "ai_audience": 4.0,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on using generative AI and scripting to automate and improve blog tagging and categorisation, with an emphasis on human oversight and auditability. While it discusses principles like accountability, transparency, and blending automation with human judgment, these are not framed as actionable organisational tenets in the sense defined by the category. There are no direct mentions of tenets or prescriptive rules guiding organisational behaviour, nor is there a deep exploration of tenets within Agile, DevOps, Lean, or similar methodologies. The main intent is technical process improvement, not the application or discussion of tenets. The audience is technical practitioners, but the content is not structured around tenet-driven guidance. The signal-to-noise ratio is moderate, with some relevant discussion of principles but not in the context required for this category.",
    "reasoning_summery": null,
    "level": "Ignored"
  },
  "Ethos": {
    "resourceId": "oRStCAqLAY4",
    "category": "Ethos",
    "calculated_at": "2025-05-13T14:02:00",
    "ai_confidence": 38.7,
    "ai_mentions": 1.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.9,
    "ai_intent": 4.2,
    "ai_audience": 5.1,
    "ai_signal": 5.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content primarily details a technical implementation of AI-driven tagging and categorisation for a blog, focusing on automation, auditability, and human oversight. While it briefly references 'ethos' in the context of human accountability versus AI agency, this is not the main theme. The discussion of foundational beliefs or system-level convictions is minimal and mostly implicit, with only a few sentences touching on the distinction between human and AI roles. The majority of the content is technical, describing scripts, data structures, and workflow improvements, rather than exploring ethos as the underpinning of sustainable delivery or authentic transformation. The audience is technical practitioners, and the signal-to-noise ratio is moderate, with some relevant reflections but mostly implementation details. No penalties were applied as the content is current and not satirical or critical.",
    "reasoning_summary": "This content is mainly a technical case study on AI-powered blog categorisation, with only brief, indirect references to ethos—mainly around human accountability. It does not deeply explore foundational beliefs or system-level convictions, so confidence for the 'Ethos' category is low.",
    "level": "Ignored"
  },
  "First Principal": {
    "resourceId": "oRStCAqLAY4",
    "category": "First Principal",
    "calculated_at": "2025-05-13T14:02:08",
    "ai_confidence": 23.7,
    "ai_mentions": 0.6,
    "ai_alignment": 2.2,
    "ai_depth": 2.8,
    "ai_intent": 2.0,
    "ai_audience": 7.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on automating and improving blog post tagging and categorisation using generative AI and PowerShell, with an emphasis on human oversight and auditability. While it discusses concepts like 'foundational ideas' and 'non-negotiable' distinctions between human and AI agency, it does not explicitly identify, explain, or apply first principles as defined in Lean, Agile, Scrum, or DevOps contexts. The main themes are technical implementation, editorial workflow, and responsible automation, not the articulation or application of first principles as immutable constraints. There are no direct mentions of 'first principles,' nor is there a substantive exploration of their role in system design or professional conduct. The audience and signal are reasonably aligned with technical practitioners, but the core content is not about first principles.",
    "reasoning_summary": "This content is about automating blog classification with AI and human oversight, not about identifying or applying first principles in Lean, Agile, Scrum, or DevOps. It lacks direct references or deep discussion of first principles, so confidence in this category is low.",
    "level": "Ignored"
  },
  "Customer Focus": {
    "resourceId": "oRStCAqLAY4",
    "category": "Customer Focus",
    "calculated_at": "2025-05-13T14:02:15",
    "ai_confidence": 27.6,
    "ai_mentions": 1.2,
    "ai_alignment": 2.8,
    "ai_depth": 3.1,
    "ai_intent": 2.5,
    "ai_audience": 4.0,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 28.0,
    "reasoning": "The content is a technical case study on using generative AI and scripting to automate blog tagging and categorisation. While it discusses improving discoverability and aligning tags/categories with user needs, it does not explicitly address defining, measuring, or prioritising customer outcomes as required by the Customer Focus category. The main focus is on editorial consistency, automation, and workflow optimisation for the author's own site, not on delivering measurable value to customers or establishing feedback loops with real users. There are no direct mentions of customer value, customer feedback, or outcome-driven development. The audience is technical practitioners, but the discussion is not anchored in customer-centric agile or DevOps philosophies.",
    "reasoning_summary": "This content focuses on automating blog tagging and categorisation using AI, with an emphasis on editorial standards and workflow efficiency. It lacks explicit discussion of customer outcomes, feedback, or value delivery, so it only weakly aligns with the Customer Focus category.",
    "level": "Ignored"
  },
  "Definition of Workflow": {
    "resourceId": "oRStCAqLAY4",
    "category": "Definition of Workflow",
    "calculated_at": "2025-05-23T22:06:14",
    "ai_confidence": 23.6,
    "ai_mentions": 0.4,
    "ai_alignment": 2.8,
    "ai_depth": 2.3,
    "ai_intent": 1.7,
    "ai_audience": 9.1,
    "ai_signal": 5.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on using AI and PowerShell scripts for blog post categorization and workflow automation within a Hugo site, describing the technical system and editorial taxonomy (Concepts, Categories, Tags), and emphasizing human oversight in AI-driven processes. However, it does not mention or explore the Definition of Workflow as defined in Kanban/agile contexts, nor does it address entry/exit policies, WIP limits, or similar agreements. While 'workflow' is mentioned, this refers to personal publishing or editorial processes rather than Kanban/DevOps workflow concepts. Audience aligns as technical practitioners, and signal is moderate, but there is no substantive discussion of Kanban-style Definition of Workflow.",
    "reasoning_summary": "This content describes a technical and editorial process for automating blog categorization with AI and human oversight. It does not explore the Definition of Workflow as defined in Kanban or agile contexts, and thus only minimally fits the category.",
    "level": "Ignored"
  },
  "Product Developer": {
    "resourceId": "oRStCAqLAY4",
    "category": "Product Developer",
    "calculated_at": "2025-06-23T09:02:06",
    "ai_confidence": 18.61,
    "ai_mentions": 0.4,
    "ai_alignment": 2.0,
    "ai_depth": 2.7,
    "ai_intent": 1.5,
    "ai_audience": 4.3,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content focuses on using generative AI and automation for content classification and tagging in a static blog platform. While there is brief mention of AI agency and accountability, it is within a technical implementation context rather than the Product Developer role as defined in agile frameworks. There are no direct references to Product Developer accountabilities, skills, or responsibilities, nor is there exploration of collective accountability, cross-functionality, or other key attributes tied to the Product Developer category. Therefore, the coverage is largely peripheral, with nearly all discussion targeted at technical system builders and content managers instead of product development teams or practitioners.",
    "reasoning_summary": "The content centers on AI-powered classification and tagging for blogs, not on the Product Developer role or accountability. It lacks direct references or thematic depth relevant to Product Developers in agile or product frameworks, resulting in a low confidence fit.",
    "level": "Ignored"
  },
  "Collective Intelligence": {
    "resourceId": "oRStCAqLAY4",
    "category": "Collective Intelligence",
    "calculated_at": "2025-06-23T09:01:49",
    "ai_confidence": 69.32,
    "ai_mentions": 3.7,
    "ai_alignment": 7.7,
    "ai_depth": 8.2,
    "ai_intent": 7.9,
    "ai_audience": 8.0,
    "ai_signal": 8.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 69.0,
    "reasoning": "The content discusses a human-AI collaborative workflow, emphasizing the complementary roles of generative AI and human oversight in blog content classification. There is explicit discussion about shared agency, traceability, deterministic human enforcement, and AI providing tactical suggestions rather than owning editorial decisions—directly referencing and aligning with the core themes of collective intelligence. It details how multi-factor assessments blend AI output and human judgment to achieve better results than either alone, and proposes further improvements to these hybrid workflows. However, 'collective intelligence' as a term is not directly mentioned and the scenario, while an exemplar of human-AI teaming, is focused on an individual practitioner context rather than a team-based socio-technical system. Thus, depth and alignment are high, intent and audience fit are strong, and the signal-to-noise ratio is excellent, but partial topical fit and indirectness in labeling slightly lower the mentions score.",
    "reasoning_summary": "The content offers a detailed case of practical human-AI collaboration, showcasing distributed accountability, shared agency, and combining human judgment with AI recommendations—a strong fit to collective intelligence in process, though not by explicit label and within a single-author context.",
    "level": "Secondary"
  },
  "Objective Key Results": {
    "resourceId": "oRStCAqLAY4",
    "category": "Objective Key Results",
    "calculated_at": "2025-06-23T09:01:55",
    "ai_confidence": 7.45,
    "ai_mentions": 0.1,
    "ai_alignment": 0.2,
    "ai_depth": 0.2,
    "ai_intent": 0.1,
    "ai_audience": 0.1,
    "ai_signal": 0.09,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content provides a detailed walkthrough of how generative AI and automation were used to overhaul tagging and categorization on a personal blog. There are in-depth discussions about classification, content organization, automation oversight, and multi-layered taxonomies (concepts, categories, tags), but there are no direct or indirect references to OKRs, their principles, theory, or practices. The system's scoring approach, mentioned as multi-factor with penalties, superficially resembles OKR-style measurement but is explicitly and exclusively focused on content classification—not outcome-driven strategic alignment or value realization. The content's main purpose is technical process improvement in content management, not structured objective setting, measurable key results, or iterative goal alignment. There is no discussion of John Doerr's OKR framework, nor are topics such as focus, alignment through transparency, outcome-based measurement, or OKR integration into Agile, Scrum, or DevOps explored.",
    "reasoning_summary": "This content is about leveraging AI to automate tagging and categorization in a blog, focusing on technical improvements to content management. It does not address OKRs, outcome-driven goal setting, or strategic alignment, so it falls entirely outside the intended OKR category.",
    "level": "Ignored"
  },
  "Agentic Engineering": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agentic Engineering",
    "calculated_at": "2025-07-23T12:05:20",
    "ai_confidence": 80.1,
    "ai_mentions": 6.8,
    "ai_alignment": 8.6,
    "ai_depth": 8.1,
    "ai_intent": 7.6,
    "ai_audience": 7.8,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 80.0,
    "reasoning": "The content describes the deliberate blending of generative AI with human oversight in a technical automation system, emphasizing agency division, transparency, and continuous adaptation. It directly discusses developer agency (regaining workflow control), ethical AI integration (AI as tactical agent, human remains accountable), automation practices, auditability, and feedback loops via a multi-layered tag/categorization system. The discussion is nuanced, explaining both technical and philosophical aspects of agency, validation, and adaptation. The audience is technical, matching the likely target of agentic engineering discourse, and the content is highly focused on the interplay of tools, human decision-making, and responsible AI use. However, direct references to 'Agentic Engineering' as a term are absent, and while all mechanisms align conceptually, the material is framed as a practical case study rather than as a treatise on agentic engineering at large.",
    "reasoning_summary": "This content aligns closely with Agentic Engineering, describing a deliberate, feedback-driven system where AI augments but does not displace human agency. It details observability, validation, and adaptive practices, making it very relevant despite not naming the category directly.",
    "level": "Secondary"
  },
  "Agentic Software Delivery": {
    "resourceId": "oRStCAqLAY4",
    "category": "Agentic Software Delivery",
    "calculated_at": "2025-08-07T06:10:24",
    "ai_confidence": 58.35,
    "ai_mentions": 2.6,
    "ai_alignment": 5.1,
    "ai_depth": 5.6,
    "ai_intent": 4.0,
    "ai_audience": 7.0,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 58.0,
    "reasoning": "Direct mentions of 'agency' and the delineation between AI tactical support and human accountability partially overlap with Agentic Software Delivery. The content describes autonomous AI role in assigning tags/categories but stresses human oversight and does not discuss embedding agents deep in software delivery pipelines, engineering practices, or large-scale organisational impact. While it references AI as a 'tactical agent' with boundaries and auditability, most examples center on personal content/classification workflows, not modern agentic delivery paradigms like telemetry, backlog management, sprint planning, or collaboration among agents/humans at an organisational or team level. The audience is technical and practice-focused, with relevant intent to responsibly augment delivery with AI, but lacks thorough coverage of agentic delivery systems, architectural, or governance frameworks beyond the blog's context.",
    "reasoning_summary": "Partially fits—describes AI agents with defined boundaries and human oversight, but applies them to blog tagging, not broader software delivery. Lacks depth on integration, engineering practices, or full agentic delivery systems.",
    "level": "Tertiary"
  },
  "Product Operating Model": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Product Operating Model",
    "calculated_at": "2025-11-24T18:58:56",
    "ai_confidence": 41.14,
    "ai_mentions": 2.2,
    "ai_alignment": 4.7,
    "ai_depth": 5.1,
    "ai_intent": 4.9,
    "ai_audience": 5.5,
    "ai_signal": 4.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 41.0,
    "reasoning": "The content details automating content classification (tags, categories, concepts) for a personal blog using AI and scripts, with emphasis on transparent, auditable processes and human oversight. While themes of systematisation, automation, and editorial governance overlap somewhat with concepts in product operating models—such as structuring processes, traceability, and integrating technology—there is no explicit or substantive discussion of product operating model frameworks, governance at an organizational level, or cross-functional alignment. The approach focuses on content management for a single-author blog, not on the broader structural, governance, or resource alignment concerns seen in organizational product operating models. Brief references to roles (AI vs. human judgment), process layers, and intent echo some vocabulary of operating models, but these are narrowly applied. There are no direct mentions of product operating models (or their recognized variants), little relevant audience overlap, and the discussion remains at the technical implementation level for blog management. No penalties were applied, as the tone is positive and current.",
    "reasoning_summary": "Content centers on technical blog classification automation, not organizational product operating model design. Only tangential thematic overlap exists; framework, structural, or governance elements are missing. Fit is minimal and largely indirect.",
    "level": "Tertiary"
  },
  "Operating Model": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "Operating Model",
    "calculated_at": "2025-11-24T18:56:46",
    "ai_confidence": 38.45,
    "ai_mentions": 0.6,
    "ai_alignment": 4.5,
    "ai_depth": 4.8,
    "ai_intent": 4.7,
    "ai_audience": 6.8,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content centers on using generative AI and scripting to automate blog classification, focusing on personal workflows and technical architecture for tagging and categorization. While it discusses how content is structured and introduces editorial taxonomies, it does not meaningfully explore or reference organizational operating models or principles of organizational design, governance, or value streams at the enterprise level. The main thrust is an individual’s content management process rather than discussions on structures, decision rights, or cross-team workflows within organizations. There are almost no direct mentions or explicit alignment with the 'Operating Model' category’s strategic or organizational themes. Audience alignment is moderately relevant given the technical transparency, but the depth and intent are not sufficient for high confidence.",
    "reasoning_summary": "This post details a solo content management automation approach, not organizational operating model design. There is little conceptual or thematic alignment, making fit with 'Operating Model' partial and incidental at best.",
    "level": "Ignored"
  },
  "AI Product Operating Model": {
    "resourceId": "oRStCAqLAY4",
    "itemId": "oRStCAqLAY4",
    "category": "AI Product Operating Model",
    "calculated_at": "2025-11-24T19:11:47",
    "ai_confidence": 38.28,
    "ai_mentions": 1.2,
    "ai_alignment": 3.6,
    "ai_depth": 4.1,
    "ai_intent": 3.8,
    "ai_audience": 4.0,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content describes an individual system that leverages generative AI and scripting for automated tagging, focusing on technical integration, human oversight, and transparent audit trails for a personal blog. It mentions architectural and workflow considerations and references concepts such as blending human and AI agency, auditability, and penalty/validation layers. However, it does not discuss organization-wide operating models, team structures, cross-functional roles, end-to-end lifecycle management, or scaling AI product practices—the core of the AI Product Operating Model category. The focus remains personal, technical, and implementation-centric rather than on organizational governance, lifecycle, or model operationalization across a business ecosystem. Mentions of AI agency vs. human agency are thoughtful, but not situated in the context of organizational practices.",
    "reasoning_summary": "Content details a personal, technical system using AI for content tagging with strong process control, but lacks discussion of organizational operating models or lifecycle management of AI products; partial fit at best.",
    "level": "Ignored"
  }
}