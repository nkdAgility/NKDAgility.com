{
  "Lean": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Lean",
    "calculated_at": "2025-05-08T08:55:13",
    "ai_confidence": 24.8,
    "ai_mentions": 0.8,
    "ai_alignment": 2.5,
    "ai_depth": 3.4,
    "ai_intent": 1.8,
    "ai_audience": 4.4,
    "ai_signal": 2.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 25.0,
    "reasoning": "The content is an in-depth critique and exploration of resilience engineering and organizational failure, focusing on real-world disasters stemming from fragile system design. While concepts such as wasteful practices and insufficient real-world testing indirectly touch on inefficiency and lack of value, Lean itself is never mentioned, nor are any Lean principles, terminology, or tools directly referenced (e.g., no mention of the Seven Wastes, 5S, Kanban, Kaizen, or value stream mapping). The discussion remains focused on resilience, disaster recovery, and architecture, not on systematic process improvement as characterized by Lean. The audience is technical/engineering leadership, which aligns somewhat with Lean audiences, but the main intent is to advocate for discipline and real testing, not Lean methodology or philosophy. The signal-to-noise ratio is moderate because all content is focused on resilience, but none is specifically about Lean. There are no outdated practices, satire, or direct contradiction of Lean, so no penalties have been applied. The confidence score is low, as the content does not fit under the 'Lean' category except perhaps in a loose, conceptual sense regarding the value of testing and process discipline, which is why there is a modest alignment and depth score.",
    "level": "Ignored"
  },
  "Engineering Excellence": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Engineering Excellence",
    "calculated_at": "2025-05-08T08:55:13",
    "ai_confidence": 90.129,
    "ai_mentions": 6.2,
    "ai_alignment": 9.7,
    "ai_depth": 9.5,
    "ai_intent": 8.8,
    "ai_audience": 8.3,
    "ai_signal": 8.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 90.0,
    "reasoning": "The content provides an in-depth critique of poor engineering practices and failures in designing for resilience, directly referencing 'engineering' and advocating for rigorous software development discipline. While it does not explicitly use the phrase 'engineering excellence,' it repeatedly discusses bad engineering versus sound engineering, the necessity of thorough testing, and engineering for failure, all of which align extremely closely with the category. The article covers root causes from technical debt (neglected dependencies like Active Directory) to the value of true operational discipline (like repeated disaster recovery exercises at Rackspace), hitting on several key topics from the category's scope. The discussion is deep, drawing on multiple real-world failures and contrasting these with best practices that epitomize engineering excellence (systematic, painful, real testing, and refusal to accept surface-level success metrics). The author explicitly ties the notion of resilience to product and engineering craftsmanship, emphasizing that real resilience can only be 'built' through engineering, not process theater. Audience targeting is technical (CTOs, senior engineers, tech leads), though there's some overlap with leadership/product roles. It is highly relevant and focused with only minor tangents woven in as storytelling and context, not filler. No outdated practices or contradictory tones are present, thus no penalties were applied. The slightly lower score for 'mentions' reflects the indirect reference to the category name but frequent invocation of its core concepts. Overall, the weighting formula results in a high confidence score that accurately reflects near-complete overlap of the content's message and the meaning of 'Engineering Excellence.'",
    "level": "Primary",
    "reasoning_summary": "This content strongly fits the 'Engineering Excellence' category. It thoroughly critiques poor engineering and highlights best practices, such as rigorous testing and resilience, which are central to the category. While it doesn’t use the exact term, its focus on technical discipline and real-world examples makes it highly relevant for technical leaders and engineers seeking excellence."
  },
  "Technical Leadership": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Technical Leadership",
    "calculated_at": "2025-05-08T08:55:13",
    "ai_confidence": 77.21,
    "ai_mentions": 3.7,
    "ai_alignment": 8.8,
    "ai_depth": 7.8,
    "ai_intent": 8.1,
    "ai_audience": 7.3,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 77.0,
    "reasoning": "The content focuses on the imperative of building real system resilience versus the danger of claiming resilience without action. It addresses leadership failures, organization-wide blind spots, and the necessity of engineering discipline for operational survivability—all clearly within the scope of technical leadership. Examples such as disaster recovery exercises at Merrill Lynch and the practices at Rackspace directly illustrate leadership behavior shaping engineering culture and outcomes. The narrative also critically examines poor leadership in crisis (Heathrow, Oracle), linking top-level decisions to technical failures. However, direct use of the term 'technical leadership' is minimal (one mention of 'leadership' with reference to product leadership but never the phrase 'technical leadership'); this limits the Direct Mentions dimension. Conceptual Alignment is very high: the text relentlessly analyzes leadership’s role in fostering resilience, tying in responsibility and systemic thinking essential for technical leaders. Depth is solid, with multiple real-world cases and layered arguments, but it focuses primarily on the leadership-culture-resilience linkage and doesn’t deeply cover topics like coaching, agile ceremonies, metrics, or specific technical-leadership frameworks, hence not a perfect score. Intent is highly aligned, aiming to inform and challenge leaders to act on resilience. The Audience Alignment is slightly marked down because, while targeting CTOs and technology executives, it implicitly addresses a broader operational and engineering audience, not exclusively technical leadership practitioners. Signal-to-noise is strong—almost all paragraphs are relevant, with minor digressions (e.g., a brief personal anecdote) integrated into the main thesis. No penalties were applied as the content is current, not satirical, and directly supports the intended category.",
    "level": "Secondary",
    "reasoning_summary": "This content strongly fits the technical leadership category, as it explores how leadership decisions directly impact system resilience and engineering culture. Real-world examples highlight both effective and poor leadership, illustrating the consequences for technical teams. While explicit references to \"technical leadership\" are limited, the analysis and intent are highly relevant for leaders aiming to foster resilient, responsible engineering practices."
  },
  "Leadership": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Leadership",
    "calculated_at": "2025-05-08T08:55:13",
    "ai_confidence": 65.8,
    "ai_mentions": 2.3,
    "ai_alignment": 6.9,
    "ai_depth": 6.8,
    "ai_intent": 3.9,
    "ai_audience": 7.2,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 66.0,
    "reasoning": "The content is primarily focused on the technical and organizational aspects of resilience in system design, with recurring themes of discipline, engineering rigor, and confronting organizational self-delusion. The word 'leadership' is mentioned three times (including one section title), mostly in the context of leadership failure or misplaced priorities. There is a direct link to a 'leadership' category, and a brief section discussing 'real product leadership' demanding hard questions about resilience, but substantive focus on Agile/Lean-aligned leadership practices is limited. The primary emphasis is on operational resilience: lessons from outages, technical strategies, and the need for recurring, real-world testing. The article highlights failures at the leadership level (e.g., 'leadership failed to create a culture...') and recognizes the cultural and behavioral impact leaders have on resilience, but the depth of discussion on leadership practices, frameworks, or behaviors is moderate and often indirect. The target audience likely overlaps with technical leaders (CTOs, senior engineers, operations managers) and those interested in organizational improvement, and much of the content is highly relevant for these personas. However, leadership is not the central theme: it serves as an undercurrent rather than the main thesis. The article is focused, critical, and offers some commentary on leadership accountability but doesn't deeply unpack leadership models or strategies. No penalties were triggered as the content is current, serious in tone, and not satirical or outdated. The confidence score reflects partial but not dominant alignment with the 'Leadership' category.",
    "level": "Secondary"
  },
  "Scrum": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Scrum",
    "calculated_at": "2025-08-07T09:26:24",
    "ai_confidence": 12.08,
    "ai_mentions": 0.15,
    "ai_alignment": 1.9,
    "ai_depth": 2.2,
    "ai_intent": 1.4,
    "ai_audience": 3.3,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content focuses almost entirely on systems resilience, organisational denial, and real-world disaster recovery, with concrete engineering and leadership examples from industry. There is no direct mention of Scrum, its events, roles, or artifacts, nor any reference to Agile concepts. While themes like 'continuous improvement' and 'iterative testing' appear, they are used in a generic sense related to engineering resilience, not Scrum's empirical process control or team-based improvement cycles. The intended audience appears to be technical leadership and engineers rather than practitioners of Scrum practices. Overall, there is minimal conceptual overlap and no substantive fit with the Scrum category.",
    "reasoning_summary": "This content does not fit the Scrum category. It addresses engineering resilience, not Scrum principles, roles, or processes. References to iteration and improvement are generic and unrelated to Scrum's framework or audience.",
    "level": "Ignored"
  },
  "Product Management": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Product Management",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 43.16,
    "ai_mentions": 2.3,
    "ai_alignment": 5.8,
    "ai_depth": 5.7,
    "ai_intent": 4.9,
    "ai_audience": 5.1,
    "ai_signal": 5.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "This content is a critical analysis of system resilience, focusing on fragility in design, operational failures, and organizational denial. 'Product' and 'product capability' are referenced explicitly, but 'Product Management' itself is not directly discussed. The closest alignment is in the sections that challenge leaders to integrate resilience into product roadmaps and operational strategy, and by highlighting the importance of thinking about customer experience during outages. However, the bulk of the discussion fixates on engineering failures, disaster recovery, and organizational culture, not on the core frameworks, methodologies, or strategic practices central to Product Management. There are some conceptual overlaps, such as the call for real product leadership and tying resilience to customer needs, but these are not explored in depth from a Product Management methodology lens (e.g., no discussion of prioritization frameworks, stakeholder balancing, Agile methods, EBM, or KPIs for product success). The main purpose appears to be a critique of technical and leadership failures, aiming to spur higher standards in resilience architecture rather than guiding product managers on strategic alignment or evidentiary decision making. The audience seems to straddle CTOs, engineering leaders, and generally those with a stake in operational stability, including but not limited to product managers. The content is focused and on-topic with respect to resilience, but the signal-to-noise for Product Management as strictly defined in the classification is moderate at best. There are no penalties for being outdated or contradicting the spirit of the category.",
    "level": "Tertiary"
  },
  "DevOps": {
    "resourceId": "LGGuvRq4g7p",
    "category": "DevOps",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 61.1,
    "ai_mentions": 0.6,
    "ai_alignment": 7.9,
    "ai_depth": 8.2,
    "ai_intent": 8.6,
    "ai_audience": 8.1,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 61.0,
    "reasoning": "The content offers a deep exploration of resilience in engineering and organisational practices, emphasizing the need to build, test, and iterate for survivability. Core DevOps principles such as designing for failure, leadership accountability, operational discipline, continuous testing, and a culture of experimentation are invoked—particularly through discussions about systemic failure, observability, shared accountability, eliminating silos, and learning through pain. However, the term 'DevOps' is never directly mentioned, nor are adjacent concepts (CICD, automation, feedback loops, shifting left) referenced explicitly; the focus is almost exclusively on resilience, a value closely associated with effective DevOps but not uniquely defined by it. The audience and intent (CTOs, technical leaders aiming to improve their operational capabilities) align well with DevOps practitioners and decision-makers. The article resists filler and tangents, focusing tightly on real events and failures, which supports a high signal-to-noise ratio. While the piece aligns strongly with the culture and goals of DevOps, the lack of direct category references and explicit language reduces the overall confidence that this content solely fits the DevOps category, warranting a moderate score in 'mentions' and a slightly conservatively weighted overall result.",
    "level": "Secondary"
  },
  "Kanban": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Kanban",
    "calculated_at": "2025-08-07T09:25:25",
    "ai_confidence": 7.38,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 0.5,
    "ai_intent": 0.9,
    "ai_audience": 2.0,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content focuses entirely on resilience engineering, failure analysis, and organizational attitudes toward operational survivability—core topics in reliability, not Kanban. There is no mention of Kanban, nor its practices (visualization, WIP limits, flow, etc.), and the discussion does not align with Kanban’s core philosophies or address its intended audience. While the content could be of interest to technical leaders or DevOps practitioners (some overlap with Kanban audiences), the thematic and conceptual match is extremely weak; there is no indication of Kanban principles, tools, metrics, or feedback loops as defined in the classification. The text’s examples and purpose are to challenge attitudes toward resilience, not to discuss Kanban method, its context, or application. Therefore, the fit is almost nonexistent.",
    "reasoning_summary": "This content is about resilience engineering and organizational failures—topics unrelated to Kanban principles or practices. No explicit or conceptual link to Kanban; therefore, it does not fit the category.",
    "level": "Ignored"
  },
  "Product Development": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Product Development",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 77.445,
    "ai_mentions": 3.5,
    "ai_alignment": 8.9,
    "ai_depth": 8.6,
    "ai_intent": 7.8,
    "ai_audience": 8.2,
    "ai_signal": 9.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 77.0,
    "reasoning": "The content directly considers resilience as a 'product capability' and critiques superficial or naïve approaches to product continuity and system survivability. It aligns well with Product Development insofar as it urges leaders and teams to build iterative, tested resilience into products from the ground up, referencing failures that stem from poor product thinking, lack of intentional design for failure, and leadership not prioritizing genuine operational survivability. Depth is high, with concrete real-world examples, a firsthand account, and comparison between failure cases and an exemplary case (Rackspace) where recurring testing and iteration built true resilience—clearly reflecting principles of iterative learning and continuous improvement. The main intent is to drive home the necessity of iterating, risk management, and system design choices—resonant with Product Development best practices. Direct mentions of 'product', 'roadmap', and 'product leadership' are present, but the text does not explicitly discuss Product Development process models, methodologies (e.g., Agile, Lean), or customer feedback cycles; these are more implied than directly addressed. Audience is fitting for product managers, CTOs, and organizational leaders interested in the product reliability and strategic risk minimization—though it slightly skews toward engineering leadership. Signal-to-noise is very high, with the entire text reinforcing the necessity of designing for resilience as a deliberate, iterated product development activity. No penalties are applied, as the content is current and not satirical or undermining; instead, it is constructively critical of failures. The lower score for direct mentions and slightly lower intent/purpose fit reflect the fact that, while deeply relevant, the piece is more about a specific product attribute (resilience as capability) than a general exploration of product development methodology. Overall, the confidence score proportionately reflects strong alignment but less explicit methodological focus.",
    "level": "Secondary",
    "reasoning_summary": "This content fits the Product Development category well, as it emphasises the importance of building resilience into products through intentional design, iteration, and risk management. While it doesn’t delve deeply into specific methodologies, it offers practical insights and real-world examples relevant to product leaders, making it highly valuable for those focused on product reliability and improvement."
  },
  "Company as a Product": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Company as a Product",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 53.973,
    "ai_mentions": 1.6,
    "ai_alignment": 5.3,
    "ai_depth": 6.1,
    "ai_intent": 4.9,
    "ai_audience": 7.8,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 54.0,
    "reasoning": "The content strongly discusses systemic organisational failures in building resilience, making several points about how leadership and organisational culture can undermine survivability by relying on shallow or performative practices. It connects resilience to 'product capability' and critiques 'shallow product thinking,' which moderately aligns to the CaaP notion of treating the company as a dynamic product—particularly in the passages urging leadership to integrate failure remediation into strategy. However, the text falls short of offering a thorough exploration of Company as a Product frameworks. It does not explicitly reference CaaP, nor does it deeply discuss integrating customer feedback, measuring strategic outcomes, or cross-functional organisational redesign. There is only one brief moment where treating resilience as a 'product capability' echoes CaaP principles, but it immediately focuses back on systems engineering and leadership failures, not the holistic company-as-product mindset. Depth suffers as most detail is on technical failures and operational discipline, not on reinventing the organisation as a product. Intent skews towards critique of common industry failures in resilience, not explicit advocacy for CaaP or its application. Audience alignment is quite high, as the examples and tone speak to senior technology leaders and executives—the core CaaP audience. The signal-to-noise ratio is strong, with most content focused and relevant, albeit not always tailored to the CaaP paradigm. No penalties were warranted—the discussion is timely, earnest, and not satirical or outdated. In sum, while the text is conceptually adjacent to CaaP (via discussions of product thinking, leadership, and organisational blindness), it is more about resilience engineering and cultural discipline than a full CaaP lens.",
    "level": "Tertiary"
  },
  "Agile Values and Principles": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Agile Values and Principles",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 28.33,
    "ai_mentions": 0.6,
    "ai_alignment": 3.5,
    "ai_depth": 4.0,
    "ai_intent": 2.5,
    "ai_audience": 5.0,
    "ai_signal": 3.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 28.0,
    "reasoning": "The content is an in-depth critique of organizational and technical failures related to system resilience, focusing on real-world incidents and the nature of engineering resilient systems. There are no direct mentions or explicit references to 'Agile Values and Principles,' the Agile Manifesto, or its twelve principles. The conceptual alignment is limited: while themes of learning from failure, testing iteratively, and proactive leadership resonate somewhat with Agile principles (e.g., continuous improvement, embracing change), the discussion is solidly centered on operational resilience, technical rigor, and disaster recovery practices, not Agile philosophy. The depth of discussion around resilience is high, but depth regarding Agile-specific values is minimal to non-existent. The intent of the content is to underline the cost of organizational self-delusion and to critique poor operational practices, not to elucidate Agile values. The audience might overlap with those interested in Agile (technical leaders, CTOs), and the content is focused, but its relevance to Agile principles is mostly tangential—connecting only at a high level, such as advocating for transparency and relentless improvement. No penalties are needed, as the tone is critical but not of Agile itself, and the content is recent and relevant. The final confidence score (28.33) reflects that while there is some very light thematic overlap with Agile principles (such as iteration over pain, learning from failure), the content is not meaningfully about Agile Values and Principles nor is it suitable for classifying into that category.",
    "level": "Ignored"
  },
  "Test Driven Development": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Test Driven Development",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 10.2,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 0.8,
    "ai_intent": 1.5,
    "ai_audience": 3.1,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content focuses exclusively on resilience engineering at the system and organizational level, emphasizing real-world failure testing, disaster recovery, and the need for operational discipline. While there is brief mention of testing (e.g., 'tested and verified under real-world conditions'), it is never in the context of Test Driven Development (TDD) as a software methodology. There are no direct or indirect mentions of the TDD cycle (Red-Green-Refactor), writing tests before code, or any of the specific practices, tools, or benefits that define TDD. The primary purpose is to persuade engineering leadership and CTOs to prioritize resilience and real disaster testing, not to discuss automated unit testing or software design techniques. The audience may have overlap with those interested in TDD (e.g. technical leaders), but the framing, depth, and intent are entirely misaligned with TDD as strictly defined. Therefore, extremely low scores are assigned on all dimensions, with a slight recognition that technical practitioners might see thematic relevance concerning 'testing for resilience.' However, this remains highly tangential and does not meet classification criteria for Test Driven Development.",
    "level": "Ignored"
  },
  "Market Share": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Market Share",
    "calculated_at": "2025-08-07T09:25:25",
    "ai_confidence": 6.6,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.0,
    "ai_intent": 0.8,
    "ai_audience": 2.0,
    "ai_signal": 0.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content focuses on system resilience, failures in engineering, organisational denial, and real-world disaster recovery, using case studies and personal experience. It does not mention 'market share', competitive advantage, or strategies/tactics for increasing market share, nor does it address the core concepts of the category. The main audience is technical/product leaders, which partially aligns with the market share category but only in a generic sense, not with strategic emphasis. There's almost no signal relating to market share, and no explicit or even implied connection to expanding product presence or competitive positioning. The content is strongly on-topic for resilience but almost entirely irrelevant for 'Market Share'. No penalties applied, as tone and recency are appropriate.",
    "reasoning_summary": "Content is wholly focused on system resilience and engineering failure, not on market share, its strategies, or metrics. There's negligible thematic or conceptual alignment with the market share category; the fit is extremely low to nonexistent.",
    "level": "Ignored"
  },
  "Scaling": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Scaling",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 19.771,
    "ai_mentions": 0.3,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.1,
    "ai_audience": 7.3,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "Direct mentions: The content never explicitly references 'Scaling', scaling frameworks, or terms synonymous with the Scaling category as defined. There is a single, indirect mention of 'negligence at scale' that refers to the magnitude of an outage, not scaling methodologies. Conceptual alignment: While the discussion is highly relevant to system resilience, engineering for failure, and operational readiness, it almost never discusses the multi-team or enterprise coordination, lean principles, or structured approaches central to Scaling as defined. Case studies (Spain, Oracle, Heathrow) are all analyzed through the lens of resilience, not scaling practices or enterprise alignment. Depth: Offers a thorough and nuanced discussion of resilience engineering failure, but that depth is focused on product, technical, organizational, and leadership failures—not on cross-team scaling, frameworks, or coordination at scale. Intent/Purpose: The main intent is critique of superficial resilience and advocating for disciplined, tested engineering—valuable, but not targeted to solving the complexities of Scaling with respect to the definition. Audience: The content targets engineering/product leaders and executives (CTOs), which overlaps with the Scaling audience, justifying the higher mark here. Signal: Content is highly focused, offering minimal tangential or filler material, though its focus is outside the Scaling category as defined. No penalties were applied since the content is neither outdated nor undermining the category's framing; it's robust, but off-topic for Scaling. The low overall confidence reflects the near-absence of Scaling content per the provided definition.",
    "level": "Ignored"
  },
  "Lead Time": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Lead Time",
    "calculated_at": "2025-08-07T09:25:25",
    "ai_confidence": 4.292,
    "ai_mentions": 0.3,
    "ai_alignment": 0.7,
    "ai_depth": 0.9,
    "ai_intent": 0.6,
    "ai_audience": 0.4,
    "ai_signal": 0.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 4.0,
    "reasoning": "There are no explicit references to Lead Time or its characteristic metrics; the content focuses exclusively on resilience, fragility, engineering for failures, and product thinking. Topics such as restoring services quickly or operational response are mentioned, but not in terms of measuring or optimizing Lead Time. Depth is almost entirely around resilience, not Lead Time, making conceptual fit minimal and largely coincidental (i.e., the mention of 'How fast can we restore service?' could potentially touch on Lead Time, but only as a minor tangent and not as the core theme). No significant intent, audience match, or signal quality for Lead Time specifically.",
    "reasoning_summary": "The content does not cover Lead Time as defined. Its focus is on organizational resilience/failure, not on measuring or optimizing Lead Time. Any overlap is vague and incidental; fit for the category is negligible.",
    "level": "Ignored"
  },
  "Acceptance Test Driven Development": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Acceptance Test Driven Development",
    "calculated_at": "2025-08-07T11:23:41",
    "ai_confidence": 2.08,
    "ai_mentions": 0.1,
    "ai_alignment": 2.2,
    "ai_depth": 2.6,
    "ai_intent": 1.3,
    "ai_audience": 3.1,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content does not directly mention Acceptance Test Driven Development (ATDD) nor does it discuss its principles, collaborative approach, or acceptance criteria. It covers resilience, engineering for failure, and real-world testing but in the context of operational reliability and organizational culture, not ATDD practices or tooling. While 'testing under real-world conditions' and 'acceptance' are thematically near, there is no link to ATDD methodology or its key tenets. The audience alignment is partial—targeting practitioners concerned with software quality—but not specifically focused on those seeking ATDD insights.",
    "reasoning_summary": "Content is about resilience, failure, and real-world testing—not ATDD. No mention of collaborative acceptance criteria or ATDD practices. Topic and intent do not match the ATDD category.",
    "level": "Ignored"
  },
  "Increment": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Increment",
    "calculated_at": "2025-05-08T08:55:13",
    "ai_confidence": 11.59,
    "ai_mentions": 0.2,
    "ai_alignment": 1.3,
    "ai_depth": 1.1,
    "ai_intent": 0.9,
    "ai_audience": 3.2,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content primarily discusses system resilience, organisational failure, disaster recovery, and engineering practices, with illustrative industry examples. Nowhere does it directly mention the concept of Increment, deliverables per iteration, Scrum or Agile frameworks, or the delivery of working software increments. The main conceptual themes focus on engineering resilience, not iterative value delivery. There are some tangential overlaps such as references to testing, iteration, and improvement, but these are in the context of operational survivability, not the Scrum Increment. No content is oriented towards measuring value delivered by each increment or the relationship to Scrum artifacts. Thus, direct mentions (0.2) and conceptual alignment (1.3) are minimal. The discussion has fair depth (1.1) but not on the category; intent (0.9) does not fit, as it is not for Scrum/Agile practitioners focused on Increment. The audience (3.2) is technical/leadership, partially overlapping, and the signal (2.1) for the target is low due to off-topic focus. No penalties are applied, as the content is not outdated nor oppositional to Increment.",
    "level": "Ignored"
  },
  "Application Lifecycle Management": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Application Lifecycle Management",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 54.9,
    "ai_mentions": 0.8,
    "ai_alignment": 6.3,
    "ai_depth": 6.7,
    "ai_intent": 6.2,
    "ai_audience": 3.7,
    "ai_signal": 4.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "Direct Mentions (0.8): The term 'Application Lifecycle Management' is not mentioned directly, nor are synonyms like ALM. The dominant terminology concerns 'resilience,' 'continuity,' 'disaster recovery,' and 'engineering,' which are tangentially related but not explicit category references.\n\nConceptual Alignment (6.3): The content aligns moderately with ALM concepts, particularly regarding operational survivability and the risks of poor lifecycle thinking. It examines aspects of leadership, product management, and failure/continuity in a way that partially matches ALM principles, but the framing stays anchored in resilience engineering and disaster recovery, not end-to-end application lifecycle management.\n\nDepth of Discussion (6.7): The exploration of real-world failures and best practices provides more than a superficial treatment of resilience as a product and organizational capability. There are detailed case studies and process critiques, but the discussion does not tie specifically into the staged ALM process (conception, development, deployment, maintenance, retirement), toolchains, or ALM frameworks, thus limiting depth relative to the category as strictly defined.\n\nIntent / Purpose Fit (6.2): The purpose is to instill a culture of discipline, truth-telling, and proactive testing around resilience—important in the context of ALM but not squarely positioned as guidance for full application lifecycle governance. The motivation is corrective, with an emphasis on operational pain, which partially diverges from the category’s mainstream intent.\n\nAudience Alignment (3.7): The article addresses CTOs, leadership, and senior technical roles concerned with operational risk, as well as product strategists. While these audiences overlap with ALM practitioners, the content is more geared toward those responsible for resilience/continuity than ALM process specialists or toolchain managers.\n\nSignal-to-Noise Ratio (4.3): The content stays focused on resilience, system design, and culture, but much of the discussion is illustrative, anecdotal, or oriented around criticism, with relatively less direct, practical ALM-relevant content. There is minimal digression, but the required focus on lifecycle methodologies, tools, and governance practices is lacking.\n\nNo penalties are applied, as the content is current, not satirical or contradictory to the ALM framing; tone is critique-driven but serious. Overall, while related to ALM, the content is best classified as resilience engineering and disaster recovery within a broader context, with only partial, indirect coverage of ALM themes.",
    "level": "Tertiary"
  },
  "Platform Engineering": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Platform Engineering",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 25.8,
    "ai_mentions": 0.5,
    "ai_alignment": 3.3,
    "ai_depth": 3.7,
    "ai_intent": 2.9,
    "ai_audience": 7.1,
    "ai_signal": 5.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 26.0,
    "reasoning": "Direct mentions of platform engineering or related specific terminology (e.g., Internal Developer Platforms, IDPs, developer self-service, automated workflows) are entirely absent—the content explores resilience and system design failures but never references Platform Engineering as a discipline. The conceptual alignment is partial: while resilience is certainly a consideration in platform engineering, the piece focuses narrowly on resilience, disaster recovery failures, and organizational mistakes without tying these ideas back to the design and operation of internal developer platforms or productivity tooling. There is clear depth in examining failures (with detailed examples and root causes explored), but this depth is about generic infrastructure, disaster planning, and organizational process rather than internal platforms or self-service capabilities. The intent is to critique poor practices and advocate for rigorous, painful engineering of resilience, which is related but not explicitly aimed at platform engineering audiences; it's a general call for responsible engineering. The audience is technical and could overlap with platform engineering stakeholders (CTOs, architects, ops leads), thus the relatively higher score there. Signal-to-noise is moderate—but a fair portion of content is narrative or case study critique, not tightly related to platform platforms, standardization, or internal tooling. Overall, this content is about system resilience as a general engineering value with limited connection to the core themes, methods, or deliverables of platform engineering as defined above.",
    "level": "Ignored"
  },
  "Deployment Frequency": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Deployment Frequency",
    "calculated_at": "2025-08-07T11:23:41",
    "ai_confidence": 11.77,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 2.1,
    "ai_intent": 0.9,
    "ai_audience": 2.4,
    "ai_signal": 1.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content focuses extensively on engineering resilience, disaster recovery, real-world testing, and cultural awareness in operations. It does not discuss deployment frequency, CI/CD, or practices related to frequent software releases. No explicit or implicit references are made to increasing or measuring deployment intervals. The main themes are resilience, survivability, and testing, not deployment cadence, metrics, or iteration cycles. Audience is loosely technical/organisational, but not geared toward those optimizing deployment frequency. Nearly all discussion, though detailed and on-topic for resilience, is off-topic for the given category.",
    "reasoning_summary": "This content centers on resilience engineering and operational survivability, offering no substantive connection to Deployment Frequency, CI/CD, or release practices. Fit to the assigned category is extremely weak and at best tangential.",
    "level": "Ignored"
  },
  "Remote Working": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Remote Working",
    "calculated_at": "2025-08-07T11:23:41",
    "ai_confidence": 6.899,
    "ai_mentions": 0.1,
    "ai_alignment": 1.4,
    "ai_depth": 1.3,
    "ai_intent": 1.2,
    "ai_audience": 1.899,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is an in-depth critique of organizational and engineering failures in building resilient systems with high-profile outages as case studies. Nowhere does it mention, reference, or discuss remote working, distributed collaboration, tools, Agile team practices, or challenges unique to remote work; nor are there even tangential allusions to work-from-home, virtual teams, or hybrid work in the Agile context. Its audience is anyone interested in operational resilience, systems engineering, and leadership, rather than Agile or remote practitioners. The low confidence score is due to negligible topical overlap and total absence of relevant signals per category definition.",
    "reasoning_summary": "Content does not mention, relate to, or align thematically with remote working or Agile remote practices. Its sole focus is on resilience engineering and organizational behavior, so category fit is negligible.",
    "level": "Ignored"
  },
  "Customer Satisfaction": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Customer Satisfaction",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 26.41,
    "ai_mentions": 0.4,
    "ai_alignment": 2.8,
    "ai_depth": 2.9,
    "ai_intent": 1.6,
    "ai_audience": 9.1,
    "ai_signal": 7.7,
    "ai_penalties_applied": true,
    "ai_penalty_points": 1,
    "ai_penalty_details": "Alignment: deducted 1 point due to a somewhat critical tone toward organizational practices, slightly undermining the holistic framing, and lack of explicit Agile/DevOps/Lean connection",
    "final_score": 26.0,
    "reasoning": "The content is a robust critique of organizational and engineering failures in the context of system resilience. While there is some brief mention of customers—such as the Rackspace case keeping 'customers online' and rhetorical questions about how customers would experience outages—these are incidental to the main argument, which is almost entirely centered on technical and organizational discipline regarding resilience, disaster recovery, and infrastructure reliability. There are no explicit references to 'customer satisfaction,' nor to measurement frameworks (Net Promoter Score, feedback loops) or Agile/Lean/DevOps practices as described in the category definition. The bulk of the discussion covers detailed product engineering failures and leadership shortcomings in resilience, not customer-centric methodologies or their impact on market fit or experience. Intent is largely about accurate design and recovery, rather than directly enhancing customer happiness or loyalty. The audience is technical/leadership, tangentially similar to the category's presumed readers, but this is more by happenstance than direct focus. The signal-to-noise ratio is high, as the content is focused and purposeful, but the focus is not on customer satisfaction. A penalty to alignment was applied due to the somewhat undermining, critical tone toward established practices, and the absence of explicit connection to Agile/DevOps customer-driven frameworks as required by the strict exclusion criteria.",
    "level": "Ignored"
  },
  "Continuous Delivery": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Continuous Delivery",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 35.27,
    "ai_mentions": 0.3,
    "ai_alignment": 3.9,
    "ai_depth": 3.8,
    "ai_intent": 4.5,
    "ai_audience": 7.1,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 35.0,
    "reasoning": "The content focuses almost entirely on resilience engineering—designing, testing, and validating systems for survivability and operational continuity under failure. There are zero direct mentions of 'Continuous Delivery' or its core vocabulary (e.g., deployment pipelines, automation, incremental releases). The alignment is partial: while Continuous Delivery principles sometimes overlap with resilience practices (e.g., rapid iteration, culture of learning from failure), the article frames resilience as a separate, meta-level product and engineering goal. Depth of discussion is strong about resilience, with many real-world examples and counter-cases, but Continuous Delivery is not discussed—automation, release frequency, user validation, etc. are all missing. The audience (technical leaders, CTOs) aligns with the general Continuous Delivery audience, but intent is adjacent rather than direct, advocating for resilience rather than for software release practices. The signal is high (low filler/tangents), but almost all content is about resilience, not Continuous Delivery. No penalties were needed: the tone is earnest and current. Ultimately, while experienced Continuous Delivery practitioners might value this material as background, its direct support and coverage of the 'Continuous Delivery' category is weak. The score reflects this with low ratings for mentions, alignment, and depth, offset partly by strong audience fit and focused delivery.",
    "level": "Ignored"
  },
  "Market Adaptability": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Market Adaptability",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 58.775,
    "ai_mentions": 1.6,
    "ai_alignment": 6.5,
    "ai_depth": 5.9,
    "ai_intent": 6.2,
    "ai_audience": 7.1,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 59.0,
    "reasoning": "The content deeply explores the topic of resilience in technical systems, with concrete case studies and sharply critical analysis of failures in disaster recovery, engineering practices, leadership, and organizational readiness. However, it does not explicitly discuss or reference 'market adaptability', nor are Agile, DevOps, Lean methodologies, or continuous feedback/innovation cycles directly named or discussed in the context of market responsiveness. The focus is on engineering discipline and operational survivability rather than organizational adaptability to market shifts. While the intent and themes brush against principles relevant to market adaptability (such as resilience, learning from failure, and systemic preparedness), the content is not tailored to show how these practices enable a business to swiftly respond to market changes or competitor moves—key hallmarks of the provided definition. There is little coverage of cross-functional teams, data-driven decision-making, or customer satisfaction as outcomes from adaptability strategies. Direct audience targeting fits, as the content addresses senior technical leaders (like CTOs) and uses examples relevant to decision-makers and practitioners; the signal is high and focused. Overall, the content is substantively relevant but lacks direct, explicit, and conceptual depth in aligning with 'Market Adaptability' as specifically defined—hence the moderate confidence score.",
    "level": "Tertiary"
  },
  "Miscellaneous": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Miscellaneous",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 37.85,
    "ai_mentions": 0.3,
    "ai_alignment": 2.7,
    "ai_depth": 3.1,
    "ai_intent": 2.4,
    "ai_audience": 6.1,
    "ai_signal": 5.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content focuses on the topic of resilience in system design and operational continuity, using industry outages as case studies. It does not mention or directly reference the 'Miscellaneous' category, resulting in a very low 'mentions' score. While the themes involve general organizational and product design failures, these are discussed from an engineering/IT resilience perspective, not as general, non-framework content—so conceptual alignment is limited. The depth is moderate, due to extensive anecdotes and technical detail, but depth regarding 'Miscellaneous' as a classification is low, as the discussion remains specifically about resilience, a technical architecture concern. The main intent is to critique poor engineering and organizational approaches to resilience, not to contribute a non-framework, broad, or catch-all context as framed for Miscellaneous. Audience alignment scores higher, as the narrative could appeal to leaders, technologists, and business practitioners—but the targeting is not specifically the broad, undefined audience typical of 'Miscellaneous.' Signal is fairly high due to focused content, but not fully, as the detailed technical narrative is outside what the category seeks. No dimension was penalized, as the content is not outdated nor is its tone contrary to Miscellaneous, only orthogonal. Overall, the confidence is low, reflecting that while the text is somewhat tangentially related to business practices, it is too technical, engineering-specific, and actionable to align well with the intended catch-all, non-framework-oriented nature of the Miscellaneous category.",
    "level": "Ignored"
  },
  "Cell Structure Design": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Cell Structure Design",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 8.7,
    "ai_mentions": 0.1,
    "ai_alignment": 1.3,
    "ai_depth": 2.2,
    "ai_intent": 2.1,
    "ai_audience": 2.5,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content 'Fragile by Design: The Cost of Pretending to Be Resilient' focuses exclusively on system and organisational resilience, catastrophic failures, disaster recovery, and the need for robust engineering. Nowhere does it mention Cell Structure Design, the Beta Codex, autonomous cells, or any of the defining concepts or language of the specified category. The only marginal theme that overlaps is a general discussion of leadership, product thinking, and organisational culture, but these are entirely in service of resilience rather than decentralised, cell-based structures. No key topics from the Cell Structure Design category are directly or indirectly covered, and the content is directed at practitioners or leaders managing operational risk (e.g., CTOs) rather than those interested in networked organisational theory. All relevant dimensions are therefore scored very low, within the 0–2.5 range, except for audience, which is slightly higher due to a partial overlap (both discuss organisational/technical leadership, but for different purposes). There are no outdated references or critical/satirical tones against Cell Structure Design, so no penalties are applied. The overall confidence is extremely low and proportionate to the complete lack of substantive or conceptual fit with the category.",
    "level": "Ignored"
  },
  "Change Management": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Change Management",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 55.2,
    "ai_mentions": 1.0,
    "ai_alignment": 6.7,
    "ai_depth": 6.4,
    "ai_intent": 5.9,
    "ai_audience": 7.1,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content focuses predominantly on the need for true resilience in systems, diagnosing failures in technical and organisational approaches, and providing vivid examples where superficial preparations fell apart. It decries box-checking and performative action, advocating for real-world testing and cultural discipline — themes that overlap with change management best practices. However, 'Change Management' itself is never named, and specific frameworks, strategies, or Agile-oriented conversations about change are absent; the article hovers near the boundary by addressing cultural, leadership, and structural change through illustrative failures. The discussion is mainly rooted in resilience engineering, with only tangent alignment to the formal field of change management as defined. The main intent is to challenge traditional notions of operational resilience, indirectly implying needed mindset shifts and cultural overhauls, but it is not authored as direct advice or structured guidance on change management methodologies. The audience is likely technical leaders (CTOs, engineering managers), partially intersecting with the category. The signal-to-noise ratio is high: arguments are well-illustrated, with few tangents. The lack of explicit reference, methodical depth, or stepwise change management concepts limits alignment and depth scores, but case studies and culture critiques give it some footing. No penalties applied, as the tone is current, earnest, and not undermining the category.",
    "level": "Tertiary"
  },
  "Coaching": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Coaching",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 21.39,
    "ai_mentions": 0.7,
    "ai_alignment": 2.5,
    "ai_depth": 2.9,
    "ai_intent": 2.0,
    "ai_audience": 9.2,
    "ai_signal": 8.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 21.0,
    "reasoning": "The content offers an in-depth critique of systemic failures in technological resilience, emphasizing engineering discipline, real-world testing, and organizational accountability. While it encourages self-reflection and continuous improvement—concepts distantly related to coaching—it does not explicitly reference coaching, mentoring, feedback, or the facilitation of learning among individuals or teams. There are no direct mentions of coaching practices, roles, or techniques such as active listening, questioning, team dynamics, psychological safety, or growth mindsets. The audience alignment is high, directed toward technical leaders and practitioners who could potentially benefit from coaching, but the piece is didactic rather than collaborative or intentionally developmental. The high signal-to-noise ratio reflects how tightly focused the content is on resilience and failure, but the conceptual and intent scores are both low because the core themes and primary purpose are outside of coaching's domain—even if fostering resilience can be an outcome of good coaching. No penalties were needed as the tone was not undermining nor the content outdated. The overall confidence reflects that this content is only marginally relevant to the Coaching category.",
    "level": "Ignored"
  },
  "Current Value": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Current Value",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 21.681,
    "ai_mentions": 0.2,
    "ai_alignment": 2.3,
    "ai_depth": 2.8,
    "ai_intent": 3.7,
    "ai_audience": 6.5,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 22.0,
    "reasoning": "The content focuses heavily on system resilience, using examples from real-world engineering disasters to illustrate points about the necessity of proactively building and testing for operational survivability. However, there are virtually no direct mentions or references to 'Current Value' as defined in Evidence-Based Management, nor are topics such as customer satisfaction, revenue impact, or performance feedback explicitly discussed. The conceptual alignment is low: while resilience can indirectly affect the delivery of value to customers and organizations, the content does not analyze or measure this in real-time or as a value metric. The depth of discussion is considerable regarding resilience practices, but is off-topic for Current Value; key indicators, metrics, and measurement techniques central to Current Value are absent. Intent is only loosely connected—the text addresses product capabilities and leadership failures, but not with a focus on evaluating tangible, current benefits. The audience (tech/engineering leaders) aligns moderately with those interested in value measurement, but the signal-to-noise ratio is affected by a primary focus on cautionary tales about fragility, rather than on Current Value analysis. There are no penalties for outdated practices or contradiction; the tone is direct but not satirical or dismissive of the EBM framework. Overall, the confidence score rightly reflects that although the content thoroughly addresses an important systems thinking topic, it does not substantively fit the 'Current Value' category per the definition provided.",
    "level": "Ignored"
  },
  "Organisational Change": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Organisational Change",
    "calculated_at": "2025-05-08T08:55:14",
    "ai_confidence": 39.05,
    "ai_mentions": 2.7,
    "ai_alignment": 4.5,
    "ai_depth": 3.9,
    "ai_intent": 3.6,
    "ai_audience": 4.1,
    "ai_signal": 3.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content primarily focuses on system and engineering resilience, using high-profile failure examples (Spain, Oracle, Heathrow) to emphasize the importance of designing for failure. It contains some references to organisational dynamics ('leadership failed to create a culture', 'organisational blindness') but does not deeply explore organisational change processes, frameworks, or strategies such as Agile transformation, Kotter's model, or structured change management. While the narrative calls for leadership accountability and touches on culture, it remains centered around technical/systemic failures and practical engineering measures rather than the discipline of organisational change. There are brief overlaps, especially where organisational culture and leadership responsibility are mentioned, which align conceptually with the category, but these are incidental to the main thrust of the argument. Case study elements (e.g., Rackspace, Merrill Lynch) are used to illustrate resilience in action but are more focused on operational discipline than structured organisational change initiatives. The intended audience appears to be both technical leaders (like CTOs) and operational executives but is not specifically addressing change practitioners or strategists. Relatively low signal-to-noise ratio results from tangential or anecdotal content that, while illustrative, does not systematically discuss organisational change. No penalties apply. The resulting confidence score reflects moderate conceptual overlap but insufficient categorical fit and depth for a strong classification under Organisational Change.",
    "level": "Ignored"
  },
  "Lean Product Development": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Lean Product Development",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 37.25,
    "ai_mentions": 0.4,
    "ai_alignment": 3.9,
    "ai_depth": 3.6,
    "ai_intent": 2.2,
    "ai_audience": 4.0,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses predominantly on resilience engineering, system failures, disaster recovery, and the shortcomings of organisational and engineering practices in designing for resilience. While these are relevant themes in high-quality product development, there is no explicit mention of 'Lean Product Development,' Lean Thinking, or its principles. The closest conceptual connection is in the advocacy for iterative improvement and learning from failure, but traditional Lean frameworks (waste reduction, value stream mapping, A3, customer feedback cycles, etc.) are absent. The author critiques design fragility and organisational blindness, favoring real-world testing and honest failure analysis—these echo some Lean values but do not address Lean PD methods or theory directly or thoroughly. Audience targeting is moderately aligned (engineering/product/leadership, but not specifically Lean practitioners). There is little off-topic filler, but the discussion strays away from Lean Product Development’s core topics. Confidence is therefore modest, with the low mentions score (no direct category naming), fair conceptual overlap, and some relevant depth, but limited intent or focus on Lean PD.",
    "level": "Ignored"
  },
  "Behaviour Driven Development": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Behaviour Driven Development",
    "calculated_at": "2025-08-07T11:23:41",
    "ai_confidence": 5.3,
    "ai_mentions": 0.0,
    "ai_alignment": 1.3,
    "ai_depth": 0.8,
    "ai_intent": 1.0,
    "ai_audience": 1.1,
    "ai_signal": 1.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 5.0,
    "reasoning": "The content is a critical analysis of organizational and engineering failures around resilience in systems, illustrated with several real-world case studies. There is no explicit or implicit mention of Behaviour Driven Development (BDD), nor discussion of its techniques, principles, tools, or stakeholder collaboration. Key BDD concepts—such as aligning software development to business objectives through shared language, acceptance criteria, or BDD frameworks—are wholly absent. The focus remains on infrastructure failures, recovery processes, and leadership shortcomings, none of which tie directly to BDD's domain. Any tenuous overlap (such as the importance of requirements, testing, or system design) is both unstated and handled without reference to BDD's methodology or intent. This content targets engineering and operations audiences concerned with resilience, not BDD practitioners or stakeholders.",
    "reasoning_summary": "This content does not discuss Behaviour Driven Development. No direct or indirect BDD topics, practices, or audience alignment are present. Its focus is exclusively on operational resilience and engineering design failures.",
    "level": "Ignored"
  },
  "Product Discovery": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Product Discovery",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 26.23,
    "ai_mentions": 1.2,
    "ai_alignment": 3.7,
    "ai_depth": 2.9,
    "ai_intent": 3.1,
    "ai_audience": 4.0,
    "ai_signal": 3.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 26.0,
    "reasoning": "The content focuses extensively on resilience in systems—highlighting failures and lessons in disaster recovery, engineering practices, and organizational culture. While there are brief, indirect nods to 'product capability' and 'product leadership'—such as the statement 'Resilience is a product capability. If your product cannot survive failure, it is not a product'—the main themes revolve around engineering for system stability, not explicitly about discovering customer needs, prioritizing product features, or running user research typical of 'Product Discovery.' There are no direct mentions of 'Product Discovery' or its core techniques, frameworks, or practices. The audience is primarily technical leaders and engineers, with an emphasis on learning from past disaster scenarios. While a few rhetorical questions about risk, customer experience, and product leadership show partial alignment with product management, these are situational and lack depth in exploring methodologies relevant to Product Discovery. Overall, the discussion remains largely outside the category definition—more on robustness in delivery than on validating product ideas, user problem discovery, or feature prioritization central to Product Discovery.",
    "level": "Ignored"
  },
  "Troubleshooting": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Troubleshooting",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 70.7,
    "ai_mentions": 2.7,
    "ai_alignment": 7.9,
    "ai_depth": 7.6,
    "ai_intent": 7.2,
    "ai_audience": 7.8,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 71.0,
    "reasoning": "The content provides a thorough critique of failures in system resilience across high-profile technical outages (e.g., Spain's grid, Oracle's cloud, Heathrow Airport), emphasizing the need for proactive engineering to test and iterate on disaster recovery and system robustness. It offers in-depth, concrete descriptions of systemic failure causes (e.g., lack of failover, fake success metrics) and contrasts them with positive examples (Rackspace) to illustrate productive, technical approaches to resilience. However, it does not directly or explicitly discuss 'troubleshooting' as defined (identification and resolution of issues) except by implication; most references are to building resilient systems, learning from failure, and prevention rather than specific troubleshooting processes or methodologies. Thus, the content aligns with the troubleshooting mindset and audience (engineers, technical leaders), and the discussion is substantial, especially in case-based diagnostics, but the explicit category fit is moderate—troubleshooting is a critical underlying theme but not the central overt topic. No penalties are warranted; the examples and recommendations are relevant and current.",
    "level": "Secondary",
    "reasoning_summary": "This content aligns moderately with the troubleshooting category. While it doesn’t focus directly on step-by-step issue identification and resolution, it thoroughly analyses system failures and highlights the importance of resilience and proactive engineering. The discussion is relevant for technical audiences interested in troubleshooting mindsets, but the main emphasis is on prevention and learning from failure rather than explicit troubleshooting methods."
  },
  "Test First Development": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Test First Development",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 10.88,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 2.1,
    "ai_intent": 1.1,
    "ai_audience": 3.5,
    "ai_signal": 1.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 11.0,
    "reasoning": "The content focuses on the importance of engineering resilience in systems, using real incidents as cautionary examples. While it heavily discusses engineering for failure, continuous testing under real conditions, and organizational shortcomings in disaster recovery, it does not mention Test First Development or its practices (such as TDD/ATDD, success criteria before implementation, or a test-first mindset) either directly or conceptually. The main theme is operational resilience, not the discipline of writing tests prior to development. There is passing overlap with the value of verification and real-world testing, which marginally relates to principles of quality, but not specifically to the principles, methods, or audience of Test First Development. Thus, the confidence score is very low, reflecting that this is not a suitable fit for the category.",
    "level": "Ignored"
  },
  "Windows": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Windows",
    "calculated_at": "2025-09-05T03:29:19",
    "ai_confidence": 1.945,
    "ai_mentions": 0.1,
    "ai_alignment": 2.0,
    "ai_depth": 1.85,
    "ai_intent": 2.0,
    "ai_audience": 3.0,
    "ai_signal": 2.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content is a thematic essay about resilience engineering, referencing numerous real-world failures in IT infrastructure and leadership. Nowhere does it mention or align specifically with the Windows operating system, nor does it cover any Windows-focused topics such as installation, configuration, or user management. The sole near-mention is a passing reference to Active Directory at Merrill Lynch, but this is contextually about enterprise authentication—not Windows operation or management. The focus is on general engineering, leadership, and systemic failure across organisations and cloud architectures. The audience and intent are generic IT/product/engineering, not Windows users or administrators. No penalties were required; the content is modern and earnest, but its fit to the Windows category is extremely weak.",
    "reasoning_summary": "This content does not specifically address Windows OS topics or management. Its focus on resilience and engineering is general; the only Windows-adjacent reference (Active Directory) is insufficient. Very weak fit for the Windows category.",
    "level": "Ignored"
  },
  "Large Scale Agility": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Large Scale Agility",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 32.73,
    "ai_mentions": 0.2,
    "ai_alignment": 3.9,
    "ai_depth": 4.2,
    "ai_intent": 2.8,
    "ai_audience": 5.4,
    "ai_signal": 4.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content deeply explores the theme of resilience in systems design and organisational culture, but does not directly reference or anchor its arguments within the context of Large Scale Agility or Agile at enterprise scale. There is no explicit or implicit mention of Agile frameworks (e.g. SAFe, LeSS, Nexus), no discussion of scaling Agile methodologies, or any reference to transformation strategies aligning business goals and Agile practices. While it discusses cultural blindness at a leadership level and the need for operational discipline—which are relevant adjacent topics—they are framed around operational resilience, disaster recovery, and engineering practices across organisations, not specifically scaling Agile principles. The main audience appears to be technical leaders and executives, which offers some overlap, but the purpose and narrative remain focused on resilience and systemic failure, not Large Scale Agility practices, frameworks, or outcomes. The content is in-depth, but the depth is not about Agile scaling. Signal remains moderate due to the coherent focus, but there is no category alignment in terminology or conceptual framework. No penalties were warranted as the content is current and not oppositional to the core category.",
    "level": "Ignored"
  },
  "Agile Product Operating Model": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Agile Product Operating Model",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 38.25,
    "ai_mentions": 1.7,
    "ai_alignment": 4.6,
    "ai_depth": 4.2,
    "ai_intent": 3.7,
    "ai_audience": 4.2,
    "ai_signal": 3.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "Direct mentions are very low—there is only a single phrase connecting 'resilience' to 'product capability,' but the Agile Product Operating Model itself is never explicitly named or discussed. The alignment is moderate, as the content discusses the need for embedding resilience into product design and touches on organisational culture, engineering discipline, and failure testing, which can be tangentially related to APOM principles such as continuous improvement and product-oriented mindset. However, it never addresses Agile methods, product management frameworks, or governance structures central to APOM. Depth is somewhat present for the topics of resilience and operational discipline, but it lacks any substantive exploration of APOM mechanics or core concepts. The author's primary intent centers on highlighting failures of resilience from an engineering and leadership perspective, rather than advancing or informing about the Agile Product Operating Model, so the intent/purpose fit remains weak. The audience is likely technical leaders and product-oriented executives, a moderately relevant overlap, but it is not APOM-specific. Signal is moderate due to a focus on operational resilience, but much of the discussion revolves around case studies of failures without actionable APOM or agile product management content. Overall, confidence is low-moderate: the piece is rich in operational resilience critique but does not substantively support or expound on the Agile Product Operating Model.",
    "level": "Ignored"
  },
  "Hybrid Agile": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Hybrid Agile",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 17.91,
    "ai_mentions": 0.0,
    "ai_alignment": 2.7,
    "ai_depth": 2.4,
    "ai_intent": 3.5,
    "ai_audience": 4.3,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content is a deep analysis of organisational and technical failures in building resilient systems, highlighting real-world cases like Spain's blackout, Heathrow, and Oracle's cloud outage. It provides detailed examples of failures in engineering and management thinking, and emphasizes the importance of building, testing, and engineering resilience. However, nowhere does the content mention or critically examine Hybrid Agile as a methodology, nor does it engage with any of the category's core issues—such as the blending of agile and traditional project management, command-and-control dynamics, or agile role empowerment. There are no direct or indirect references to project delivery frameworks, hybrid methodologies, or agile terminology. The audience could partly overlap (technical leaders, CTOs), but the central theme is resilience engineering, not failures of Hybrid Agile. The signal-to-noise ratio is high as the content is focused, but this focus is almost entirely orthogonal to Hybrid Agile. Therefore, while the depth and audience fit prevent a bottom score, the lack of category relevancy means the overall confidence is very low.",
    "level": "Ignored"
  },
  "Organisational Physics": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Organisational Physics",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 54.7,
    "ai_mentions": 2.1,
    "ai_alignment": 6.0,
    "ai_depth": 6.7,
    "ai_intent": 6.2,
    "ai_audience": 7.3,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content addresses organisational failure, resilience, and leadership, with substantial case analysis (Heathrow, Oracle, Merrill Lynch, etc.), and discusses systemic causes of fragility. It occasionally refers to 'systemic failure,' 'organisational blindness,' and the need for cultural/leadership change, partially aligning with the systems thinking focus in Organisational Physics. However, the discussion stops short of explicitly exploring systems thinking frameworks, feedback loops, or adaptive systems. The term 'Organisational Physics' is not directly mentioned, and while the discussion is partly holistic, it remains largely at the level of resilience engineering, leadership, and operational discipline. The audience is moderately aligned (executive/technical leaders), and the content remains focused with high signal. There is moderate depth (includes examples, cause analysis, lessons), but it neither directly educates on Organisational Physics as defined nor employs its key frameworks. The score reflects meaningful but partial conceptual overlap—e.g., organisational blindness is attributed to system design and leadership, not individual error—but lacks direct systems thinking analysis or systemic mapping. No penalties were applied as the content is current, not satirical, and does not contradict the frame.",
    "level": "Tertiary"
  },
  "Site Reliability Engineering": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Site Reliability Engineering",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 79.76,
    "ai_mentions": 3.9,
    "ai_alignment": 8.4,
    "ai_depth": 8.6,
    "ai_intent": 8.2,
    "ai_audience": 8.6,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 80.0,
    "reasoning": "The content provides a thorough critique on failures of resilience in production systems, directly referencing principles and challenges core to Site Reliability Engineering (SRE), such as engineering for failure, disaster recovery, observability, incident response, and the organizational/cultural aspects of operational reliability. While 'SRE' and related explicit terms (SLOs, SLIs, SLAs, monitoring, automation) are not directly named, the substance unmistakably overlaps with SRE values and philosophy. The depth is strong, using real-world postmortems and organizational examples to dig beneath surface practices—this is in the spirit of SRE. The intent is squarely to advocate for building and testing real resilience (engineering for failure), which is foundational to SRE. The audience is technical leadership, likely SREs or those shaping production-critical architectures. Some minor deduction in 'mentions' as the text never names 'Site Reliability Engineering' or directly references Google's SRE framework, and a slight drop in 'signal' since several paragraphs deliver organizational criticism or anecdotal context that, while illustrative, are not always focused strictly on SRE practices. However, no outdated or derogatory tone penalties apply. Final confidence reflects very strong alignment with the SRE category, despite lack of explicit SRE terminology.",
    "level": "Secondary",
    "reasoning_summary": "This content strongly aligns with the SRE category, as it delves into core principles like resilience, incident response, and operational reliability, using real-world examples. While it doesn’t explicitly mention SRE terms, its focus and depth clearly target SRE values and practices, making it highly relevant for technical leaders and those involved in production system reliability."
  },
  "Portfolio Management": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Portfolio Management",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 15.46,
    "ai_mentions": 0.3,
    "ai_alignment": 1.25,
    "ai_depth": 1.9,
    "ai_intent": 2.25,
    "ai_audience": 3.05,
    "ai_signal": 2.65,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 15.0,
    "reasoning": "The content is focused primarily on the concept of resilience, engineering for failure, disaster recovery, and cultural/leadership failures related to system stability. While these are important organisational topics, there is almost no direct or explicit reference to portfolio management as defined—there is no discussion of aligning organizational strategy with project investment, no references to portfolio, prioritization, value streams, or related methodologies. The only mild link is the mention of leadership and product strategy in the context of resilience, but this doesn’t rise to a substantial overlap with the category. The article's main intent is critique and instruction on engineering for resilience, not portfolio-level management practices. The depth is relatively high regarding resilience but not for portfolio management concepts. The intended audience could overlap slightly with portfolio-focused strategists, but more as a side effect. Signal-to-noise is moderate: the piece is focused, but not on the evaluated category. There are no grounds for penalties as the content isn’t outdated or contradictory to portfolio management, just largely unrelated.",
    "level": "Ignored"
  },
  "Lean Startup": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Lean Startup",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 15.89,
    "ai_mentions": 0.2,
    "ai_alignment": 2.35,
    "ai_depth": 2.65,
    "ai_intent": 2.22,
    "ai_audience": 4.8,
    "ai_signal": 4.92,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "The content 'Fragile by Design: The Cost of Pretending to Be Resilient' centers on system resilience, operational risk, and failure as features of robust engineering and leadership. It emphasizes recurring real-world testing, learning from failures, and integrating resilience into product design and operations. However, there are virtually no direct or indirect mentions of Lean Startup concepts such as Minimum Viable Product (MVP), Build-Measure-Learn loops, customer development, lean metrics, or rapid experimentation aimed at business validation. The audience seems targeted at technology executives or CTOs focused on high-availability engineering, not Lean Startup practitioners. Some process-style references to iteration and learning from pain loosely echo the iterative mindset of Lean Startup, but they are not framed in a business hypothesis-testing or startup context. The depth is moderate in terms of resilience techniques, but entirely disconnected from Lean Startup methodology. The content is focused and relevant to resilience, but not to Lean Startup, so the signal-to-noise ratio for this category is low. No penalties were applied as the content is not outdated and the tone is not oppositional—just orthogonal. The final confidence reflects that, while tangential process overlap exists around iteration and learning, there is almost no fit with Lean Startup as strictly defined.",
    "level": "Ignored"
  },
  "Estimation": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Estimation",
    "calculated_at": "2025-09-17T23:12:27",
    "ai_confidence": 2.1,
    "ai_mentions": 0.0,
    "ai_alignment": 1.8,
    "ai_depth": 2.1,
    "ai_intent": 2.6,
    "ai_audience": 4.1,
    "ai_signal": 3.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content provides a detailed discussion of resilience engineering failures, focusing on real-world incidents, culture, and testing. It does not mention, refer to, or analyze estimation, forecasting, Agile/Scrum planning, empirical data, or related techniques. Its intent and themes (resilience, engineering for survivability, honest postmortem) target architects and leaders but do not align with estimation practices or the audience directly seeking improvement in Agile estimation. Scores are low across all dimensions, with audience alignment modestly higher due to the potential overlap with technical leadership roles, yet the main content remains irrelevant to the Estimation category by definition.",
    "reasoning_summary": "This content focuses entirely on resilience, system failure, and engineering discipline, with no mention or exploration of estimation practices, techniques, or Agile forecasting. It does not fit the Estimation category.",
    "level": "Ignored"
  },
  "Agile Planning": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Agile Planning",
    "calculated_at": "2025-10-01T16:42:12",
    "ai_confidence": 14.74,
    "ai_mentions": 0.1,
    "ai_alignment": 2.9,
    "ai_depth": 2.6,
    "ai_intent": 1.7,
    "ai_audience": 5.0,
    "ai_signal": 2.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 15.0,
    "reasoning": "The content is a strongly argued essay on genuine operational resilience and technical discipline, criticizing 'fantasy continuity' and advocating real-world testing. It references leadership, systemic failure, and cultural blindness but does not mention or explore Agile Planning, iterative work breakdown (sprints/stories/backlogs), or any Agile-specific planning methodologies. The concepts of iteration and learning through disciplined testing are present but not within an Agile Planning framework, and there’s no linkage to Agile practices, planning rituals, or frameworks. Audience might overlap with Agile practitioners, but the focus and main purpose are not about balancing flexibility and predictability in delivery; they're about engineering and organizational honesty in building robust systems.",
    "reasoning_summary": "This content focuses on operational resilience and engineering discipline, not on Agile Planning methodologies or principles. While iterative improvement is discussed, Agile Planning is not explored, making the fit minimal.",
    "level": "Ignored"
  },
  "Product Backlog": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Product Backlog",
    "calculated_at": "2025-05-08T08:55:13",
    "ai_confidence": 3.82,
    "ai_mentions": 0.2,
    "ai_alignment": 1.9,
    "ai_depth": 1.7,
    "ai_intent": 0.9,
    "ai_audience": 5.1,
    "ai_signal": 3.2,
    "ai_penalties_applied": true,
    "ai_penalty_points": 2.0,
    "ai_penalty_details": "alignment (-1, because core discussion is not Product Backlog-centric but focuses on resilience/engineering rather than Agile backlog practices); intent (-1, as the main purpose is to critique organizational blindness and resilience gaps, not backlog management advice)",
    "final_score": 4.0,
    "reasoning": "The content is centered on operational resilience, critiquing bad engineering, organizational blindness, and failure to build genuinely robust systems. There is a very brief mention of 'product capability' and 'roadmap,' but these do not explicitly or deeply invoke Product Backlog concepts, nor do they reference prioritization, backlog refinement, or Agile methods. The discussion is critical in tone toward superficial resilience, but not the concept of Product Backlog itself. The intended audience (CTOs, engineering leaders) overlaps partially with Agile practitioners, hence a moderate audience score, but the substance and signal-to-noise ratio remain low in relevance to the Product Backlog category. No tools, practices, or backlog management topics are discussed. Penalties were applied to alignment and intent, given the tangential relationship. The confidence score is very low due to these reasons, demonstrating very little alignment and direct fit with the Product Backlog classification.",
    "level": "Ignored"
  },
  "Agile Product Management": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Agile Product Management",
    "calculated_at": "2025-10-01T16:58:40",
    "ai_confidence": 31.86,
    "ai_mentions": 0.6,
    "ai_alignment": 2.9,
    "ai_depth": 3.4,
    "ai_intent": 2.9,
    "ai_audience": 3.6,
    "ai_signal": 4.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 32.0,
    "reasoning": "The content focuses intensely on resilience, engineering discipline, and failure recovery, using examples of system outages and organizational denial. While it briefly references 'shallow product thinking' and the importance of resilience as a product capability, there is almost no explicit mention of agile product management principles, methodologies (such as backlog prioritization, Scrum, product owner duties), or iterative delivery. The main themes revolve around organizational culture, engineering practices, leaders' denial, and the rigor of operational testing, rather than aligning product strategy with agile principles or maximizing product value through feedback loops. Audience focus seems somewhat aligned with technical/product leadership, but the intent and core discussion do not match the specific technical or strategic practices of agile product management. The article is thoughtful and substantial—especially in critiquing surface-level approaches to resilience—but it is not primarily, nor deeply, an exploration of Agile Product Management.",
    "reasoning_summary": "The content centers on resilience engineering and organizational denial, with only passing reference to product thinking. It lacks core Agile Product Management topics or intent, resulting in a weak category fit. Focus is on operations, not agile practices.",
    "level": "Ignored"
  },
  "Self Organisation": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Self Organisation",
    "calculated_at": "2025-05-08T08:55:15",
    "ai_confidence": 16.48,
    "ai_mentions": 0.4,
    "ai_alignment": 1.2,
    "ai_depth": 1.7,
    "ai_intent": 0.9,
    "ai_audience": 4.6,
    "ai_signal": 1.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "The content focuses on resilience engineering, system failure, and organisational blindness, but does not directly mention self-organisation or its principles. There is no discussion of team autonomy, empowerment, or Agile practices that are central to the definition of the 'Self Organisation' category. Instead, the emphasis is on leadership failure, engineering discipline, and real-world disaster recovery scenarios. While the concept of organisational culture is discussed (e.g., the need for discipline from leadership), the connection to self-organising teams is only tangential at best and never explicit. The main audience appears to be technical leaders, CTOs, or individuals responsible for system reliability, aligning more with resilience and infrastructure than self-organisation in Agile contexts. Most of the content is sharply focused on resilience failures, with only brief, indirect connections to the intended category. Minimal scores are assigned across Direct Mentions, Conceptual Alignment, Depth, Intent, and Signal-to-Noise, with Audience Alignment slightly higher given the professional context, but still not matching the self-organisation audience exactly. No penalties applied, as the tone does not contradict or undermine the category, and content is not outdated. The low confidence score reflects that self-organisation is not a pertinent or substantial topic within this content.",
    "level": "Ignored"
  },
  "Agile Philosophy": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Agile Philosophy",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 38.06,
    "ai_mentions": 0.7,
    "ai_alignment": 4.1,
    "ai_depth": 4.8,
    "ai_intent": 3.7,
    "ai_audience": 6.2,
    "ai_signal": 7.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content primarily addresses the organizational and technical challenges of building resilient systems, focusing on themes like real-world testing, discipline, leadership responsibility, and learning from failure. While these concepts tangentially align with certain aspects of the Agile Philosophy—such as continuous improvement, learning through iteration, and confronting organizational inertia—the text never explicitly references Agile, its mindset, or the Agile Manifesto. There are no direct mentions of Agile, agility, or its principles; instead, the emphasis is on resilience engineering and operational excellence. The depth and specifics around topics like engineering for failure and cultural blindness are substantial, but they orbit resilience as a discipline and do not widen the lens to Agile as an overall mindset, nor do they discuss Agile's customer collaboration, adaptability, or feedback loops explicitly. The intended audience aligns somewhat, as the themes are relevant to leaders mindful of organizational culture and change, but most of the discussion is technical and operational. Ultimately, while the article is conceptually adjacent to philosophies underpinning Agile, it doesn't fully embody or discuss Agile Philosophy itself, justifying a moderate but not strong confidence score.",
    "level": "Ignored"
  },
  "Sociotechnical Systems": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Sociotechnical Systems",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 69.29,
    "ai_mentions": 2.3,
    "ai_alignment": 7.2,
    "ai_depth": 7.6,
    "ai_intent": 6.8,
    "ai_audience": 7.1,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 69.0,
    "reasoning": "The content never directly mentions the phrase 'Sociotechnical Systems' and explicit category language is minimal (Score: 2.3). However, it aligns moderately with the category's conceptual definition—extensively exploring how engineering practices, leadership, organisational culture, and technical strategies interact to cause either resilience or catastrophic system failures (Alignment: 7.2). Discussion depth is substantial: numerous real-world case studies are dissected, analyzing both technical and organisational contributors to failure (Depth: 7.6). The main intent is to illustrate how a lack of integrated thinking between organisational (leadership, culture, product management) and technical components creates fragile systems, matching the category’s core sensibility (Intent: 6.8). The audience is technical leaders, architects, and CTOs—well aligned with the category, though not as explicitly sociotechnical as a dedicated academic audience, so a slight reduction applies (Audience: 7.1). The narrative stays highly focused on relevant interplay, with little unrelated digression, yielding a high signal-to-noise ratio (Signal: 7.5). No content is outdated, nor is the tone satirical or antagonistic toward the sociotechnical perspective, so no penalties apply. The moderate confidence reflects the absence of explicit category language but is elevated by the strength and focus of the argument's sociotechnical interplay—organisational blindness, leadership failures, disaster recovery culture, and technical execution are all treated as interdependent causes of systemic fragility and resilience.",
    "level": "Secondary"
  },
  "Internal Developer Platform": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Internal Developer Platform",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 9.5,
    "ai_mentions": 0.2,
    "ai_alignment": 0.8,
    "ai_depth": 1.1,
    "ai_intent": 0.3,
    "ai_audience": 0.5,
    "ai_signal": 0.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content is a reflective and critical analysis of organizational failures regarding resilience in IT systems, highlighting real-world outages and the need for rigorous testing and design for survivability. However, there are no direct mentions or references to Internal Developer Platforms (IDP), their components, implementation, or their role in streamlining development, deployment, or collaboration. The primary theme is operational resilience rather than developer platforms or their frameworks. While the intended audience (technologists, technical leaders, CTOs) might overlap with the IDP space, the article provides no substantive discussion, best practices, tools, or case studies relevant to IDPs specifically. There are no conceptual connections or in-depth alignment with the Internal Developer Platform category. As such, every dimension sees extremely low scores, led by a near-absence of direct reference, minimal thematic overlap, no relevant depth, off-category intent, only weak audience overlap, and a low signal-to-noise ratio for this classification purpose. No penalty deductions were necessary, as the content is neither outdated nor actively undermining the category.",
    "level": "Ignored"
  },
  "GitHub": {
    "resourceId": "LGGuvRq4g7p",
    "category": "GitHub",
    "calculated_at": "2025-10-01T16:58:39",
    "ai_confidence": 1.5,
    "ai_mentions": 0.2,
    "ai_alignment": 0.3,
    "ai_depth": 0.3,
    "ai_intent": 0.3,
    "ai_audience": 0.2,
    "ai_signal": 0.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "No mention of GitHub, its tools, or related practices anywhere in the content. The discussion focuses on resilience, engineering failures, disaster recovery, and operational culture, with examples from various industries, but does not discuss version control, collaboration, CI/CD, or any features relevant to GitHub. The main ideas and intent are centered on organisational and technical resilience, not code or project management services. Audience could include engineers but not with a GitHub-specific focus. Nearly 100% is off-topic for GitHub.",
    "reasoning_summary": "The content is entirely about resilience, engineering failures, and operational strategy, with zero references to GitHub, its services, or related practices. There is no alignment in topic, intent, or audience with the GitHub category.",
    "level": "Ignored"
  },
  "Value Stream Management": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Value Stream Management",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 18.56,
    "ai_mentions": 0.35,
    "ai_alignment": 2.2,
    "ai_depth": 2.45,
    "ai_intent": 2.9,
    "ai_audience": 5.1,
    "ai_signal": 3.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content is a critical discussion of resilience and fragility in technology systems, highlighting engineering and organisational failures across several major incidents (blackouts, outages, disaster recovery, etc.). However, 'Value Stream Management' is not directly mentioned, nor are its core techniques such as value stream mapping, waste reduction, metrics, or explicit process improvement frameworks. The alignment is limited because, while the article deals with operational failures and some aspects of organisational culture that could overlap with VSM (e.g., leadership blindness to system integrity), it never frames its analysis in terms of value stream flow, customer value delivery, or continuous improvement practices as defined by VSM. The depth of discussion is high regarding resilience but not about VSM principles. The article is aimed at technical leadership and practitioners—a partially aligned audience—but the messaging and examples serve a broader operational reliability and engineering focus, not value delivery per se. Signal-to-noise is moderate: the piece is laser-focused on resilience, but this is a tangential, not central, concept in VSM. No penalties apply, as the tone is critical but not satirical or outdated. Overall, the content only glosses over areas that might intersect with value-centric thinking and does not offer substantive discussion of Value Stream Management’s actual practices or philosophy, resulting in a low but nonzero confidence score.",
    "level": "Ignored"
  },
  "Definition of Done": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Definition of Done",
    "calculated_at": "2025-05-08T08:55:13",
    "ai_confidence": 13.38,
    "ai_mentions": 0.0,
    "ai_alignment": 2.4,
    "ai_depth": 1.9,
    "ai_intent": 1.5,
    "ai_audience": 4.8,
    "ai_signal": 2.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content focuses comprehensively on the importance of building resilience into systems, using incidents like national blackouts and cloud outages as case studies. While it addresses concepts such as operational quality, disaster recovery, and product survivability, at no point does it reference or discuss the Definition of Done (DoD) in Agile or Scrum. There is no direct mention of DoD or related criteria; all coverage centers on resilience engineering, culture, testing, and real-world drills, which, though thematically adjacent to quality practices, do not align with DoD's core Agile meaning. The depth and intent are firmly rooted in advocating for resilience as a product and organizational capability, not as an explicit definition of completion or shared deliverable standards. The audience is technical and leadership-focused, which slightly overlaps with DoD's typical audience, but given the significant conceptual gap, only a modest score is awarded here. Signal is low because nearly the entire article is off-topic for DoD, focusing instead on resilience failures and best practices. No penalties were necessary, as there are no obvious outdated references or contradictory tones regarding DoD; the content simply doesn't fit. The final confidence score is low due to the near-total lack of alignment with DoD as strictly defined.",
    "level": "Ignored"
  },
  "Azure DevOps": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Azure DevOps",
    "calculated_at": "2025-10-01T16:58:03",
    "ai_confidence": 3.53,
    "ai_mentions": 0.1,
    "ai_alignment": 1.2,
    "ai_depth": 1.3,
    "ai_intent": 0.8,
    "ai_audience": 0.7,
    "ai_signal": 1.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 4.0,
    "reasoning": "The content discusses system resilience, engineering failures, and organizational culture, but never mentions Azure DevOps or any of its services, tools, or practices. There is general thematic overlap with DevOps principles, such as the importance of testing and real-world validation, but these are not anchored in Azure DevOps context. No evidence is provided of Azure DevOps usage, best practices, or applicability. The intent is critical and analytical, but not targeted at or constructed around Azure DevOps audience interests or workflows.",
    "reasoning_summary": "No direct or indirect Azure DevOps references; discusses resilience and engineering failures broadly. Does not fit the category except for tangential conceptual overlap with DevOps principles. Fit is minimal and incidental.",
    "level": "Ignored"
  },
  "Competence": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Competence",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 41.96,
    "ai_mentions": 1.7,
    "ai_alignment": 4.2,
    "ai_depth": 4.7,
    "ai_intent": 3.9,
    "ai_audience": 4.6,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content is centered on resilience in engineering and organizational practice, with detailed examples of systems failures and how true resilience requires ongoing, discipline-driven testing. However, it focuses on resilience as a system property rather than linking this directly to professional competence, skill development, or mastery as defined in the 'Competence' category. Explicit mentions of competence or related terms are absent, and while the ideas touch on discipline, engineering rigor, and leadership, these are not framed through the lens of competence. The exploration is deep regarding what constitutes genuine resilience but only loosely overlaps with the cultivation of competence at the personal or team skill level. The intent is more to critique and educate on resilience failures and effective practices rather than advancing a discussion on professional or organizational competence per se. The audience appears to be technical leaders and practitioners, somewhat overlapping with those interested in competence, but the focus remains on resilience as a concept in design/operations. Signal-to-noise is moderate: a large portion is tightly argued but almost exclusively about resilience and organizational behavior, rather than about skill/competence development. No penalties for outdated practice or negative framing are applied, as the content remains current and earnest.",
    "level": "Tertiary"
  },
  "Team Motivation": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Team Motivation",
    "calculated_at": "2025-10-01T16:58:44",
    "ai_confidence": 14.22,
    "ai_mentions": 0.1,
    "ai_alignment": 1.45,
    "ai_depth": 1.1,
    "ai_intent": 1.3,
    "ai_audience": 6.5,
    "ai_signal": 7.2,
    "ai_penalties_applied": true,
    "ai_penalty_points": 2.5,
    "ai_penalty_details": "Direct Mentions (-0.9): No explicit or implicit references to motivation or team dynamics; Alignment (-0.5): Main ideas are not about motivation; Depth (-0.5): Does not explore motivational strategies; Intent (-0.3): Purpose is technical critique, not motivational; Audience: no deduction; Signal: no deduction.",
    "final_score": 14.0,
    "reasoning": "The content focuses on organisational and technical failures in engineering and disaster recovery. While it touches on leadership, culture, and discipline, it does so from the perspective of operational resilience, not team motivation. There are no direct or implied discussions of psychological factors, engagement, or practices intended to build motivation or team performance. The intent is a cautionary analysis of system fragility, not exploration of how to inspire or empower teams. Audience is only partially aligned, as some readers may be leaders, but the content is not tailored to those seeking motivational insights. Penalties applied for lack of direct mention, poor alignment, superficial depth regarding the category, and intent.",
    "reasoning_summary": "This content critiques resilience failures in technical and organisational contexts; it lacks focus on engagement, ownership, or psychological aspects of team motivation. Fit to the category is minimal and mostly incidental.",
    "level": "Ignored"
  },
  "Daily Scrum": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Daily Scrum",
    "calculated_at": "2025-10-01T16:58:07",
    "ai_confidence": 4.74,
    "ai_mentions": 0.1,
    "ai_alignment": 0.6,
    "ai_depth": 0.9,
    "ai_intent": 1.2,
    "ai_audience": 0.7,
    "ai_signal": 1.0,
    "ai_penalties_applied": true,
    "ai_penalty_points": 2.0,
    "ai_penalty_details": "alignment: 1 point deducted for critical tone undermining organisational practices common in Agile/Scrum; audience: 1 point deducted for content targeting broader engineering/product stakeholders rather than Scrum practitioners.",
    "final_score": 5.0,
    "reasoning": "The content never mentions the Daily Scrum, nor discusses Scrum events or team practices. Its deep dive into system resilience, failure, and organisational blindness offers no direct or indirect connection to the Daily Scrum's goals, structure, or best practices. The tone is critical of leadership and traditional 'resilience' postures but does not constructively address Scrum or Agile frameworks. While the intended audience may overlap in larger organisations, the message and focus are engineering- and leadership-centric, not Scrum team-oriented.",
    "reasoning_summary": "No mention or meaningful alignment to Daily Scrum or Scrum events. Focuses on system resilience and organisational failures, not on team inspection or adaptation per Scrum. Fit is negligible; only remote tangential relevance.",
    "level": "Ignored"
  },
  "Agentic Agility": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Agentic Agility",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 38.94,
    "ai_mentions": 0.2,
    "ai_alignment": 3.1,
    "ai_depth": 4.4,
    "ai_intent": 4.6,
    "ai_audience": 8.2,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content focuses on the criticality of resilience in socio-technical systems, primarily targeting technical leaders and executives, as indicated by examples (CTO, enterprise outages) and recommendations for engineering discipline. However, the piece does not directly mention agentic agility, agency, intentionality, or adaptive action in explicit Agile, Scrum, or DevOps contexts. There is an implicit alignment with adaptive behavior (e.g., iterating over pain points, leadership accountability, proactive testing), but agency is only tangentially referenced through leader-driven testing and organizational culture critiques. The depth is moderate, as it analyzes root causes of fragile systems and contrasts superficial compliance with genuine resilience, but lacks detailed discussion of agency, autonomy, or accountability in the explicit Agile/DevOps sense, nor does it distinguish between human or AI agency. The intent fits partially: the essay aims to expose organizational self-delusion and the real path to resilience—overlapping conceptually with agentic action—but never centers on agility or the evolution of goals. For audience, the technical executive sector is directly targeted. The structure stays highly focused on resilience (signal), with negligible unrelated content. The absence of direct references keeps the mentions score extremely low; conceptual alignment and depth are middling due to indirect associations; audience and signal are strong. No penalties are warranted, as the tone is serious and current. The confidence score is low-to-moderate: while the essay critiques failures of leadership and prescribes disciplined, intentional practice, it does not address the role or development of agency in Agile frameworks or operationalize agentic agility. It fits loosely at the intersection of resilience engineering, organizational learning, and responsibility—but does not sufficiently substantiate Agentic Agility per the strict classification.",
    "level": "Ignored"
  },
  "Collaboration Tools": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Collaboration Tools",
    "calculated_at": "2025-10-01T16:58:45",
    "ai_confidence": 5.2,
    "ai_mentions": 0.2,
    "ai_alignment": 0.4,
    "ai_depth": 0.3,
    "ai_intent": 0.3,
    "ai_audience": 2.0,
    "ai_signal": 1.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 5.0,
    "reasoning": "The content exclusively explores issues surrounding systemic resilience, organizational behavior, engineering rigor, and testing. Although the text discusses operational discipline and product/organizational failures, it does not mention, discuss, or allude to collaboration tools, platforms, or features that facilitate team communication or coordination in Agile teams. The focus is on technical and organizational causes of fragility, without any reference to tool selection, integration, or use cases relevant to collaboration tools. The intended audience seems technical and leadership, but the subject matter never touches the category's domain.",
    "reasoning_summary": "The content does not fit the 'Collaboration Tools' category; it never mentions or discusses tools that enable Agile team collaboration or communication. Its focus is solely on systemic resilience, not collaboration platforms.",
    "level": "Ignored"
  },
  "Frequent Releases": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Frequent Releases",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 21.79,
    "ai_mentions": 0.5,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 2.1,
    "ai_audience": 6.2,
    "ai_signal": 5.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 22.0,
    "reasoning": "The content focuses on resilience engineering, catastrophic failures, and the importance of engineering discipline — not on Frequent Releases or its related core concepts. There is no direct mention of release frequency, continuous delivery, CI/CD, or DevOps practices as related to accelerating delivery. The only tangential overlap is the theme of iteration, exemplified by Rackspace repeatedly testing their backup transfer process — but this is described in the context of resilience testing, not software releasing. Principles like 'testing often,' 'learning from pain,' and 'building for survivability' are conceptually similar to Agile/DevOps mindsets, so there is minor alignment, but the main thrust remains operational resilience, not software release cadence. The intended audience (CTOs, engineering leaders) overlaps with those interested in release practices, but all substantive discussion is about system hardening rather than delivering or automating software updates. Overall, the signal is focused on resilience, not frequent releases; any implied relevance is indirect. No penalties were applied, as the tone is not critical of 'frequent releases,' nor is any content outdated or obsolete.",
    "level": "Ignored"
  },
  "Sensemaking": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Sensemaking",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 53.775,
    "ai_mentions": 1.2,
    "ai_alignment": 5.7,
    "ai_depth": 6.9,
    "ai_intent": 4.8,
    "ai_audience": 7.3,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 54.0,
    "reasoning": "Direct mentions of sensemaking are absent; the content does not use the term 'sensemaking' or reference its common frameworks directly (e.g. Cynefin). The main focus is on resilience engineering—exploring the failures of organisations to engineer for resilience and the cost of superficial approaches to continuity. There is strong alignment with organizational learning from failure and the need to accurately perceive and address system fragility, which echoes sensemaking themes, particularly the critique of 'organisational blindness' and the importance of recognizing and iteratively correcting errors. However, the piece does not directly address how organizations interpret complexity or uncertainty with intent to make decisions—it is more about the necessity and design of resilience, using case studies, lessons, and cultural factors (like leadership accountability and culture of testing). The discussion is in-depth concerning resilience but only tangentially overlaps with sensemaking (mainly in its critique of delusion and advocacy for reality-based system evaluation). The intent is closer to advocating best practices in resilience than directly enabling organizational sensemaking or awareness. The target audience is practitioners or leaders responsible for resilience/engineering, which can overlap with a sensemaking audience, but the focus is less on collective interpretation and more on technical/operational preparedness. The content is highly focused and relevant to its theme (resilience), with little filler. Overall, there is conceptual overlap but not direct alignment, and the category is not the explicit focus.",
    "level": "Tertiary"
  },
  "Social Technologies": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Social Technologies",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 42.879,
    "ai_mentions": 0.5,
    "ai_alignment": 5.7,
    "ai_depth": 6.2,
    "ai_intent": 4.6,
    "ai_audience": 7.2,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "The content is a deep critique of the lack of resilience in large-scale systems, with detailed real-world failures and an argument for engineering rigor and operational discipline. While it touches organizational culture and leadership, it does not discuss frameworks or methodologies that foster collaboration, self-organization, or collective intelligence as outlined in the Social Technologies definition. There are some mentions of leadership failures, but these do not delve into social frameworks or the techniques/processes that underpin social technologies. Instead, the substance is focused on resilient system design, disaster recovery, and operational preparedness—areas adjacent to but not encompassed by the Social Technologies category. The audience is technical and executive leadership, which aligns decently, and the focus is sustained without filler. However, there is one direct, though passing, mention of 'leadership,' but not of social technologies or related methodologies. There is some conceptual overlap (organizational blindness, learning from failure, cultural discipline) but not enough to warrant high scores on alignment or intent. No penalties were applied, as content is current and not satirical or critical of the broader category, though it is critical of specific (mis)practices. The resulting weighted confidence score is moderate, reflecting partial but insufficient alignment with the Social Technologies definition.",
    "level": "Tertiary"
  },
  "Product Validation": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Product Validation",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 43.35,
    "ai_mentions": 1.8,
    "ai_alignment": 4.3,
    "ai_depth": 4.7,
    "ai_intent": 2.6,
    "ai_audience": 6.2,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "The content is an extensive exploration of system resilience, emphasizing the consequences of poor engineering and organizational blindness, supported by real-world examples of high-profile failures. While it references 'product capability' and advocates for rigorous testing and verification, its primary focus is on resilience engineering, disaster recovery, and operational continuity rather than the methodologies and practices of product validation as defined by this category. There is little direct discussion of user testing, customer feedback loops, market fit, or evidence-based hypothesis validation. Instead, resilience testing described here centers on operational and infrastructure robustness—relevant to product quality, but not directly aligned with the intent and conceptual scope of Product Validation. The depth is reasonable regarding resilience, but not in the targeted key practices of product validation. The audience is technical and executive, with some overlap, but the main intent is to critique organizational attitudes toward resilience, not to explore practical approaches to testing product concepts with users. Signal-to-noise is fair, as most content is focused but remains off-center from product validation. No penalties are applied, as the piece is neither outdated nor satirical, and the tone, while critical, does not undermine the framing. The final confidence score is low to moderate, reflecting indirect and shallow alignment with the Product Validation category.",
    "level": "Tertiary"
  },
  "Lean Principles": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Lean Principles",
    "calculated_at": "2025-05-08T08:55:16",
    "ai_confidence": 36.58,
    "ai_mentions": 1.1,
    "ai_alignment": 3.8,
    "ai_depth": 3.2,
    "ai_intent": 3.4,
    "ai_audience": 4.1,
    "ai_signal": 4.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content is a critical exploration of resilience in engineering and organisational systems. Although it heavily discusses process failure, resilience, and the cultural/procedural underpinnings of system design, it does not directly reference or discuss Lean Principles, nor does it use Lean terminology (e.g., Muda, Kaizen, value stream, 5S, flow, pull, waste elimination). The closest conceptual alignment is the advocacy for continuous improvement and learning from failure, which is core to Lean, but the focus is on resilience engineering rather than waste reduction, value maximisation, or Lean-specific practices. No mention of Lean tools or specific Lean philosophies appears in the content. The primary audience (CTOs, architects, leaders) is adjacent to but not specifically the Lean audience. Depth of discussion about resilience is strong, but not about Lean. The signal-to-noise ratio is relatively high as the topic is consistent, but it's off-topic for Lean Principles itself. There are no outdated references or contradictory tones toward Lean that would require penalties. The score reflects that while some ideas overlap conceptually, the content is not about Lean Principles and would not fit within the strict definition or topical boundaries provided.",
    "level": "Ignored"
  },
  "Engineering Practices": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Engineering Practices",
    "calculated_at": "2025-05-08T08:55:17",
    "ai_confidence": 79.77,
    "ai_mentions": 4.2,
    "ai_alignment": 8.8,
    "ai_depth": 8.5,
    "ai_intent": 8.0,
    "ai_audience": 7.1,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 80.0,
    "reasoning": "The content is deeply relevant to Engineering Practices, focusing on themes like system resilience, failure assumptions, operational discipline, and disaster recovery within engineering contexts. It uses concrete industry examples to highlight consequences of bad engineering and the necessity of iterated, testable practices. However, it does not make direct, explicit mention of signature Agile engineering practices (e.g., TDD, Clean Code, CI/CD, pair programming), and fundamental terms like 'automation' or 'test-first' do not appear verbatim. The discussion is conceptually well-aligned—emphasizing the need to build, design, and repeatedly test resilience (correlating with test-driven and automation mindsets)—and offers detailed depth on technical failure analysis and operational rigor. The primary intent is to advise engineering leaders and practitioners on rethinking resilience as an engineering outcome, not as a box-ticking exercise. While the technical audience is well-targeted (CTOs, engineering leaders, practitioners), general leadership and organisational culture are also addressed, slightly diluting the tight focus expected for Engineering Practices. The writing is sharp and purpose-driven, though a small percentage is devoted to organizational/leadership analysis and criticism, lowering the signal-to-noise ratio marginally. No outdated or contradictory practices are referenced, and the tone is critical but ultimately supportive of sound engineering. Final confidence is high, but not maximal, due to few direct references to core Agile practice nomenclature and a wider, somewhat cross-disciplinary audience.",
    "level": "Secondary",
    "reasoning_summary": "This content strongly aligns with Engineering Practices, as it explores system resilience, failure analysis, and operational discipline using real-world examples. While it doesn’t explicitly reference core Agile terms or practices, its focus on iterative testing and robust engineering makes it highly relevant. The inclusion of leadership and organisational themes broadens its scope slightly, but the technical depth and intent remain clear and valuable."
  },
  "Liberating Structures": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Liberating Structures",
    "calculated_at": "2025-10-01T16:58:49",
    "ai_confidence": 2.2,
    "ai_mentions": 0.0,
    "ai_alignment": 2.1,
    "ai_depth": 1.8,
    "ai_intent": 2.0,
    "ai_audience": 3.1,
    "ai_signal": 3.2,
    "ai_penalties_applied": true,
    "ai_penalty_points": 1,
    "ai_penalty_details": "Intent penalized (-1) due to a critical tone that is partially misaligned with the constructive framing of Liberating Structures, lacking discussion of facilitation techniques.",
    "final_score": 2.0,
    "reasoning": "The content discusses resilience engineering, organisational blindness, and real-world testing, but never mentions Liberating Structures or group facilitation methods. Its primary intent is to critique operational and engineering failures, not to explore facilitation toolkits or engagement structures. There is no linkage to facilitation, Scrum ceremonies, or collaborative team practices. The audience (engineering/product leaders) may overlap slightly, but the theme and topics do not discuss, advocate, or analyze Liberating Structures or related practices. A penalty was applied for intent, as the tone is critical of management culture and does not fit the supportive or constructive nature of Liberating Structures content.",
    "reasoning_summary": "No content relates to Liberating Structures or facilitation techniques; focus is on engineering, product, and organisational resilience failures. Direct and conceptual alignment with the category is lacking, so fit is absent.",
    "level": "Ignored"
  },
  "Systems Thinking": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Systems Thinking",
    "calculated_at": "2025-08-07T06:11:18",
    "ai_confidence": 54.8,
    "ai_mentions": 1.5,
    "ai_alignment": 6.2,
    "ai_depth": 5.8,
    "ai_intent": 6.1,
    "ai_audience": 6.3,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "This content analyzes high-profile system failures, dissecting how fragility results from single-point optimizations, lack of feedback awareness, and cultural denial. However, it never directly discusses Systems Thinking or its core terminology (feedback loops, system dynamics, interdependencies), and frames resilience mainly as an engineering and leadership problem, not explicitly a systemic or holistic one. While it gestures at emergent properties and organizational causality (e.g., Heathrow case, Merrill Lynch), it doesn't mention mapping techniques, foundational principles of Systems Thinking, or explicit systemic tools/frameworks. The audience (engineers, leaders) and themes align partially, but the practical application is resilience engineering, not Systems Thinking per se. Overall, the fit is partial: it exemplifies problems that Systems Thinking could address, but does not frame or solve them through its specific lens.",
    "reasoning_summary": "While the content touches on system fragility and organizational interdependencies, it never references or deeply engages with Systems Thinking principles or methods. The fit is partial, focused on resilience rather than explicit Systems Thinking.",
    "level": "Tertiary"
  },
  "Product Delivery": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Product Delivery",
    "calculated_at": "2025-08-07T07:07:10",
    "ai_confidence": 53.4,
    "ai_mentions": 1.6,
    "ai_alignment": 6.9,
    "ai_depth": 7.2,
    "ai_intent": 6.1,
    "ai_audience": 6.7,
    "ai_signal": 7.4,
    "ai_penalties_applied": true,
    "ai_penalty_points": 2,
    "ai_penalty_details": "mentions penalized for very few direct references to 'product delivery'; intent penalized for partially critical/contrarian framing that distances itself from product delivery best practices.",
    "final_score": 53.0,
    "reasoning": "The content criticizes bad engineering and organizational denial leading to fragile systems, emphasizing that real resilience is achieved through regular, rigorous real-world testing. It aligns with product delivery regarding resilience as a product capability and the consequences of not including it in a delivery process. However, direct mentions of 'product delivery' and its core practices (such as Agile, CI/CD, or feature planning) are minimal, with the main focus being on resilience and engineering rather than the broader methodologies/processes of software product delivery. Still, themes about real-world recovery testing, roadmap responsibilities, and leadership failures intersect with product delivery concerns. Penalties: (1) Mentions—very little explicit discussion of product delivery terminologies; (2) Intent—tone is somewhat critical/contrarian to current product delivery norms.",
    "reasoning_summary": "Partial fit: The content strongly focuses on resilience as a product trait and its organizational importance, but has sparse direct reference to delivery practices or methodologies. Its main theme overlaps with, but doesn't center on, product delivery.",
    "level": "Tertiary"
  },
  "Customer Feedback Loops": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Customer Feedback Loops",
    "calculated_at": "2025-08-07T07:06:34",
    "ai_confidence": 8.45,
    "ai_mentions": 0.1,
    "ai_alignment": 0.9,
    "ai_depth": 0.8,
    "ai_intent": 0.3,
    "ai_audience": 3.5,
    "ai_signal": 0.6,
    "ai_penalties_applied": true,
    "ai_penalty_points": 4.5,
    "ai_penalty_details": "All dimensions penalized - content is critical and undermines standard approaches (contradicts tone), focuses on internal engineering and operational testing rather than feedback loop mechanics, very little explicit or implicit discussion of customer feedback, audience fit is only partial.",
    "final_score": 8.0,
    "reasoning": "This content critiques organizational and engineering failures leading to fragile systems, focusing extensively on internal testing, operational discipline, and leadership attitudes. While it discusses the importance of real-world verification and iterating based on failure, it frames lessons learnt in terms of operational resilience rather than systematic, ongoing integration of end-user or customer feedback. There are no mentions of customer feedback mechanisms, nor of approaches to incorporate customer insights, nor the role of feedback loops in iterative development. The focus is entirely on internal practices, system design, and response to engineering failures. The only tangential fit is the concept of 'iteration over pain' and 'testing in the real world', which could loosely parallel iterative feedback, but even this is about system reliability, not about learning directly from customers. Additionally, the tone is frequently critical and undermining of standard practices, which warrants minor penalty deductions in all categories. Audience fit is also limited; the piece is targeted at engineering leaders and executives, overlapping only partially with a feedback-loop-focused product audience.",
    "reasoning_summary": "Content is not aligned with Customer Feedback Loops; it critiques resilience practices and operational testing, not product feedback mechanisms. No discussion of collecting or acting on customer feedback. Fit is only indirect and minimal.",
    "level": "Ignored"
  },
  "Trend Analysis": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Trend Analysis",
    "calculated_at": "2025-08-07T07:07:15",
    "ai_confidence": 46.12,
    "ai_mentions": 1.7,
    "ai_alignment": 5.6,
    "ai_depth": 6.1,
    "ai_intent": 5.3,
    "ai_audience": 7.2,
    "ai_signal": 7.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 46.0,
    "reasoning": "The content delivers a sustained critique on organizational, engineering, and product failures regarding resilience, offering real-world examples and some case comparisons. However, it does not analyze trends over time, assess shifting practices, or explore patterns impacting methodologies in Agile, DevOps, or business agility contexts. Focus centers on engineering rigor, product resilience, and leadership discipline—topics adjacent to Trend Analysis but lacking in systematic examination of patterns or shifts driving strategic decisions. No obsolete information or category-contradicting tone occurs. Audience (technologists, strategists) aligns with the target group. While relevant to building resilient systems, the piece is not primarily a Trend Analysis nor does it use typical tools or data to identify actionable trends.",
    "reasoning_summary": "While rich in case analysis and relevant to resiliency in tech organizations, the content does not directly address trend patterns or shifts; its fit with 'Trend Analysis' is partial and mostly indirect, not systematic or comprehensive.",
    "level": "Tertiary"
  },
  "Decision Theory": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Decision Theory",
    "calculated_at": "2025-08-07T07:06:39",
    "ai_confidence": 32.85,
    "ai_mentions": 0.1,
    "ai_alignment": 3.4,
    "ai_depth": 4.05,
    "ai_intent": 4.2,
    "ai_audience": 5.4,
    "ai_signal": 6.15,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content focuses on engineering, organisational, and cultural failures that lead to system fragility, contrasting real versus performative resilience. While it repeatedly discusses risk, testing, and failure assumptions—key issues in decision-making—it never explicitly draws on Decision Theory frameworks, heuristics, probability, or behavioral economics. The main themes are system design, leadership accountability, and operational rigor, rather than the formal study or application of how decisions are made under uncertainty. Some alignment exists in treatment of risk perceptions and cultural denial of reality, which slightly overlap with cognitive psychology, but the core category elements (e.g., probabilistic modeling, decision frameworks, heuristics, biases) are largely absent or only implicitly referenced. The aim is to instill discipline in resilience practice, not to dissect or apply Decision Theory per se. The audience is overlapping (product, engineering, leadership) but not targeted at decision theorists or those interested in decision models.",
    "reasoning_summary": "This content critiques resilience failures in engineering and culture but does not directly discuss or apply Decision Theory concepts, frameworks, or terminology. Alignment is partial and mostly incidental to decision-making under uncertainty.",
    "level": "Ignored"
  },
  "Business Agility": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Business Agility",
    "calculated_at": "2025-10-01T16:58:50",
    "ai_confidence": 38.25,
    "ai_mentions": 0.0,
    "ai_alignment": 4.5,
    "ai_depth": 4.8,
    "ai_intent": 3.7,
    "ai_audience": 5.0,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content deeply explores resilience as an engineering, product, and organisational trait, emphasizing discipline, robust testing, and leadership accountability. However, it never explicitly references 'business agility' or its core themes (adaptability, innovation, agile transformation, frameworks). While case studies and leadership failures are discussed, the focus is on resilience and operational survivability, not on adaptive change, customer-centric innovation, or agile practices at an organisational scale. The intent is more about warning against complacency in resilience than promoting business agility. The audience may overlap (executives/tech leaders), but the main themes, terminology, and recommendations are not mapped to business agility principles.",
    "reasoning_summary": "The content is focused on engineering and organisational resilience, not on business agility or its principles. While it talks about leadership and culture, it does not address adaptability, innovation, or agile methodologies.",
    "level": "Ignored"
  },
  "Enterprise Agility": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Enterprise Agility",
    "calculated_at": "2025-10-01T16:58:12",
    "ai_confidence": 51.15,
    "ai_mentions": 1.3,
    "ai_alignment": 5.6,
    "ai_depth": 6.8,
    "ai_intent": 4.7,
    "ai_audience": 6.1,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 51.0,
    "reasoning": "Direct mention of 'Enterprise Agility' does not occur; focus is on resilience engineering, organisational denial, and failures in operational survivability. The content critiques leadership and culture but does not explicitly discuss frameworks, agile transformations, or agility at scale. It provides substantial depth on why organisations fail at resilience, referencing leadership, culture, and testing discipline—tangentially related to enterprise agility’s focus on adaptability and organisational learning. The audience is likely leaders and engineers concerned with operational continuity, moderately overlapping with the agility audience. Much content is on the topic of operational resilience, with little tangential filler. However, since neither intent nor the main theme is fostering enterprise agility (e.g., introducing frameworks, leading change, scaling agility), the fit is partial and indirect, focused on resilience culture over agility transformation.",
    "reasoning_summary": "Content centers on organisational resilience and failure culture. While themes of leadership, iterative improvement, and organisational learning align partly with enterprise agility, the main focus is resilience engineering, not agility transformation. Partial fit only.",
    "level": "Tertiary"
  },
  "Technical Debt": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Technical Debt",
    "calculated_at": "2025-10-01T16:58:18",
    "ai_confidence": 34.58,
    "ai_mentions": 1.2,
    "ai_alignment": 3.9,
    "ai_depth": 3.8,
    "ai_intent": 3.5,
    "ai_audience": 7.2,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 35.0,
    "reasoning": "The content thoroughly discusses systemic fragility, engineering failures, and the critical importance of building and testing resilience. While many examples (Spain, Oracle, Heathrow) echo consequences of poor long-term design and operational discipline, the term 'technical debt' is never mentioned, nor are its canonical concepts or mitigation strategies directly explored. The focus is on resilience engineering and organizational denial, not explicitly the management, accrual, or remediation of technical debt. Some adjacent ideas (bad engineering/design trade-offs, fake success metrics, and hidden fragility) could relate to technical debt in a broad sense, but the linkage is indirect. The target audience (practitioners, leaders) aligns broadly with technical debt discourse. However, the overall signal is only partially matched, as the principal themes do not directly address technical debt as defined.",
    "reasoning_summary": "Content focuses on engineering resilience and organizational failure, not explicitly on technical debt. Connections to technical debt are indirect and thematic, not central. Only partial alignment to the technical debt category definition.",
    "level": "Ignored"
  },
  "Evidence Based Leadership": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Evidence Based Leadership",
    "calculated_at": "2025-10-31T18:34:27",
    "ai_confidence": 32.58,
    "ai_mentions": 1.4,
    "ai_alignment": 3.2,
    "ai_depth": 3.6,
    "ai_intent": 2.3,
    "ai_audience": 4.8,
    "ai_signal": 3.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content primarily critiques failures in engineering and organizational thinking that led to fragile systems, using real-world examples. It mentions leadership in the context of accountability and culture but does not explicitly discuss or apply evidence-based leadership practices, empirical decision-making, or reference Evidence-Based Management frameworks. The focus is instead on technical and cultural failures, with only a brief linkage to leadership. It does not explore data-driven leadership decisions, referencing metrics, or formal evidence-based leadership techniques. The intent is more cautionary than instructive in evidence-based leadership, and case studies focus on resilience outcomes, not leadership improvement through evidence. The audience is partially aligned—leaders could learn from the stories, but the content addresses technical and cultural flaws more than leadership methodology.",
    "reasoning_summary": "While leadership failures are discussed, the content lacks substantive engagement with evidence-based leadership principles, practices, or frameworks. Its focus is mostly on resilience engineering and organizational denial rather than data-driven leadership.",
    "level": "Ignored"
  },
  "Artificial Intelligence": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Artificial Intelligence",
    "calculated_at": "2025-10-31T18:34:44",
    "ai_confidence": 6.7,
    "ai_mentions": 0.3,
    "ai_alignment": 1.6,
    "ai_depth": 1.5,
    "ai_intent": 0.9,
    "ai_audience": 1.1,
    "ai_signal": 0.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content focuses on resilience, engineering for failure, systems design, and organizational behavior, specifically regarding how organizations prepare for and test robust infrastructures. There is an in-depth discussion of real-world outages (e.g., Oracle, Heathrow), bad engineering practices, and culture around resilience. However, there are no direct mentions or discussions of Artificial Intelligence, nor any reference to how AI, machine learning, or intelligent automation relate to Agile, DevOps, or software engineering in these contexts. The core themes—real-world testing, system dependencies, leadership blindness—align more with operational resilience and engineering rigor, not the integration of AI or its contribution to these practices. Any conceptual overlap (such as automation or resilience testing) is generic and not explicitly or implicitly linked to AI or its use cases in the described fields.",
    "reasoning_summary": "This content is about engineering resilience and organizational failure, not AI or its use in Agile, DevOps, or software engineering processes. There is no mention or implied discussion of AI, so fit with the 'Artificial Intelligence' category is extremely weak.",
    "level": "Ignored"
  },
  "Empirical Process Control": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Empirical Process Control",
    "calculated_at": "2025-10-31T18:34:29",
    "ai_confidence": 45.4,
    "ai_mentions": 0.6,
    "ai_alignment": 5.3,
    "ai_depth": 5.7,
    "ai_intent": 4.4,
    "ai_audience": 5.2,
    "ai_signal": 5.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 45.0,
    "reasoning": "The content robustly critiques organizational myths of resilience and argues that real resilience must be earned by iterative, real-world testing and brutal honesty about failure. While these practices generally align with empirical approaches (feedback, testing hypotheses, evidence-based adaptation), the text never explicitly references empirical process control, nor does it directly mention transparency, inspection, or adaptation in the Agile sense. There is little or no discussion of Agile, Scrum, Kanban, Lean, or relevant key figures. The focus is primarily on reliability engineering and organizational culture, not on empirical process control as a management approach. There is moderate conceptual overlap with empirical principles (experimentation, feedback loops), but the language and context do not directly address the category as defined. The audience appears to be practitioners and leaders interested in resilience but not necessarily agile professionals, and the intent is critiquing organizational self-delusion, not promoting empirical process control directly. Signal-to-noise is moderate: while clear and focused, the empirical process control lens is indirect and not primary.",
    "reasoning_summary": "Content critiques fake resilience and advocates real-world testing, aligning partially with empirical principles. However, it lacks explicit references to empirical process control, Agile, or Scrum, making its fit with the category moderate and indirect.",
    "level": "Tertiary"
  },
  "Ability to Innovate": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Ability to Innovate",
    "calculated_at": "2025-10-31T18:34:46",
    "ai_confidence": 33.05,
    "ai_mentions": 1.6,
    "ai_alignment": 3.4,
    "ai_depth": 4.2,
    "ai_intent": 3.6,
    "ai_audience": 7.4,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content thoroughly examines organisational and engineering failures around resilience, operational continuity, and system design, with detailed real-world case studies. It discusses testing, leadership, and discipline in resilience but does not directly address innovation, the ability to innovate, innovation metrics, or mechanisms for enhancing innovation. The main focus is on building, testing, and iterating resilience, not fostering or measuring innovation within Agile, DevOps, or EBM contexts. As such, conceptual and direct fit with 'Ability to Innovate' is low, though there are loose links around iterative improvement and problem recognition. The audience (technical leaders/execs) partially aligns, and much of the text is focused and relevant to the main topic (resilience), but not to innovation specifically.",
    "reasoning_summary": "Content focuses on resilience, disaster recovery, and system robustness—not on innovation capability or fostering innovation. There are only weak, indirect ties to 'Ability to Innovate.' Fit with the specified category is low and mostly incidental.",
    "level": "Ignored"
  },
  "One Engineering System": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "One Engineering System",
    "calculated_at": "2025-10-31T18:34:35",
    "ai_confidence": 13.37,
    "ai_mentions": 0.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.2,
    "ai_intent": 2.4,
    "ai_audience": 2.8,
    "ai_signal": 1.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content focuses on the necessity for real resilience, emphasizing rigorous, real-world engineering practices and critical analysis of failure cases in large-scale systems. However, it makes no direct mention of the One Engineering System (1ES), nor does it discuss principles, components, or implementation of 1ES as a unified engineering framework. While the themes—standardization, cross-team integration, and operational discipline—are tangentially related, the piece remains conceptual and anecdotal, critiquing bad engineering and organizational denial without referencing 1ES or similar frameworks. As a result, the alignment, depth, and intent with the specific 'One Engineering System' category are partial at best, and the fit is weak.",
    "reasoning_summary": "The content discusses the need for engineering resilience but makes no reference to One Engineering System and only tangentially aligns with its core ideas. It lacks focus on unified frameworks or standardisation; fit with the category is minimal and mostly superficial.",
    "level": "Ignored"
  },
  "Agile Planning Tools": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Agile Planning Tools",
    "calculated_at": "2025-10-31T18:34:49",
    "ai_confidence": 1.7,
    "ai_mentions": 0.0,
    "ai_alignment": 2.0,
    "ai_depth": 2.3,
    "ai_intent": 1.7,
    "ai_audience": 2.1,
    "ai_signal": 2.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content focuses on operational resilience, engineering failure modes, organisational blindness, and real-world disaster testing. There are no direct or indirect mentions of Agile Planning Tools, backlog management, sprint/release planning, Jira/Trello/Asana, or any Agile-specific planning practices. The main themes concern infrastructural robustness, leadership failure, and the need for rigorous real-world validation of resilience—none of which align with the intent or audience of the Agile Planning Tools category, which is specifically about facilitating Agile planning and execution via tooling and methodologies.",
    "reasoning_summary": "The content does not address Agile Planning Tools or related practices. Its focus is system resilience and organisational failures, which are outside the category’s scope. The match is negligible and incidental, not thematic.",
    "level": "Ignored"
  },
  "Evidence Based Management": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Evidence Based Management",
    "calculated_at": "2025-10-31T18:34:35",
    "ai_confidence": 29.2,
    "ai_mentions": 0.6,
    "ai_alignment": 3.2,
    "ai_depth": 2.5,
    "ai_intent": 3.8,
    "ai_audience": 5.2,
    "ai_signal": 6.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 29.0,
    "reasoning": "The content provides a detailed critique of engineering and organisational failures in resilience but does not directly discuss Evidence-Based Management or its key concepts (empirical measurement, outcome management, etc.). There is some conceptual overlap via criticism of 'fake success metrics' and calls for real-world testing, which align loosely with empirical approaches and skepticism towards output metrics, but EBM is never mentioned, and the primary discussion centers on operational resilience, not the strategic, data-driven decision-making of EBM. Examples (e.g., disaster recovery exercises, Rackspace's key test) stress the value of frequent, real-world validation, marginally touching upon empirical thinking, yet without strategic management focus.",
    "reasoning_summary": "Content focuses on technical/organisational resilience, not Evidence-Based Management. Any empirical aspects relate to operational practice, not strategic, evidence-based management. Fit is marginal and indirect.",
    "level": "Ignored"
  },
  "Metrics and Learning": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Metrics and Learning",
    "calculated_at": "2025-10-31T18:34:53",
    "ai_confidence": 43.075,
    "ai_mentions": 1.7,
    "ai_alignment": 5.9,
    "ai_depth": 4.8,
    "ai_intent": 5.6,
    "ai_audience": 6.2,
    "ai_signal": 6.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "Direct Mentions (1.7): The content does not explicitly reference metrics, learning, or related frameworks. Conceptual Alignment (5.9): Some emphasis on feedback, testing, and continuous improvement aligns with the category, but lacks grounding in data or measurement. Depth (4.8): While it explores resilience failures and improvement, coverage of metrics, learning cycles, or evidence-based practices is surface-level or implied. Intent (5.6): The primary aim is to critique poor resilience engineering and promote discipline/testing, tangential but semi-relevant to metrics and learning. Audience (6.2): Likely targets technical leads, engineers, and product managers—partially overlapping the Metrics and Learning category's audience. Signal (6.5): Content remains focused on resilience theme, but not predominantly on data, metrics, or learning loops. No penalties applied; content is current and not satirical.",
    "reasoning_summary": "The piece advocates real-world testing and iterative improvement for resilience but lacks explicit focus on metrics, measurement, or structured learning, making category fit partial and indirect.",
    "level": "Tertiary"
  },
  "Product Strategy": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Product Strategy",
    "calculated_at": "2025-10-31T18:34:36",
    "ai_confidence": 57.285,
    "ai_mentions": 2.7,
    "ai_alignment": 6.4,
    "ai_depth": 7.2,
    "ai_intent": 6.6,
    "ai_audience": 6.8,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 57.0,
    "reasoning": "The content discusses resilience as a product capability and criticizes failures in leadership, product thinking, and organizational strategy—overlapping substantially with product strategy concerns (roadmap, vision, risk, customer impact). However, the primary focus is on engineering for resilience and real-world failure scenarios, and it does not deeply engage with central product strategy topics such as competitive positioning, market analysis, or strategic alignment beyond continuity and survivability. Mentions of product, roadmaps, and leadership are present, but domain language and explicit frameworks/tools from product strategy are largely absent. The core audience appears to be leaders and strategists, but also deeply technical/operational (not exclusively product executives). The signal is good, with only light tangential material. No penalty for outdatedness or negative tone.",
    "reasoning_summary": "This content fits partially: it dwells on product resilience and strategic organizational failures, but lacks comprehensive coverage of classic product strategy topics such as market analysis, competitive positioning, or structured vision/roadmap development.",
    "level": "Tertiary"
  },
  "Scrum Master": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Scrum Master",
    "calculated_at": "2025-10-31T18:34:57",
    "ai_confidence": 6.2,
    "ai_mentions": 0.0,
    "ai_alignment": 1.9,
    "ai_depth": 2.2,
    "ai_intent": 2.3,
    "ai_audience": 0.7,
    "ai_signal": 1.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The content does not mention the Scrum Master or Scrum at all. It focuses entirely on resilience, system failure, engineering, leadership, and organisational denial. While there are minor overlaps with systemic thinking and the need for organisational accountability, there is no direct or indirect discussion of the Scrum Master's accountability, responsibilities, or impact. The intended audience appears to be engineers, operational leaders, and executives—not Scrum Masters or those interested in Scrum. All dimensions score extremely low, as there is no meaningful fit to the assigned category. No penalty is applied as content is not outdated or derogatory to Scrum.",
    "reasoning_summary": "No connection to Scrum Master accountability. Content is about engineering resilience and organisational denial—no relevance to the role or responsibilities of a Scrum Master. No alignment to the category definition.",
    "level": "Ignored"
  },
  "Strategic Goals": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Strategic Goals",
    "calculated_at": "2025-11-10T14:44:52",
    "ai_confidence": 35.892,
    "ai_mentions": 1.6,
    "ai_alignment": 3.2,
    "ai_depth": 3.5,
    "ai_intent": 2.4,
    "ai_audience": 2.7,
    "ai_signal": 3.0,
    "ai_penalties_applied": true,
    "ai_penalty_points": 2.0,
    "ai_penalty_details": "Penalties applied to 'intent' (-1) for a critical, almost satirical tone contrary to standard strategic framing, and 'alignment' (-1) since discussion of resilience, while strategic at times, is largely decoupled from agile strategic goals.",
    "final_score": 36.0,
    "reasoning": "The content focuses primarily on engineering resilience, organisational blindness, and the costs of poor disaster recovery, with deep real-world examples. While it touches on themes relevant to strategy and culture, there is little explicit or thorough discussion of 'strategic goals' as defined (long-term objectives, alignment with agile principles, competitive advantage). Shallow references to leadership, culture, and operational survivability are present, but the framing is critical of poor strategy rather than explicating how to set or achieve strategic goals. There are no frameworks, evidence-based measurement, agile methodology dialogue, or explicit strategy-setting. The piece is written for engineers, perhaps critical leadership, but not squarely for a strategic, executive, or evidence-based management audience, nor does it provide substantive guidance or conceptual development in the Strategic Goals context. Penalties apply for a tone that contradicts standard strategic goal framing (satirical/critical), and for a lack of agile/strategic integration.",
    "reasoning_summary": "The content critiques failures in resilience and organisational denial, occasionally intersecting with strategy and leadership, but lacks direct discussion or alignment with strategic goals as defined. Fit is partial and indirect at best.",
    "level": "Ignored"
  },
  "Minimum Viable Product": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Minimum Viable Product",
    "calculated_at": "2025-11-10T14:44:07",
    "ai_confidence": 8.95,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 1.1,
    "ai_intent": 1.2,
    "ai_audience": 2.5,
    "ai_signal": 2.45,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "Direct mentions or references to Minimum Viable Product (MVP) are absent. The primary discussion centers on resilience, engineering for failure, and organisational learning via real-world testing. These themes overlap with broader Agile and evidence-based concepts, but do not specifically address MVP principles such as minimal feature development, hypothesis testing, or early product iterations as a market validation technique. The discussion of product capability and iteration (e.g., 'iterating over pain') could relate to the spirit of MVP, but it is in service of resilience, not validating a market-facing MVP. The intended audience (product/engineering/leadership) somewhat overlaps with the MVP category's core audience, but this content's focus remains tangential to MVP's definition and purpose.",
    "reasoning_summary": "Content does not fit the MVP category. Focus is on engineering resilience and organisational learning via failure testing, with minimal conceptual or thematic overlap with Minimum Viable Product topics.",
    "level": "Ignored"
  },
  "Agile Frameworks": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Agile Frameworks",
    "calculated_at": "2025-11-10T14:45:06",
    "ai_confidence": 10.3,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.3,
    "ai_intent": 1.0,
    "ai_audience": 4.6,
    "ai_signal": 1.0,
    "ai_penalties_applied": true,
    "ai_penalty_points": 1.5,
    "ai_penalty_details": "mentions (-1, no direct reference to Agile Frameworks); alignment (-0.5, discussions related to engineering and resilience but not Agile theories or frameworks); no penalties elsewhere.",
    "final_score": 10.0,
    "reasoning": "There are no direct mentions or discussions about Agile Frameworks, their principles, values, or comparative analysis. The content solely focuses on resilience engineering, operational failure, and organisational blindness, outside the scope of Agile frameworks. While the audience (engineering/leadership) could intersect with Agile topics, intent, alignment, and depth are off-target. Penalties applied for lack of direct references and partial thematic misalignment.",
    "reasoning_summary": "The content does not address Agile frameworks or their principles, instead focusing on resilience engineering and organisational failures, making it a poor fit for the Agile Frameworks category.",
    "level": "Ignored"
  },
  "Digital Transformation": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Digital Transformation",
    "calculated_at": "2025-11-10T14:44:59",
    "ai_confidence": 49.868,
    "ai_mentions": 1.6,
    "ai_alignment": 5.9,
    "ai_depth": 6.2,
    "ai_intent": 5.3,
    "ai_audience": 5.6,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 50.0,
    "reasoning": "The content deeply analyzes failures in building resilient systems, focusing on engineering, product thinking, and culture. However, it frames resilience as an operational/engineering quality, not as a piece of broader digital transformation strategy (such as digital adoption, business agility or digital-driven organisational change). There are strong themes of change management and leadership failures, but examples and discussion focus on operational outages, not digital transformation initiatives or leveraging digital for business innovation. The audience skews technical to middle-management. No digital transformation terminology or frameworks are cited; the connection is indirect and partial.",
    "reasoning_summary": "Content centers on resilience failures in engineering and operations, not the strategic use of digital technologies for business transformation. Fit is partial; some cultural and leadership discussion, but not digital transformation-focused.",
    "level": "Tertiary"
  },
  "Lean Thinking": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Lean Thinking",
    "calculated_at": "2025-11-10T14:44:11",
    "ai_confidence": 23.648,
    "ai_mentions": 0.6,
    "ai_alignment": 2.4,
    "ai_depth": 2.8,
    "ai_intent": 2.2,
    "ai_audience": 8.1,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content focuses on resilience through engineering, cultural discipline, and real-world testing, but does not discuss Lean Thinking principles (value, waste, flow, etc.), Lean tools (5S, Kanban), or even mention Lean explicitly. There is high alignment with technical and leadership audiences, and the writing is direct and focused. However, the main ideas are about resilience engineering, operational discipline, and organizational denial, not Lean Thinking as defined (minimizing waste, value stream mapping, etc.). The phrase 'lean into it' appears, but in a colloquial, non-technical context unrelated to Lean methodology. No key Lean frameworks or terminology are present, nor is there discussion of value stream mapping, waste elimination, flow, pull, or continuous improvement (Kaizen) in the Lean sense.",
    "reasoning_summary": "Resilience is discussed deeply, but Lean Thinking is neither directly referenced nor conceptually central. The content doesn't cover Lean principles, tools, or value stream improvement, so the fit is weak and mostly coincidental.",
    "level": "Ignored"
  },
  "Operational Practices": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Operational Practices",
    "calculated_at": "2025-11-10T14:45:03",
    "ai_confidence": 76.32,
    "ai_mentions": 2.5,
    "ai_alignment": 8.9,
    "ai_depth": 8.5,
    "ai_intent": 8.8,
    "ai_audience": 7.9,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 76.0,
    "reasoning": "The content provides a detailed practical critique of fragile operational approaches, emphasizing real-world testing, disciplined disaster recovery, rigor in engineering for failure, and resilience as a built capability. It offers concrete examples (Rackspace, Heathrow, Oracle), actionable operational guidance (testing under real conditions, leadership discipline), and explicit alignment with operational efficiency and survivability—the core of Operational Practices. However, it does not directly mention the category term ('Operational Practices') nor use much terminology directly referencing Agile, DevOps, or Lean frameworks; instead, its focus is on resilience engineering as an applied operational discipline. The audience appears to be technical leads and product practitioners responsible for operational outcomes, aligning well, although there are some conceptual asides and illustrative stories that don't directly name operational KPIs/metrics or reference process tools. No penalties apply. The fit is strong but not complete due to explicit category terminology and direct linkage to Agile/DevOps/Lean systems being more implicit than stated.",
    "reasoning_summary": "The content heavily focuses on practical strategies to improve operational resilience and efficiency, aligning well with 'Operational Practices.' While explicit mentions are low and references to Agile/DevOps/Lean are implicit, overall thematic fit is strong.",
    "level": "Secondary"
  },
  "Sprint Review": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Sprint Review",
    "calculated_at": "2025-05-13T21:54:46",
    "ai_confidence": 8.0,
    "ai_mentions": 0.0,
    "ai_alignment": 0.7,
    "ai_depth": 1.2,
    "ai_intent": 0.8,
    "ai_audience": 1.0,
    "ai_signal": 1.0,
    "ai_penalties_applied": true,
    "ai_penalty_points": 1.0,
    "ai_penalty_details": "All dimensions receive the minimum because the content is strongly critical and not aligned with the Sprint Review framing. No dimension was deducted for outdated information, only for contradicting spirit/intent.",
    "final_score": 8.0,
    "reasoning": "The article does not explicitly mention or reference Sprint Review or any Scrum practices. Its focus is on system and organizational resilience in engineering, not on Scrum events, reviews, stakeholder collaboration, or backlog adaptation. All scoring dimensions are minimal: no mentions, no thematic alignment, and no relevant depth in Sprint Review specifics. Because the tone is highly critical and diverges from the collaborative, constructive intent of the Sprint Review, a penalty has been applied.",
    "reasoning_summary": "This content does not mention or align with Sprint Review—it critiques system resilience, not Scrum events. No Scrum practices or stakeholder reviews are discussed, so confidence is extremely low.",
    "level": "Ignored"
  },
  "Cross Functional Teams": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Cross Functional Teams",
    "calculated_at": "2025-11-10T14:44:15",
    "ai_confidence": 14.87,
    "ai_mentions": 0.2,
    "ai_alignment": 1.8,
    "ai_depth": 2.3,
    "ai_intent": 2.2,
    "ai_audience": 3.5,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 15.0,
    "reasoning": "The content is deeply focused on organisational resilience, failure modes, and leadership in engineering/disaster recovery, not cross-functional teams. It never directly mentions or discusses cross-functional teams' structure, characteristics, or benefits within Agile. Any alignment is only tangential; at best, the content indirectly implies that organizational silos or leadership failures are problematic, but it does not tie these to cross-functional teamwork. There are no case studies, best practices, challenges, or deeply relevant themes about cross-functional collaboration. The main audience seems to be technical leads/IT executives, matching somewhat, but all major scoring factors for this category are either absent or negligible.",
    "reasoning_summary": "Content focuses on organisational resilience and leadership failures in system design, not cross-functional teams. No direct mention or substantive discussion connects it to cross-functional team topics. Alignment to the category is minimal and incidental.",
    "level": "Ignored"
  },
  "Scrum Values": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Scrum Values",
    "calculated_at": "2025-11-10T14:45:07",
    "ai_confidence": 2.45,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 2.4,
    "ai_intent": 3.3,
    "ai_audience": 3.5,
    "ai_signal": 2.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content focuses on engineering and organizational resilience, critiquing failures and emphasizing practical verification. It does not discuss Scrum Values explicitly or implicitly, nor does it touch on commitment, courage, focus, openness, or respect. The themes, purpose, and examples are targeted at general engineering and product leadership practices, not Scrum teams or the philosophical underpinnings of Scrum. Audience fit is somewhat plausible for Agile practitioners, but the linkage is not established; the discussion remains tightly centered on resilience, not Scrum Values.",
    "reasoning_summary": "The content is about engineering and organizational approaches to resilience, not Scrum Values. No Scrum Value is discussed or referenced, nor is there any alignment to the category's core principles. Fit is almost entirely absent.",
    "level": "Ignored"
  },
  "Deployment Strategies": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Deployment Strategies",
    "calculated_at": "2025-11-10T14:44:19",
    "ai_confidence": 37.72,
    "ai_mentions": 1.1,
    "ai_alignment": 4.7,
    "ai_depth": 4.2,
    "ai_intent": 2.6,
    "ai_audience": 5.9,
    "ai_signal": 5.4,
    "ai_penalties_applied": true,
    "ai_penalty_points": 2.5,
    "ai_penalty_details": "Mentions (-0.4): No explicit naming of deployment strategies, terms, or techniques; Alignment (-0.5): Focus on resilience with only tangential relationship to deployment methodologies; Depth (-0.6): Lacks substantive exploration of deployment practices; Intent (-0.5): Primarily diagnostic/critical, not instructive for deployment; Audience (-0.3): Mix of technical and leadership audience, partial overlap; Signal (-0.2): Some tangential content and anecdotes dilute core focus.",
    "final_score": 38.0,
    "reasoning": "This content critiques organizational and engineering failures in achieving resilience, showcasing notable outages and emphasizing real-world testing. However, it does not explicitly address or detail deployment strategies—there are no direct mentions of blue-green deployments, canary releases, rolling updates, or Infrastructure as Code. The main thrust is about resilience engineering, not deployment techniques; the discussion of 'disaster recovery' is more about operational readiness than deployment methodology. Depth on deployment strategies is very limited; actionable or method-based insights tied to software deployment are absent. Tone is critical/skeptical and focuses more on organizational culture and engineering rigor than on deployment strategy. Penalties are applied for lack of explicit mention, tangential focus, and low actionable alignment.",
    "reasoning_summary": "Primary focus is resilience and organizational failure, not deployment strategies. Lacks explicit method discussion—only indirectly related to deployment. Content fit with 'Deployment Strategies' is partial and mostly tangential.",
    "level": "Ignored"
  },
  "Organisational Psychology": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Organisational Psychology",
    "calculated_at": "2025-11-10T14:44:25",
    "ai_confidence": 29.779,
    "ai_mentions": 1.8,
    "ai_alignment": 3.3,
    "ai_depth": 3.6,
    "ai_intent": 2.9,
    "ai_audience": 4.7,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 30.0,
    "reasoning": "The content primarily critiques technical, architectural, and operational failures around resilience. It makes some references to leadership, organisational denial, and culture (e.g., 'organisational blindness', failure to face reality), but these are not explored as core psychological principles or theories. There are no meaningful discussions of motivation, engagement, team dynamics, or psychological safety; rather, blame and leadership failures are described more as management or strategic shortcomings. The focus remains on technical and process-oriented causes, with only passing nods to psychological concepts, and the intent is to promote engineering and testing rigour more than to explore organisational psychology. Audience alignment is partial, as leaders are referenced, but mostly for their technical decisions rather than psychological influences. Thus, there are minimal direct mentions, weak conceptual alignment, and only shallow depth on the category definition.",
    "reasoning_summary": "Content is mainly technical/operational with minor references to leadership and organisational denial. It does not deeply explore the psychological principles, theories, or topics central to organisational psychology. Fit is partial and mostly indirect.",
    "level": "Ignored"
  },
  "Agile Transformation": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Agile Transformation",
    "calculated_at": "2025-11-24T18:56:59",
    "ai_confidence": 33.34,
    "ai_mentions": 0.4,
    "ai_alignment": 4.1,
    "ai_depth": 4.7,
    "ai_intent": 3.6,
    "ai_audience": 3.4,
    "ai_signal": 3.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content discusses organisational failures, engineering for resilience, leadership blind spots, and real-world testing, all relevant to organisational change and improvement. However, it never references Agile, Agile principles, or transformation frameworks. Foundational concepts such as culture, iterative improvement, and leadership are present, but there are no explicit or even implicit links to Agile Transformation methodologies, metrics, or philosophy. The audience may overlap (leaders, engineers, strategists), and some cultural/leadership points touch on themes shared by Agile transformation (e.g., learning from failure, continuous improvement), but the content is focused on engineering/operational resilience, not Agile principles or transformations. Any alignment is indirect and not substantial.",
    "reasoning_summary": "Content explores organisational resilience, leadership, and real-world failure, but makes no mention of Agile frameworks, values, or transformation methodology. Only a tangential, partial thematic overlap exists—confidence for Agile Transformation is low.",
    "level": "Ignored"
  },
  "Agile Leadership": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Agile Leadership",
    "calculated_at": "2025-11-24T18:56:59",
    "ai_confidence": 35.92,
    "ai_mentions": 0.7,
    "ai_alignment": 3.8,
    "ai_depth": 4.3,
    "ai_intent": 3.7,
    "ai_audience": 4.2,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 36.0,
    "reasoning": "Direct mentions of Agile Leadership are nearly absent, apart from a brief nod to product [leadership]. The content primarily focuses on technical failures in resilience engineering, with criticisms aimed more at product, engineering, and general leadership failures than Agile-specific leadership. There is some conceptual overlap—calling for honest, accountable leadership and a culture of discipline—but these themes lack explicit Agile framing (servant leadership, Agile values, transformation, etc.). The depth is moderate where it critiques leadership blindness and calls for cultural change, but the overall orientation is technical resilience, not Agile leadership. The audience is broadly practitioners/technical managers more than Agile leaders. Content stays on topic for resilience but not for Agile Leadership specifically. No penalties apply.",
    "reasoning_summary": "Content critiques leadership failures in resilience, but lacks explicit Agile context or principles. Overlap is partial—some leadership themes present, but not specifically about Agile Leadership. Fit is weak and mostly tangential.",
    "level": "Ignored"
  },
  "Organisational Culture": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Organisational Culture",
    "calculated_at": "2025-11-24T18:57:01",
    "ai_confidence": 68.3,
    "ai_mentions": 3.2,
    "ai_alignment": 7.4,
    "ai_depth": 7.6,
    "ai_intent": 6.8,
    "ai_audience": 7.2,
    "ai_signal": 8.0,
    "ai_penalties_applied": true,
    "ai_penalty_points": 1.2,
    "ai_penalty_details": "1 point deducted from mentions due to limited direct reference to 'culture' as a main theme; 0.2 from intent due to occasional critical/satirical tone toward leadership.",
    "final_score": 68.0,
    "reasoning": "The content focuses mainly on resilience and engineering failures, but includes a significant section ('Organisational Blindness') explicitly linking leadership, denial, and cultural issues to system fragility. It discusses how leadership and organisational culture fail to foster true resilience—matching one dimension of the category. However, the core theme is more about engineering/product practices than an in-depth exploration of organisational culture. Concepts like denial, fake success metrics, and leadership accountability are discussed, but broader culture topics (employee engagement, continuous improvement, broader transformation) are not expanded upon. The critique of leadership and surface-level blame aligns partially, but the overall narrative remains focused on engineering, not culture as a holistic driver. Tone is often critical, potentially undermining constructive framing. Audience is relevant (leaders, executives), and the arguments support the value of cultural change but with only moderate depth.",
    "reasoning_summary": "Content partially fits: it explicitly connects leadership and cultural denial to failures in resilience but remains mostly centered on engineering and operational practice with only moderate exploration of organisational culture as a transformative force.",
    "level": "Secondary"
  },
  "Agnostic Agile": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Agnostic Agile",
    "calculated_at": "2025-11-24T18:56:46",
    "ai_confidence": 15.95,
    "ai_mentions": 0.1,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 4.2,
    "ai_signal": 2.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "The content directly addresses resilience in engineering, leadership, and organizational denial, without mentioning Agnostic Agile or its principles. There is some conceptual overlap with context-driven and pragmatic thinking, but none with Agnostic Agile's philosophy, ethical focus, or comparison with agile frameworks. Discussion depth and audience overlap are minor (relevant to technical/leadership roles) but do not focus on Agnostic Agile as defined. Most content is off-topic for this category.",
    "reasoning_summary": "This article does not fit the Agnostic Agile category; it discusses system resilience and engineering failures without referencing Agnostic Agile, its philosophy, principles, or comparative agile frameworks. Any overlap is incidental, not intentional.",
    "level": "Ignored"
  },
  "Team Collaboration": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Team Collaboration",
    "calculated_at": "2025-11-24T18:56:54",
    "ai_confidence": 19.2,
    "ai_mentions": 0.4,
    "ai_alignment": 2.1,
    "ai_depth": 2.7,
    "ai_intent": 1.5,
    "ai_audience": 6.3,
    "ai_signal": 3.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content focuses extensively on systems resilience, engineering rigor, organizational blindness, and leadership failures. While the discussion touches on organizational culture, accountability, and leadership denial, it does not directly or deeply engage with team collaboration within Agile, Scrum, or DevOps frameworks. Techniques for team communication, shared ownership, or cross-functional collaboration are absent. There's minimal direct reference to team dynamics as defined by the category; the audience is broadly technical, but not specifically collaborative practitioners.",
    "reasoning_summary": "The content addresses organizational failures and resilience but does not discuss team collaboration within Agile, Scrum, or DevOps. The main focus is on engineering and leadership, making fit to 'Team Collaboration' partial and indirect at best.",
    "level": "Ignored"
  },
  "Throughput": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Throughput",
    "calculated_at": "2025-11-24T18:56:45",
    "ai_confidence": 5.1,
    "ai_mentions": 0.2,
    "ai_alignment": 0.8,
    "ai_depth": 1.1,
    "ai_intent": 0.4,
    "ai_audience": 1.2,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 5.0,
    "reasoning": "The content's primary focus is on resilience versus fragility in engineering and organizational practices. There is no explicit mention of throughput as a metric, nor any substantial discussion on measuring delivery capacity, flow, or work completion rates. The themes revolve around failure, disaster recovery, organisational denial, and the need for real-world resilience testing. Metrics and delivery throughput are not cited, analysed, or even implied as a lens for understanding delivery health. Content is intended for technical and leadership audiences, but it does not intersect with throughput measurement’s purpose, visualization, or evidence-based inspection. The fit is extremely marginal—almost non-existent.",
    "reasoning_summary": "Content focuses on resilience, engineering, and organizational failures—not throughput or its measurement. No mention of throughput as a delivery metric; thus, content does not fit the ‘Throughput’ category.",
    "level": "Ignored"
  },
  "Technical Excellence": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Technical Excellence",
    "calculated_at": "2025-11-24T18:56:45",
    "ai_confidence": 73.55,
    "ai_mentions": 2.8,
    "ai_alignment": 8.7,
    "ai_depth": 8.5,
    "ai_intent": 9.0,
    "ai_audience": 8.0,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 74.0,
    "reasoning": "Direct mention of 'technical excellence' is absent, but the content strongly aligns with its principles by deeply analyzing how poor engineering, lack of real-world testing, and superficial continuity planning lead to failure. It critiques and illustrates the necessity of technical excellence through resilience engineering, architectural robustness, rigorous testing, and a culture that prioritizes operational survivability over compliance theater. With numerous concrete examples (Spain, Oracle, Heathrow, Merrill Lynch, and Rackspace), it explores how disciplined, engineering-driven approaches distinguish true resilience from fragile, wishful design. The audience (engineers, leaders, teams) and intent (instructional, cautionary) closely match the category. However, key terms like TDD, CI/CD, modular architecture, or Agile are implicit rather than explicit, accounting for a lower score on 'mentions.' No penalties apply as the tone is critical but supportive of the technical excellence mindset.",
    "reasoning_summary": "This content robustly fits 'Technical Excellence' via an in-depth critique of engineering failures and real-world testing. While it lacks explicit category terms, its intent and depth fully align with the core principles outlined.",
    "level": "Secondary"
  },
  "Agile Strategy": {
    "category": "Agile Strategy",
    "calculated_at": "2025-04-29T14:03:19",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses resilience in systems and organisational failures but does not explicitly mention Agile methodologies or strategies. While it touches on themes of adaptability and leadership, which are relevant to Agile, the primary focus is on engineering and operational resilience rather than Agile strategy. The depth of discussion is more technical and operational than strategic, leading to a low confidence score in alignment with the Agile Strategy category.",
    "level": "Ignored"
  },
  "Team Performance": {
    "category": "Team Performance",
    "calculated_at": "2025-04-29T14:03:22",
    "ai_confidence": 32.0,
    "ai_mentions": 5,
    "ai_alignment": 15,
    "ai_depth": 12,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses resilience in systems and organisations, focusing on failures and the need for robust engineering practices. While it touches on organisational dynamics and leadership's role in creating a culture of resilience, it does not explicitly address team performance metrics or delivery capabilities at the team level. The primary focus is on systemic failures and resilience rather than team dynamics or performance metrics, leading to a lower confidence score in the 'Team Performance' category.",
    "level": "Ignored"
  },
  "Install and Configuration": {
    "category": "Install and Configuration",
    "calculated_at": "2025-04-29T14:03:25",
    "ai_confidence": 10.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 10,
    "final_score": 10.0,
    "reasoning": "The content primarily discusses the concept of resilience in systems and organisational failures rather than providing actionable instructions or insights related to the installation and configuration of tools or software. While it touches on the importance of engineering for resilience, it does not delve into specific installation procedures, configuration best practices, or troubleshooting, which are essential for the 'Install and Configuration' category.",
    "level": "Ignored"
  },
  "Professional Scrum": {
    "category": "Professional Scrum",
    "calculated_at": "2025-04-29T14:03:28",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses resilience in systems and organisational culture but does not explicitly mention Scrum or its principles. While it touches on themes of accountability and the need for disciplined practices, it lacks a direct connection to the ethos of Professional Scrum, focusing instead on engineering and operational failures.",
    "level": "Ignored"
  },
  "Transparency": {
    "category": "Transparency",
    "calculated_at": "2025-04-29T14:03:32",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 15.0,
    "reasoning": "The content discusses resilience and organisational failures but does not explicitly address transparency or its role in Agile processes. While it touches on the importance of visibility in systems and leadership accountability, it lacks a focused discussion on transparency as defined in the category. The mention of leadership's failure to own internal issues hints at a lack of transparency, but this is not the primary focus of the content.",
    "level": "Ignored"
  },
  "Automated Testing": {
    "category": "Automated Testing",
    "calculated_at": "2025-04-29T14:03:35",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 10,
    "final_score": 15.0,
    "reasoning": "The content discusses resilience in systems and the importance of testing under real-world conditions, but it does not explicitly mention automated testing or its methodologies. While there are references to testing systems, the focus is more on resilience and failure management rather than the principles and practices of automated testing as defined in the category. The discussion lacks depth in terms of automated testing frameworks, tools, or best practices, leading to a low confidence score.",
    "level": "Ignored"
  },
  "Azure Pipelines": {
    "category": "Azure Pipelines",
    "calculated_at": "2025-04-29T14:03:37",
    "ai_confidence": 10.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 10.0,
    "reasoning": "The content discusses resilience in systems and organisational failures but does not mention Azure Pipelines or any related CI/CD practices. It focuses on broader engineering and operational challenges rather than specific Azure DevOps topics.",
    "level": "Ignored"
  },
  "Employee Engagement": {
    "category": "Employee Engagement",
    "calculated_at": "2025-04-29T14:03:41",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, focusing on technical aspects and engineering practices. While it touches on leadership and culture, it does not directly address employee engagement, motivation, or commitment among team members, which are the core themes of the category.",
    "level": "Ignored"
  },
  "Psychological Safety": {
    "category": "Psychological Safety",
    "calculated_at": "2025-04-29T14:03:44",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of psychological safety. While it touches on leadership and culture, it does not explore how these relate to creating a psychologically safe environment for team members. The focus is on engineering and operational strategies rather than the emotional and interpersonal aspects of psychological safety.",
    "level": "Ignored"
  },
  "Value Stream Mapping": {
    "category": "Value Stream Mapping",
    "calculated_at": "2025-04-29T14:03:47",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of Value Stream Mapping or its principles. While there are themes of optimisation and efficiency, they are not explicitly tied to VSM or Lean methodologies. The discussion lacks depth on VSM-related topics, making it largely irrelevant to the category.",
    "level": "Ignored"
  },
  "Working Agreements": {
    "category": "Working Agreements",
    "calculated_at": "2025-04-29T14:03:49",
    "ai_confidence": 10.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 10.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of working agreements or teamwork principles. While it touches on leadership and culture, it does not align with the core themes of working agreements, such as collaboration norms or communication protocols. The discussion lacks depth regarding any structured approach to teamwork, resulting in a very low confidence score for this category.",
    "level": "Ignored"
  },
  "Software Development": {
    "category": "Software Development",
    "calculated_at": "2025-04-29T14:03:52",
    "ai_confidence": 62.0,
    "ai_mentions": 2,
    "ai_alignment": 75.0,
    "ai_depth": 55.0,
    "non_ai_confidence": 0,
    "final_score": 62.0,
    "reasoning": "The content discusses the importance of resilience in system design, which aligns with software architecture principles. It mentions engineering practices and the need for testing under real-world conditions, which are relevant to software development. However, the focus is more on organisational failures and resilience rather than specific software development methodologies or practices, leading to a moderate confidence score.",
    "level": "Secondary"
  },
  "Backlog Refinement": {
    "category": "Backlog Refinement",
    "calculated_at": "2025-04-29T14:03:55",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of backlog refinement or Agile practices. While it touches on themes of operational readiness and iterative improvement, these concepts are not specifically related to backlog refinement or its techniques, making the alignment and depth very low.",
    "level": "Ignored"
  },
  "Time to Market": {
    "category": "Time to Market",
    "calculated_at": "2025-04-29T14:03:59",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 10,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses resilience in systems and the failures of organisations to maintain operational stability. While it touches on the importance of testing and iterating systems, it does not explicitly address Time to Market or its associated metrics, nor does it explore strategies for improving the speed of delivering value to customers. The focus is more on engineering and organisational culture rather than the efficiency of transforming ideas into market-ready products.",
    "level": "Ignored"
  },
  "Continuous Integration": {
    "category": "Continuous Integration",
    "calculated_at": "2025-04-29T14:04:02",
    "ai_confidence": 10.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 10.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures rather than Continuous Integration practices. While it touches on the importance of testing and engineering for failure, it does not explicitly mention CI principles, tools, or practices, nor does it focus on code integration or automated testing in the context of CI.",
    "level": "Ignored"
  },
  "Forecasting": {
    "category": "Forecasting",
    "calculated_at": "2025-04-29T14:04:05",
    "ai_confidence": 10.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 10.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of forecasting methodologies or practices within Agile and Scrum frameworks. While it touches on the importance of anticipating failures, it does not align with the core themes of forecasting, such as predicting delivery timelines or utilising empirical data for decision-making. The discussion lacks depth in any forecasting-related context, making it largely irrelevant to the category.",
    "level": "Ignored"
  },
  "Personal": {
    "category": "Personal",
    "calculated_at": "2025-04-29T14:04:08",
    "ai_confidence": 45.0,
    "ai_mentions": 5,
    "ai_alignment": 30,
    "ai_depth": 40,
    "non_ai_confidence": 0,
    "final_score": 45.0,
    "reasoning": "The content includes personal anecdotes, particularly the author's experiences at Merrill Lynch, which aligns with the Personal category. However, the primary focus is on technical discussions about resilience and system failures rather than personal reflections on Agile or Scrum methodologies. While there are mentions of personal experiences, they are not the central theme, leading to a moderate confidence score.",
    "level": "Tertiary"
  },
  "Mentoring": {
    "category": "Mentoring",
    "calculated_at": "2025-04-29T14:04:11",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the concept of resilience in systems and organisations, focusing on engineering and operational strategies rather than mentoring or coaching in Agile environments. While it touches on leadership failures, it does not provide guidance or techniques relevant to mentoring, coaching, or developing skills in Agile practices.",
    "level": "Ignored"
  },
  "Azure Repos": {
    "category": "Azure Repos",
    "calculated_at": "2025-04-29T14:04:14",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 5.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of Azure Repos or its functionalities. While it touches on themes relevant to software development, it does not align with the specific focus on Azure Repos, source control management, or related best practices.",
    "level": "Ignored"
  },
  "Project Management": {
    "category": "Project Management",
    "calculated_at": "2025-04-29T14:04:18",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses resilience in systems and organisational failures, which touches on aspects of project management, particularly in terms of risk management and operational strategy. However, it lacks direct mentions of project management methodologies, lifecycle phases, or specific tools and techniques. The focus is more on engineering and organisational culture rather than the broader principles and practices of project management.",
    "level": "Ignored"
  },
  "System Configuration": {
    "category": "System Configuration",
    "calculated_at": "2025-04-29T14:04:23",
    "ai_confidence": 32.0,
    "ai_mentions": 5,
    "ai_alignment": 25,
    "ai_depth": 20,
    "non_ai_confidence": 10,
    "final_score": 32.0,
    "reasoning": "The content discusses resilience in systems, which is tangentially related to system configuration, particularly in the context of ensuring systems are designed to handle failures. However, it primarily focuses on the philosophical and organisational aspects of resilience rather than specific configuration practices or tools. While there are mentions of system failures and the need for robust design, the depth of discussion does not delve into configuration management tools or best practices, leading to a lower confidence score in the category of System Configuration.",
    "level": "Ignored"
  },
  "Beta Codex": {
    "category": "Beta Codex",
    "calculated_at": "2025-04-29T14:04:26",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, focusing on engineering and operational practices rather than the principles of Beta Codex. While it touches on leadership and culture, it does not explicitly mention decentralisation or human-centric approaches, which are core to Beta Codex. The discussion lacks depth in terms of adaptive organisational cultures and does not provide case studies or comparisons relevant to Beta Codex, leading to a low confidence score.",
    "level": "Ignored"
  },
  "Product Owner": {
    "category": "Product Owner",
    "calculated_at": "2025-04-29T14:04:29",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 15.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 10,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of the Product Owner role or its accountability. While it touches on product leadership and decision-making, it does not align closely with the core themes of the Product Owner's accountability within Scrum. The depth of discussion regarding the Product Owner's responsibilities is minimal, leading to a low confidence score.",
    "level": "Ignored"
  },
  "Definition of Ready": {
    "category": "Definition of Ready",
    "calculated_at": "2025-04-29T14:04:32",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 10,
    "final_score": 5.0,
    "reasoning": "The content focuses on resilience in systems and organisational failures, with no direct mention of the Definition of Ready or its criteria. While it discusses the importance of preparedness and testing, it does not align with the specific themes of backlog item readiness or Agile practices. The discussion is primarily about engineering and operational resilience, which is outside the scope of the Definition of Ready.",
    "level": "Ignored"
  },
  "Unrealised Value": {
    "category": "Unrealised Value",
    "calculated_at": "2025-04-29T14:04:35",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses the concept of resilience in systems and organisations, focusing on failures and the need for robust engineering practices. While it touches on the importance of operational survivability, it does not explicitly mention or explore the concept of Unrealised Value or its indicators, strategies, or frameworks. The discussion is more centred on the consequences of poor design and leadership rather than identifying untapped opportunities for value creation, which is the core focus of the Unrealised Value category.",
    "level": "Ignored"
  },
  "Release Management": {
    "category": "Release Management",
    "calculated_at": "2025-04-29T14:04:38",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 30.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 25.0,
    "reasoning": "The content discusses resilience in systems and the importance of engineering for failure, but it does not explicitly mention release management or related practices. While it touches on themes of operational strategy and organisational culture, it lacks a direct focus on the planning, scheduling, and controlling of software releases, which are central to release management. The discussion is more about system resilience and organisational failures rather than the specific processes involved in managing software releases.",
    "level": "Ignored"
  },
  "Cycle Time": {
    "category": "Cycle Time",
    "calculated_at": "2025-04-29T14:04:41",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of Cycle Time or its measurement. While it touches on themes of operational efficiency and the consequences of poor engineering, it does not align with the core topics of Cycle Time, such as its definition, measurement methods, or strategies for improvement. The discussion is more focused on resilience and disaster recovery rather than the specific metric of Cycle Time.",
    "level": "Ignored"
  },
  "Technical Mastery": {
    "category": "Technical Mastery",
    "calculated_at": "2025-04-29T14:04:45",
    "ai_confidence": 85.0,
    "ai_mentions": 15,
    "ai_alignment": 35,
    "ai_depth": 30,
    "non_ai_confidence": 0,
    "final_score": 85.0,
    "reasoning": "The content discusses the importance of resilience in system design, emphasising engineering practices that prevent catastrophic failures. It directly addresses principles of software craftsmanship by highlighting the need for systems to be designed with failure in mind, which aligns with best practices in software architecture. The depth of discussion is significant, as it provides real-world examples and insights into organisational failures and successes, demonstrating a strong understanding of the technical aspects of resilience. However, while it touches on technical mastery, it also delves into organisational culture and leadership, which slightly detracts from its primary focus on technical practices.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the category, as it thoroughly explores resilience in system design and highlights key engineering practices that prevent failures. While it also touches on organisational culture and leadership, the main emphasis remains on technical principles and real-world examples, demonstrating a solid grasp of software craftsmanship and best practices in architecture."
  },
  "Continuous Improvement": {
    "category": "Continuous Improvement",
    "calculated_at": "2025-04-29T14:04:49",
    "ai_confidence": 78.0,
    "ai_mentions": 2,
    "ai_alignment": 35,
    "ai_depth": 30,
    "non_ai_confidence": 0,
    "final_score": 78.0,
    "reasoning": "The content discusses the importance of resilience in systems and organisations, highlighting the need for continuous testing and iteration to build true resilience. It mentions the concept of learning from failures and adapting processes, which aligns with the principles of Continuous Improvement. However, while it touches on these themes, the primary focus is more on resilience and operational effectiveness rather than a dedicated discussion on Continuous Improvement practices. The depth of discussion on resilience and the examples provided contribute to a strong alignment, but the lack of explicit focus on Continuous Improvement as a standalone topic slightly lowers the confidence score.",
    "level": "Secondary",
    "reasoning_summary": "This content mainly explores resilience in systems and organisations, emphasising ongoing testing, learning from failures, and adapting processes. While these ideas overlap with Continuous Improvement, the main emphasis is on resilience rather than a direct, in-depth discussion of Continuous Improvement methods, making the fit partial but not complete."
  },
  "Complexity Thinking": {
    "category": "Complexity Thinking",
    "calculated_at": "2025-04-29T14:04:53",
    "ai_confidence": 72.0,
    "ai_mentions": 15,
    "ai_alignment": 30,
    "ai_depth": 25,
    "non_ai_confidence": 10,
    "final_score": 72.0,
    "reasoning": "The content discusses the concept of resilience in systems, which aligns with complexity thinking by addressing the non-linear dynamics and emergent behaviours in complex adaptive systems. It highlights the importance of understanding failure and the need for organisations to adapt and learn from it, which resonates with the principles of complexity science. However, while it touches on these themes, it does not explicitly reference complexity frameworks or theories, leading to a slightly lower confidence score in terms of direct mentions and depth of discussion.",
    "level": "Secondary",
    "reasoning_summary": "This content is relevant to the category as it explores resilience within systems, a key aspect of complexity thinking. It addresses how organisations adapt to failure and highlights emergent behaviours typical of complex adaptive systems. However, it doesn’t directly reference specific complexity frameworks or theories, which slightly limits its alignment with the category’s core concepts."
  },
  "Value Delivery": {
    "category": "Value Delivery",
    "calculated_at": "2025-04-29T14:04:55",
    "ai_confidence": 32.0,
    "ai_mentions": 10.0,
    "ai_alignment": 40.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses resilience in systems and the importance of engineering for failure, which indirectly relates to value delivery by emphasising the need for reliable systems that enhance customer satisfaction. However, it lacks direct mentions of Agile, Scrum, or DevOps methodologies, and does not focus on iterative development or customer feedback mechanisms, which are core to the Value Delivery category.",
    "level": "Ignored"
  },
  "Experimentation": {
    "category": "Experimentation",
    "calculated_at": "2025-04-29T14:04:59",
    "ai_confidence": 32.0,
    "ai_mentions": 2,
    "ai_alignment": 35.0,
    "ai_depth": 25.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses resilience and the importance of testing systems under real-world conditions, which aligns with the concept of experimentation. However, it primarily focuses on failures and organisational culture rather than a structured hypothesis-driven approach to experimentation in Agile workflows. The mentions of testing and iterating over failures are relevant but do not constitute a primary focus on experimentation as defined in the category. The depth of discussion on experimentation techniques is limited, leading to a lower confidence score.",
    "level": "Ignored"
  },
  "Azure Boards": {
    "category": "Azure Boards",
    "calculated_at": "2025-04-29T14:05:03",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content does not mention Azure Boards or any related concepts. It focuses on resilience in systems and organisational failures, which are unrelated to Azure Boards or Agile project management. There is no discussion of work items, planning processes, or team collaboration, which are key themes of the Azure Boards category.",
    "level": "Ignored"
  },
  "Revenue per Employee": {
    "category": "Revenue per Employee",
    "calculated_at": "2025-04-29T14:05:06",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of Revenue per Employee or its implications. While it touches on organisational effectiveness, it does not provide empirical data or analysis related to workforce efficiency or financial performance metrics, which are central to the category of Revenue per Employee.",
    "level": "Ignored"
  },
  "Modern Source Control": {
    "category": "Modern Source Control",
    "calculated_at": "2025-04-29T14:05:08",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of version control practices or related methodologies. While it touches on the importance of engineering and operational strategies, it does not align with the core themes of modern source control, such as version control systems, branching strategies, or collaboration workflows.",
    "level": "Ignored"
  },
  "Working Software": {
    "category": "Working Software",
    "calculated_at": "2025-04-29T14:05:11",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 15.0,
    "reasoning": "The content discusses resilience in systems and the failures of various organisations, but it does not focus on working software as an output artifact. While it touches on the importance of engineering and testing, it lacks direct references to working software, Agile practices, or the delivery of usable software increments. The discussion is more about organisational failures and resilience rather than the creation or maintenance of working software.",
    "level": "Ignored"
  },
  "Scrum Team": {
    "category": "Scrum Team",
    "calculated_at": "2025-04-29T14:05:15",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 5.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of Scrum Teams or their roles. While it touches on themes of accountability and leadership, these are not specific to the Scrum framework or its team structure. The focus is on engineering and operational resilience rather than the responsibilities and dynamics of a Scrum Team.",
    "level": "Ignored"
  },
  "Common Goals": {
    "category": "Common Goals",
    "calculated_at": "2025-04-29T14:05:17",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses the concept of resilience in systems and organisations, focusing on engineering failures and operational challenges. While it touches on leadership and organisational culture, it does not explicitly mention or align with the principles of Common Goals in Agile or DevOps. The discussion lacks a clear connection to shared objectives or strategic alignment, which are central to the Common Goals category. Therefore, the confidence score reflects minimal relevance to the category.",
    "level": "Ignored"
  },
  "Open Space Agile": {
    "category": "Open Space Agile",
    "calculated_at": "2025-04-29T14:05:22",
    "ai_confidence": 10.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 10.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of Open Space Agile principles or practices. While it touches on themes of organisational culture and leadership, which could relate to Agile transformation, it does not align with the core concepts of Open Space Agile, such as collective participation or psychological safety. The depth of discussion is focused on engineering and operational resilience rather than collaborative change processes, leading to a very low confidence score.",
    "level": "Ignored"
  },
  "Continuous Learning": {
    "category": "Continuous Learning",
    "calculated_at": "2025-04-29T14:05:25",
    "ai_confidence": 32.0,
    "ai_mentions": 10.0,
    "ai_alignment": 40.0,
    "ai_depth": 50.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses resilience and the importance of learning from failures, which aligns with the principles of Continuous Learning. However, it primarily focuses on engineering and operational failures rather than team dynamics or knowledge sharing. While it touches on the need for iterative testing and learning from pain, it lacks a direct emphasis on fostering a growth mindset or effective knowledge sharing within teams, which are key aspects of the Continuous Learning category.",
    "level": "Ignored"
  },
  "Asynchronous Development": {
    "category": "Asynchronous Development",
    "calculated_at": "2025-04-29T14:05:28",
    "ai_confidence": 5.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 5.0,
    "reasoning": "The content primarily discusses resilience in systems and organisational failures, with no direct mention of asynchronous development or its principles. While it touches on themes of operational effectiveness and team dynamics, it does not align with the core topics of asynchronous collaboration or remote teamwork. The focus is on engineering and disaster recovery rather than asynchronous methodologies.",
    "level": "Ignored"
  },
  "Organisational Agility": {
    "category": "Organisational Agility",
    "calculated_at": "2025-04-29T14:05:32",
    "ai_confidence": 55.0,
    "ai_mentions": 2,
    "ai_alignment": 60.0,
    "ai_depth": 50.0,
    "non_ai_confidence": 10,
    "final_score": 55.0,
    "reasoning": "The content discusses the importance of resilience in organisational systems and highlights the need for a cultural shift towards operational survivability. It mentions leadership's role in fostering a culture that prioritises resilience, which aligns with the principles of organisational agility. However, the primary focus is on resilience rather than agility itself, and while it touches on related themes, it does not delve deeply into agile methodologies or practices. The discussion is somewhat relevant but lacks comprehensive exploration of agility as defined in the category.",
    "level": "Tertiary"
  },
  "Flow Efficiency": {
    "category": "Flow Efficiency",
    "calculated_at": "2025-04-29T14:05:35",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 15.0,
    "reasoning": "The content primarily discusses resilience in systems and the consequences of poor engineering practices, rather than focusing on flow efficiency or optimising work throughput. While it touches on the importance of testing and iterating systems, it does not directly address flow efficiency principles, techniques for eliminating bottlenecks, or metrics related to flow efficiency. The discussion is more aligned with organisational failures and resilience rather than the optimisation of work across a value stream.",
    "level": "Ignored"
  },
  "Hypothesis Driven Development": {
    "category": "Hypothesis Driven Development",
    "calculated_at": "2025-04-29T14:05:38",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 10.0,
    "non_ai_confidence": 0,
    "final_score": 15.0,
    "reasoning": "The content discusses resilience in systems and the importance of testing and iterating on product capabilities, but it does not explicitly mention hypothesis formulation or experimentation. While there are elements of learning from failures, the focus is more on engineering and operational strategies rather than on hypothesis-driven development principles.",
    "level": "Ignored"
  },
  "Pragmatic Thinking": {
    "category": "Pragmatic Thinking",
    "calculated_at": "2025-04-29T14:05:42",
    "ai_confidence": 82.0,
    "ai_mentions": 15,
    "ai_alignment": 32,
    "ai_depth": 30,
    "non_ai_confidence": 10,
    "final_score": 82.0,
    "reasoning": "The content discusses the importance of resilience in systems, emphasising practical problem-solving strategies and real-world applications of resilience principles. It provides detailed examples of failures due to poor engineering and organisational blindness, aligning well with the core themes of pragmatic thinking. The depth of discussion is significant, as it explores the necessity of testing systems under real conditions and iterating over failures to build resilience, which is a practical approach to navigating complexity in project management. However, while it touches on Agile and DevOps indirectly, it does not explicitly mention these frameworks, which slightly lowers the confidence score.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the category, as it explores resilience through practical examples and real-world problem-solving, highlighting the value of learning from failures. Its focus on iterative improvement and system testing aligns with pragmatic approaches to complexity. While it doesn’t directly reference Agile or DevOps, its emphasis on practical application and organisational learning supports its relevance."
  },
  "Entrepreneurship": {
    "category": "Entrepreneurship",
    "calculated_at": "2025-04-29T14:05:45",
    "ai_confidence": 32.0,
    "ai_mentions": 2,
    "ai_alignment": 25.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses resilience in systems and organisations, which is tangentially related to entrepreneurship through the lens of innovation and risk management. However, it primarily focuses on engineering and operational failures rather than the entrepreneurial mindset or strategies for creating and sustaining ventures. The mentions of leadership and organisational culture touch on aspects relevant to entrepreneurship, but the overall depth and focus are more aligned with operational management than entrepreneurial principles.",
    "level": "Ignored"
  },
  "Shift Left Strategy": {
    "category": "Shift Left Strategy",
    "calculated_at": "2025-04-29T14:05:48",
    "ai_confidence": 15.0,
    "ai_mentions": 10.0,
    "ai_alignment": 10.0,
    "ai_depth": 20.0,
    "non_ai_confidence": 0,
    "final_score": 15.0,
    "reasoning": "The content discusses resilience in systems and the importance of testing and verifying under real-world conditions, which aligns with some principles of the Shift-Left Strategy. However, it primarily focuses on resilience and organisational failures rather than explicitly addressing the integration of testing, security, and compliance early in the software development lifecycle. The mention of testing is too vague and does not delve into specific Shift-Left practices or methodologies, leading to a low confidence score.",
    "level": "Ignored"
  },
  "Test Automation": {
    "category": "Test Automation",
    "calculated_at": "2025-04-29T14:05:51",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content discusses resilience in systems and the importance of testing under real-world conditions, but it does not explicitly mention test automation or its principles, practices, or tools. While there are references to testing and failure, they are not focused on the automation aspect, which is central to the Test Automation category.",
    "level": "Ignored"
  },
  "Decision Making": {
    "category": "Decision Making",
    "calculated_at": "2025-04-29T14:05:54",
    "ai_confidence": 32.0,
    "ai_mentions": 5,
    "ai_alignment": 20,
    "ai_depth": 15,
    "non_ai_confidence": 0,
    "final_score": 32.0,
    "reasoning": "The content discusses resilience in systems and the failures of organisations to adequately prepare for and respond to crises. While it touches on decision-making aspects, such as the need for leadership to ask critical questions about risk and recovery, it primarily focuses on the consequences of poor engineering and organisational culture rather than structured, evidence-based decision-making methodologies. The mention of decision-making is not the primary focus, and the depth of discussion on decision-making frameworks is limited.",
    "level": "Ignored"
  },
  "Customer Retention": {
    "category": "Customer Retention",
    "calculated_at": "2025-04-29T14:05:58",
    "ai_confidence": 12.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": 0,
    "final_score": 12.0,
    "reasoning": "The content primarily discusses the concept of resilience in systems and organisations, focusing on engineering failures and disaster recovery. While there are implications for customer experience in terms of service reliability, the content does not explicitly address customer retention strategies, user engagement, or methodologies aimed at minimising churn. The discussion lacks direct mentions of customer satisfaction, feedback mechanisms, or personalisation, which are critical to the Customer Retention category.",
    "level": "Ignored"
  },
  "Principle": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Principle",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 64.0,
    "ai_mentions": 14,
    "ai_alignment": 50.0,
    "ai_depth": 70.0,
    "non_ai_confidence": null,
    "final_score": 64.0,
    "reasoning": "The content discusses resilience as a principle in systems design and organizational culture, specifically emphasizing how resilience should be engineered and tested under real-world conditions rather than treated as a theoretical exercise. There are direct mentions of the principles surrounding resilience, such as the importance of assuming failure, cultivating a culture of operational survivability, and the necessity for continuous testing and iteration. However, it is not solely focused on the categories discussed like Agile or Lean methods, which slightly detracts from the alignment with those frameworks. The depth of discussion on specific resilience principles is considerable, providing concrete examples and lessons learned from failures and successes in organizations.",
    "level": "Secondary"
  },
  "Tool": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Tool",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 25.0,
    "ai_mentions": 10.0,
    "ai_alignment": 20.0,
    "ai_depth": 30.0,
    "non_ai_confidence": null,
    "final_score": 25.0,
    "reasoning": "The content discusses systems engineering and resilience but does not focus on specific tools or practices that align with Agile, Lean, or DevOps frameworks. While it touches on concepts like testing and disaster recovery, it does not provide detailed information or practical applications related to specific tools that facilitate these processes.",
    "level": "Ignored"
  },
  "Accountability": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Accountability",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 32.0,
    "ai_mentions": 10.0,
    "ai_alignment": 40.0,
    "ai_depth": 40.0,
    "non_ai_confidence": null,
    "final_score": 32.0,
    "reasoning": "The content primarily discusses resilience in systems and organizational failures without a strong focus on accountability as defined in the category. While it touches on leadership failures and the need for ownership in terms of system design and disaster recovery, it lacks explicit discussions around clearly defined roles, structural accountabilities in teams, or outcome ownership. The mention of leadership and systemic failures indicates a tangential relationship to accountability, but it is not the core focus, resulting in a lower confidence score.",
    "level": "Ignored"
  },
  "Philosophy": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Philosophy",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 45.0,
    "ai_mentions": 5,
    "ai_alignment": 30,
    "ai_depth": 50,
    "non_ai_confidence": null,
    "final_score": 45.0,
    "reasoning": "The content discusses resilience in systems and the philosophical implications of design choices and organizational culture affecting operational reliability. While it touches upon important themes such as leadership, culture, and decision-making that resonate with philosophical underpinnings, the focus is more on practical failures and specific cases rather than on a theoretical exploration of philosophical principles. The analysis provided gives insights into the organizational approach to resilience and failure, hinting at deeper philosophical beliefs, but it does not delve into the foundational beliefs themselves or their broader implications in organizational dynamics.",
    "level": "Tertiary"
  },
  "Discipline": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Discipline",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 65.0,
    "ai_mentions": 2,
    "ai_alignment": 70.0,
    "ai_depth": 60.0,
    "non_ai_confidence": null,
    "final_score": 65.0,
    "reasoning": "The content discusses resilience in systems engineering and operations management, emphasizing the need for discipline in creating resilient architectures. It explicitly mentions the importance of structured approaches to testing and iterating on systems, which aligns with the idea of discipline as a systematic application of principles. However, the conversation is more focused on resilience and operational failures than on a comprehensive exploration of the discipline itself, leading to a slightly lower score. The content provides specific examples and cases but mainly revolves around the challenges of fragility rather than a deep theoretical exploration of discipline in the broader context. This results in a somewhat strong but not entirely aligned confidence score.",
    "level": "Secondary"
  },
  "Artifact": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Artifact",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 15.0,
    "non_ai_confidence": null,
    "final_score": 25.0,
    "reasoning": "The content strongly discusses the concepts of resilience and failure in systems design, touching on product capabilities and organisational failures. However, it does not explicitly reference any specific artifacts as formal representations of work, such as Agile or Scrum artifacts. The focus is more on broader engineering and organizational philosophies rather than on the structure, purpose, or role of defined artifacts within Agile, Lean, or DevOps frameworks.",
    "level": "Ignored"
  },
  "Observability": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Observability",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 65.0,
    "ai_mentions": 60.0,
    "ai_alignment": 70.0,
    "ai_depth": 60.0,
    "non_ai_confidence": null,
    "final_score": 65.0,
    "reasoning": "The content discusses resilience in systems, which indirectly touches upon concepts related to observability, such as the need for systems to be tested under real conditions and the importance of understanding internal states to ensure resilience. However, observability is not the main focus; instead, the primary theme revolves around resilience and the organizational failures that lead to system fragility. There are mentions of the lack of 'meaningful observability' in the context of failures but not a detailed exploration of observability metrics, tools, or best practices. Overall, it aligns with observability principles but lacks depth in focusing on observability specifically.",
    "level": "Secondary"
  },
  "Practice": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Practice",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 20.0,
    "ai_depth": 30.0,
    "non_ai_confidence": null,
    "final_score": 25.0,
    "reasoning": "The content discusses resilience in systems and the importance of engineering for failure, but it does not focus on practical, repeatable actions or methods that teams can adopt to improve their effectiveness. There are implications of iterative practices and testing, but they are not explicitly presented as actionable techniques. The primary focus is on the consequences of poor practices and organizational culture rather than concrete practices themselves.",
    "level": "Ignored"
  },
  "Method": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Method",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 32.0,
    "ai_mentions": 10.0,
    "ai_alignment": 35.0,
    "ai_depth": 25.0,
    "non_ai_confidence": null,
    "final_score": 32.0,
    "reasoning": "The content discusses resilience and the failures of various systems but does not explicitly present a structured step-by-step method for achieving resilience. It mentions the need for discipline and testing under real conditions, which aligns with the concept of methods but lacks detailed procedural discussions typical of the category. The focus is more on the importance of resilience rather than specific methods to achieve it, leading to a lower overall confidence score.",
    "level": "Ignored"
  },
  "Strategy": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Strategy",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 62.0,
    "ai_mentions": 3,
    "ai_alignment": 35,
    "ai_depth": 25,
    "non_ai_confidence": null,
    "final_score": 62.0,
    "reasoning": "While the content discusses resilience in systems and the need for strategic planning related to operational survivability, it primarily focuses on examples of failure rather than providing a concrete strategy for aligning systems with organizational goals. The direct mentions of strategy and operational strategy indicate relevance, but the depth of discussion shifts heavily towards operational failures and examples rather than a high-level strategic analysis. Therefore, it falls short of a strong alignment with strategic discussions as defined.",
    "level": "Secondary"
  },
  "Model": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Model",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 25.0,
    "ai_mentions": 2,
    "ai_alignment": 20.0,
    "ai_depth": 30.0,
    "non_ai_confidence": null,
    "final_score": 25.0,
    "reasoning": "Although the content discusses the concept of resilience, it primarily focuses on failures and the need for better engineering rather than on models or frameworks. It briefly mentions elements related to operational strategy, but these are not presented as models to inform decision-making in Agile or Lean contexts. The depth of discussion revolves around case studies and examples rather than a conceptual model. Thus, the alignment with the category 'Model' is weak, but there is some mention of principles relevant to organizational resilience.",
    "level": "Ignored"
  },
  "Framework": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Framework",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 15.0,
    "ai_mentions": 0,
    "ai_alignment": 10.0,
    "ai_depth": 25.0,
    "non_ai_confidence": null,
    "final_score": 15.0,
    "reasoning": "The content discusses resilience in systems and organisations but does not explicitly focus on structured methodologies or frameworks related to Agile, DevOps, or Lean principles. It touches on themes of operational resilience and failure but lacks reference to specific frameworks or their implementation strategies, making the discussion only tangentially related to the Framework category.",
    "level": "Ignored"
  },
  "Tenet": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Tenet",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 25.0,
    "ai_mentions": 0,
    "ai_alignment": 40.0,
    "ai_depth": 20.0,
    "non_ai_confidence": null,
    "final_score": 25.0,
    "reasoning": "The content discusses resilience in system design but does not explicitly mention Agile, Lean, or DevOps tenets. While there are actionable insights on building resilience and learning from failures, the focus on resilience as a concept rather than a guiding principle for decision-making and behaviors in Agile or Lean methodologies reduces its alignment with the 'Tenet' category. The depth of discussion is also limited as it doesn't provide specific examples of tenets or how they translate into actionable practices within organizations.",
    "level": "Ignored"
  },
  "Capability": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Capability",
    "calculated_at": "2025-05-01T14:48:27",
    "ai_confidence": 68.0,
    "ai_mentions": 3,
    "ai_alignment": 90.0,
    "ai_depth": 75.0,
    "non_ai_confidence": null,
    "final_score": 68.0,
    "reasoning": "The content discusses the importance of resilience as a product capability and emphasizes that resilience must be built and tested within systems and organizations. It highlights the cultivation of resilience through discipline and intentional practice, aligning well with the themes of capability development and organizational culture. However, while it touches heavily on resilience, it does not explore broader capabilities in Agile or DevOps frameworks or strategies for embedding such capabilities, which slightly limits its depth in the context of the Capability category.",
    "level": "Secondary"
  },
  "Service Level Expectation": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Service Level Expectation",
    "calculated_at": "2025-05-06T20:54:11",
    "ai_confidence": 1.1,
    "ai_mentions": 0.0,
    "ai_alignment": 1.2,
    "ai_depth": 1.5,
    "ai_intent": 1.4,
    "ai_audience": 1.7,
    "ai_signal": 1.6,
    "ai_penalties_applied": true,
    "ai_penalty_points": 1.5,
    "ai_penalty_details": "alignment (-0.5): Discussion of resilience and operational reliability is conceptually adjacent but not aligned with Agile SLE. depth (-0.5): Critiques metrics and fake success but never covers SLE as defined. intent (-0.5): Strongly critical and framed around engineering/leadership failure, weakening purpose fit for SLE.",
    "final_score": 1.0,
    "reasoning": "The content does not reference Service Level Expectation (SLE) directly and does not discuss its definition, calculation, or application within Agile, Scrum, or Kanban. Instead, the focus is on resilience engineering, operational failures, disaster recovery testing, and leadership accountability. While there are mentions of metrics and system restoration timelines, these are not within the SLE framework or terminology, nor do they reference Kanban, Scrum, or Agile flow management. The audience is technical/leadership but not specifically Agile practitioners, and there are no references to SLE authorities or concepts. The discussion is deep, but only with respect to resilience and recovery—not SLE or related Agile predictability tools. Penalties were applied due to the critical tone against certain metric practices (faux resilience) and the complete absence of SLE, even as a contrast. Overall, there is almost no signal that relates to SLE by the provided definition, resulting in a very low confidence score.",
    "level": "Ignored"
  },
  "Ethos": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Ethos",
    "calculated_at": "2025-05-13T21:54:46",
    "ai_confidence": 79.29,
    "ai_mentions": 1.8,
    "ai_alignment": 8.9,
    "ai_depth": 8.4,
    "ai_intent": 9.1,
    "ai_audience": 8.7,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 79.0,
    "reasoning": "The content critiques superficial approaches to resilience in systems, exposing the consequences of lacking genuine, demonstrated resilience. It delves into ethos by contrasting performative compliance with rigorous, system-embedded discipline and conviction. Through grounded examples and detailed analysis, it highlights how true resilience is built on hard-earned, tested beliefs shaping behavior and outcomes—key characteristics of the 'Ethos' category. It targets experienced practitioners and leaders who influence system-level decisions. Direct mentions are low (content doesn't use 'ethos'), but the conceptual fit, treatment depth, and intent score high. Some focus on bad engineering overlaps with practice critique, but the central message is aligned with foundational convictions underlying sustainable system delivery. No penalties applied.",
    "reasoning_summary": "This piece powerfully showcases the difference between performative and authentic resilience, illustrating how deep convictions—ethos—must guide leadership and engineering. While 'ethos' isn’t named directly, the argument thoroughly embodies it, warranting a high confidence score.",
    "level": "Secondary"
  },
  "Customer Focus": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Customer Focus",
    "calculated_at": "2025-05-13T21:54:46",
    "ai_confidence": 36.74,
    "ai_mentions": 0.2,
    "ai_alignment": 3.3,
    "ai_depth": 3.7,
    "ai_intent": 2.8,
    "ai_audience": 2.4,
    "ai_signal": 2.6,
    "ai_penalties_applied": true,
    "ai_penalty_points": 1.7,
    "ai_penalty_details": "alignment (-0.7: customer perspective is heavily implied but not explicit), depth (-0.4: focus is more on engineering process, not customer outcomes), intent (-0.3: main thesis is resilience, not customer value), audience (-0.2: technical/leadership rather than product/customer-centric)",
    "final_score": 37.0,
    "reasoning": "The content focuses on resilience as an engineering and organizational discipline, using examples of critical failures and systemic fragility to argue for rigorous, real-world testing. While there are references to customer impact (e.g., product as liability, keeping customers online), the primary emphasis is on internal practices, survivability, and leadership accountability. Direct articulation of customer needs, feedback loops, or outcome-driven development is lacking. The audience leans technical/operational, and the discussion does not prioritize measurable customer value as defined by the category. Minor penalties are applied for insufficient alignment with 'Customer Focus', lack of actionable practices linking to customer outcomes, and for the intent being resilience-first rather than customer-first.",
    "reasoning_summary": "This content promotes resilience in engineering and leadership, but frames it mainly as system survivability, not delivering measurable customer value. Customer outcomes are only implied, so alignment with 'Customer Focus' is partial and indirect. The emphasis is on internal discipline rather than explicit customer-driven product development.",
    "level": "Ignored"
  },
  "First Principal": {
    "resourceId": "LGGuvRq4g7p",
    "category": "First Principal",
    "calculated_at": "2025-05-13T21:54:48",
    "ai_confidence": 44.2,
    "ai_mentions": 1.1,
    "ai_alignment": 4.6,
    "ai_depth": 4.9,
    "ai_intent": 4.2,
    "ai_audience": 7.1,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 44.0,
    "reasoning": "The content delivers a compelling critique of organizational and engineering failures regarding resilience, mainly in the context of disaster recovery and IT failure. While it emphasizes recurring, 'non-negotiable' testing and cultural discipline as essential for resilience (touching on foundational, immutable constraints), it does not directly identify, explain, or distinguish 'first principles' in Lean, Agile, Scrum, or DevOps. It presents strong opinions and examples about operational rigor and product survivability, but lacks explicit conceptual alignment or deep discussion of first principles as defined. Mentions are indirect; discussion is relevant but more heuristic (e.g., 'If something is hard, do it more'), not framed as foundational principles from canonical theorists or frameworks. Audience and signal are strong; main gaps are in alignment, depth of first principles, and mention frequency.",
    "reasoning_summary": "This content expertly highlights the need for operational rigor in resilience, stressing immutable constraints, but stops short of expressly identifying or dissecting first principles in Lean, Agile, Scrum, or DevOps, limiting its alignment with the category.",
    "level": "Tertiary"
  },
  "Definition of Workflow": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Definition of Workflow",
    "calculated_at": "2025-05-23T22:06:07",
    "ai_confidence": 5.13,
    "ai_mentions": 0.2,
    "ai_alignment": 0.4,
    "ai_depth": 0.6,
    "ai_intent": 0.4,
    "ai_audience": 1.7,
    "ai_signal": 0.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 5.0,
    "reasoning": "The content focuses exclusively on engineering resilience, systemic fragility, and leadership failures in the context of real-world disaster recovery, operational survivability, and robust product design. Nowhere does it mention or reference the Definition of Workflow, Kanban, explicit workflow policies, entry/exit criteria, or WIP limits. The notion of 'workflow' as understood in Kanban/agile is not present, either directly or implicitly. The content does target an audience (technical leaders, product/engineering practitioners) adjacent to workflow discussions, but its depth, discussions, and examples are about resilience engineering and organizational culture, not workflow agreements or policies. Thus, all scoring dimensions are quite low and reflect negligible conceptual or topical overlap.",
    "reasoning_summary": "This content explores engineering resilience and organizational failures, not workflow policies or the Definition of Workflow found in Kanban/agile. It has minimal to zero relevance to the category.",
    "level": "Ignored"
  },
  "Product Developer": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Product Developer",
    "calculated_at": "2025-06-23T09:02:20",
    "ai_confidence": 29.85,
    "ai_mentions": 1.6,
    "ai_alignment": 3.5,
    "ai_depth": 3.7,
    "ai_intent": 2.9,
    "ai_audience": 4.2,
    "ai_signal": 3.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 30.0,
    "reasoning": "The content critiques failures in resilience, engineering, and product thinking, emphasizing that resilience is a product capability and must be engineered and tested. However, it does not discuss the Product Developer role, accountabilities, or behaviors according to modern frameworks. There is a passing reference to 'product leadership,' but the focus is more on organizational and engineering failures, with minimal connection to cross-functional product development roles or collective accountability. The audience is broadly technical/product leaders, not specifically Product Developers. Overall, the themes are only tangentially relevant to the category definition.",
    "reasoning_summary": "While the article highlights the importance of building resilience as a product capability, it does not address the Product Developer role, accountability, or behaviors. Its main focus is on organizational and engineering pitfalls, making its relevance to the Product Developer category limited and mostly indirect.",
    "level": "Ignored"
  },
  "Collective Intelligence": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Collective Intelligence",
    "calculated_at": "2025-06-23T09:01:57",
    "ai_confidence": 13.45,
    "ai_mentions": 0.4,
    "ai_alignment": 2.3,
    "ai_depth": 2.0,
    "ai_intent": 2.7,
    "ai_audience": 3.8,
    "ai_signal": 4.5,
    "ai_penalties_applied": true,
    "ai_penalty_points": 2,
    "ai_penalty_details": "Mentions (−0.5): The content uses a strong critical/satirical tone against poor practices. Alignment (−0.5): Tone is harsh/critical of organizations, undermining the collaborative ethos in the category.",
    "final_score": 13.0,
    "reasoning": "The content focuses on engineering and organizational failures regarding resilience. It critiques shallow approaches and highlights the need for real-world testing and systemic discipline. While there are elements about shared responsibility, all human-AI collaborative or collective intelligence themes are absent. There is no discussion of humans and AI as team members, distributed cognition, or design for human-AI collaboration. The critique is leveled at human organizational flaws, not at the interplay of human and AI capabilities. The intent is to provoke more rigorous human practices, not explore or develop collective intelligence as defined in this category. Some marginal resonance with team-based learning could justify low single-point alignment, but there are no explicit or implicit collective intelligence references.",
    "reasoning_summary": "This content delivers a human-focused critique on organizational resilience failures, offering no discussion of human-AI collaboration or collective intelligence patterns. Its themes do not align with the intended category beyond a distant, superficial resonance regarding team learning.",
    "level": "Ignored"
  },
  "Objective Key Results": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Objective Key Results",
    "calculated_at": "2025-06-23T09:02:04",
    "ai_confidence": 2.5,
    "ai_mentions": 0.0,
    "ai_alignment": 2.1,
    "ai_depth": 3.1,
    "ai_intent": 3.8,
    "ai_audience": 4.5,
    "ai_signal": 4.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "There is no direct mention of OKRs, their principles, or practices. The piece focuses on resilience engineering, disaster recovery, and organizational learning. While it touches themes such as accountability, iterative improvement, and organizational discipline, none are discussed in relation to OKRs as a framework. No OKR terminology, alignment with John Doerr's principles, or outcome-based measurement is present. The content's intent is to advocate for practical, tested resilience rather than outcome-driven goal frameworks. The audience are leaders and engineers interested in operational resilience, not specifically OKR practitioners or strategists.",
    "reasoning_summary": "The content is focused entirely on resilience engineering and organizational discipline, with no reference or conceptual alignment to Objective Key Results or the OKR framework.",
    "level": "Ignored"
  },
  "Agentic Engineering": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Agentic Engineering",
    "calculated_at": "2025-07-23T12:05:37",
    "ai_confidence": 55.75,
    "ai_mentions": 0.4,
    "ai_alignment": 7.3,
    "ai_depth": 7.7,
    "ai_intent": 6.2,
    "ai_audience": 6.1,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 56.0,
    "reasoning": "There are no explicit mentions of 'Agentic Engineering' or its key terminology. The content strongly aligns conceptually with system design choices, proactive resilience engineering, and organisational dynamics around operational survivability, which overlap with agentic principles, especially regarding engineer agency, feedback-driven adaptation, and engineering for resilience. However, specific agentic engineering themes—like maximising both human and AI agency, ethical AI integration, or DevOps-infused craft—are only partially present or inferred, not discussed in detail. The depth is marked by concrete case analyses, cultural critique, and advocacy for rigorous, intentional testing. The purpose supports philosophical engineering principles, but the focus is more on resilience through discipline than on explicit decision-making autonomy for humans or AI systems. The audience seems to be technical leaders and practitioners. Content is highly focused, with little tangential material.",
    "reasoning_summary": "The article robustly critiques fragility in system design and champions disciplined resilience engineering practices, supporting elements of agentic philosophy but lacking explicit references to agentic engineering or AI autonomy. Its conceptual and practical alignment is partial but meaningful to the category.",
    "level": "Tertiary"
  },
  "Agentic Software Delivery": {
    "resourceId": "LGGuvRq4g7p",
    "category": "Agentic Software Delivery",
    "calculated_at": "2025-08-07T06:10:10",
    "ai_confidence": 21.68,
    "ai_mentions": 0.0,
    "ai_alignment": 2.4,
    "ai_depth": 2.1,
    "ai_intent": 2.5,
    "ai_audience": 6.2,
    "ai_signal": 8.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 22.0,
    "reasoning": "The content makes no explicit reference to agentic software delivery or autonomous AI agents. Its core focus is on engineering resilience and organisational failures, not the integration of AI agents, contextual intelligence, or agentic practices. Themes of rigorous real-world testing, system design, and operational discipline are strongly aligned with resilience engineering, but do not extend to the agentic paradigm as defined. No modern engineering practices related to agentic delivery (e.g., CI/CD, governance for agent-human interaction, AI feedback loops) are discussed. The audience is technical and leadership-focused, which somewhat matches, but the substance is outside scope for 'Agentic Software Delivery'. No outdated/contradictory content or penalties found.",
    "reasoning_summary": "The content is about engineering for resilience, not agentic software delivery. It lacks mention of AI agents, contextual intelligence, or agentic integration, so the fit for this category is minimal.",
    "level": "Ignored"
  },
  "Product Operating Model": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Product Operating Model",
    "calculated_at": "2025-11-24T18:56:46",
    "ai_confidence": 37.6,
    "ai_mentions": 1.3,
    "ai_alignment": 4.6,
    "ai_depth": 4.8,
    "ai_intent": 4.2,
    "ai_audience": 5.4,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "Direct mentions of 'Product Operating Model' or explicit model structures are absent. The content focuses on resilience as a product capability and criticizes failures stemming from poor product thinking and leadership, but does not substantively discuss frameworks, roles, governance, or structures that define a product operating model. Some alignment exists: discussion implicates leadership, organizational culture, and the consequences of superficial approaches to product and operational resilience, which can tie into operating model considerations. However, there is little depth concerning the actual design, implementation, or governance mechanisms characteristic of product operating models. The primary audience could include organizational leaders and practitioners, but the intent is more about promoting a mindset around resilience than educating on operating models. Signal is decent, as the content is focused, but most detail is about failures and principles, not concrete structures. No outdated references or undermining tone, so no penalties.",
    "reasoning_summary": "The content addresses product resilience and organizational failure, with some indirect links to operating model themes, but lacks explicit discussion on structures or frameworks. Fit is partial and lacks depth on the product operating model topic.",
    "level": "Ignored"
  },
  "Operating Model": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "Operating Model",
    "calculated_at": "2025-11-24T18:56:58",
    "ai_confidence": 36.15,
    "ai_mentions": 1.2,
    "ai_alignment": 3.6,
    "ai_depth": 3.8,
    "ai_intent": 4.1,
    "ai_audience": 4.7,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 36.0,
    "reasoning": "Direct mentions of 'operating model' are entirely absent; the content never names or overtly analyzes operating models, their structure/design, or organizational alignment. The main focus is on system/software resilience, engineering discipline, product thinking, and organizational culture/leadership regarding operational risk and denial. There is some conceptual overlap with operating models in the mention of organizational behaviors and failures at leadership levels, but no explicit connection to the design, structure, or transformation of operating models. Depth is moderate, with thorough case studies and practical examples, but always in the context of engineering resilience and testing, not operating model principles, frameworks, or redesigns. The audience slightly overlaps with operational or leadership roles interested in resilience. Less than half the content would be considered relevant to an Operating Model specialist, as it frames resilience as an outcome of cultural and engineering rigor, not structural design or transformation. This leads to a low confidence score: the fit is partial and mostly indirect.",
    "reasoning_summary": "Content centers on system resilience and organizational denial without discussing operating model design, structure, or transformation. Fit is partial and indirect; the main themes only tangentially touch on operating model concepts.",
    "level": "Ignored"
  },
  "AI Product Operating Model": {
    "resourceId": "LGGuvRq4g7p",
    "itemId": "LGGuvRq4g7p",
    "category": "AI Product Operating Model",
    "calculated_at": "2025-11-24T18:57:01",
    "ai_confidence": 14.25,
    "ai_mentions": 0.0,
    "ai_alignment": 2.2,
    "ai_depth": 2.8,
    "ai_intent": 2.0,
    "ai_audience": 4.6,
    "ai_signal": 3.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on systemic fragility and the need for rigorous, tested resilience in engineered systems, using case studies from energy grids, cloud infrastructure, and airport IT. While it discusses resilience as a product capability and critiques organizational approaches, it does not address AI products or operational models, nor does it reference AI-specific considerations such as data/model governance, MLOps, AI roles, or lifecycle management. The discussion remains general to engineering, product resilience, and organizational culture. There are no explicit or implicit references to AI, machine learning, or how organizations operate AI-driven products; as such, only the most general principles of operational discipline and testing could be distantly mapped to the AI Product Operating Model category, and even that is quite a stretch. Scoring reflects minimal direct or conceptual alignment with the intended category.",
    "reasoning_summary": "Does not fit the AI Product Operating Model category: focused on resilience in general engineered and product systems, lacking any AI context, operating model specifics, or relevant governance/lifecycle topics.",
    "level": "Ignored"
  }
}