{
  "Tool": {
    "resourceId": "Throughput",
    "category": "Tool",
    "calculated_at": "2025-08-07T11:37:17",
    "ai_confidence": 57.69,
    "ai_mentions": 2.7,
    "ai_alignment": 6.4,
    "ai_depth": 5.8,
    "ai_intent": 5.6,
    "ai_audience": 7.2,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 58.0,
    "reasoning": "The content centers on throughput as a metric, describing its relevance to workflow efficiency and system performance in Agile/Lean contexts. 'Tools like cumulative flow diagrams and flow analytics' are mentioned as mechanisms for visualizing throughput, providing some link to the Tool category. However, the explanation primarily focuses on the metric concept itself; discussion of software or implementation tools is brief and non-central. There is moderate alignment and depth, but the main intent is not specifically about tools, resulting in middling scores for direct mention, depth, and intent. The content targets practitioners and is largely relevant, but is not an in-depth discourse on Tool selection, use, or features.",
    "reasoning_summary": "The content mainly explains throughput as a metric, only briefly referencing tools for visualization. It partially fits the Tool category but does not explore tool features, implementation, or integration in depth.",
    "level": "Tertiary"
  },
  "Accountability": {
    "resourceId": "Throughput",
    "category": "Accountability",
    "calculated_at": "2025-08-07T11:37:09",
    "ai_confidence": 25.85,
    "ai_mentions": 0.2,
    "ai_alignment": 2.3,
    "ai_depth": 2.1,
    "ai_intent": 2.7,
    "ai_audience": 9.1,
    "ai_signal": 8.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 26.0,
    "reasoning": "The content focuses on throughput as a delivery and flow metric, emphasizing transparency, empirical inspection, and system-level performance. However, it does not address outcome ownership, role accountabilities, or the structural mechanisms that define accountability in work systems. Direct mentions and conceptual alignment with accountability as a foundational construct are minimal, with no explicit discussion of who owns outcomes or how accountability shapes team behavior. The main audience and signal are relevant but do not compensate for the lack of direct or in-depth treatment of accountability.",
    "reasoning_summary": "This content is about system throughput metrics, not structural or role-based accountability. It lacks discussion of outcome ownership, accountabilities, or their impact, making it a poor fit for the 'Accountability' category.",
    "level": "Ignored"
  },
  "Framework": {
    "resourceId": "Throughput",
    "category": "Framework",
    "calculated_at": "2025-08-07T07:09:53",
    "ai_confidence": 29.2,
    "ai_mentions": 1.1,
    "ai_alignment": 2.7,
    "ai_depth": 2.9,
    "ai_intent": 2.1,
    "ai_audience": 6.6,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 29.0,
    "reasoning": "The content focuses exclusively on throughput as a metric in Agile/Lean contexts. While it references frameworks conceptually (e.g., cumulative flow, work-in-progress limits), it does not directly discuss, compare, or provide guidelines about frameworks themselves. It lacks exploration of framework principles or adaptation strategies, and does not mention any frameworks by name. The audience is relevant (Agile/Lean practitioners), and the content is highly focused, but its main focus—thoroughly describing a metric—falls outside the strict framework definition. Hence, confidence is low.",
    "reasoning_summary": "Content is about throughput as a metric, not frameworks or their adaptation. Lacks direct or in-depth discussion of frameworks. Only tangentially relevant by association with Agile/Lean practices, so fit for 'Framework' is weak.",
    "level": "Ignored"
  },
  "Tenet": {
    "resourceId": "Throughput",
    "category": "Tenet",
    "calculated_at": "2025-08-07T09:28:18",
    "ai_confidence": 72.6,
    "ai_mentions": 3.1,
    "ai_alignment": 8.8,
    "ai_depth": 7.7,
    "ai_intent": 8.3,
    "ai_audience": 7.9,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 73.0,
    "reasoning": "The content explains throughput as a concept and metric within Agile and Lean contexts, focusing on how it enables inspection, feedback, transparency, and continuous improvement. These elements are strongly aligned with tenets (e.g., empirical inspection, feedback loops, flow efficiency). However, the discussion does not explicitly name 'tenet,' nor does it clearly state which guiding rules are derived. Instead, the text focuses on describing throughput’s practical use for process improvement. While its application strongly aligns conceptually with key tenets—especially empirical feedback and continuous improvement—the discussion is more operational than doctrinal. Thus, Direct Mentions are low, but conceptual alignment, intent, and relevance are high overall.",
    "reasoning_summary": "Content explains throughput's role in feedback, empirical inspection, and flow efficiency, concepts core to tenets in Agile/Lean. Lacks explicit 'tenet' framing, but has high alignment with tenet-driven practices. Fit is strong but not absolute.",
    "level": "Secondary"
  },
  "Method": {
    "resourceId": "Throughput",
    "category": "Method",
    "calculated_at": "2025-08-07T06:12:08",
    "ai_confidence": 58.94,
    "ai_mentions": 2.5,
    "ai_alignment": 6.4,
    "ai_depth": 6.7,
    "ai_intent": 7.0,
    "ai_audience": 8.4,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 59.0,
    "reasoning": "The content explains throughput as a metric in Agile/Lean systems, discussing its uses for inspection, improvement, and related tools. While it relates to methods via empirical inspection and workflow adjustments, it does not describe a step-by-step process or detailed method usage. The alignment is partial: throughput supports and informs method adaptation, but is itself a measurement concept rather than a procedural method. The audience and signal-to-noise are high, but direct mentions and depth regarding methodical procedures are moderate. No penalties apply as the content is relevant and current.",
    "reasoning_summary": "Content focuses on throughput as a metric supporting Agile/Lean improvement. It indirectly relates to 'Method' by enabling method adaptation via feedback, but does not detail structured procedures itself. Partial but not strong fit.",
    "level": "Tertiary"
  },
  "Strategy": {
    "resourceId": "Throughput",
    "category": "Strategy",
    "calculated_at": "2025-08-07T09:28:33",
    "ai_confidence": 41.25,
    "ai_mentions": 1.8,
    "ai_alignment": 4.2,
    "ai_depth": 3.9,
    "ai_intent": 4.5,
    "ai_audience": 6.1,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 41.0,
    "reasoning": "The content focuses on the definition, analysis, and application of throughput as a delivery metric. While it mentions decision-making and benefits to flow efficiency, it does not explicitly reference or substantially discuss high-level strategic alignment or planning. The primary intent is operational—teaching how throughput aids process improvement—rather than connecting the metric to overarching business goals or strategic decision-making frameworks. The audience includes practitioners interested in process metrics rather than executive strategists. There are passing references to decision-making and improvement, but not at the enterprise vision or strategic planning level the category requires.",
    "reasoning_summary": "Content centers on throughput as an operational metric; while it touches on decision-making and improvement, it does not align deeply or thoroughly with high-level strategic themes required for the Strategy category.",
    "level": "Tertiary"
  },
  "Practice": {
    "resourceId": "Throughput",
    "category": "Practice",
    "calculated_at": "2025-08-07T07:09:58",
    "ai_confidence": 75.25,
    "ai_mentions": 5.9,
    "ai_alignment": 8.2,
    "ai_depth": 8.6,
    "ai_intent": 7.5,
    "ai_audience": 7.2,
    "ai_signal": 8.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 75.0,
    "reasoning": "The content describes the practice of tracking throughput to enable empirical inspection of a team's delivery process within Agile and Lean contexts. It aligns well with the Practice category by focusing on actionable techniques (tracking, analyzing, using flow diagrams) and continuous improvement. However, the content stops short of providing specific repeatable actions or step-by-step 'how-to' guidance; instead, it describes throughput’s importance and how it supports decision-making. There is no outdated information or negative tone. The audience is practitioners concerned with improvement. Signal is high, as all examples are on topic.",
    "reasoning_summary": "The content fits the Practice category by describing throughput tracking as a technique for process improvement. While not outlining explicit steps, it focuses on actionable team behaviors and applies to practitioners. Partial but solid alignment.",
    "level": "Secondary"
  },
  "Philosophy": {
    "resourceId": "Throughput",
    "category": "Philosophy",
    "calculated_at": "2025-08-07T11:37:09",
    "ai_confidence": 43.84,
    "ai_mentions": 0.6,
    "ai_alignment": 3.2,
    "ai_depth": 3.5,
    "ai_intent": 2.9,
    "ai_audience": 7.1,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 44.0,
    "reasoning": "The content describes throughput as a metric, focusing on measurement, trends, and process improvement, which is procedural and practical. There is a minor nod to transparency and empirical inspection, brushing against philosophical concepts underpinning Agile/Lean, but the main emphasis remains on what throughput is, how it’s tracked, and its practical implications. There is no explicit or in-depth discussion on foundational beliefs, values, or the broader 'why' that motivates the use of throughput; tools and metrics are discussed more than the core philosophy. The intent is informative for practitioners rather than exploring underlying philosophies or cultural shifts.",
    "reasoning_summary": "Content primarily explains the practical use of throughput as a metric, with only light touch on underlying philosophies. Fit with 'Philosophy' is minimal and partial, mainly through brief mention of empirical inspection and transparency.",
    "level": "Tertiary"
  },
  "Observability": {
    "resourceId": "Throughput",
    "category": "Observability",
    "calculated_at": "2025-08-07T09:28:35",
    "ai_confidence": 92.7,
    "ai_mentions": 7.7,
    "ai_alignment": 9.5,
    "ai_depth": 9.2,
    "ai_intent": 9.0,
    "ai_audience": 9.2,
    "ai_signal": 8.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 93.0,
    "reasoning": "The content directly refers to throughput as an 'observability metric' and discusses its role in measuring system performance, tracking flow, and providing actionable insights—all core to the observability concept in Agile/DevOps. It covers tools, data-driven decision-making, and transparency, strongly aligning with the category definition. While the emphasis is on throughput, it explicitly situates the metric within an observability practice and mentions real-time analytics and flow visualization. No penalties, as the content is current, framed supportively, and closely matched to the prescribed audience and scope.",
    "reasoning_summary": "The content fits 'Observability' well by focusing on throughput as a core observability metric, emphasizing system insights, decision-making, and Agile practices. Its theme, intent, and audience alignment are all strong, offering an explicit, relevant discussion.",
    "level": "Primary"
  },
  "Capability": {
    "resourceId": "Throughput",
    "category": "Capability",
    "calculated_at": "2025-08-07T09:28:15",
    "ai_confidence": 38.85,
    "ai_mentions": 0.9,
    "ai_alignment": 4.2,
    "ai_depth": 3.6,
    "ai_intent": 4.5,
    "ai_audience": 5.2,
    "ai_signal": 4.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content describes throughput as a system-level delivery metric supporting inspection and improvement of flow efficiency. However, it focuses on the metric itself and its role in empirical analysis and process improvement, not on the broader cultivation or embedding of capability as a lasting organisational attribute. It does not discuss competencies, cultural embedding, or systemic development but instead illustrates throughput as an indicator or observation tool. Its primary intent is informational around measurement and its use in process adjustment, rather than in building or sustaining capability. No penalties were applied as the content is recent and neutral in tone.",
    "reasoning_summary": "Content centers on throughput as a metric for flow and improvement in Agile/Lean, but does not directly discuss lasting capability-building or embedded competencies; fit to Capability is partial and mostly indirect.",
    "level": "Ignored"
  },
  "Model": {
    "resourceId": "Throughput",
    "category": "Model",
    "calculated_at": "2025-08-07T07:09:58",
    "ai_confidence": 66.7,
    "ai_mentions": 2.3,
    "ai_alignment": 7.6,
    "ai_depth": 6.8,
    "ai_intent": 7.2,
    "ai_audience": 8.7,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 67.0,
    "reasoning": "The content discusses throughput as a delivery metric central to Agile/Lean systems analysis, flow, and improvement. While not named as a 'model,' throughput is explained as a concept to guide decision-making (e.g., adjusting WIP limits, flow analysis). It references metric tools and conceptual use, but does not connect throughput directly as a conceptual 'model' or tie it explicitly to frameworks like Kanban or DevOps models. Discussion is fairly deep and targeted at Agile/Lean practitioners, but explicit modeling language is missing.",
    "reasoning_summary": "The content closely aligns with the 'Model' category by describing throughput as a conceptual tool for analysis and decision-making in Agile/Lean, but lacks explicit framing as a 'model.' Fit is substantial, but not complete.",
    "level": "Secondary"
  },
  "Principle": {
    "resourceId": "Throughput",
    "category": "Principle",
    "calculated_at": "2025-08-07T07:09:57",
    "ai_confidence": 56.4,
    "ai_mentions": 2.3,
    "ai_alignment": 6.2,
    "ai_depth": 5.8,
    "ai_intent": 6.5,
    "ai_audience": 8.9,
    "ai_signal": 8.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 56.0,
    "reasoning": "The content explains throughput primarily as a metric for flow and value delivery. It indirectly references principles of empiricism and continuous improvement via the use of throughput for inspection and adaptation. However, it does not directly discuss principles, instead focusing on practical measurement and technique, with only some linkage to guiding rules underlying Agile/Lean systems. Thus, conceptual alignment exists but is not central, and there is little direct exploration of principles; audience and signal are strong due to technical focus and relevance.",
    "reasoning_summary": "Content focuses on throughput as a metric, referencing empiricism and continuous improvement, but does not directly discuss principles. Fit is partial via implied principle application rather than direct principle discussion.",
    "level": "Tertiary"
  },
  "Artifact": {
    "resourceId": "Throughput",
    "category": "Artifact",
    "calculated_at": "2025-08-07T11:37:09",
    "ai_confidence": 38.1,
    "ai_mentions": 2.2,
    "ai_alignment": 4.7,
    "ai_depth": 4.3,
    "ai_intent": 4.8,
    "ai_audience": 6.1,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content defines and explains throughput as a metric for flow efficiency. While it references empirical inspection and transparency (core to artifacts), it frames throughput as a metric rather than a formal artifact. Discussion is about system measurement, not explicit artifact structures, types, or management. Audience and signal are moderate since this is relevant for Agile/Lean practitioners, but the primary topic is flow analytics and metrics, not artifact representation or use. No penalties applied, as the content is neither outdated nor contradictory.",
    "reasoning_summary": "While throughput helps with inspection and transparency, the content focuses on metrics and flow measurement, not on artifacts as formal work representations. Only a partial fit to the 'Artifact' category.",
    "level": "Ignored"
  },
  "Discipline": {
    "resourceId": "Throughput",
    "category": "Discipline",
    "calculated_at": "2025-09-05T03:31:47",
    "ai_confidence": 46.862,
    "ai_mentions": 1.4,
    "ai_alignment": 5.3,
    "ai_depth": 5.8,
    "ai_intent": 5.0,
    "ai_audience": 8.3,
    "ai_signal": 7.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 47.0,
    "reasoning": "The content explains throughput as a delivery metric and discusses its use in Agile and Lean contexts for continuous improvement and flow analysis. However, it focuses primarily on the metric as a technique/tool, with only brief references to its application within broader disciplines. It does not delve into the established principles, governance, or evolution of Agile/Lean as disciplines. The audience is well-aligned (practitioners/teams), and the tone is appropriate. However, conceptual alignment and depth are partial: the material is relevant but tool-centric, lacking a systemic or disciplinary focus, thus resulting in a mid-level confidence score.",
    "reasoning_summary": "The content is tool-focused, describing throughput’s role in process improvement, with only limited connection to discipline as defined. Fit with the category is partial due to a lack of discussion of systemic principles or the maturation of disciplines.",
    "level": "Tertiary"
  },
  "Lean Principles": {
    "resourceId": "-OIIzYxzBnS",
    "itemId": "-OIIzYxzBnS",
    "category": "Lean Principles",
    "calculated_at": "2025-10-31T18:57:18",
    "ai_confidence": 82.83,
    "ai_mentions": 6.7,
    "ai_alignment": 8.9,
    "ai_depth": 8.4,
    "ai_intent": 8.2,
    "ai_audience": 8.3,
    "ai_signal": 9.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 83.0,
    "reasoning": "The content discusses throughput as a flow metric and ties it to concepts of flow efficiency, constraint identification, and continuous improvement, which are central to Lean Principles. It explicitly mentions this Lean context but does not elaborate on waste reduction or directly name Lean principles. The discussion is moderately deep, providing context, tools, and implications for improvement, with a primary intent that is supportive and informative for a Lean/Agile-oriented audience. There is little off-topic or filler content, keeping a strong signal-to-noise ratio. No penalties apply because there are no outdated concepts, and the tone aligns with Lean's improvement-focused framing.",
    "reasoning_summary": "This content fits the Lean Principles category since throughput and flow are core Lean concerns. The relation is clear but not exhaustive, as other Lean concepts (e.g., waste types, 5S) are not directly addressed. Strong partial fit.",
    "level": "Primary"
  },
  "Market Adaptability": {
    "resourceId": "Throughput",
    "category": "Market Adaptability",
    "calculated_at": "2025-09-17T23:12:59",
    "ai_confidence": 69.67,
    "ai_mentions": 2.1,
    "ai_alignment": 7.4,
    "ai_depth": 7.7,
    "ai_intent": 7.2,
    "ai_audience": 7.8,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 70.0,
    "reasoning": "The content discusses throughput as a metric for measuring delivery in Agile/Lean contexts and its role in enabling flow inspection and continuous improvement. While it addresses tools and principles relevant to market adaptability (e.g., feedback loops, real-time analytics, team adjustments), there are no explicit mentions of 'market adaptability' or direct discussion of how throughput helps organizations respond to market shifts or competitive pressures. The conceptual alignment is moderate because the metric is supportive of adaptability, but the connection is indirect. The discussion is relevant for technical and Agile practitioners and stays focused, but doesn't deeply explore organizational strategies for market responsiveness.",
    "reasoning_summary": "The content aligns moderately with Market Adaptability by covering throughput's role in Agile/Lean improvement, but it does not directly address strategies for responding to market change or pressures. Its fit is partial and mostly supportive, not explicit.",
    "level": "Secondary"
  },
  "Self Organisation": {
    "resourceId": "Throughput",
    "category": "Self Organisation",
    "calculated_at": "2025-10-01T17:10:23",
    "ai_confidence": 36.21,
    "ai_mentions": 0.3,
    "ai_alignment": 3.9,
    "ai_depth": 3.6,
    "ai_intent": 4.7,
    "ai_audience": 7.4,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 36.0,
    "reasoning": "The content focuses on the throughput metric as a flow and delivery measurement tool in Agile and Lean, addressing continuous improvement, transparency, and empirical inspection. However, it does not directly mention self-organisation or principles/practices uniquely tied to it. While throughput can support self-organising teams via transparency and empirical data for decision-making, the article does not explicitly discuss team autonomy, ownership, or mechanisms promoting self-organisation. Depth and alignment are limited by a narrow focus on measurement, not team dynamics.",
    "reasoning_summary": "The article centers on throughput measurement, which can inform aspects of self-organisation but does not explicitly discuss self-organising teams, autonomy, or related principles. Fit with the Self Organisation category is weak and indirect.",
    "level": "Ignored"
  },
  "Remote Working": {
    "resourceId": "Throughput",
    "category": "Remote Working",
    "calculated_at": "2025-10-01T17:11:25",
    "ai_confidence": 9.77,
    "ai_mentions": 0.13,
    "ai_alignment": 0.35,
    "ai_depth": 0.4,
    "ai_intent": 0.15,
    "ai_audience": 7.21,
    "ai_signal": 7.95,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content strictly discusses throughput as a delivery metric and flow visualization tool in Agile/Lean settings, but it does not mention, reference, or explore remote working or distributed team practices. No discussion links throughput to the remote or distributed context, and all techniques and tools described are framed generically, not specific to remote Agile teams. Thus, it fits the interests of Agile practitioners but is not relevant to the remote specifics required by the category.",
    "reasoning_summary": "The content does not address remote work or distributed teams—it solely covers the throughput metric in Agile delivery. There is no alignment with Remote Working topics, so fit is minimal.",
    "level": "Ignored"
  },
  "Social Technologies": {
    "resourceId": "Throughput",
    "category": "Social Technologies",
    "calculated_at": "2025-10-01T16:42:46",
    "ai_confidence": 55.3,
    "ai_mentions": 1.1,
    "ai_alignment": 7.0,
    "ai_depth": 6.2,
    "ai_intent": 8.0,
    "ai_audience": 8.5,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content focuses on throughput, a quantitative metric for delivery, relevant in Agile and Lean contexts. It addresses team decision-making and continuous improvement, which partially align with social technologies. However, it lacks explicit discussion of social frameworks, self-organisation, or collective intelligence. The main aim is metric-based analysis rather than collaboration or emergent problem-solving, resulting in partial conceptual fit. The audience overlaps, but the discussion is mostly technical with occasional linkage to transparency and improvement.",
    "reasoning_summary": "The content touches on themes like decision-making and continuous improvement, but focuses on throughput as a delivery metric rather than discussing social frameworks or collaboration. It partially fits but is not a strong match for Social Technologies.",
    "level": "Tertiary"
  },
  "Customer Satisfaction": {
    "resourceId": "Throughput",
    "category": "Customer Satisfaction",
    "calculated_at": "2025-05-06T11:29:20",
    "ai_confidence": 16.525,
    "ai_mentions": 0.7,
    "ai_alignment": 1.6,
    "ai_depth": 1.9,
    "ai_intent": 1.4,
    "ai_audience": 7.1,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 17.0,
    "reasoning": "The content primarily discusses throughput as a system delivery and flow metric, focusing on how much work is completed per unit of time. While throughput is relevant to operational efficiency in Agile and Lean contexts, the material makes no mention of customer satisfaction, customer experience, or feedback mechanisms tied to measuring or enhancing customer happiness. \n\n1. **Direct Mentions (0.7):** There are no explicit or indirect mentions of 'customer satisfaction,' 'customer happiness,' or related terminology. The focus remains tightly on throughput as a metric for internal team/process optimization.\n2. **Conceptual Alignment (1.6):** The ideas pertain to process performance, system inspection, and delivery efficiency—not customer satisfaction principles or practices. At best, there is a tangential link where better throughput could support improvements in customer satisfaction, but this is neither stated nor implied.\n3. **Depth of Discussion (1.9):** The discussion is thorough about throughput as a metric, including tools and analytics, but provides no substantive exploration of how this connects to customer satisfaction or product-market fit.\n4. **Intent/Purpose Fit (1.4):** The central purpose is to inform about throughput as a delivery/flow metric, not to discuss customer satisfaction or its improvement.\n5. **Audience Alignment (7.1):** The content is targeted at Agile/Lean practitioners or those interested in process metrics, which aligns with one intended audience of the 'Customer Satisfaction' category (e.g., Agile teams). However, it does not address executives or customer success professionals.\n6. **Signal-to-Noise Ratio (7.8):** The content is very focused and well-written for its chosen topic, with little to no irrelevant material. However, its relevance to customer satisfaction is minimal.\n\nNo penalty adjustments are required, as the content is up-to-date and neutral in tone. Given the near absence of references to customer satisfaction—either direct or indirect—the level is 'Tertiary': only the faintest conceptual relationship exists. The final confidence score rightly reflects a very low probability that this content meaningfully fits the 'Customer Satisfaction' category.",
    "level": "Ignored"
  },
  "Change Management": {
    "resourceId": "-OIIzYxzBnS",
    "itemId": "-OIIzYxzBnS",
    "category": "Change Management",
    "calculated_at": "2025-10-31T18:57:16",
    "ai_confidence": 31.616,
    "ai_mentions": 0.7,
    "ai_alignment": 3.8,
    "ai_depth": 3.5,
    "ai_intent": 3.9,
    "ai_audience": 6.1,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 32.0,
    "reasoning": "The content describes throughput as a delivery metric, focusing on flow efficiency and system performance in Agile/Lean contexts. While it mentions that throughput data can inform workflow changes and continuous improvement (adjacent to change management), it never directly addresses strategies, people aspects, stakeholder engagement, leadership, or principles central to change management. The primary focus is operational measurement rather than substantive organizational change or transition. The audience and signal are moderately aligned due to Agile context, but the content remains largely metrics-focused and only indirectly connects to change management concepts.",
    "reasoning_summary": "This content is centered on throughput as a metric for workflow inspection, not on strategies or principles of change management. Any fit is incidental and limited to its use in informing process improvements, making category alignment weak and partial.",
    "level": "Ignored"
  },
  "Empirical Process Control": {
    "resourceId": "Throughput",
    "category": "Empirical Process Control",
    "calculated_at": "2025-10-01T17:10:32",
    "ai_confidence": 77.6,
    "ai_mentions": 5.3,
    "ai_alignment": 8.0,
    "ai_depth": 7.6,
    "ai_intent": 8.1,
    "ai_audience": 7.8,
    "ai_signal": 7.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 78.0,
    "reasoning": "Direct mentions of 'empirical inspection' and references to inspection, transparency, and adaptation strongly align with Empirical Process Control, even though the term itself is only partially referenced. The focus is on inspection via throughput, continuous improvement, and supporting Agile/Lean principles rather than solely describing throughput as a metric. There is substantial discussion of how throughput enables evidence-based adaptations, fitting squarely within the category definition. The content targets practitioners interested in empirical Agile practices. No penalty for outdatedness, tone, or contradiction.",
    "reasoning_summary": "The content closely fits Empirical Process Control by emphasizing inspection, evidence-based adaptation, and transparency through throughput metrics in Agile/Lean contexts. It is mostly focused, but explicit terminology use could be deeper.",
    "level": "Secondary"
  },
  "Transparency": {
    "resourceId": "Throughput",
    "category": "Transparency",
    "calculated_at": "2025-10-01T17:11:20",
    "ai_confidence": 57.55,
    "ai_mentions": 2.2,
    "ai_alignment": 6.9,
    "ai_depth": 6.4,
    "ai_intent": 6.8,
    "ai_audience": 7.2,
    "ai_signal": 6.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 58.0,
    "reasoning": "The content discusses throughput as a metric for system delivery, focusing mainly on observability and empirical inspection. It tangentially touches on transparency—stating throughput supports transparency and helps visualize work—but transparency isn't the main subject. References to visualizing throughput data and enabling empirical inspection align somewhat with transparency practices in Agile. However, most of the depth is about throughput itself, with only brief mentions of its link to transparency. There are no penalties since the content is current and not critical or satirical. The confidence score is moderate: transparency is present as a secondary benefit, not the core topic.",
    "reasoning_summary": "Transparency is mentioned and supported by throughput data visualization, but it's not the main focus. The core topic is throughput itself, so content fits the category only partially and indirectly.",
    "level": "Tertiary"
  },
  "Engineering Excellence": {
    "resourceId": "Throughput",
    "category": "Engineering Excellence",
    "calculated_at": "2025-10-01T17:11:15",
    "ai_confidence": 68.6,
    "ai_mentions": 2.2,
    "ai_alignment": 7.5,
    "ai_depth": 7.3,
    "ai_intent": 7.0,
    "ai_audience": 7.6,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 69.0,
    "reasoning": "The content introduces throughput as a delivery metric, focusing on workflow analysis, system constraints, and continuous improvement. It aligns with Engineering Excellence through the lens of metrics, measurement, and quality inspection, but does not explicitly mention engineering best practices, code quality, or technical topics such as code reviews, CI/CD, or automation. The discussion is moderately deep in the context of metrics but leans towards broader Agile process analysis rather than explicit engineering craftsmanship. The audience is technical but possibly includes delivery/Agile leads. Signal is somewhat diluted by general workflow improvement concepts, rather than sharp focus on established software engineering excellence themes.",
    "reasoning_summary": "The content partially fits the category by emphasizing throughput as a metric for monitoring system performance and improvement but lacks explicit connections to core engineering best practices or code quality standards.",
    "level": "Secondary"
  },
  "Time to Market": {
    "resourceId": "Throughput",
    "category": "Time to Market",
    "calculated_at": "2025-05-06T11:29:15",
    "ai_confidence": 67.03,
    "ai_mentions": 2.6,
    "ai_alignment": 7.8,
    "ai_depth": 6.8,
    "ai_intent": 7.3,
    "ai_audience": 8.1,
    "ai_signal": 8.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 67.0,
    "reasoning": "The content focuses primarily on the concept of Throughput — defining it, distinguishing it from productivity, and discussing its use as an observability metric. While Throughput is highly relevant to the measurement and optimization of Time to Market, the article does not explicitly mention 'Time to Market,' nor does it fully explore end-to-end value delivery speed or the broader organizational implications emphasized in the category definition. The main intent is educational and aligns well with the technical and continuous improvement audience targeted by Time to Market topics. There is some depth in discussing how throughput supports empirical inspection and continuous improvement, referencing use of cumulative flow diagrams and connections to lead time and cycle time. However, the content falls short of an in-depth, comprehensive discussion of Time to Market as a holistic metric, lacking direct strategies, case studies, or discussion on optimizing Time to Market beyond monitoring throughput. The signal-to-noise ratio and audience fit are strong, but the scope is somewhat narrower than required for a Primary classification; thus, the content is classified as Secondary. No penalties are applied, as the content is current, constructive, and consistent with modern Agile/Lean/Evidence-Based Management practices.",
    "level": "Secondary"
  },
  "Agentic Agility": {
    "resourceId": "Throughput",
    "category": "Agentic Agility",
    "calculated_at": "2025-10-01T17:10:28",
    "ai_confidence": 38.45,
    "ai_mentions": 0.15,
    "ai_alignment": 3.65,
    "ai_depth": 3.25,
    "ai_intent": 3.45,
    "ai_audience": 5.1,
    "ai_signal": 6.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 38.0,
    "reasoning": "The content discusses throughput as a delivery metric, focusing on empirical inspection, flow, and continuous improvement. However, it does not mention 'agency,' 'agentic agility,' autonomy, intentional adaptive action, or distinguish human/AI agency. No critical or opposing tone is observed. The content is relevant to Agile and technical audiences, but its focus is purely on delivery metrics and empirical feedback, not on agency or agentic behavior within Agile contexts.",
    "reasoning_summary": "This content centers on delivery metrics (throughput) and empirical inspection but does not address the core agentic agility themes, such as agency or intentional adaptive action. Fit with the category is weak and largely tangential.",
    "level": "Ignored"
  },
  "Lean Startup": {
    "resourceId": "Throughput",
    "category": "Lean Startup",
    "calculated_at": "2025-10-01T17:11:30",
    "ai_confidence": 16.07,
    "ai_mentions": 0.3,
    "ai_alignment": 2.2,
    "ai_depth": 2.5,
    "ai_intent": 1.9,
    "ai_audience": 3.4,
    "ai_signal": 2.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "The content focuses on throughput as a flow and delivery metric in Agile and Lean contexts but does not mention Lean Startup, MVPs, Build-Measure-Learn, or validated learning. It explains system performance and process optimization relevant in Lean but unrelated to iterative startup methodologies or entrepreneurial learning cycles central to Lean Startup. No penalties applied, as it is not critical, outdated, or oppositional—just off-topic for Lean Startup.",
    "reasoning_summary": "This content discusses throughput as a delivery and flow metric, aligned with general Lean/Agile but not Lean Startup. It lacks reference to Lean Startup principles, cycles, or validated learning. Only a marginal fit, primarily by incidental mention of Lean.",
    "level": "Ignored"
  },
  "Cycle Time": {
    "resourceId": "Throughput",
    "category": "Cycle Time",
    "calculated_at": "2025-10-01T17:10:38",
    "ai_confidence": 27.48,
    "ai_mentions": 1.7,
    "ai_alignment": 2.5,
    "ai_depth": 2.8,
    "ai_intent": 2.3,
    "ai_audience": 7.2,
    "ai_signal": 4.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 27.0,
    "reasoning": "The content focuses almost entirely on Throughput, defining it and exploring its implications for flow efficiency and Agile teams. Cycle Time is only mentioned once in relation to other metrics, with no explanation, depth, or direct focus on it. The content is technically relevant for a similar audience but does not discuss Cycle Time's definition, measurement, or use cases, nor are any Cycle Time-specific strategies or visualizations covered. There is minimal topical overlap beyond a passing contextual reference.",
    "reasoning_summary": "Content is about Throughput, not Cycle Time. Cycle Time is only superficially mentioned alongside other metrics; core ideas, intent, and discussion depth are not about Cycle Time.",
    "level": "Ignored"
  },
  "Coaching": {
    "resourceId": "Throughput",
    "category": "Coaching",
    "calculated_at": "2025-10-01T17:10:42",
    "ai_confidence": 13.1,
    "ai_mentions": 0.3,
    "ai_alignment": 1.6,
    "ai_depth": 1.4,
    "ai_intent": 2.5,
    "ai_audience": 4.5,
    "ai_signal": 6.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content focuses exclusively on throughput as a delivery and flow metric, with explanations about measurement, visualization, and continuous improvement. It does not explicitly or implicitly discuss coaching practices or the coach's role. There are no mentions of team facilitation, feedback, skill development, or the distinctions central to the coaching category. The only tangential alignment is that continuous improvement is sometimes part of a coach's interest, but here it is handled in strictly process/metric terms, not via interpersonal or developmental means. No penalties are applied as the content is not outdated and does not contradict the category.",
    "reasoning_summary": "The content only describes throughput as a metric and tool for system inspection; it does not discuss coaching themes, methods, or roles. Alignment with the 'Coaching' category is tangential at best; therefore, confidence is very low.",
    "level": "Ignored"
  },
  "Miscellaneous": {
    "resourceId": "-OIIzYxzBnS",
    "itemId": "-OIIzYxzBnS",
    "category": "Miscellaneous",
    "calculated_at": "2025-10-31T18:57:13",
    "ai_confidence": 27.9,
    "ai_mentions": 1.1,
    "ai_alignment": 2.7,
    "ai_depth": 3.3,
    "ai_intent": 2.2,
    "ai_audience": 3.1,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 28.0,
    "reasoning": "The content centers on throughput as a metric, directly referencing its role within Agile and Lean contexts and related tools (cumulative flow diagrams, flow analytics). It goes beyond anecdotal discussion, describing actionable practices connected to established frameworks. Mentions of 'in Agile and Lean contexts' and use of throughput with lead time and cycle time demonstrate clear alignment with those frameworks—thus, the fit for Miscellaneous is low, as the content explicitly connects to recognised theories and methodologies.",
    "reasoning_summary": "Content is tied to core Agile and Lean practices and tools, not Miscellaneous; it discusses established frameworks and actionable insights, making it a poor fit for the Miscellaneous category.",
    "level": "Ignored"
  },
  "Employee Engagement": {
    "resourceId": "-OIIzYxzBnS",
    "itemId": "-OIIzYxzBnS",
    "category": "Employee Engagement",
    "calculated_at": "2025-10-31T18:57:37",
    "ai_confidence": 8.36,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.4,
    "ai_intent": 0.3,
    "ai_audience": 4.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content discusses throughput as a metric for delivery and system efficiency, focusing on workflow, flow analytics, and process improvement. No direct mention or substantial discussion of motivation, psychological or social factors, or employee commitment. The intent is to inform about a technical topic, not employee engagement. Audience is likely practitioners in Agile/Lean, but the theme is not related to engagement. High signal for process-related insights, but very little (if any) signal for employee engagement themes.",
    "reasoning_summary": "This content focuses on throughput as a technical workflow/process metric, not on employee engagement. No discussion of motivation, commitment, or psychological/social aspects of team dynamics. Fit with Employee Engagement is minimal and indirect.",
    "level": "Ignored"
  },
  "Agile Planning": {
    "resourceId": "-OIIzYxzBnS",
    "itemId": "-OIIzYxzBnS",
    "category": "Agile Planning",
    "calculated_at": "2025-10-31T18:57:45",
    "ai_confidence": 66.87,
    "ai_mentions": 3.8,
    "ai_alignment": 7.1,
    "ai_depth": 7.4,
    "ai_intent": 7.2,
    "ai_audience": 7.6,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 67.0,
    "reasoning": "The content centers on throughput as a metric for inspecting flow and system delivery in Agile/Lean contexts, referencing its use in empirical inspection and continuous improvement. While it discusses planning cadence and feedback loops (relevant to Agile Planning), the direct focus is on measurement rather than explicit planning frameworks or practices. It names Agile contexts but does not delve into planning ceremonies or specific planning processes. The intent is informative for Agile practitioners seeking to improve flow and delivery, matching the audience. The discussion is focused, with little off-topic content.",
    "reasoning_summary": "Strong partial fit: Discusses throughput as an Agile metric tied to planning cadence and feedback but does not explicitly detail Agile Planning methods or practices. Supports Agile Planning through metrics rather than primary focus.",
    "level": "Secondary"
  },
  "Continuous Integration": {
    "resourceId": "Throughput",
    "category": "Continuous Integration",
    "calculated_at": "2025-10-01T17:11:35",
    "ai_confidence": 22.05,
    "ai_mentions": 0.2,
    "ai_alignment": 1.6,
    "ai_depth": 2.3,
    "ai_intent": 2.0,
    "ai_audience": 6.0,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 22.0,
    "reasoning": "The content discusses throughput as a delivery and flow metric, emphasizing system performance, workflow analysis, and continuous improvement. However, there is no explicit mention of Continuous Integration, nor does it address CI concepts such as code integration or automated testing. The main themes—metric observability and flow—align with process improvement generally but not specifically with the principles or practices of CI. The intended audience (teams improving delivery) loosely overlaps with CI practitioners, but the core focus is not on CI itself.",
    "reasoning_summary": "Content focuses on throughput and system flow efficiency, not on Continuous Integration. There are no direct links to CI practices, tools, or intent. This is mostly unrelated to the assigned category except for a tangential focus on delivery improvement.",
    "level": "Ignored"
  },
  "Value Stream Mapping": {
    "resourceId": "Throughput",
    "category": "Value Stream Mapping",
    "calculated_at": "2025-05-06T11:29:22",
    "ai_confidence": 46.31,
    "ai_mentions": 1.65,
    "ai_alignment": 4.72,
    "ai_depth": 4.86,
    "ai_intent": 4.39,
    "ai_audience": 7.42,
    "ai_signal": 7.07,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 46.0,
    "reasoning": "The content focuses closely on 'Throughput' as a metric of flow in Lean and Agile environments, with discussion of how it helps analyse efficiency and constraints. However, there is only an indirect alignment to Value Stream Mapping (VSM): VSM is not directly mentioned, and the discussion centers around throughput as a standalone metric rather than the VSM methodology or practice itself. There are no walkthroughs, techniques, or visualisation examples specific to VSM (such as current/future state mapping, specific Lean waste identification, or value/non-value analysis). \n\nMentions (1.650): There is no explicit mention of Value Stream Mapping, and only an implied connection via discussion of flow and constraints analysis—thus a very low score reflecting only indirect referencing.\nAlignment (4.720): The topic of throughput and flow analysis can be a component of VSM, but the main ideas do not match the full core meaning of the category, landing in the lower-middle range.\nDepth (4.860): The discussion on throughput is reasonably detailed for its subject, but there is no exploration of VSM principles or mapping process, thus the depth as relates to the category is limited.\nIntent (4.390): The content’s main intent is to educate about throughput as a Lean/Agile metric, not about teaching or exploring Value Stream Mapping, so the fit is tangential.\nAudience (7.420): The content uses Lean/Agile terminology suited for practitioners interested in workflow improvement, which overlaps substantially with the VSM audience.\nSignal (7.070): The content is highly focused on throughput and flow efficiency, which is relevant to the kinds of issues VSM seeks to solve, with minimal filler or off-topic diversion.\n\nThere were no penalty adjustments required as the content is not outdated, nor is it critical of Lean or VSM principles. \n\nGiven the low direct mention and only moderate alignment/depth, this content should be classified as only 'Tertiary' relevance to Value Stream Mapping. The confidence score of 46.310 reflects that, sitting well below 50 and proportionate to the tangential relationship.",
    "level": "Tertiary"
  },
  "Sprint Review": {
    "resourceId": "Throughput",
    "category": "Sprint Review",
    "calculated_at": "2025-05-13T21:57:38",
    "ai_confidence": 12.0,
    "ai_mentions": 0.2,
    "ai_alignment": 1.8,
    "ai_depth": 1.4,
    "ai_intent": 3.2,
    "ai_audience": 2.3,
    "ai_signal": 1.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content focuses exclusively on throughput as a flow and performance metric, describing its observability, value, and usage across Agile and Lean teams. It does not mention Sprint Reviews, their purpose, participants, or related Scrum practices. There's no discussion of increment inspection, stakeholder engagement, or any explicit or implicit Sprint Review processes. Minimal if any overlap with category intent or audience.",
    "reasoning_summary": "The content centers on throughput and workflow metrics, not Sprint Review. It doesn't address the event, participants, goals, or practices central to Sprint Review, so confidence in this classification is very low.",
    "level": "Ignored"
  },
  "Throughput": {
    "resourceId": "-OIIzYxzBnS",
    "itemId": "-OIIzYxzBnS",
    "category": "Throughput",
    "calculated_at": "2025-10-31T18:57:47",
    "ai_confidence": 97.6,
    "ai_mentions": 9.6,
    "ai_alignment": 9.8,
    "ai_depth": 9.7,
    "ai_intent": 9.6,
    "ai_audience": 9.0,
    "ai_signal": 9.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 98.0,
    "reasoning": "The content directly and repeatedly defines and discusses throughput as a delivery metric, consistent with the category's core meaning. It goes beyond surface mention, explaining how throughput is tracked, visualized (e.g., cumulative flow diagrams), and used to analyse system constraints and delivery health. It distinguishes throughput from productivity and gives practical Agile/Lean context, serving both practitioners and strategists. There is no significant filler, outdatedness, or off-topic content. No penalty adjustments are warranted.",
    "reasoning_summary": "The content is an exemplary, focused discussion on throughput as a delivery metric, detailing its definition, visualization, and use in Agile/Lean systems. Fit is both comprehensive and directly aligned to the category definition.",
    "level": "Primary"
  },
  "Unrealised Value": {
    "resourceId": "-OIIzYxzBnS",
    "itemId": "-OIIzYxzBnS",
    "category": "Unrealised Value",
    "calculated_at": "2025-10-31T18:57:21",
    "ai_confidence": 13.3,
    "ai_mentions": 0.0,
    "ai_alignment": 2.3,
    "ai_depth": 2.8,
    "ai_intent": 1.9,
    "ai_audience": 3.5,
    "ai_signal": 2.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content discusses throughput as a metric for inspecting delivery flow and system performance. There is no mention or conceptual discussion of Unrealised Value or its indicators—focus remains on operational metrics. No penalties applied as there is no contradictory or outdated content.",
    "reasoning_summary": "This content does not fit 'Unrealised Value'; its themes are operational throughput, not potential value, innovation, or opportunity. Intent and alignment are weak, with no exploration of Unrealised Value concepts.",
    "level": "Ignored"
  },
  "Leadership": {
    "resourceId": "-OIIzYxzBnS",
    "itemId": "-OIIzYxzBnS",
    "category": "Leadership",
    "calculated_at": "2025-10-31T18:57:44",
    "ai_confidence": 22.093,
    "ai_mentions": 0.9,
    "ai_alignment": 2.1,
    "ai_depth": 2.7,
    "ai_intent": 2.0,
    "ai_audience": 7.2,
    "ai_signal": 6.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 22.0,
    "reasoning": "The content centers on throughput as a metric for flow efficiency and delivery effectiveness in Agile/Lean teams. It discusses how throughput informs empirical inspection and team-level improvement, but does not directly mention or substantially discuss leadership, leadership roles, or the impact of leadership on teams. There are indirect connections—leaders may use throughput metrics for decision-making or team guidance—but the main focus is on workflow health, system performance, and continuous improvement, not leadership practices or models. Thus, mention and alignment are low, while audience fit and signal are somewhat higher due to general relevance to Agile professionals.",
    "reasoning_summary": "This content discusses throughput as a flow metric for Agile and Lean teams. It does not reference or deeply explore leadership themes, making the fit to the Leadership category minimal and largely indirect.",
    "level": "Ignored"
  },
  "Estimation": {
    "resourceId": "-OIIzYxzBnS",
    "itemId": "-OIIzYxzBnS",
    "category": "Estimation",
    "calculated_at": "2025-10-31T18:57:05",
    "ai_confidence": 20.75,
    "ai_mentions": 1.2,
    "ai_alignment": 2.2,
    "ai_depth": 2.6,
    "ai_intent": 2.1,
    "ai_audience": 8.7,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 21.0,
    "reasoning": "The content describes throughput as a delivery/flow metric, emphasizing system performance, workflow inspection, and continuous improvement. There is no direct mention of estimation practices, techniques, or their relationship to forecasting. Throughput is addressed as an observability/flow measure, not as an estimation tool, and the link to estimation or its significance in planning or forecasting is not made explicit. The audience (Agile/Lean practitioners) overlaps, but the main ideas are more about flow/effectiveness than estimation, yielding minimal alignment and low confidence.",
    "reasoning_summary": "Content focuses on throughput as a flow metric, not on estimation practices or techniques. While relevant to Agile practitioners, it does not address estimation, forecasting, or empirical planning methods. Fit with 'Estimation' is minimal and indirect.",
    "level": "Ignored"
  },
  "Psychological Safety": {
    "resourceId": "-OIIzYxzBnS",
    "itemId": "-OIIzYxzBnS",
    "category": "Psychological Safety",
    "calculated_at": "2025-10-31T18:57:06",
    "ai_confidence": 7.35,
    "ai_mentions": 0.0,
    "ai_alignment": 0.2,
    "ai_depth": 0.4,
    "ai_intent": 0.6,
    "ai_audience": 4.6,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content exclusively discusses throughput as a delivery metric, its measurement, and practical applications in Agile/Lean contexts. There are no explicit or indirect references to psychological safety, nor are there themes relating to team dynamics, risk taking, open communication, or supportive culture. Audience fit aligns partially, as practitioners of Agile/Lean may care about both throughput and psychological safety, but the content itself remains strictly metric-focused and does not cross over into the category. The scoring reflects negligible alignment on all core dimensions except audience and signal, which are only modest due to general topic adjacency.",
    "reasoning_summary": "The content focuses solely on measuring throughput with no mention or exploration of psychological safety. There is no intent, theme, or purpose overlap with the category, resulting in a very low fit.",
    "level": "Ignored"
  },
  "Automated Testing": {
    "resourceId": "Throughput",
    "category": "Automated Testing",
    "calculated_at": "2025-05-06T11:29:20",
    "ai_confidence": 8.05,
    "ai_mentions": 0.2,
    "ai_alignment": 0.7,
    "ai_depth": 0.75,
    "ai_intent": 0.6,
    "ai_audience": 0.9,
    "ai_signal": 0.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0.0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content titled 'Throughput' is entirely focused on the definition, use, and interpretation of throughput as a delivery metric in Agile and Lean environments. There are zero direct mentions or even indirect references to automated testing or any of its subtopics (frameworks, tools, practices, test types, CI/CD, etc.). The main idea is about delivery flow and system observability, not about testing processes or quality assurance. \n\nDirect Mentions (0.20): No reference to automated testing or related terminologies, only an indirect proximate relationship through the Agile/Lean context. \n\nConceptual Alignment (0.70): There's minimal overlap, only to the extent that both automated testing and throughput are used in Agile/Lean delivery improvement efforts. However, automated testing is not discussed, nor are any of its principles or roles in workflows.\n\nDepth (0.75): The depth is solely on throughput metrics, flow efficiency, and system constraint identification, not automated testing.\n\nIntent (0.60): The purpose is educational/informative, but not toward automated testing; the intent is misaligned—the content's target is delivery flow rather than testing practices.\n\nAudience (0.90): The intended audience is likely technical or delivery-oriented—relevant to the audience for automated testing but not specifically targeted. \n\nSignal (0.90): The content is highly focused on throughput—very little noise—but none of it is about the designated category, leaving primary relevance low. \n\nNo penalties were applied. The overall confidence level is very low, consistent with a tertiary (indirect/incidental) connection at best.",
    "level": "Ignored"
  },
  "Hybrid Agile": {
    "resourceId": "Throughput",
    "category": "Hybrid Agile",
    "calculated_at": "2025-05-06T11:29:15",
    "ai_confidence": 13.7,
    "ai_mentions": 0.4,
    "ai_alignment": 1.6,
    "ai_depth": 1.5,
    "ai_intent": 2.2,
    "ai_audience": 4.1,
    "ai_signal": 4.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content, while informative about the concept of throughput as a delivery metric, contains no explicit or implicit mention of Hybrid Agile, nor does it discuss the integration of traditional and agile methods, pitfalls of Hybrid Agile, or related dysfunctions. (Mentions: 0.4) The content is conceptually only tangentially relevant, as throughput is a metric used in both Agile and Lean, but it is not specifically connected to Hybrid Agile contexts or their unique challenges. (Alignment: 1.6) The depth of discussion is about throughput as a standalone metric and does not extend into the territory of structural, cultural, or process-related hybridization issues. (Depth: 1.5) The intent appears to be educational about throughput metrics in general, rather than critically analyzing or critiquing hybrid methodologies (Intent: 2.2). The audience is likely practitioners or teams interested in delivery metrics—overlapping somewhat with the Hybrid Agile audience—hence a mid-score (Audience: 4.1). The majority of the content is focused on throughput and does not deviate into irrelevant material, so the signal-to-noise ratio is relatively high, though not perfect due to lack of Hybrid Agile focus (Signal: 4.9). No penalty points are applied, as the content is neither outdated nor contradictory in tone. This resource is categorized as 'Tertiary' level—only peripherally relevant to the Hybrid Agile category.",
    "level": "Ignored"
  },
  "Value Delivery": {
    "resourceId": "Throughput",
    "category": "Value Delivery",
    "calculated_at": "2025-05-06T11:29:22",
    "ai_confidence": 79.25,
    "ai_mentions": 4.7,
    "ai_alignment": 8.2,
    "ai_depth": 7.9,
    "ai_intent": 8.4,
    "ai_audience": 7.3,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 79.0,
    "reasoning": "The content discusses 'Throughput' as a metric tied closely to delivery and flow efficiency, offering a systemic view of how teams inspect value flow and improve systems. \n\n- Mentions (4.7): The term 'value' and references to delivery, flow, and systems are present but not repetitive or explicit about 'Value Delivery' as an overarching theme; rather, they appear in supporting role to throughput. Explicit category terms are sparsely named.\n- Alignment (8.2): The content conceptually aligns with strategies for maximising and measuring value (key topic), referencing how throughput reveals value flow and supports inspection and improvement—core objectives in Value Delivery.\n- Depth (7.9): There is meaningful detail about how throughput enables transparency, empirical inspection, and continuous improvement. Discussion covers tools (cumulative flow diagrams) and decision-making based on the metric. However, it doesn’t deeply explore value strategy, or methods for maximising customer value beyond metric assessment.\n- Intent (8.4): The purpose is to inform and equip Agile/Lean practitioners to use throughput as a tool for system and value delivery improvement, which is solidly aligned with the category’s intent.\n- Audience (7.3): The intended audience is teams or technical Agile practitioners familiar with observability metrics, not senior leaders or general audiences. This matches most of the Value Delivery audience, but is not as broad as might be possible.\n- Signal (7.6): The content is focused, with little distraction or off-topic material, but it could interlink more directly with broader value delivery philosophies.\n\nNo penalties were applied: The advice is up-to-date, aligns with Agile/Lean practices, and is neither critical nor contradictory.\n\nThis evaluation places 'Throughput' as a secondary tier fit — it is tightly relevant, but mainly explores a metric in the service of value delivery, rather than serving as a comprehensive or primary resource on the broader topic.",
    "level": "Secondary",
    "reasoning_summary": "The content fits the category because it explains how throughput, while not the main focus of value delivery, is a key metric that helps teams understand and improve the flow of value. It offers practical insights for Agile/Lean practitioners, aligning with the category’s intent, though it doesn’t cover value delivery in depth or from a strategic perspective. Overall, it’s a relevant but not exhaustive resource for this topic."
  },
  "Revenue per Employee": {
    "resourceId": "Throughput",
    "category": "Revenue per Employee",
    "calculated_at": "2025-05-06T11:29:16",
    "ai_confidence": 11.312,
    "ai_mentions": 0.4,
    "ai_alignment": 1.6,
    "ai_depth": 1.2,
    "ai_intent": 2.0,
    "ai_audience": 2.3,
    "ai_signal": 1.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 11.0,
    "reasoning": "The content focuses exclusively on the metric of throughput as used in operational, Agile, and Lean contexts, examining how much work is completed per unit time and how this helps teams inspect flow efficiency. There are no direct or indirect mentions of Revenue per Employee, nor is there any discussion of financial performance, workforce efficiency from a revenue perspective, or organization-wide financial metrics. The entire discussion deals with system-level throughput as a delivery metric rather than as a financial observability signal. The content is informative, relevant to Agile/Lean practitioners, and avoids off-topic commentary, so the signal/noise ratio is modest. However, because it never even links throughput to revenue or financial outcomes via workforce size, it only very distantly aligns with the intent behind Revenue per Employee: both are about efficiency, but in entirely different domains (operational flow vs financial headcount leverage). No penalties were applied since there is no outdated or satirical tone. The scores reflect minimal relevance; the primary topic is an operational/delivery metric, not a financial metric about organizational effectiveness.",
    "level": "Ignored"
  },
  "Sociotechnical Systems": {
    "resourceId": "Throughput",
    "category": "Sociotechnical Systems",
    "calculated_at": "2025-05-06T11:29:16",
    "ai_confidence": 48.84,
    "ai_mentions": 1.8,
    "ai_alignment": 5.7,
    "ai_depth": 5.5,
    "ai_intent": 5.9,
    "ai_audience": 6.2,
    "ai_signal": 7.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 49.0,
    "reasoning": "The content discusses 'Throughput' as a software delivery metric, focusing on flow, observability, and continuous improvement. \n\n- **Mentions (1.8):** There is no explicit mention of 'Sociotechnical Systems' as a term, nor reference to its key frameworks or subject terminology. The discussion centers on throughput, not directly naming nor repeatedly referencing the broader category.\n\n- **Alignment (5.7):** The content shows partial conceptual overlap—concepts like workflow, team inspection, and system constraints *touch on* the social-technical intersection. However, the emphasis is far more technical and metric-driven, with only faint allusions (e.g., mention of team composition, planning cadence) to organisational/people elements. Most discussion is about measurement, not about the integration or interplay of social and technical systems as per the classification definition.\n\n- **Depth (5.5):** There is moderate depth around how throughput is measured and used in Agile/Lean contexts. However, the exploration is narrowly focused on the metric and associated practices, not thoroughly unpacking ramifications for organisational culture, structure, or deeper sociotechnical themes (such as team dynamics or case studies).\n\n- **Intent (5.9):** The main intent seems to be informative—explaining a delivery metric. While it is somewhat relevant for sociotechnical discussions (since throughput has implications for teamwork and continuous improvement), the content is not primarily about sociotechnical systems, nor does it aim to bridge social and technical factors in any extensive way.\n\n- **Audience (6.2):** The content is aimed at practitioners (teams, Agile/Lean delivery groups) who might be interested in performance metrics, which can overlap with a sociotechnical audience. However, it is not targeted at those deliberately seeking in-depth sociotechnical analysis or strategy.\n\n- **Signal (7.3):** The content is tightly focused on the topic of throughput with minimal off-topic material, although much of it remains at a surface level with respect to sociotechnical issues.\n\n- **Penalty Assessment:** No deductions were warranted—the content is current, neutral in tone, and not contradictory.\n\n- **Level:** This resource would be classified as 'Tertiary.' It may inform or be referenced by sociotechnical system discussions, but it neither centers on nor deeply explores the category. \n\n**In sum:** While throughput is an important organizational metric and can be relevant within sociotechnical systems contexts, the content itself is not about *the interplay between social and technical systems*, nor does it meaningfully address sociotechnical frameworks or dynamics.",
    "level": "Tertiary"
  },
  "Company as a Product": {
    "resourceId": "Throughput",
    "category": "Company as a Product",
    "calculated_at": "2025-05-06T11:29:18",
    "ai_confidence": 37.332,
    "ai_mentions": 0.8,
    "ai_alignment": 3.4,
    "ai_depth": 2.9,
    "ai_intent": 4.0,
    "ai_audience": 5.8,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "This content focuses exclusively on the concept of throughput as a delivery metric, emphasizing its role in observability, workflow efficiency, and system performance analysis. There are no direct mentions whatsoever of 'Company as a Product,' nor does the content explicitly frame throughput in the context of organisation-as-product strategy, whole-company evolution, or customer-centric organisational design. \n\nMentions (0.8): No direct mentions of CaaP or related terminology, and only a faint conceptual overlap with the idea of continuous improvement/inspection. \n\nAlignment (3.4): The use of throughput for empirical inspection and continuous improvement has a weak but plausible thematic connection to CaaP principles, such as measuring outcomes and enabling feedback loops. However, the focus is at the team/system level, not at organisational design or strategy. \n\nDepth (2.9): The discussion dives into how throughput is used, its comparison to productivity, and related tools, but does not move beyond surface-level process improvement or link measurement explicitly to company-wide agility, cross-functional collaboration, or alignment with strategic goals.\n\nIntent (4.0): The content aims to inform practitioners about throughput as a metric for process improvement. While this has tangential relevance to some CaaP objectives, the primary audience and intent is metric observability rather than organisational transformation.\n\nAudience (5.8): The audience is likely delivery teams, Agile/Lean practitioners, or engineering managers—not explicitly executives or strategists. However, the content could be referenced by broader organisational initiatives.\n\nSignal (6.1): The discussion is tightly focused on throughput, with a clear absence of extraneous information; high signal within the stated topic, but low relevance to CaaP.\n\nNo penalties are applied: Content is current, relevant, and does not satirise or contradict the CaaP framing. The final confidence is appropriately low and signals only tertiary relevance: throughput is a metric that may be used within a CaaP framework, but the specific content does not address CaaP principles, strategy, or implementation directly.",
    "level": "Ignored"
  },
  "Definition of Done": {
    "resourceId": "Throughput",
    "category": "Definition of Done",
    "calculated_at": "2025-05-06T11:29:17",
    "ai_confidence": 12.178,
    "ai_mentions": 0.3,
    "ai_alignment": 0.9,
    "ai_depth": 1.2,
    "ai_intent": 0.7,
    "ai_audience": 6.1,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "The content focuses exclusively on the definition, purpose, and value of throughput as a delivery metric—discussing its use in inspecting work completed, improving flow efficiency, and revealing system constraints. There is no mention of the Definition of Done (DoD) as an Agile/Scrum concept, nor does the content explore any of the core principles, practices, or criteria associated with DoD. There is minimal to no conceptual overlap, except for the very broad notion of ensuring completed work is inspected—yet this is from a flow and measurement perspective rather than any shared understanding of done-ness. It does not discuss acceptance criteria, team alignment on quality, Scrum artefacts, or best practices for DoD. The content’s audience (Agile/Lean practitioners) overlaps with those interested in DoD, but the subject matter does not serve the DoD purpose or intent. The focus and clarity of the content are high within its own scope, but relevance to the DoD category is very weak, meriting a Tertiary level and very low confidence score.",
    "level": "Ignored"
  },
  "Personal": {
    "resourceId": "Throughput",
    "category": "Personal",
    "calculated_at": "2025-05-06T11:29:20",
    "ai_confidence": 19.433,
    "ai_mentions": 0.5,
    "ai_alignment": 1.3,
    "ai_depth": 2.2,
    "ai_intent": 3.0,
    "ai_audience": 5.7,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "This content primarily provides a factual and technical overview of the metric 'Throughput,' used in Agile and Lean methodologies. \n\n- **Mentions (0.5):** The text makes no direct or explicit reference to personal experiences, anecdotes, or subjective insights; indirect relevance is minimal and general.\n- **Conceptual Alignment (1.3):** The content does not align with the core meaning of 'Personal.' It discusses system-level measurement and analysis, not reflections or individual experiences. There's a minor link in the sense that teams use throughput, but this is not expanded in a personal context.\n- **Depth (2.2):** The discussion of throughput is moderately detailed regarding its applications in Agile/Lean, but entirely from a technical and system performance lens; no personal dimension is introduced.\n- **Intent (3.0):** The intent is educational and objective, focusing on defining throughput for general readers, with no observable personal or reflective purpose.\n- **Audience (5.7):** The audience is likely practitioners or managers interested in metrics, which may slightly overlap with those seeking personal stories from Agile experience, but the true intent is more technical/managerial.\n- **Signal (7.6):** The content is focused and on-topic regarding throughput and its uses; there is little to no filler, but since these points are not handled in a personal framework, only general focus applies.\n\nNo penalty is applied, as the content is up-to-date, neutral in tone, and not actively misrepresentative. The content is strictly technical and informative; therefore, the 'Personal' category only tertiarily applies, which is reflected in the low confidence score.",
    "level": "Ignored"
  },
  "Working Software": {
    "resourceId": "Throughput",
    "category": "Working Software",
    "calculated_at": "2025-05-06T11:29:17",
    "ai_confidence": 27.55,
    "ai_mentions": 0.6,
    "ai_alignment": 2.7,
    "ai_depth": 2.9,
    "ai_intent": 1.8,
    "ai_audience": 4.2,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 28.0,
    "reasoning": "The content focuses on throughput as a metric for delivery and flow efficiency but does not directly discuss the concept, definition, or role of 'Working Software' as an artifact. \n\nMentions (0.6): There are no explicit or implicit references to 'Working Software'—the language is about 'work items' and 'flow', not deliverable software artifacts.\n\nAlignment (2.7): The content lightly aligns with 'Working Software' because throughput is often tracked in environments (Agile, Lean) where the goal is frequent delivery of usable software. However, the core theme is measuring workflow, not software delivery.\n\nDepth (2.9): The discussion is thorough regarding throughput as a metric but offers no substantive exploration of working software itself, its characteristics, or value.\n\nIntent (1.8): The content’s main intent is to explain throughput as a flow metric—only tangentially related to working software; intent/purpose is not aligned with the core category.\n\nAudience (4.2): The content speaks to Agile/Lean practitioners (somewhat consistent with the target audience for 'Working Software'), but the focus is on process metrics, not software artifacts.\n\nSignal (5.1): The text is tightly focused on throughput and its implications—so signal-to-noise is fair—but the signals are around delivery metrics, not 'Working Software.'\n\nNo penalties were applied since the content is not outdated, critical, or off-tone. Given its focus, the content is at best tertiarily related to 'Working Software', mainly because achieving high throughput often facilitates, but does not define or describe, the production of working software. This is reflected in the low confidence score.",
    "level": "Ignored"
  },
  "Organisational Culture": {
    "resourceId": "Throughput",
    "category": "Organisational Culture",
    "calculated_at": "2025-05-06T11:29:17",
    "ai_confidence": 33.85,
    "ai_mentions": 1.2,
    "ai_alignment": 3.3,
    "ai_depth": 3.1,
    "ai_intent": 3.5,
    "ai_audience": 7.2,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 34.0,
    "reasoning": "The content extensively discusses throughput as a delivery and workflow metric, focusing on measuring and analyzing system performance, flow efficiency, and using tools to visualize work completed over time. \n\n- Mentions (1.2): The term 'Organisational Culture' or direct cultural vocabulary is not explicitly mentioned, nor are cultural dimensions, leadership, or team dynamics discussed. The content references Agile and Lean, but in the context of metrics rather than cultural transformation.\n- Alignment (3.3): There is a tangential connection where throughput supports transparency and continuous improvement—concepts that are relevant to culture. However, these references are byproducts of the metric's use and not the main focus; culture’s foundational influence on agility or transformation is not directly addressed.\n- Depth (3.1): The content stays at a process and measurement level. It does not deeply address cultural change, leadership roles, or culture’s impact on teamwork and agility. The link to culture is implied (e.g., enabling continuous improvement) but not explored.\n- Intent (3.5): The main purpose is to explain throughput as a metric, its applications, and its analytical value. While it hints at continuous improvement (culturally relevant), culture is not the stated or practical aim of the content.\n- Audience (7.2): The audience naturally overlaps with those concerned with organisational culture (Agile and Lean practitioners, teams), though the focus is more on operations/metrics rather than transformation strategists or leadership.\n- Signal (7.8): The content is tightly focused and on-topic regarding throughput, with minimal digression and high relevance for its stated intent. \n\nNo penalties were applied as the content is current, neutral in tone, and not critical or satirical. \n\nOverall, the content is best categorized as tertiary relevance to 'Organisational Culture'—a process/tool-oriented primer where culture is an indirect (at best) beneficiary of the practices described. The confidence score is low, reflecting pervasive distance from direct cultural focus.",
    "level": "Ignored"
  },
  "Lead Time": {
    "resourceId": "Throughput",
    "category": "Lead Time",
    "calculated_at": "2025-05-06T11:29:26",
    "ai_confidence": 35.55,
    "ai_mentions": 2.3,
    "ai_alignment": 4.2,
    "ai_depth": 3.9,
    "ai_intent": 3.6,
    "ai_audience": 7.0,
    "ai_signal": 5.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 36.0,
    "reasoning": "The resource focuses almost exclusively on 'Throughput', defining it as the amount of work a system completes over a specific time period. 'Lead Time' is only referenced as a related, but distinct, metric. \n\n- For 'Direct Mentions', Lead Time is mentioned only in passing—there is no explicit definition, deep discussion, or emphasis on its importance or measurement, so a low score is warranted (2.3).\n- For 'Conceptual Alignment', the content acknowledges Lead Time's connection with throughput ('used with lead time and cycle time') but the main concepts revolve around throughput analysis, not Lead Time's core meaning. Instead, Lead Time is presented as an adjacent metric, thus only partial alignment (4.2).\n- 'Depth of Discussion' is minimal regarding Lead Time; all substantive detail, techniques, and examples concern throughput (3.9).\n- For 'Intent/Purpose Fit', the purpose centers on throughput, not Lead Time. The mention of Lead Time is supportive but not core (3.6).\n- 'Audience Alignment' is higher (7.0) because the resource still targets the same process-improvement or Agile-focused audience for whom Lead Time topics are relevant.\n- 'Signal-to-Noise Ratio' is moderate (5.2): the content is on-topic for flow metrics generally, but the direct relevance to Lead Time is minor, making much of the content tangential for this category.\n- No penalty adjustments are applied—nothing is outdated or contradictory to the Lead Time framing.\n\nIn summary, Lead Time is a peripheral topic here. The resource is clearly Tertiary in relation to the Lead Time category: it is relevant only incidentally, providing almost no direct value for a user specifically seeking Lead Time information. The confidence score of 35.55 accurately reflects that the connection is indirect and mostly contextual, not core.",
    "level": "Ignored"
  },
  "Liberating Structures": {
    "resourceId": "Throughput",
    "category": "Liberating Structures",
    "calculated_at": "2025-05-06T11:29:18",
    "ai_confidence": 8.633,
    "ai_mentions": 0.1,
    "ai_alignment": 0.3,
    "ai_depth": 0.2,
    "ai_intent": 0.5,
    "ai_audience": 1.0,
    "ai_signal": 0.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content is solely about 'Throughput' as an Agile metric. There is no direct mention of Liberating Structures, nor are any of its specific methods or facilitation techniques discussed. The audience is generally Agile practitioners or teams, which matches the Liberating Structures audience superficially, but the content is exclusively focused on workflow metrics, not facilitation or interaction structuring. The conceptual alignment is negligible: no parts reference using Liberating Structures to inspect throughput or facilitate discussions about throughput, nor does it mention engagement, self-facilitation, or collaborative structures. The depth of discussion around Liberating Structures is virtually zero, as every point is strictly about throughput metrics, analytics, and process inspection. Intent and signal scores are low—while the piece is clear and relevant for metrics tracking, it is off-topic for the Liberating Structures category. No penalties are needed as the content is neither outdated nor critical of the category. Ultimately, the overall confidence that this content fits under 'Liberating Structures' is very low, classified as 'Tertiary' level, meaning it's not a fit except as a remote tangent if a facilitation session used metrics as a case study.",
    "level": "Ignored"
  },
  "System Configuration": {
    "resourceId": "Throughput",
    "category": "System Configuration",
    "calculated_at": "2025-05-06T11:29:18",
    "ai_confidence": 23.03,
    "ai_mentions": 0.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.4,
    "ai_intent": 2.7,
    "ai_audience": 3.9,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "Direct Mentions (0.2): The content does not directly reference 'system configuration' or related terminology such as configuration management, setup, or automation. 'System' is mentioned generically in the sense of performance, but not configuration.\n\nConceptual Alignment (2.8): The content centers on 'throughput', a metric for measuring performance and delivery. While performance monitoring is tangentially related to system configuration, this treatment is confined solely to observability/flow metrics—there's no substantive discussion of configuration tools, practices, or the operational aspects of systems.\n\nDepth of Discussion (2.4): Discussion focuses entirely on the definition, use, and value of throughput as a metric. There is no exploration of system configuration or practices for optimizing system setups—any implied connection (e.g., impact of workflow changes) remains surface-level and is not tied to technical setup/configuration.\n\nIntent (2.7): The intent is informative about throughput as a performance/delivery metric, not about configuring systems. While teams optimizing throughput may eventually consider configuration, the content's main purpose is unrelated.\n\nAudience Alignment (3.9): The content targets practitioners interested in Agile/Lean metrics and workflows—potentially overlapping with system configuration's audience but skewed toward delivery/project management professionals.\n\nSignal-to-Noise Ratio (3.1): The content is focused and stays on throughput and its uses. However, nearly all of it falls outside the boundaries of 'System Configuration', so its relevance signal for the category is very weak.\n\nNo penalties were applied, as the content maintains a neutral, current, and informative tone, with no evidence of outdated information or contradictory framing.\n\nThis is rated as Tertiary because although system performance is discussed, it's strictly in the context of delivery metrics, not the setup, integration, or ongoing maintenance/configuration of systems.",
    "level": "Ignored"
  },
  "Continuous Delivery": {
    "resourceId": "Throughput",
    "category": "Continuous Delivery",
    "calculated_at": "2025-05-06T11:29:19",
    "ai_confidence": 48.95,
    "ai_mentions": 1.8,
    "ai_alignment": 5.1,
    "ai_depth": 5.5,
    "ai_intent": 5.8,
    "ai_audience": 6.7,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 49.0,
    "reasoning": "The content closely examines the metric 'throughput', explaining what it is, how it can be observed and measured, and its role in process improvement. However, the article avoids explicit mention of 'Continuous Delivery' (mentions: 1.8), only loosely connecting the concept to general software delivery improvements. The conceptual alignment (5.1) is partial: while throughput is a valuable metric in Continuous Delivery, its portrayal here skews broader, referencing Agile and Lean without emphasizing the discipline, automation, or release practices that define Continuous Delivery per the classification meaning. The depth of discussion (5.5) is moderate, focusing on how throughput enables feedback, inspection, and adjustment, but lacking detailed ties to Continuous Delivery principles, automation, or deployment. The intent (5.8) is to inform about throughput for process enhancement, which aligns tangentially—improving delivery is relevant, but not exclusively targeted at Continuous Delivery. Audience fit (6.7) is reasonable, aimed at practitioners interested in delivery metrics, though not specifically Continuous Delivery specialists. The signal-to-noise ratio is good (7.0), as the content is focused, lean, and avoids filler, but much is not category-specific. No penalties are applied. Overall, the score is in the lower-middle range reflecting only indirect, secondary relevance—the content could inform Continuous Delivery discussions but does not address them as its main focus. Thus, the level is 'Tertiary'.",
    "level": "Tertiary"
  },
  "Product Delivery": {
    "resourceId": "Throughput",
    "category": "Product Delivery",
    "calculated_at": "2025-05-06T11:29:20",
    "ai_confidence": 83.29,
    "ai_mentions": 7.8,
    "ai_alignment": 8.9,
    "ai_depth": 8.3,
    "ai_intent": 8.6,
    "ai_audience": 8.0,
    "ai_signal": 9.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 83.0,
    "reasoning": "Mentions (7.8): The content does not explicitly use the term 'product delivery,' but frequently references concepts central to it (e.g., delivery metric, delivers completed work items, Agile and Lean contexts, flow efficiency); this scores above average but not maximal due to lack of direct naming. Alignment (8.9): The content is highly aligned—the discussion of throughput centers on measurement and feedback in Agile/Lean practices, directly related to delivery flow and product delivery outcomes. Depth (8.3): The discussion is substantial; it explains throughput, contrasts it with productivity, connects it to flow analytics, cumulative flow diagrams, and practical planning adjustments. However, it is focused on one aspect (throughput) rather than the entirety of product delivery practices, so not maximal. Intent (8.6): The piece is informative and clearly designed to help practitioners understand how throughput supports empirical inspection and continuous improvement in delivery. Audience (8.0): The target audience is practitioners involved in software delivery—Agile teams, managers, and analysts—matching well with the defined category. Signal (9.1): The content is highly focused on throughput’s relevance to delivery processes; extraneous material is minimal. No penalty deductions were needed; the content is current and supports the category framing. This resource is 'Secondary' because while deeply relevant, it concentrates on one dimension (throughput metrics), rather than the whole of product delivery.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the category, as it thoroughly explores throughput within Agile and Lean delivery contexts. While it doesn’t use the exact term 'product delivery,' it clearly addresses related concepts and is aimed at practitioners in this space. The discussion is detailed and practical, though it focuses mainly on throughput rather than the full spectrum of product delivery practices."
  },
  "Current Value": {
    "resourceId": "Throughput",
    "category": "Current Value",
    "calculated_at": "2025-05-06T11:29:22",
    "ai_confidence": 54.143,
    "ai_mentions": 2.2,
    "ai_alignment": 5.7,
    "ai_depth": 6.3,
    "ai_intent": 6.0,
    "ai_audience": 7.1,
    "ai_signal": 6.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 54.0,
    "reasoning": "The content provides a detailed exploration of throughput as a delivery metric and its role in Agile and Lean contexts. However, it never directly mentions 'Current Value' or Evidence-Based Management (EBM). \n\n- Direct Mentions (2.2): The content never refers to Current Value or EBM explicitly. It stays focused on throughput, representing only an indirect component of Current Value; thus, the score is low but above 0 because it discusses related indicator metrics.\n\n- Conceptual Alignment (5.7): While throughput can be a supporting indicator for assessing Current Value (since it relates to flow and delivery), the piece does not make this linkage explicit nor connect throughput to the tangible benefits realized by customers or organisations, which is at the heart of the Current Value dimension.\n\n- Depth of Discussion (6.3): The content discusses throughput in depth, exploring its definition, purpose, use cases (trend identification, workflow adjustments), and visualisation tools. However, it does not connect these to Current Value assessment or broader business outcomes; its depth is within a narrower metric scope.\n\n- Intent/Purpose Fit (6.0): The primary intent is educational and informative for practitioners wanting to understand throughput. The purpose is tangentially relevant to Current Value, but is not centered on assessing or discussing Current Value as defined by EBM theories.\n\n- Audience Alignment (7.1): The intended audience matches that for Current Value discussions—mainly Agile and Lean practitioners and team leaders. The focus is on process improvement and decision-making support, which aligns well with users of EBM metrics.\n\n- Signal-to-Noise Ratio (6.6): The content stays on topic and is concise about throughput and its practical applications. Nevertheless, it's largely single-metric focused and doesn't expand to directly relevant value measurement discussions, leaving the signal as solid but not highly targeted for Current Value.\n\n- No penalties were applied, as the content is current, professional, and does not contradict the category framing.\n\n- Level: The content is 'Tertiary' to the category—it is peripherally related and covers supporting metrics, but does not focus on or anchor itself in Current Value theory or measurement as required by strict category alignment.\n\nIn summary, while the content is valuable for Agile or Lean practitioners and covers an important metric, its degree of confidence for strict 'Current Value' classification is moderate-to-low, per the provided rubric.",
    "level": "Tertiary"
  },
  "Organisational Change": {
    "resourceId": "Throughput",
    "category": "Organisational Change",
    "calculated_at": "2025-05-06T11:29:25",
    "ai_confidence": 42.325,
    "ai_mentions": 1.6,
    "ai_alignment": 3.7,
    "ai_depth": 3.4,
    "ai_intent": 4.1,
    "ai_audience": 5.3,
    "ai_signal": 5.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "Direct Mentions: The content does not mention 'Organisational Change' or related terminology explicitly. Agile and Lean are referenced as contexts, but these are only connected to throughput as a metric rather than change frameworks. Hence, low marks are justified here.\n\nConceptual Alignment: The content primarily focuses on throughput as a metric for delivery and flow efficiency. While these concepts may support organisational change, they are not themselves organisational change strategies, methodologies, or frameworks. The link to change is indirect, mainly through potential discussions of improvement, but lacks clear organizational transformation language.\n\nDepth of Discussion: The text details what throughput is, how to measure it, and how it is used by teams. However, it does not discuss change processes, change frameworks, leadership roles, or other hallmark elements of organisational change. Therefore, the treatment is too metric-centered for strong depth in this category.\n\nIntent/Purpose Fit: The purpose is informative about throughput (a delivery metric used in Agile and Lean), not organisational change practices. While continuous improvement is mentioned, the focus remains on the metric, not on change management strategies or outcomes.\n\nAudience Alignment: The audience appears to be practitioners or team-level members interested in metrics and process improvement—not the primary audience expected for organisational change (executive leaders or change strategists). However, there is some overlap with Agile practitioners.\n\nSignal-to-Noise Ratio: The content is narrowly focused, mostly on-topic for throughput and its usage in Agile/Lean contexts, so distracting content is minimal. However, since the topic itself is tangential to organisational change (as defined), the relevance is not high.\n\nPenalties: No outdated references or contradictions present, so no penalties applied.\n\nLevel: Tertiary — The connection to 'Organisational Change' is indirect and supportive at best; throughput is a potential input to organisational change initiatives, but is most often a process metric, not a change topic itself.",
    "level": "Tertiary"
  },
  "Decision Making": {
    "resourceId": "Throughput",
    "category": "Decision Making",
    "calculated_at": "2025-05-06T20:57:00",
    "ai_confidence": 72.96,
    "ai_mentions": 2.7,
    "ai_alignment": 8.8,
    "ai_depth": 7.9,
    "ai_intent": 8.3,
    "ai_audience": 8.6,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 73.0,
    "reasoning": "The content focuses on throughput as a metric for flow efficiency and improvement, strongly aligning with evidence-based analysis and iterative feedback (aligned with the Decision Making category’s emphasis on structured, data-driven decisions). It directly references informed decision-making ('provides feedback that informs decision-making') but does not mention Decision Making explicitly multiple times, resulting in a lower Direct Mentions score (2.7). The conceptual alignment is high (8.8) because the content describes how throughput informs process adjustments objectively. Depth is substantial (7.9), detailing cumulative flow diagrams, constraints, feedback loops, and empirical inspection, though it is centered only around one metric and does not discuss broader frameworks or multiple methods. The intent is clearly to educate about using throughput data for operational decisions (8.3). The audience (8.6) matches practitioners and teams seeking evidence-based improvements. Signal-to-noise is high (8.5), as the discussion is focused with no filler. No penalties are applied because the content is current, objective, and reinforces category principles. The confidence score reflects strong relevance, high alignment, and actionable value, though it is not comprehensive on all Decision Making dimensions.",
    "level": "Secondary",
    "reasoning_summary": "This content fits the Decision Making category well, as it highlights how throughput data supports evidence-based process improvements. While it doesn’t cover every aspect of decision making, it clearly demonstrates how structured analysis and feedback loops guide operational choices, making it highly relevant for practitioners seeking data-driven approaches. The focus is practical and informative, with minimal extraneous detail."
  },
  "Collaboration Tools": {
    "resourceId": "Throughput",
    "category": "Collaboration Tools",
    "calculated_at": "2025-05-06T20:56:45",
    "ai_confidence": 24.2,
    "ai_mentions": 0.7,
    "ai_alignment": 2.4,
    "ai_depth": 2.7,
    "ai_intent": 1.2,
    "ai_audience": 8.1,
    "ai_signal": 6.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content does not directly mention or discuss collaboration tools or specific platforms that facilitate team collaboration in Agile environments. The main focus is on the concept of throughput as a metric for team/system performance, with reference to tools like cumulative flow diagrams and flow analytics — these, however, are analytical tools rather than collaboration platforms. The alignment and depth are minimal, as the discussion revolves around inspection and improvement using metrics rather than enhancing communication or coordination through collaboration tools. The audience is aligned because Agile practitioners are the intended readers, which lifts the audience score. The signal-to-noise ratio is above average since the content is focused, but its relevance to collaboration tools is very limited. Overall, the very low confidence score reflects the lack of direct or meaningful connection to the specified category, while acknowledging a minor indirect link via some analytic tools.",
    "level": "Ignored"
  },
  "Business Agility": {
    "resourceId": "Throughput",
    "category": "Business Agility",
    "calculated_at": "2025-05-06T20:57:00",
    "ai_confidence": 70.6,
    "ai_mentions": 2.4,
    "ai_alignment": 8.0,
    "ai_depth": 6.8,
    "ai_intent": 7.5,
    "ai_audience": 7.2,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 71.0,
    "reasoning": "The content discusses throughput as a metric for quantifying work completed, emphasizing its role in flow efficiency, detecting constraints, and supporting continuous improvement. While the topic is relevant for Agile and Lean practices, which are foundational to business agility, the term 'business agility' is not directly mentioned. Instead, the content stays at the team/process metric level, focusing on throughput itself rather than the broader organizational or strategic themes central to business agility (such as leadership, culture, or enterprise agility frameworks). Still, it discusses its value in Agile and Lean contexts and positively aligns with the concerns of organizations pursuing responsiveness and empirical improvement. The discussion is moderately deep, providing explanation and situational usage, but does not extend to case studies, broader frameworks, or organizational implementation. The intent is informative and fits professionals interested in optimizing delivery, but is slightly below a full strategic alignment. The target audience appears to be practitioners and team leads, which overlaps but does not fully encompass the executive/organizational audience for business agility. The content is tightly focused, with minimal off-topic or filler discussion. Thus, the confidence score accurately reflects that, while solidly aligned, the discussion is not deeply or explicitly anchored in business agility as defined.",
    "level": "Secondary",
    "reasoning_summary": "The content effectively explains throughput as a key metric for Agile and Lean teams, highlighting its role in improving flow and identifying bottlenecks. While it’s highly relevant for those optimising delivery processes, it doesn’t directly address broader business agility themes like leadership or organisational change, making it more suitable for practitioners than strategic decision-makers."
  },
  "Organisational Agility": {
    "resourceId": "Throughput",
    "category": "Organisational Agility",
    "calculated_at": "2025-05-06T20:56:45",
    "ai_confidence": 67.52,
    "ai_mentions": 2.2,
    "ai_alignment": 7.6,
    "ai_depth": 7.3,
    "ai_intent": 7.7,
    "ai_audience": 8.1,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content focuses on throughput as a delivery metric and emphasizes inspection, flow efficiency, system constraints, and using throughput for empirical analysis and continuous improvement. These concepts align well with Organisational Agility, particularly through the mention of Agile and Lean contexts, use of analytics, and enabling organizational transparency and adaptability. However, the content stays narrowly focused on one metric rather than broader strategic, leadership, or cultural aspects of Organisational Agility, resulting in moderate rather than high scores for depth and conceptual alignment. The intent matches the category by supporting process improvement and agility, and the target audience (teams interested in delivery process improvement) aligns closely. The signal-to-noise ratio is high since the discussion remains relevant and focused. No penalties are warranted as the content is current, not critical or satirical, and reflects up-to-date practices. The overall confidence score reflects a solid but not comprehensive fit to the category.",
    "level": "Secondary"
  },
  "Backlog Refinement": {
    "resourceId": "Throughput",
    "category": "Backlog Refinement",
    "calculated_at": "2025-05-06T20:57:00",
    "ai_confidence": 8.3,
    "ai_mentions": 0.2,
    "ai_alignment": 1.8,
    "ai_depth": 1.0,
    "ai_intent": 1.1,
    "ai_audience": 2.1,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content focuses entirely on 'Throughput', a delivery metric for quantifying completed work over time and supporting flow improvement practices. There is no direct mention of Backlog Refinement, nor is there discussion of refining backlog items, prioritization, user stories, or related practices. While throughput can inform aspects of agile process inspection (including refinement), the content lacks conceptual alignment and depth relevant to Backlog Refinement. Its audience is broadly agile/lean practitioners interested in metrics, not those specifically seeking Backlog Refinement guidance. Nearly all of the content is off-topic for backlog refinement, but a small overlap exists in the general agile improvement philosophy. Consequently, the confidence score is very low, with minimal scores across all dimensions and no penalties applied.",
    "level": "Ignored"
  },
  "Scrum Team": {
    "resourceId": "Throughput",
    "category": "Scrum Team",
    "calculated_at": "2025-05-06T20:56:45",
    "ai_confidence": 13.3,
    "ai_mentions": 0.7,
    "ai_alignment": 1.8,
    "ai_depth": 2.4,
    "ai_intent": 2.8,
    "ai_audience": 3.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content focuses entirely on throughput as a metric for measuring delivery in a system or team context. There is no explicit mention of 'Scrum Team', nor are Scrum-specific accountabilities, structure, or the distinctions defined by the Scrum Guide explored. The concept aligns most closely to teams in Agile or Lean contexts, but does not discuss the Scrum Team, its structure, purpose, or role in accountability. The depth is limited to key benefits, tools, and outcomes of using throughput, but not specific to Scrum Team responsibilities or self-management. The intended audience appears to be delivery teams or flow-focused practitioners generally, not specifically those interested in the nuances of Scrum Team accountability. The relevance signal is focused on flow and metrics; while somewhat useful to Scrum Teams, it is incidental rather than direct. Penalties are not applied, as there is no outdated or contradictory content. Overall, confidence that this specifically fits the 'Scrum Team' category is very low.",
    "level": "Ignored"
  },
  "Agile Strategy": {
    "resourceId": "Throughput",
    "category": "Agile Strategy",
    "calculated_at": "2025-05-06T20:56:45",
    "ai_confidence": 52.6,
    "ai_mentions": 2.4,
    "ai_alignment": 5.1,
    "ai_depth": 5.7,
    "ai_intent": 5.0,
    "ai_audience": 6.0,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 53.0,
    "reasoning": "The content discusses throughput as a delivery metric, emphasizing its use in analyzing flow efficiency, investigating system constraints, and supporting empirical inspection. Although Agile is referenced briefly (\"In Agile and Lean contexts\"), the primary focus is on throughput itself as a metric, rather than on strategic or organizational alignment with Agile principles. The description covers how throughput helps teams inspect delivery and improve workflow, which aligns somewhat with Agile's continuous improvement principle but does not explicitly address strategic planning, organizational vision, or leadership roles tied to Agile Strategy. The depth is moderate, providing more than surface-level discussion but focused on metric usage and tools (like cumulative flow diagrams) rather than strategic integration. The audience aligns somewhat with Agile practitioners or managers interested in metrics, but is not exclusively targeted at executive or strategic stakeholders. The intent is informative about a practice relevant within Agile, but not about Agile Strategy as defined in the classification. Signal-to-noise ratio is good, with little irrelevant content, but much is technical/process-focused rather than strategic. No penalties apply, as the content is current and neutral in tone.",
    "level": "Tertiary"
  },
  "Scrum": {
    "resourceId": "Throughput",
    "category": "Scrum",
    "calculated_at": "2025-05-06T20:57:01",
    "ai_confidence": 40.55,
    "ai_mentions": 0.4,
    "ai_alignment": 4.7,
    "ai_depth": 4.1,
    "ai_intent": 4.7,
    "ai_audience": 6.2,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 41.0,
    "reasoning": "The content discusses throughput as a delivery metric, focusing on its role in quantifying completed work over time and supporting empirical process control. While the content references principles like transparency, inspection, and continuous improvement, these are broader Agile and Lean concepts and not exclusive to Scrum. There is no explicit mention of Scrum, its roles, events, or artifacts. The main ideas overlap with Scrum in areas such as empirical inspection and iterative improvement, but the discussion remains generic, referencing Agile and Lean equally. The depth is moderate, focusing on throughput's uses and tooling, but not directly connecting to Scrum events or artifacts (e.g., sprints, backlogs). The intent is informative for practitioners measuring workflow but is not purpose-built for Scrum audiences. The audience alignment is fairly strong, as Scrum teams may track throughput, but the relevance for Scrum is tangential. The signal-to-noise ratio is high, as the content is focused and clear without filler, yet remains framework-agnostic. No penalties are applied, as the content is not outdated or critical, but the lack of direct Scrum framing and primary context limits overall confidence.",
    "level": "Tertiary"
  },
  "Product Validation": {
    "resourceId": "Throughput",
    "category": "Product Validation",
    "calculated_at": "2025-05-06T20:56:49",
    "ai_confidence": 21.8,
    "ai_mentions": 0.5,
    "ai_alignment": 2.8,
    "ai_depth": 2.2,
    "ai_intent": 2.7,
    "ai_audience": 5.2,
    "ai_signal": 4.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 22.0,
    "reasoning": "The content discusses throughput as a delivery metric, focusing on flow efficiency, system constraints, and delivery performance. There are no explicit or frequent direct mentions of 'product validation' or its key topics—such as user testing, market fit analysis, or prototyping with real customers. Conceptually, the focus is on process optimization and workflow inspection (e.g., using cumulative flow diagrams), which supports general product and process improvement but lacks alignment with validating product ideas against user needs. The depth is limited to agile and lean throughput practices, not extending into user engagement or validation loops. The intent is to inform teams about throughput measurement for flow efficiency, not to guide users on product validation strategies. The audience could overlap with those interested in validation (e.g., product teams), but the content is more about process effectiveness than validation. Signal-to-noise is moderate since all content is focused, but not on the relevant application. No penalties for outdated content or negative tone are required. The overall confidence score reflects the limited applicability to the 'Product Validation' category.",
    "level": "Ignored"
  },
  "Site Reliability Engineering": {
    "resourceId": "Throughput",
    "category": "Site Reliability Engineering",
    "calculated_at": "2025-05-06T20:56:49",
    "ai_confidence": 36.05,
    "ai_mentions": 0.6,
    "ai_alignment": 3.2,
    "ai_depth": 2.9,
    "ai_intent": 3.7,
    "ai_audience": 4.8,
    "ai_signal": 3.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 36.0,
    "reasoning": "The content focuses on throughput as a metric for delivery and workflow analysis. While throughput is relevant to monitoring and system performance, the discussion is set in the context of Agile, Lean, and general workflow efficiency, not specifically Site Reliability Engineering (SRE). There are no direct mentions of SRE, its principles, or its unique practices (such as SLOs, SLIs, incident response, or Google SRE's formalized definitions). The conceptual alignment is modest, as reliability engineers may consider throughput, but the main ideas and intent are about delivery optimization and team performance, which is tangential to the SRE category. The audience appears geared toward teams engaged in software delivery process improvement (Agile/Lean), rather than SRE practitioners specifically. There is some relevance, but the content does not explore or connect to the core practices or concerns of SRE, and thus earns a low-to-moderate confidence score.",
    "level": "Ignored"
  },
  "Kanban": {
    "resourceId": "Throughput",
    "category": "Kanban",
    "calculated_at": "2025-05-06T20:56:49",
    "ai_confidence": 77.7,
    "ai_mentions": 2.3,
    "ai_alignment": 8.8,
    "ai_depth": 7.6,
    "ai_intent": 8.5,
    "ai_audience": 8.6,
    "ai_signal": 8.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 78.0,
    "reasoning": "The content focuses on throughput as a metric for measuring work completed over time, explicitly referencing its use in observing flow, identifying constraints, and supporting continuous improvement. These concepts are central to Kanban practice—particularly the emphasis on flow efficiency, visual metrics (cumulative flow diagrams), and feedback-driven improvement. However, the content does not mention 'Kanban' explicitly, nor does it describe Kanban boards, WIP limits, or other direct practices, thus the 'Direct Mentions' score is low. The conceptual alignment, depth, intent, and audience scores are high, as the topic appeals directly to practitioners interested in flow-based, empirical delivery systems and resonates strongly with Kanban philosophy. The signal-to-noise ratio is also high as the discussion is focused with little irrelevant information. No out-of-date or contradictory content is present; therefore, no penalties are applied. The overall confidence reflects strong conceptual matching to Kanban, somewhat limited by the lack of explicit category mention.",
    "level": "Secondary",
    "reasoning_summary": "This content aligns well with Kanban principles by emphasising flow, throughput, and continuous improvement—core aspects of Kanban practice. While it doesn’t directly mention Kanban or its specific tools, the focus on empirical, flow-based delivery systems makes it highly relevant for practitioners in this area. The discussion is clear, targeted, and free from irrelevant or outdated information, supporting a strong conceptual match to the category."
  },
  "Agile Leadership": {
    "resourceId": "Throughput",
    "category": "Agile Leadership",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 41.6,
    "ai_mentions": 1.1,
    "ai_alignment": 3.2,
    "ai_depth": 3.8,
    "ai_intent": 3.0,
    "ai_audience": 6.2,
    "ai_signal": 4.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content focuses on explaining throughput as an Agile/Lean delivery metric, emphasizing its value for teams and system flow. While it references concepts like improvement and decision-making, there are no explicit or substantial mentions of Agile leadership, nor direct discussion of leadership roles, practices, or empowerment strategies. The content is conceptually adjacent—throughput data may be used by leaders, but leadership itself is not discussed. The depth is moderate, as the text stays focused on metric explanation, not broader leadership implications. Intent is to inform about throughput, not Agile leadership. The audience is likely Agile practitioners or teams rather than leaders, though leaders could find it useful. Signal is reasonably high due to focus, but relevance to the category is tangential. No outdated ideas or contradictory tones observed; thus, no penalties applied. Overall, the confidence score reflects a weak alignment with the 'Agile Leadership' category.",
    "level": "Tertiary"
  },
  "Digital Transformation": {
    "resourceId": "Throughput",
    "category": "Digital Transformation",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 39.25,
    "ai_mentions": 0.2,
    "ai_alignment": 3.1,
    "ai_depth": 3.6,
    "ai_intent": 3.9,
    "ai_audience": 6.2,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content focuses narrowly on the concept of throughput as a delivery and observability metric, exploring its role in flow efficiency, system constraints, and empirical inspection within Agile and Lean contexts. However, it does not mention or relate directly to 'Digital Transformation,' nor does it explicitly discuss the adoption or integration of digital technologies to enhance business agility, foster innovation, or transform organizational processes or culture. The closest connection is the reference to analytics tools for visualizing throughput, which could be tangentially related to digital transformation methodologies. The discussion lacks strategic context, broader technological implications, or significant relevance to digital transformation case studies, change management, or business transformation metrics. As such, the alignment, depth, and intent scores are moderate. The intended audience (teams interested in flow optimization, potentially digital or operational teams) aligns partially with the digital transformation audience, and the content is focused with little off-topic material, so signal is higher. No penalties for outdated or contradictory tone were necessary.",
    "level": "Ignored"
  },
  "Daily Scrum": {
    "resourceId": "Throughput",
    "category": "Daily Scrum",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 8.2,
    "ai_mentions": 0.0,
    "ai_alignment": 1.3,
    "ai_depth": 1.1,
    "ai_intent": 1.8,
    "ai_audience": 2.5,
    "ai_signal": 1.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content focuses entirely on throughput as a flow and delivery metric used in Agile and Lean systems but does not mention or allude to the Daily Scrum or its specific practices, structure, or purpose. There are no direct mentions of Daily Scrum (score: 0.0). Conceptual alignment is extremely low, as although the content briefly touches on empirical inspection and transparency, these are not discussed in the context of the Daily Scrum (score: 1.3). The depth of discussion is also minimal regarding the Daily Scrum (score: 1.1), as all substantial content pertains to throughput metrics and flow analytics. The intent is only tangentially related, since the information could theoretically be relevant to Scrum practitioners but the main purpose is generic process inspection rather than focusing on the Daily Scrum event (score: 1.8). For audience alignment, the content targets Agile/Lean practitioners, which may overlap somewhat with those interested in Daily Scrum topics, but not specifically (score: 2.5). Signal is low due to lack of overlap or relevant material for this category (score: 1.5). No penalties are warranted as the content is current and neutral in tone. The final score is low, reflecting that the content does not meaningfully fit under the Daily Scrum category.",
    "level": "Ignored"
  },
  "Value Stream Management": {
    "resourceId": "Throughput",
    "category": "Value Stream Management",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 67.6,
    "ai_mentions": 2.4,
    "ai_alignment": 8.0,
    "ai_depth": 6.7,
    "ai_intent": 7.7,
    "ai_audience": 7.0,
    "ai_signal": 7.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 68.0,
    "reasoning": "The content centers on 'throughput' as a key system metric, commonly used in Agile and Lean contexts to analyze work flow, system performance, and constraints. This is highly relevant to Value Stream Management, as throughput is one of the important metrics used for assessing value delivery and identifying process bottlenecks. The alignment score is high (8.0) because while throughput is crucial to value stream analysis, the content doesn't explicitly mention 'Value Stream Management' or discuss the full methodology. The depth of discussion is moderately high (6.7), covering applications, distinctions from productivity, and links to process improvement, but does not address VSM frameworks, mapping, or organizational alignment directly. Intent is solid (7.7), as the article seeks to inform practitioners on flow-centric metrics, aiding transparency and improvement, which are core to VSM's aims. Audience is technical/operational (7.0), appropriate for practitioners involved in system improvement, but not exclusively tailored to VSM strategists or executives. The signal-to-noise ratio is strong (7.2) since the entire piece is focused on throughput's role in delivery performance without off-topic tangents. Low direct mention score (2.4) reflects the absence of explicit 'Value Stream Management' references. No penalties were applied as the content is current and neutral in tone.",
    "level": "Secondary"
  },
  "Technical Leadership": {
    "resourceId": "Throughput",
    "category": "Technical Leadership",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 64.6,
    "ai_mentions": 2.1,
    "ai_alignment": 7.0,
    "ai_depth": 6.3,
    "ai_intent": 7.2,
    "ai_audience": 8.0,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 65.0,
    "reasoning": "The content provides a focused description of throughput as a delivery metric, emphasizing its application in Agile and Lean contexts to inspect flow and system performance. It discusses tools (e.g., cumulative flow diagrams), concepts (flow of value, work-in-progress limits, team adjustments), and the importance of transparency and continuous improvement—elements relevant to agile technical leadership. However, there are no direct mentions or explicit references to 'technical leadership' or its named principles. While the content aligns with the interest areas of technical leaders (e.g., leveraging metrics for improvement, informing team decisions), it doesn't deeply discuss leadership roles, team dynamics, coaching, or direct application of leadership strategies. The audience is likely technical leaders or practitioners who care about delivery metrics, but it is not exclusive to technical leadership, which slightly lowers the alignment and intent scores. No penalties were needed, as the content is up to date, constructive in tone, and free from outdated or contrary practices.",
    "level": "Secondary"
  },
  "Lean Product Development": {
    "resourceId": "Throughput",
    "category": "Lean Product Development",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 65.35,
    "ai_mentions": 3.7,
    "ai_alignment": 7.2,
    "ai_depth": 6.9,
    "ai_intent": 7.1,
    "ai_audience": 7.6,
    "ai_signal": 6.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 65.0,
    "reasoning": "The content discusses 'throughput' as a metric for inspecting how much work is completed over time. The description ties throughput to analysis of flow efficiency and system constraints, which are germane to Lean Product Development principles of waste reduction and process optimization. There's mention of Lean and Agile contexts, cumulative flow diagrams, and continuous improvement, showing some conceptual overlap. However, the article does not directly use the phrase 'Lean Product Development,' nor does it delve into broader Lean principles, customer focus, or cultural transformation. The primary focus is metric-centric rather than discussing the full span of Lean methods or tools like A3 Problem Solving or Value Stream Mapping. Audience targeting aligns well, suitable for Lean practitioners or teams tracking delivery performance, but the scope is narrower than the full category. No outdated practices or contradictory tone are present, so no penalties are applied. The confidence reflects moderate-to-strong category fit based on partial but clearly related content.",
    "level": "Secondary"
  },
  "One Engineering System": {
    "resourceId": "Throughput",
    "category": "One Engineering System",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 16.25,
    "ai_mentions": 0.2,
    "ai_alignment": 1.0,
    "ai_depth": 1.1,
    "ai_intent": 2.0,
    "ai_audience": 6.1,
    "ai_signal": 2.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "The content focuses on explaining throughput as a delivery metric in software engineering contexts, particularly in relation to Agile and Lean practices. There are no direct mentions or explicit references to 'One Engineering System' or its framework, goals, or integration principles. Conceptual alignment and depth are minimal, as the discussion is generic and could apply to most engineering methodologies. The intent is informative but not targeted at 1ES unification or standardisation. Audience is technical, matching the typical 1ES audience, but the signal-to-noise ratio suffers due to the absence of any real link to 1ES. No penalties were applied as there is no outdating or contradicting tone, but overall, the confidence for this being content about 'One Engineering System' is very low.",
    "level": "Ignored"
  },
  "Enterprise Agility": {
    "resourceId": "Throughput",
    "category": "Enterprise Agility",
    "calculated_at": "2025-05-06T20:57:01",
    "ai_confidence": 37.35,
    "ai_mentions": 0.6,
    "ai_alignment": 3.7,
    "ai_depth": 2.9,
    "ai_intent": 3.5,
    "ai_audience": 3.4,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content focuses on throughput as a delivery metric relevant to Agile and Lean practices. However, it primarily describes throughput in the context of team-level flow efficiency and observability, rather than relating it to organisation-wide agility or transformation. There are no direct mentions of 'Enterprise Agility', frameworks for scaling agility, organisational structures, culture, leadership roles, or change management at scale. Alignment is partial—the metric can be used at an enterprise level for agility, but the piece does not frame it as such. Depth is limited: it remains on tool usage and metric definition, without exploring how throughput supports enterprise-wide responsiveness or adaptability. The intent is to inform about throughput, not about enterprise agility per se. The target audience appears to be practitioners (teams or team leads) rather than organisational leaders or strategists. The signal-to-noise ratio is relatively high because the content stays tightly focused on throughput, but its scope is too narrow for strong relevance to Enterprise Agility. No penalties are applied since the content is current, accurate, and neutral in tone.",
    "level": "Ignored"
  },
  "Project Management": {
    "resourceId": "Throughput",
    "category": "Project Management",
    "calculated_at": "2025-05-06T20:57:02",
    "ai_confidence": 79.5,
    "ai_mentions": 3.2,
    "ai_alignment": 8.7,
    "ai_depth": 7.9,
    "ai_intent": 8.1,
    "ai_audience": 8.6,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 80.0,
    "reasoning": "The content focuses on throughput as a metric for evaluating system delivery performance and workflow efficiency, which is relevant to project management, especially within Agile and Lean methodologies. In terms of direct mentions, there is no explicit reference to 'project management' or common methodologies by name, resulting in a lower score in that dimension. However, the conceptual alignment is strong: throughput and its use for flow inspection, constraint identification, planning, and continuous improvement are core topics in project management practices. Discussion depth is moderate, discussing throughput's role, usage, and associated tools (cumulative flow diagrams, flow analytics) but lacking broader coverage of multiple methodologies or phases. The audience appears well-targeted—practitioners interested in project oversight, process improvement, and agile/lean metrics. The signal-to-noise ratio is high with tight, relevant content, and there is no obsolete information or penalties. The overall confidence reflects good alignment and practical relevance to project management but does not reach maximum scores due to limited direct references and a somewhat narrow focus on the throughput metric rather than holistic project management practices.",
    "level": "Secondary",
    "reasoning_summary": "This content is a good fit for the project management category, as it explores throughput—a key metric in Agile and Lean workflows—and its role in process improvement and planning. While it doesn’t explicitly mention project management or specific methodologies, its focus on practical tools and concepts makes it highly relevant for professionals seeking to optimise delivery and workflow efficiency."
  },
  "Sensemaking": {
    "resourceId": "Throughput",
    "category": "Sensemaking",
    "calculated_at": "2025-05-06T20:57:02",
    "ai_confidence": 42.35,
    "ai_mentions": 1.65,
    "ai_alignment": 4.75,
    "ai_depth": 4.9,
    "ai_intent": 5.35,
    "ai_audience": 8.05,
    "ai_signal": 8.25,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content titled 'Throughput' focuses on the definition and practical application of throughput as a metric in delivery contexts. It covers how throughput is measured and tools used for visualisation (e.g., cumulative flow diagrams), as well as how it enables improvement and decision-making in Agile/Lean processes. However, there are almost no direct references to the concept or terminology of 'Sensemaking.' While the content tangentially touches on the use of data for decision-making ('informs decision-making,' 'empirical inspection'), it does not directly delve into the principles of sensemaking, models/frameworks for complexity, or organisational interpretive practices. The main audience (teams using Agile/Lean) partially overlaps but is more operational/technical than the broader organisational and leadership focus of sensemaking. Signal-to-noise is high due to the focused description, but the depth in direct sensemaking concepts is limited, and the core intent appears more about performance measurement than about interpreting complex situations for informed, adaptive organisational decisions. No penalties apply, as the content is not outdated or satirical, but overall confidence is limited by lack of explicit and substantial sensemaking discussion.",
    "level": "Tertiary"
  },
  "Team Performance": {
    "resourceId": "Throughput",
    "category": "Team Performance",
    "calculated_at": "2025-05-06T20:57:02",
    "ai_confidence": 95.1,
    "ai_mentions": 8.7,
    "ai_alignment": 9.6,
    "ai_depth": 9.4,
    "ai_intent": 9.3,
    "ai_audience": 9.2,
    "ai_signal": 8.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 95.0,
    "reasoning": "The content directly explores throughput as a team-level delivery metric and consistently frames it within the context of system-wide performance, aligning closely with the 'Team Performance' category definition. It avoids focusing on individual metrics, HR evaluation, or culture-only arguments, dedicating nearly all of its detail to measuring and interpreting team delivery using systemic data. The explanation of throughput's role in diagnosing system constraints, continuous improvement, and empirical feedback directly fits key classification topics. The audience is clearly delivery teams, agile practitioners, and those analyzing work systems. Slight deductions in 'mentions' and 'signal' reflect that while the main category term ('team performance') is not repeatedly used verbatim, the concepts are processed in-depth. All other dimensions score highly due to the content's relevance, thoroughness, and actionable focus for the intended audience. No penalties apply as the content is current, neutral-toned, and maps perfectly to the classification scoring requirements.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the 'Team Performance' category, as it thoroughly discusses throughput as a team-level metric and its impact on system-wide delivery. It avoids individual or HR-focused measures, instead offering actionable insights for teams and agile practitioners. The focus on systemic data and continuous improvement makes it highly relevant, even though the exact term 'team performance' isn’t used repeatedly."
  },
  "Platform Engineering": {
    "resourceId": "Throughput",
    "category": "Platform Engineering",
    "calculated_at": "2025-05-06T20:57:02",
    "ai_confidence": 12.6,
    "ai_mentions": 0.2,
    "ai_alignment": 1.5,
    "ai_depth": 1.8,
    "ai_intent": 1.7,
    "ai_audience": 3.1,
    "ai_signal": 2.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content is a general overview of the throughput metric in the context of flow efficiency and system performance. There is no direct mention of platform engineering or related concepts such as Internal Developer Platforms (IDPs), standardization, automation, or self-service capabilities. The content refers broadly to Agile and Lean principles and observability metrics without any explicit connection to the core focus areas of platform engineering. Its intent is to explain throughput as a metric, which may incidentally be relevant in platform engineering but is not the focus here. The targeted audience appears to be general software teams or process improvement practitioners, not specifically platform engineers. Most information is relevant to general process or delivery optimization, resulting in a low confidence score for the platform engineering category.",
    "level": "Ignored"
  },
  "Windows": {
    "resourceId": "Throughput",
    "category": "Windows",
    "calculated_at": "2025-05-06T20:56:46",
    "ai_confidence": 3.42,
    "ai_mentions": 0.0,
    "ai_alignment": 0.8,
    "ai_depth": 1.1,
    "ai_intent": 1.5,
    "ai_audience": 5.0,
    "ai_signal": 5.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content never directly mentions Windows, nor does it align conceptually with the Windows OS or its management. Its focus is on the general concept of throughput as a performance and delivery metric, often found in software development and agile methodologies—there is no reference to Windows installation, configuration, updates, troubleshooting, or any other topic relevant to the Windows category. The depth is low because no part of the content discusses Windows-specific concepts or guidance. Intent is misaligned, as the purpose is to inform about throughput as a metric, not about Windows. The audience is generic (possibly technical teams), not specifically those interested in Windows OS, but could incidentally include Windows practitioners. The signal is reasonably focused on throughput, but again, not within the Windows context. No penalties are needed since the content is not outdated or critical in tone, merely irrelevant to the Windows category.",
    "level": "Ignored"
  },
  "Customer Feedback Loops": {
    "resourceId": "Throughput",
    "category": "Customer Feedback Loops",
    "calculated_at": "2025-05-06T20:56:46",
    "ai_confidence": 24.74,
    "ai_mentions": 0.35,
    "ai_alignment": 2.44,
    "ai_depth": 2.58,
    "ai_intent": 1.88,
    "ai_audience": 3.16,
    "ai_signal": 2.77,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 25.0,
    "reasoning": "The content focuses on the concept of throughput as a delivery metric in Agile and Lean environments, primarily discussing workflow efficiency, flow analytics, and empirical process improvement. While feedback and continuous improvement are mentioned (e.g., 'throughput enables empirical inspection' and 'provides feedback that informs decision-making'), these are generic references to operational feedback, not to customer feedback or the integration of customer insights into product development. There are no explicit or implicit references to mechanisms for collecting, analyzing, or acting on customer feedback, nor are key themes like feedback loops, customer insight gathering, or integration into the product backlog explored. The audience (teams measuring delivery effectiveness) moderately overlaps with those interested in feedback loops, but the content is not targeted toward customer-feedback-driven practices. Overall, the fit is low, as it does not substantially address or illustrate the 'Customer Feedback Loops' category.",
    "level": "Ignored"
  },
  "Scaling": {
    "resourceId": "Throughput",
    "category": "Scaling",
    "calculated_at": "2025-05-06T20:56:46",
    "ai_confidence": 40.25,
    "ai_mentions": 0.3,
    "ai_alignment": 4.7,
    "ai_depth": 4.8,
    "ai_intent": 5.5,
    "ai_audience": 6.2,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 40.0,
    "reasoning": "The content is focused on the metric of throughput as it relates to Agile and Lean practices, specifically in terms of flow, system constraints, and performance evaluation. While throughput is relevant to the measurement of value delivery at scale, the content does not explicitly address scaling frameworks, cross-team coordination, or enterprise-level challenges. There is only an implicit (not direct) connection to the Scaling category, as throughput can be a KPI in scaled environments, but the article is entirely generic—it does not mention scaling, multi-team coordination, or practices like SAFe/LeSS/Nexus. Depth is moderate: the explanation is thorough about throughput itself, but does not expand to broader scaling methodologies. The audience seems to be Agile practitioners interested in metrics, possibly relevant for scaling contexts, but the main intent is not explicitly about scaling. Signal-to-noise is reasonably high as the content is focused, but the scope is narrower than required for 'Scaling.' No penalties are applied as the content is recent, not critical, and not satirical. Thus, the confidence is low-to-moderate.",
    "level": "Ignored"
  },
  "Test Automation": {
    "resourceId": "Throughput",
    "category": "Test Automation",
    "calculated_at": "2025-05-06T20:56:46",
    "ai_confidence": 5.8,
    "ai_mentions": 0.0,
    "ai_alignment": 1.4,
    "ai_depth": 1.9,
    "ai_intent": 0.9,
    "ai_audience": 0.8,
    "ai_signal": 0.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 6.0,
    "reasoning": "The content explicitly discusses 'throughput' as a metric for delivery and system flow in Agile and Lean contexts, focusing on process analysis and efficiency, not on anything test automation-specific. There are zero mentions of test automation or its tools, principles, frameworks, or practices. The conceptual alignment is very low, as throughput, while a potentially useful metric in automated CI/CD pipelines, is covered here only as a general delivery and process metric, not in the context of software testing or automation. The depth is minimal regarding test automation, and the intent clearly aligns with workflow optimization rather than automated testing practices. The audience is more focused on delivery and process-oriented individuals rather than practitioners of test automation. The signal-to-noise ratio is low for test automation, as all of the content is off-topic for this category. No penalties were applied, as the content is not outdated or contradictory; it simply doesn't align. The final confidence score reflects an extremely weak fit.",
    "level": "Ignored"
  },
  "Technical Excellence": {
    "resourceId": "Throughput",
    "category": "Technical Excellence",
    "calculated_at": "2025-05-06T20:56:46",
    "ai_confidence": 45.383,
    "ai_mentions": 0.2,
    "ai_alignment": 4.7,
    "ai_depth": 3.9,
    "ai_intent": 4.2,
    "ai_audience": 5.0,
    "ai_signal": 6.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 45.0,
    "reasoning": "The content thoroughly explains throughput as a delivery metric, focusing on its utility for analyzing flow, detecting constraints, and supporting continuous improvement. However, it does not mention 'technical excellence' directly, nor does it explicitly discuss core engineering practices (like TDD, CI/CD, modular architecture, or emergent design) central to the classification definition. The conceptual alignment is moderate: while throughput and its observability contribute indirectly to technical excellence by enabling improvement and transparency, the content centers on process measurement rather than engineering practices. Depth is moderate, focusing on how throughput can guide decision-making, but lacking deeper discussion on how it directly improves technical excellence. The intent is informative and largely relevant to teams interested in technical performance, which partially overlaps with the intended audience for technical excellence. The signal-to-noise ratio is good, as all content is relevant to metrics, though the connection to technical excellence is indirect. No penalties were necessary as there is no outdated or undermining tone, and no obsolete practices were referenced.",
    "level": "Tertiary"
  },
  "Behaviour Driven Development": {
    "resourceId": "Throughput",
    "category": "Behaviour Driven Development",
    "calculated_at": "2025-05-06T20:56:46",
    "ai_confidence": 8.8,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.3,
    "ai_intent": 0.4,
    "ai_audience": 1.2,
    "ai_signal": 0.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content fully centers around software delivery metrics (throughput), flow analysis, and Lean/Agile practices. There is no mention or reference to Behaviour Driven Development (BDD) or any of its key concepts (user stories, acceptance criteria, BDD tools, collaboration with business stakeholders, scenario specification, etc.). The main focus is on process performance measurement—a topic allied to Agile delivery but strictly outside BDD's scope. Therefore, it barely fits the BDD category except in the most tangential sense (i.e., teams using BDD might also care about throughput, but the connection is not explicit here). Scores are extremely low across all dimensions; no penalties were needed since the tone and recency are appropriate.",
    "level": "Ignored"
  },
  "Mentoring": {
    "resourceId": "Throughput",
    "category": "Mentoring",
    "calculated_at": "2025-05-06T20:56:46",
    "ai_confidence": 17.06,
    "ai_mentions": 0.1,
    "ai_alignment": 2.4,
    "ai_depth": 1.8,
    "ai_intent": 1.9,
    "ai_audience": 3.4,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 17.0,
    "reasoning": "The content focuses on the concept of 'throughput' as a metric for work completed in a system, with detailed discussion of how it aids in inspecting flow, identifying constraints, and driving continuous improvement. There are no direct mentions of mentoring or coaching, nor does the content discuss guidance, skill development, or mentoring relationships. The article is more about understanding and using throughput metrics, which is tangentially relevant only to mentoring as background knowledge for team improvement. Most examples are tool/process-oriented and not centered on the mentoring process or the development of people. The primary audience appears to be Agile practitioners or team leads interested in flow metrics. Overall, due to the lack of explicit references to mentoring and a focus outside the mentoring process, the confidence is low.",
    "level": "Ignored"
  },
  "Evidence Based Management": {
    "resourceId": "Throughput",
    "category": "Evidence Based Management",
    "calculated_at": "2025-05-06T20:56:46",
    "ai_confidence": 77.8,
    "ai_mentions": 2.7,
    "ai_alignment": 8.6,
    "ai_depth": 8.2,
    "ai_intent": 8.1,
    "ai_audience": 7.4,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 78.0,
    "reasoning": "The content focuses on throughput as a metric for observing and analyzing workflow efficiency, emphasizing empirical inspection and data-informed decision-making—both core themes of Evidence Based Management (EBM). Although 'Evidence Based Management' is not mentioned by name (low direct mention score), discussion centers on relevant practices: using throughput metrics to inspect value delivery, detect constraints, drive improvements, and inform management decisions. The article connects metric tracking to outcomes (flow efficiency, continuous improvement), aligning with EBM’s outcome-driven approach rather than just output measurement. The depth is strong, as the content details quantitative inspection, analysis tools (cumulative flow, analytics), and practical implications for team/planning adjustments. The primary audience matches well—managers, team leads, or Agile practitioners seeking to inform management decisions with hard metrics. There is minimal off-topic discussion, maintaining a focused signal. Since no obsolete practices or contradictory tones are present, no penalties were applied. The medium confidence score reflects clear conceptual and practical fit with EBM, moderately hampered by the lack of explicit category naming and only tangential reference to some EBM key topics (e.g., less on unrealized value or innovation rate).",
    "level": "Secondary",
    "reasoning_summary": "This content aligns well with Evidence Based Management, as it highlights the use of throughput metrics to guide workflow improvements and management decisions. While it doesn’t explicitly mention EBM, its focus on data-driven analysis, outcome measurement, and practical tools makes it highly relevant for managers and Agile practitioners aiming to optimise value delivery through empirical methods."
  },
  "Product Development": {
    "resourceId": "Throughput",
    "category": "Product Development",
    "calculated_at": "2025-05-06T20:56:46",
    "ai_confidence": 87.45,
    "ai_mentions": 6.3,
    "ai_alignment": 9.2,
    "ai_depth": 8.6,
    "ai_intent": 9.0,
    "ai_audience": 8.8,
    "ai_signal": 9.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 87.0,
    "reasoning": "The content provides a detailed discussion of throughput as a metric for measuring delivery flow, a foundational concept in Agile and Lean product development methodologies. Though the term 'Product Development' is not directly stated, the content clearly frames throughput in the context of iterative improvement, empirical inspection, and feedback loops—all core themes of the category. The explanation connects throughput to team practices such as adjusting WIP limits, inspecting for constraints, using cumulative flow diagrams, and driving continuous improvement, hallmarks of modern product development. The intended audience is practitioners interested in improving delivery processes, which closely matches the category. The minor deduction in 'mentions' reflects the absence of explicit category naming, but this does not detract from the strong conceptual and practical alignment with the definition and key topics. There is very little irrelevant or off-topic material; the entire piece is highly focused. No penalties were applied, as the content is up-to-date, constructive, and directly supports the advancement of product development methodologies.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the Product Development category. It explores throughput as a key metric within Agile and Lean frameworks, focusing on iterative improvement and feedback—central to product development. While the term isn’t explicitly used, the discussion aligns with best practices and is highly relevant for practitioners aiming to enhance delivery processes. The content is focused, practical, and supports the category’s core themes."
  },
  "Trend Analysis": {
    "resourceId": "Throughput",
    "category": "Trend Analysis",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 77.6,
    "ai_mentions": 4.6,
    "ai_alignment": 8.7,
    "ai_depth": 8.1,
    "ai_intent": 7.9,
    "ai_audience": 8.3,
    "ai_signal": 8.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 78.0,
    "reasoning": "The content explicitly discusses throughput as a delivery metric for measuring system performance over time and highlights its use in detecting trends and informing decisions, which aligns closely with the aim of trend analysis in Agile and DevOps contexts. While 'trend analysis' is not explicitly named, phrases like 'detect trends,' 'tracking over time,' and 'informs decision-making' cover core conceptual ground. The discussion goes beyond surface-level by describing tools (cumulative flow diagrams, flow analytics), practical application (adjustments to WIP, team composition), and agile-specific scenarios, demonstrating depth. The intended audience—practitioners seeking to understand and improve delivery flow—matches well. Almost all content is relevant, with a clear, focused explanation. The only notable gap is the absence of explicit case studies or data-driven examples of long-term trend analysis, and the lack of the exact category term limits maximum marks for direct mentions. No penalties are warranted as the content is current and adheres to established framing.",
    "level": "Secondary",
    "reasoning_summary": "This content is a strong fit for the trend analysis category, as it thoroughly explores how throughput metrics help identify patterns and inform decisions in Agile and DevOps. While it doesn’t use the exact term ‘trend analysis’ or provide case studies, it clearly addresses the concept through practical tools and examples, making it highly relevant for practitioners aiming to improve delivery flow."
  },
  "Agile Frameworks": {
    "resourceId": "Throughput",
    "category": "Agile Frameworks",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 63.35,
    "ai_mentions": 4.2,
    "ai_alignment": 7.0,
    "ai_depth": 6.7,
    "ai_intent": 6.9,
    "ai_audience": 7.3,
    "ai_signal": 6.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 63.0,
    "reasoning": "The content provides a focused definition and discussion on throughput as a delivery metric relevant to Agile and Lean contexts, mentioning its use with tools like cumulative flow diagrams (common in Kanban) and its alignment with empirical inspection and continuous improvement—key Agile themes. However, it does not specifically mention or compare particular Agile frameworks (e.g., Scrum, Kanban, XP), nor does it directly engage with the principles or the deeper structure of Agile frameworks themselves. Its main aim is informative and aligned with audiences who care about agile metrics, but the discussion remains tool- and metric-centric rather than framework-centric. There are some relevant Agile alignment cues, but only brief, indirect references to Agile frameworks as such. No penalties for tone or obsolescence were needed.",
    "level": "Secondary"
  },
  "GitHub": {
    "resourceId": "Throughput",
    "category": "GitHub",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 7.9,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.2,
    "ai_intent": 0.3,
    "ai_audience": 1.1,
    "ai_signal": 0.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content defines and explains the concept of throughput as a delivery metric and discusses its relevance to Agile and Lean methodologies. However, there are no direct or indirect mentions of GitHub, its tools, or its functionalities. The main focus is on general development practices and metrics rather than any platform-specific implementations. There is no indication that the intended audience is uniquely GitHub users. The signal is high for general Agile/Lean topics but not for GitHub specifics. The confidence score reflects the total lack of category-specific relevance and direct mentions, with very low scores across all dimensions.",
    "level": "Ignored"
  },
  "Competence": {
    "resourceId": "Throughput",
    "category": "Competence",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 20.6,
    "ai_mentions": 0.5,
    "ai_alignment": 2.1,
    "ai_depth": 2.2,
    "ai_intent": 1.5,
    "ai_audience": 7.2,
    "ai_signal": 8.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 21.0,
    "reasoning": "The content on throughput focuses primarily on delivery metrics and system flow analysis, with little to no direct mention or exploration of competence as defined in the category. 'Competence' is neither named nor conceptually emphasized; the focus is on quantitative workflow metrics, not on skill development, professionalism, or capability. The depth of discussion is centered on metrics and observability tools, lacking exploration into how competence drives or is impacted by throughput. The main purpose is to inform about throughput as a metric, not to discuss professional competence. The target audience (Agile, Lean practitioners) does overlap partially with the competence category; however, the content itself is not tailored to competence discussion. Nearly all the content is relevant to flow metrics (high signal), but little is applicable to competence per se. No penalties were needed as the tone is objective and up-to-date. The confidence score is proportionately very low, as only a peripheral conceptual connection to competence (through enabling inspection and continuous improvement) is present.",
    "level": "Ignored"
  },
  "Frequent Releases": {
    "resourceId": "Throughput",
    "category": "Frequent Releases",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 52.2,
    "ai_mentions": 1.9,
    "ai_alignment": 5.7,
    "ai_depth": 5.5,
    "ai_intent": 5.3,
    "ai_audience": 8.1,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 52.0,
    "reasoning": "The content focuses on 'Throughput' as a general metric for measuring work completed over time within Agile and Lean contexts. While throughput is related to understanding delivery performance, there are no direct mentions of 'Frequent Releases' or its subtopics (such as CI/CD, release automation, or DevOps practices). The conceptual alignment is moderate, as throughput data can indirectly inform strategies that support frequent delivery. However, there is minimal depth discussing actual software release practices, and the main purpose is educational about throughput—not specifically about frequent releases. The audience is appropriate (technical teams, Agile/Lean practitioners), and most of the content is focused and relevant, but the connection to the Frequent Releases category is associative rather than explicit or deep.",
    "level": "Tertiary"
  },
  "Modern Source Control": {
    "resourceId": "Throughput",
    "category": "Modern Source Control",
    "calculated_at": "2025-05-06T20:56:51",
    "ai_confidence": 22.83,
    "ai_mentions": 0.06,
    "ai_alignment": 1.35,
    "ai_depth": 1.27,
    "ai_intent": 2.19,
    "ai_audience": 3.03,
    "ai_signal": 2.31,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "The content is fully focused on the metric of throughput within delivery processes, primarily in Agile or Lean environments. There is no direct mention of source control systems, version control practices, or related topics. While there is a tangential reference to continuous improvement and flow metrics—which may indirectly affect situations where source control is relevant—it does not discuss version control practices, tools, or strategies at any level of depth. The intended audience appears to be teams interested in process metrics rather than specifically source control practitioners. Nearly all of the content is off-topic with respect to the Modern Source Control category, justifying very low scores in direct mentions, alignment, and depth. There are no outdated or contradictory aspects, so no penalties were applied. The resulting confidence score is appropriately very low, reflecting clear lack of fit for this category.",
    "level": "Ignored"
  },
  "Team Motivation": {
    "resourceId": "Throughput",
    "category": "Team Motivation",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 34.2,
    "ai_mentions": 1.0,
    "ai_alignment": 3.5,
    "ai_depth": 3.9,
    "ai_intent": 3.7,
    "ai_audience": 6.3,
    "ai_signal": 6.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 34.0,
    "reasoning": "The content focuses on throughput as a delivery and flow metric in Agile contexts, emphasizing system performance, the use of cumulative flow diagrams, feedback loops, and empirical process control. However, it does not directly mention team motivation, nor does it explicitly discuss strategies or psychological factors that drive team engagement, ownership, or high performance. The alignment dimension is moderately low, as the content touches indirectly on continuous improvement and team inspection but frames everything around system metrics rather than team dynamics, trust, empowerment, or motivation. The depth is somewhat higher than alignment as it offers a thorough description of throughput and its uses, but remains technical and process-focused rather than motivational. The intent is mainly informative about throughput as a metric, not about motivating teams, resulting in a lower score here. Audience fit is reasonable since the topic is relevant to Agile practitioners, but may not specifically target those seeking team motivation strategies. Signal-to-noise is fairly high, as the content is focused, but its relevance to the team motivation category is tangential. No penalties applied, as the content is current, neutral in tone, and not critical of the category. The overall confidence reflects that while there is a loose connection to team practices and improvement, the content does not substantially address or exemplify team motivation topics.",
    "level": "Ignored"
  },
  "Metrics and Learning": {
    "resourceId": "Throughput",
    "category": "Metrics and Learning",
    "calculated_at": "2025-05-06T20:56:51",
    "ai_confidence": 91.4,
    "ai_mentions": 8.5,
    "ai_alignment": 9.4,
    "ai_depth": 9.2,
    "ai_intent": 9.3,
    "ai_audience": 9.0,
    "ai_signal": 9.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 91.0,
    "reasoning": "The content directly addresses a core metric (throughput) used in Agile and Lean environments and repeatedly links throughput to key concepts in 'Metrics and Learning,' such as empirical inspection, feedback, continuous improvement, and evidence-based decision-making. Tools like cumulative flow diagrams are mentioned, aligning with technology/data-driven practice expectations. The discussion is deep, outlining how throughput supports analysis of trends, constraints, and decisions, without diverging or introducing off-topic material. The audience fit is strong, focusing on teams and practitioners in Agile or DevOps. The content is nearly exclusively focused on relevant, modern practices, with no outdated references or critical/satirical tone. Overall, the confidence score is high because the material addresses both the 'what' (throughput as a metric) and the 'why/how' (its role in learning and improvement cycles) in considerable detail.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the category, as it thoroughly explores throughput as a key metric in Agile and Lean contexts. It clearly connects throughput to learning, feedback, and continuous improvement, using relevant tools and examples. The discussion is focused, up-to-date, and tailored to practitioners, making it highly relevant and appropriate for the intended audience."
  },
  "Product Discovery": {
    "resourceId": "Throughput",
    "category": "Product Discovery",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 13.6,
    "ai_mentions": 0.1,
    "ai_alignment": 1.6,
    "ai_depth": 1.3,
    "ai_intent": 1.8,
    "ai_audience": 4.2,
    "ai_signal": 2.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content exclusively discusses throughput as a delivery and flow metric used for system performance analysis, workflow inspection, and process improvement. There are no direct or indirect references to Product Discovery, nor does the content address identifying customer needs, defining product features, or the methodologies and practices inherent to Product Discovery. The audience may share some overlap (e.g., product teams), but the focus is operational/process improvement, not discovery. The thoroughness and alignment to the Product Discovery category are very low, and the relevance is almost negligible. No penalties are applied as the content is contemporary and neutral in tone, but confidence rightfully sits at a very low value due to off-topic content.",
    "level": "Ignored"
  },
  "Engineering Practices": {
    "resourceId": "Throughput",
    "category": "Engineering Practices",
    "calculated_at": "2025-05-06T20:56:52",
    "ai_confidence": 54.83,
    "ai_mentions": 2.5,
    "ai_alignment": 6.8,
    "ai_depth": 6.65,
    "ai_intent": 8.0,
    "ai_audience": 7.3,
    "ai_signal": 7.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 55.0,
    "reasoning": "The content extensively discusses 'throughput' as a delivery and observability metric relevant to Agile and Lean teams, aligning with empirical inspection and continuous improvement. However, it does not explicitly mention any of the hallmark engineering practices outlined in the category definition—such as clean code, TDD, CI/CD, refactoring, or pair programming. The main theme is measurement and system flow rather than engineering methodology or code-level practices. The audience (Agile practitioners interested in delivery/process metrics) partially overlaps but is not exclusively technical or practice-focused. The discussion goes beyond superficial, referencing analytics, flow diagrams, and continuous improvement, but remains at a process and measurement level instead of hands-on engineering disciplines. The signal is high and tightly focused on throughput with minimal tangential content, but the engineering practices connection is indirect. No penalties are required since the information is current and supportive, not outdated or critical. The final score reflects moderate alignment and intent fit but low explicit mention and only partial conceptual overlap with the 'Engineering Practices' category.",
    "level": "Tertiary"
  },
  "Organisational Psychology": {
    "resourceId": "Throughput",
    "category": "Organisational Psychology",
    "calculated_at": "2025-05-06T20:56:51",
    "ai_confidence": 16.483,
    "ai_mentions": 0.2,
    "ai_alignment": 2.1,
    "ai_depth": 1.4,
    "ai_intent": 1.5,
    "ai_audience": 4.2,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "The content exclusively discusses throughput as a metric for work delivery and system performance. There are no explicit or implicit references to psychological theories, principles, or concepts such as motivation, leadership, team dynamics, or employee engagement. The closest the content comes to anything related to organisational psychology is the mention of 'team composition,' but this is addressed only from a workflow efficiency and system constraint perspective, not from a psychological viewpoint. The main audience is likely process analysts or Agile practitioners; the intent is process improvement, not the psychological experiences of employees within organisations. Signal-to-noise is relatively low for this category: while focused, it is off-topic for organisational psychology. No penalties were applied, as the content is neither outdated nor critical of the category, but the confidence remains very low due to a lack of alignment with organisational psychology's core focus.",
    "level": "Ignored"
  },
  "DevOps": {
    "resourceId": "Throughput",
    "category": "DevOps",
    "calculated_at": "2025-05-06T20:56:52",
    "ai_confidence": 56.4,
    "ai_mentions": 2.6,
    "ai_alignment": 6.3,
    "ai_depth": 6.5,
    "ai_intent": 5.7,
    "ai_audience": 7.2,
    "ai_signal": 7.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 56.0,
    "reasoning": "The content thoroughly describes throughput as an observability metric and focuses on flow efficiency, constraints, and empirical inspection—key concepts within the DevOps philosophy. Flow efficiency, continuous improvement, and data-driven feedback loops are all reinforced through the discussion of throughput. However, the term 'DevOps' is never mentioned directly, nor are DevOps-specific practices or cultural principles explicitly cited. Much of the terminology also aligns with Agile, Lean, and general software delivery processes. The audience seems technical and relevant, and the signal-to-noise ratio is high, with little off-topic information. However, the lack of explicit DevOps references and broad applicability outside purely DevOps contexts mean the conceptual alignment and intent, while solid, are not exclusive or deeply rooted in DevOps. No penalties were applied, as the content is current and not contradictory. The confidence reflects strong overlap with DevOps themes but stops short of a definitive category fit.",
    "level": "Tertiary"
  },
  "Complexity Thinking": {
    "resourceId": "Throughput",
    "category": "Complexity Thinking",
    "calculated_at": "2025-05-06T20:56:53",
    "ai_confidence": 17.35,
    "ai_mentions": 0.7,
    "ai_alignment": 2.6,
    "ai_depth": 1.9,
    "ai_intent": 3.4,
    "ai_audience": 3.2,
    "ai_signal": 3.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 17.0,
    "reasoning": "The content provides a precise explanation of throughput as a delivery metric and discusses how it is used to analyze workflow efficiency, system constraints, and value flow. However, there is no explicit mention of any complexity science frameworks (e.g., Cynefin, Stacey Matrix), complexity theory principles (emergence, non-linearity, self-organization), or references to complex adaptive systems. The content frames throughput in terms of systems and improvement but only focuses on high-level concepts from Lean and Agile, without integrating the deeper uncertainty, unpredictability, and emergent behavior perspectives central to Complexity Thinking. Its primary audience is practitioners interested in workflow metrics; it does not target complexity thinkers or strategists. There is a lack of depth and direct alignment with Complexity Thinking, with no significant off-topic or filler content. The low scores reflect that, while the content is relevant to systems thinking and process improvement, it does not satisfy the requirements or intent of the 'Complexity Thinking' category.",
    "level": "Ignored"
  },
  "Internal Developer Platform": {
    "resourceId": "Throughput",
    "category": "Internal Developer Platform",
    "calculated_at": "2025-05-06T20:56:53",
    "ai_confidence": 8.75,
    "ai_mentions": 0.3,
    "ai_alignment": 1.2,
    "ai_depth": 1.5,
    "ai_intent": 0.8,
    "ai_audience": 2.1,
    "ai_signal": 2.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content focuses exclusively on the concept of throughput as a delivery metric, predominantly in generic software development and Agile/Lean contexts. There are no explicit mentions or direct references to Internal Developer Platforms (IDPs), nor is there any discussion about IDP frameworks, their components, specific benefits, or how throughput would be measured within an IDP setting. The main ideas center around flow efficiency and system constraints, but without linking these to the IDP paradigm. The intent, audience, and relevance are only marginally aligned with the IDP category because throughput may be observed within an IDP, but could just as easily be present in any development environment. The discussion remains generic and does not cite any tools, technologies, or practices that are distinct to IDPs. As there are no satirical, critical, or obsolete references, no penalties are applied. The confidence score is very low to reflect the lack of fit with the Internal Developer Platform category.",
    "level": "Ignored"
  },
  "Shift Left Strategy": {
    "resourceId": "Throughput",
    "category": "Shift Left Strategy",
    "calculated_at": "2025-05-06T20:56:53",
    "ai_confidence": 18.2,
    "ai_mentions": 0.0,
    "ai_alignment": 2.0,
    "ai_depth": 2.3,
    "ai_intent": 2.1,
    "ai_audience": 5.0,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content is an overview of throughput as a delivery metric, discussing its use for flow analysis, system constraints, and empirical inspection within Agile/Lean contexts. There are no direct mentions of the Shift-Left Strategy, nor is there discussion of integrating testing, security, or compliance earlier in the SDLC. The content focuses on delivery and process metrics rather than shifting practices left in the development process. While it addresses audiences interested in process improvement (relevant to Shift-Left practitioners), and uses terminology familiar to those in software delivery, the primary themes and intent are not conceptually aligned with Shift-Left Strategy. There is only marginal overlap regarding early inspection and continuous improvement, but this is common to many Agile/Lean concepts and not specific to Shift-Left. Signal-to-noise ratio is moderate given the narrow focus, but most discussion is orthogonal to the Shift-Left concept. No penalties applied as content is accurate and current.",
    "level": "Ignored"
  },
  "Application Lifecycle Management": {
    "resourceId": "Throughput",
    "category": "Application Lifecycle Management",
    "calculated_at": "2025-05-06T20:56:54",
    "ai_confidence": 43.08,
    "ai_mentions": 0.5,
    "ai_alignment": 4.4,
    "ai_depth": 4.7,
    "ai_intent": 4.2,
    "ai_audience": 6.4,
    "ai_signal": 5.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 43.0,
    "reasoning": "The content focuses on 'Throughput' as a metric for measuring work completed over time, explaining its role in monitoring system efficiency, identifying constraints, and supporting continuous improvement. It discusses tools like cumulative flow diagrams, and references its use within Agile and Lean frameworks. However, there are only indirect ties to Application Lifecycle Management (ALM): throughput is mentioned as a delivery metric but the content does not directly reference or deeply explore the end-to-end processes, tools, or governance aspects core to ALM. There are no explicit mentions of ALM, and while throughput data can inform lifecycle decisions, the article does not situate its discussion within the broader ALM context (e.g., application governance, full lifecycle stages, or integration with ALM tooling). The intended audience seems to be delivery teams or Agile practitioners, who could overlap with ALM audiences, but the content is not specifically tailored to ALM strategists or managers. The signal is moderate since all of the information is relevant to monitoring software delivery, but it's not specifically or exclusively about ALM. Therefore, the final confidence score is low-mid, reflecting that the content is tangentially but not centrally relevant to the ALM category.",
    "level": "Tertiary"
  },
  "Agile Product Management": {
    "resourceId": "Throughput",
    "category": "Agile Product Management",
    "calculated_at": "2025-05-06T20:56:54",
    "ai_confidence": 65.8,
    "ai_mentions": 4.1,
    "ai_alignment": 6.6,
    "ai_depth": 6.8,
    "ai_intent": 6.3,
    "ai_audience": 7.0,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 66.0,
    "reasoning": "The content focuses on the metric of throughput, describing its role in monitoring and improving the flow of work at a system level. There are references to Agile and Lean contexts, continuous improvement, flow analytics, and empirical decision-making—topics adjacent to Agile Product Management. However, there is no direct mention of Agile Product Management, Product Owners, backlog prioritization, or customer value maximization. The language and concepts (e.g., 'work-in-progress limits', 'cumulative flow diagrams') are common in Agile/Lean product environments, aligning with the practices used to inform product delivery strategies. The discussion is moderately deep for a metric, explaining its impact and how it supports team-level inspection and adaptation, but does not directly engage with the broader scope of Agile Product Management such as customer feedback loops, stakeholder engagement, or strategic alignment. The audience seems to be Agile practitioners concerned with delivery health, which overlaps with (but does not exactly target) Agile product managers. The content is focused throughout and avoids irrelevant tangents, maintaining a good signal-to-noise ratio. No penalties are applied, as the content is current and supportive. Overall, the content fits as an informative input relevant to Agile Product Management, but is not fully centered on it, justifying a moderate confidence score.",
    "level": "Secondary"
  },
  "Product Strategy": {
    "resourceId": "Throughput",
    "category": "Product Strategy",
    "calculated_at": "2025-05-06T20:56:54",
    "ai_confidence": 26.15,
    "ai_mentions": 0.4,
    "ai_alignment": 2.7,
    "ai_depth": 2.2,
    "ai_intent": 2.6,
    "ai_audience": 3.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 26.0,
    "reasoning": "The content discusses throughput as a delivery and flow metric, focusing on measurement of system performance and the use of Agile/Lean analytics. It covers tools and concepts like cumulative flow diagrams, flow efficiency, and the use of throughput for continuous improvement. However, there is no direct reference to product strategy, product vision, roadmapping, market analysis, or other core elements specified in the category definition. The intent is to inform on operational delivery metrics rather than strategic direction. The audience appears more operational/Agile practitioner than product strategists, and much of the detail is technical in nature rather than strategic. As a result, conceptual alignment, depth, intent fit, and audience scores are all low, with only minor signal. No penalties were applied as the content is neither outdated nor contradicts the category outright. The final confidence score reflects that this content is only tangentially relevant, if at all, to Product Strategy.",
    "level": "Ignored"
  },
  "Release Management": {
    "resourceId": "Throughput",
    "category": "Release Management",
    "calculated_at": "2025-05-06T20:56:56",
    "ai_confidence": 35.25,
    "ai_mentions": 0.4,
    "ai_alignment": 4.2,
    "ai_depth": 4.5,
    "ai_intent": 4.7,
    "ai_audience": 5.0,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 35.0,
    "reasoning": "The content discusses throughput as a delivery metric, focusing primarily on work completion rates, flow analysis, and system efficiency. While throughput is relevant to software delivery and touches on metrics that may be used in Release Management, the article does not directly mention release-related concepts such as release planning, scheduling, coordination between development and operations, or CI/CD. The main audience appears to be practitioners interested in delivery metrics rather than Release Management specialists. The depth is moderate, offering several practical considerations, but overall, the discussion remains more about team/system flow and process improvement than about software releases specifically. Signal-to-noise is relatively high since the content is focused, but its signal for Release Management specifically is limited. Minimal explicit connections to Release Management results in low direct mention and only partial conceptual alignment, justifying a moderate but not high confidence score.",
    "level": "Ignored"
  },
  "Cross Functional Teams": {
    "resourceId": "Throughput",
    "category": "Cross Functional Teams",
    "calculated_at": "2025-05-06T20:56:56",
    "ai_confidence": 13.54,
    "ai_mentions": 0.2,
    "ai_alignment": 1.1,
    "ai_depth": 1.3,
    "ai_intent": 0.4,
    "ai_audience": 5.7,
    "ai_signal": 1.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses exclusively on the definition and application of throughput as a delivery and flow metric. There is no direct mention of cross-functional teams, nor is there substantive discussion about team structure, diversity of skills, or collaborative practices—all of which are central to the 'Cross Functional Teams' category. The material aligns more with Agile analytics and performance measurement at a system level, not with cross-functional team dynamics or best practices. Audience alignment is relatively neutral, as practitioners interested in Agile metrics may overlap with those interested in team structures, but the bulk of the discussion is not targeted toward building or managing cross-functional teams. There is minimal noise since the content stays focused on throughput; however, that topic is largely irrelevant to the required category. No penalties were needed as the content is recent and not satirical or critical.",
    "level": "Ignored"
  },
  "Flow Efficiency": {
    "resourceId": "Throughput",
    "category": "Flow Efficiency",
    "calculated_at": "2025-05-06T20:56:57",
    "ai_confidence": 92.11,
    "ai_mentions": 7.7,
    "ai_alignment": 9.5,
    "ai_depth": 9.2,
    "ai_intent": 8.5,
    "ai_audience": 8.2,
    "ai_signal": 9.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 92.0,
    "reasoning": "The content introduces throughput as a delivery metric, explicitly connecting it to the analysis of flow efficiency and system constraints. While 'flow efficiency' is only directly mentioned in the description and not repeatedly in the main text, the explanation consistently focuses on core concepts: measurement of throughput in the context of Lean and Agile methodologies, visual management tools like cumulative flow diagrams, the use of cycle time and lead time, and continuous improvement. The direct mention score (7.7) is moderate due to only one explicit usage, but high alignment (9.5) and depth (9.2) reflect thorough coverage of how throughput relates to optimizing value stream performance and identifying bottlenecks—core to the category definition. The intent (8.5) is focused on educating practitioners (audience 8.2) on improving work delivery by optimizing throughput—a central concern of Flow Efficiency. The signal is very high (9.0) as nearly all content is relevant, with negligible off-topic information. There are no penalties, as the information is current, accurate, and not critical or satirical of the category.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the Flow Efficiency category. It clearly explains how throughput relates to analysing and improving value stream performance, using Lean and Agile concepts. The focus on measurement, visual tools, and continuous improvement directly supports practitioners aiming to optimise work delivery, making the content highly relevant and well-aligned with the category’s core themes."
  },
  "Large Scale Agility": {
    "resourceId": "Throughput",
    "category": "Large Scale Agility",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 32.5,
    "ai_mentions": 0.7,
    "ai_alignment": 3.0,
    "ai_depth": 2.2,
    "ai_intent": 3.5,
    "ai_audience": 4.1,
    "ai_signal": 3.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 32.0,
    "reasoning": "The content focuses on throughput as a metric for flow and delivery in teams, referencing Agile and Lean contexts, but at no point does it mention scaling Agile, enterprise-level considerations, or cross-team/organizational alignment. Throughput is relevant at all levels, but the discussion is contained strictly to a team/system level, not enterprise agility. There are no direct references to large-scale frameworks (e.g., SAFe, LeSS), transformation, or enterprise-wide alignment. The target audience seems to be practitioners interested in team performance metrics rather than strategists or leadership overseeing large-scale agility. The discussion is detailed for the metric itself but not in relation to large-scale Agile. There are no penalties as the content is current and neutral in tone, but the lack of scale-related context keeps scores modest across all dimensions. Final confidence score is low, reflecting weak alignment to the intended category.",
    "level": "Ignored"
  },
  "Product Owner": {
    "resourceId": "Throughput",
    "category": "Product Owner",
    "calculated_at": "2025-05-06T20:56:54",
    "ai_confidence": 18.45,
    "ai_mentions": 1.2,
    "ai_alignment": 2.9,
    "ai_depth": 2.8,
    "ai_intent": 1.7,
    "ai_audience": 5.1,
    "ai_signal": 5.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content defines throughput as an Agile delivery metric focused on flow and system constraints. It describes what throughput measures, its use with tools such as cumulative flow diagrams, and its application in Agile and Lean contexts. However, it does not mention the Product Owner role or accountability, nor does it discuss backlog prioritisation, stakeholder management, or value maximisation—the hallmarks of the Product Owner category definition. The content’s main intent is general education about throughput as a metric, not about the Product Owner or their responsibilities. While throughput data may be useful for Product Owners, this is not stated or implied in the content. Consequently, direct mentions and conceptual alignment are low, as is depth regarding Product Owner accountability. The primary audience seems broadly Agile teams and practitioners interested in metrics, with a slight possibility that Product Owners could find it tangentially relevant. The content is focused and on-topic about metrics, so signal-to-noise is modestly above neutral. No penalties were applied, as the content is neither outdated nor overtly critical.",
    "level": "Ignored"
  },
  "Experimentation": {
    "resourceId": "Throughput",
    "category": "Experimentation",
    "calculated_at": "2025-05-06T20:56:56",
    "ai_confidence": 34.07,
    "ai_mentions": 0.5,
    "ai_alignment": 3.5,
    "ai_depth": 3.9,
    "ai_intent": 3.7,
    "ai_audience": 8.1,
    "ai_signal": 7.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 34.0,
    "reasoning": "The content is a deep dive into the metric of throughput as used in Agile and Lean contexts. There is no direct mention of 'experimentation' nor explicit reference to hypothesis-driven approaches. While the content discusses how throughput helps assess the impact of workflow changes, it frames this more as ongoing measurement and process inspection, rather than as hypothesis formation, structured testing, or experimental validation. The closest alignment comes from language such as 'empirical inspection', 'provides feedback', and 'guides adjustments', which are tangentially related to experimentation, but the focus remains strictly on observability and flow analysis. The intended audience (Agile practitioners, team leads) does overlap with the experimentation category. The content maintains high signal but lacks focus on experimental design, analysis, or systematic learning from tests, limiting conceptual and intentional fit. Thus, the confidence score is moderate but well below threshold for strong categorical alignment.",
    "level": "Ignored"
  },
  "Service Level Expectation": {
    "resourceId": "Throughput",
    "category": "Service Level Expectation",
    "calculated_at": "2025-05-06T20:56:57",
    "ai_confidence": 7.4,
    "ai_mentions": 0.0,
    "ai_alignment": 0.5,
    "ai_depth": 0.3,
    "ai_intent": 0.3,
    "ai_audience": 3.2,
    "ai_signal": 3.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content is entirely focused on throughput as a flow metric in Agile and Lean systems. There are no explicit mentions of Service Level Expectation (SLE), nor any reference to its definition, calculation, or application. While throughput is sometimes used as an input for broader discussions of predictability or flow (topics tangentially related to SLE), this piece never bridges the connection. Its primary intent is to inform about throughput, not SLE. The audience alignment and signal scores are slightly higher because the intended readers—teams familiar with Agile/Lean metrics—could overlap with those interested in SLE, and the text is focused and relevant to metrics discussions. However, the lack of direct, conceptual, and in-depth treatment of SLE results in extremely low scores for direct mentions, alignment, depth, and intent. No penalties were applied since there are no outdated practices or contradictory tone. The final confidence score of 7.4 reflects the near-total lack of SLE relevance, with only a trace of conceptual proximity due to overlapping metric domains.",
    "level": "Ignored"
  },
  "Decision Theory": {
    "resourceId": "Throughput",
    "category": "Decision Theory",
    "calculated_at": "2025-05-06T20:56:57",
    "ai_confidence": 44.12,
    "ai_mentions": 1.2,
    "ai_alignment": 5.1,
    "ai_depth": 4.8,
    "ai_intent": 4.6,
    "ai_audience": 7.0,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 44.0,
    "reasoning": "The content primarily focuses on throughput as a metric for measuring flow efficiency and system performance in delivery contexts. Decision-making is referenced, but only indirectly—throughput data 'informs decision-making and guides adjustments'—without explicit discussion of decision theory concepts, models, heuristics, or probability. The alignment dimension reflects the moderate fit: while throughput data is used for decisions, the main thrust is on metric tracking, not on frameworks for decision-making under uncertainty. Depth is limited, mainly describing practical uses of throughput rather than decision theory analysis. Audience alignment and signal are relatively high, as the readers (likely Agile practitioners or managers) could intersect with those interested in decision theory, and the content is focused with minimal off-topic filler. However, direct mention and intent are low, as decision theory is never named nor deeply explored—the main purpose is metric explanation rather than theoretical discussion. No penalties are applied, as the content is current and neutral in tone. The confidence score thus reflects a loose or tangential relevance, not a direct fit.",
    "level": "Tertiary"
  },
  "Definition of Ready": {
    "resourceId": "Throughput",
    "category": "Definition of Ready",
    "calculated_at": "2025-05-06T20:56:57",
    "ai_confidence": 7.6,
    "ai_mentions": 0.0,
    "ai_alignment": 1.2,
    "ai_depth": 0.9,
    "ai_intent": 1.3,
    "ai_audience": 2.5,
    "ai_signal": 1.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content exclusively discusses throughput as a flow and system delivery metric, useful for inspecting team efficiency, constraints, and continuous improvement. There are zero explicit mentions of the Definition of Ready or its core criteria, nor does it address the readiness or refinement of backlog items. Its conceptual alignment is minimal because throughput pertains to outcome measurement, not ensuring items are 'ready.' Depth and intent scores remain very low as the focus and purpose do not match the DoR category; all substantial content is about flow metrics, not actionable standards for planning. The audience is general Agile practitioners, which only weakly overlaps with DoR’s specific focus on backlog readiness. Most of the content is noise for DoR, so signal is extremely low. No penalties apply as the information is not outdated and the tone is neutral. The resulting confidence score is very low, accurately reflecting the lack of direct or indirect relevance.",
    "level": "Ignored"
  },
  "Artificial Intelligence": {
    "resourceId": "Throughput",
    "category": "Artificial Intelligence",
    "calculated_at": "2025-05-06T20:56:47",
    "ai_confidence": 3.1,
    "ai_mentions": 0.2,
    "ai_alignment": 0.5,
    "ai_depth": 0.4,
    "ai_intent": 0.5,
    "ai_audience": 0.8,
    "ai_signal": 0.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content provides an overview of throughput as a delivery metric in Agile and Lean contexts. There are no explicit mentions of Artificial Intelligence, nor does the content explore any application of AI or related tools in the context of throughput measurement, Agile, or DevOps. The main focus is on manual and systemic aspects of throughput, such as visualisation tools like cumulative flow diagrams, but without reference to AI-driven analytics, automation, or intelligent workflows. The intent is purely educational about throughput metrics, and the audience is mainly practitioners interested in Agile metrics. As such, direct mentions, conceptual alignment, depth, and intent toward the AI category are all minimal. No out-of-date or contradictory references are present; no penalties are assessed. The resulting confidence score is appropriately low, reflecting the near-nonexistent connection to Artificial Intelligence as defined by the category.",
    "level": "Ignored"
  },
  "Product Management": {
    "resourceId": "Throughput",
    "category": "Product Management",
    "calculated_at": "2025-05-06T20:56:47",
    "ai_confidence": 49.75,
    "ai_mentions": 1.7,
    "ai_alignment": 5.8,
    "ai_depth": 5.6,
    "ai_intent": 3.9,
    "ai_audience": 5.1,
    "ai_signal": 5.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 50.0,
    "reasoning": "The content provides an explanation of throughput as a metric for flow efficiency in Agile and Lean contexts. There are some indirect conceptual alignments with product management, such as flow, continuous improvement, and empirical decision-making, which are relevant topics. However, the discussion is generic and primarily addresses principles of workflow optimization—important for both engineering and broader process management, but not directly tied to the strategic responsibilities of product managers as defined by the category. There is only a minimal direct link to product management frameworks, audiences, or methodologies, and the term 'product management' itself is never mentioned. The intent is more informative about throughput as a delivery/process metric, not specifically focused on how product managers would leverage such data for strategic product decisions. The audience seems to be general Agile or Lean practitioners rather than product managers exclusively. No penalties were applied as there is no outdated or contradictory material. The confidence score is balanced—acknowledging relevant overlaps but reflecting the lack of strong, explicit fit to the defined Product Management category.",
    "level": "Tertiary"
  },
  "Customer Retention": {
    "resourceId": "Throughput",
    "category": "Customer Retention",
    "calculated_at": "2025-05-06T20:56:47",
    "ai_confidence": 13.4,
    "ai_mentions": 0.3,
    "ai_alignment": 1.4,
    "ai_depth": 1.4,
    "ai_intent": 2.1,
    "ai_audience": 4.2,
    "ai_signal": 4.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content provides an explanation of throughput as a delivery and flow metric within Agile and Lean contexts, focusing on system efficiency, constraints, and workflow improvement. There is no direct mention of customer retention, nor are there references to retaining customers, customer engagement, satisfaction, or related strategies. The discussion centers on internal team measures of delivery rather than explicit customer outcomes. While increased throughput may eventually support better customer experiences, the content here does not establish that connection or discuss methods, KPIs, or examples fitting the customer retention category. It does not conflict with customer retention but is almost entirely orthogonal to the category definition. Thus, scores for direct mentions, conceptual alignment, and depth are minimal; intent and audience are only somewhat relevant due to overlap with Agile/Lean practitioners; signal is moderately on-topic for delivery performance but not for customer retention.",
    "level": "Ignored"
  },
  "Minimum Viable Product": {
    "resourceId": "Throughput",
    "category": "Minimum Viable Product",
    "calculated_at": "2025-05-06T20:56:47",
    "ai_confidence": 13.06,
    "ai_mentions": 0.15,
    "ai_alignment": 1.25,
    "ai_depth": 1.15,
    "ai_intent": 1.0,
    "ai_audience": 6.0,
    "ai_signal": 4.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content thoroughly discusses throughput as an Agile delivery metric, focusing on flow, value delivery, and analytics for continuous improvement. However, it does not directly mention MVP or its definition, development, or validation processes. No examples, case studies, or best practices relating to Minimum Viable Products are present. The audience is somewhat aligned (Agile/Lean practitioners), but the content's primary focus is system performance and workflow optimization, not MVP. Signal is moderate since it stays focused on throughput with little irrelevant content, but the direct relevance to MVP remains minimal. Thus, the very low confidence score reflects incidental rather than intentional overlap with the MVP category.",
    "level": "Ignored"
  },
  "Beta Codex": {
    "resourceId": "Throughput",
    "category": "Beta Codex",
    "calculated_at": "2025-05-06T20:56:47",
    "ai_confidence": 21.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.7,
    "ai_depth": 2.5,
    "ai_intent": 2.9,
    "ai_audience": 5.1,
    "ai_signal": 3.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 22.0,
    "reasoning": "This content focuses on the concept of 'throughput' as a delivery and flow metric, emphasizing its importance in tracking work completed over time and supporting continuous improvement. While these are valuable concepts in Agile and Lean, there is no explicit mention or discussion of Beta Codex, decentralization, or human-centric, adaptive organizational design. The content's language—'teams', 'decision-making', 'continuous improvement'—could align with Beta Codex principles in a broad sense, but the main thrust is generic and could apply equally to traditional, hierarchical, or Lean settings. There is no exploration of decentralization, adaptive frameworks, or a direct comparison to traditional models. The audience seems to be practitioners interested in metrics and workflow health, and the discussion avoids irrelevant filler, but does not meaningfully address Beta Codex's unique tenets. Thus, the confidence is appropriately low.",
    "level": "Ignored"
  },
  "Lean Thinking": {
    "resourceId": "Throughput",
    "category": "Lean Thinking",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 72.98,
    "ai_mentions": 4.4,
    "ai_alignment": 7.2,
    "ai_depth": 7.4,
    "ai_intent": 7.1,
    "ai_audience": 8.2,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 73.0,
    "reasoning": "The content directly discusses the concept of throughput as it relates to the flow of value, a principle aligned with Lean Thinking. It references the analysis of flow efficiency, identification of constraints, and continuous improvement—key Lean concepts. Although the term \"Lean Thinking\" is not explicitly mentioned, 'Lean contexts' are referenced, and terminology like 'flow,' 'constraints,' and 'continuous improvement' signal alignment. The discussion provides some depth, going beyond surface-level definitions by explaining how throughput is used for empirical inspection, decision-making, and improvement. However, it does not discuss foundational Lean principles (such as Value Stream Mapping, waste elimination, or specific Lean tools like 5S or Kanban) in detail, limiting conceptual and depth scores. The main purpose is educational and relevant to Lean practitioners, and the audience is well aligned for technical teams or Lean/Agile professionals. Signal-to-noise is high as the content remains focused and avoids tangential issues. No penalties were applied as there are no obsolete references, criticisms, or misrepresentations. The final confidence is slightly above moderate, reflecting strong alignment but limited direct mention and only moderate depth.",
    "level": "Secondary",
    "reasoning_summary": "This content is a good fit for the Lean Thinking category, as it explores key Lean concepts like flow, constraints, and continuous improvement, even if it doesn’t mention all foundational principles or tools in detail. Its focus is educational and relevant for Lean or Agile professionals, maintaining clarity and relevance throughout. While depth is moderate, the alignment with Lean practices is clear, supporting a confident classification."
  },
  "Agile Planning Tools": {
    "resourceId": "Throughput",
    "category": "Agile Planning Tools",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 53.35,
    "ai_mentions": 3.2,
    "ai_alignment": 5.8,
    "ai_depth": 5.4,
    "ai_intent": 4.7,
    "ai_audience": 7.0,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 53.0,
    "reasoning": "The content centers on the metric 'throughput,' exploring its definition, value in measuring delivery efficiency, and role in flow analysis. References to Agile and Lean contexts are present but not explicitly tied to Agile Planning Tools per se. While cumulative flow diagrams and flow analytics (which are found in some Agile Planning Tools) are mentioned, the discussion focuses on the metric itself and its broader process improvement utility, not on evaluating or using planning tools. The primary intent is to inform about throughput as a concept, not about tools or tool-based practices. There is some overlap in audience, as Agile practitioners tracking throughput may also use Agile planning tools, but the audience may also include general process improvement or Lean professionals. The majority of content is tightly focused, but the lack of direct tool discussion leads to middle scores for conceptual alignment, depth, and intent. No penalties were applied as the information is up-to-date and not contradictory.",
    "level": "Tertiary"
  },
  "Professional Scrum": {
    "resourceId": "Throughput",
    "category": "Professional Scrum",
    "calculated_at": "2025-05-06T20:56:50",
    "ai_confidence": 61.51,
    "ai_mentions": 1.4,
    "ai_alignment": 6.5,
    "ai_depth": 6.9,
    "ai_intent": 7.4,
    "ai_audience": 7.0,
    "ai_signal": 6.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 62.0,
    "reasoning": "The content provides an informed overview of throughput as a metric, highlighting its role in empirical inspection, enabling transparency, and informing decisions—concepts that align with Professional Scrum’s use of evidence-based management and empiricism. It mentions continuous improvement and focuses on system-level performance rather than individuals, resonating with Scrum values and the ethos of professionalism. However, 'Professional Scrum' is not directly named or referenced, and the explanation is rooted in general Agile/Lean practice rather than uniquely Scrum. While it avoids anti-patterns or obsolete practices and is relevant to Scrum practitioners interested in metrics, it does not deeply explore how Professional Scrum uniquely applies throughput, nor does it explicitly frame the discussion in terms of Scrum roles or the Scrum Guide’s philosophy. Thus, the alignment and depth scores reflect moderately strong but not exemplary affinity, and the direct mention score is quite low. No penalties apply as the content is current and supportive. The final confidence score is proportionate for content with general relevance but without highly specific focus on 'Professional Scrum.'",
    "level": "Secondary"
  },
  "Increment": {
    "resourceId": "Throughput",
    "category": "Increment",
    "calculated_at": "2025-05-06T20:56:53",
    "ai_confidence": 14.05,
    "ai_mentions": 0.1,
    "ai_alignment": 1.4,
    "ai_depth": 1.8,
    "ai_intent": 2.35,
    "ai_audience": 4.95,
    "ai_signal": 4.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses entirely on throughput as a metric for inspecting and improving delivery flow in Agile and Lean systems, with no direct or even indirect references to the concept of Increment as defined for this category. There are zero explicit mentions of 'Increment' or any of its artifacts, and the main themes (inspection, metrics, system constraints) are conceptually adjacent but not directly aligned with 'the tangible, usable output' of Scrum iterations. Discussion depth is reasonable for throughput as a metric but does not address Increment’s specific qualities, such as functional software, practices for ensuring Increment quality, or its relationship to other Scrum artifacts. The intent is about process improvement and measurement, not directly increment delivery. Audience fit is reasonably strong (aimed at practitioners and Agile teams, like Increment), and signal-to-noise is high since the content is focused and non-rambling. No penalties are applied as the information is neither outdated nor undermining the Increment concept—it is simply misaligned. The resulting confidence score is low, reflecting minimal inclusion of Increment content according to the established criteria.",
    "level": "Ignored"
  },
  "Product Backlog": {
    "resourceId": "Throughput",
    "category": "Product Backlog",
    "calculated_at": "2025-05-06T20:56:54",
    "ai_confidence": 18.45,
    "ai_mentions": 0.25,
    "ai_alignment": 2.4,
    "ai_depth": 2.1,
    "ai_intent": 2.8,
    "ai_audience": 5.2,
    "ai_signal": 4.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content focuses exclusively on throughput as a delivery metric, explaining its meaning, uses, and benefits for flow analysis in Agile and Lean contexts. There are no direct mentions of the Product Backlog, nor does the content cover any of the key topics associated with backlog management, refinement, prioritisation, or its relationship to stakeholder value as defined in the classification. The conceptual alignment is weak: while throughput might be a secondary performance metric used by teams that manage a backlog, the content does not relate throughput to backlog practices, backlog items, or any actual prioritisation or work management processes. Depth and intent are both limited to throughput as a workflow measure, not as an input or output of backlog management. The audience may overlap somewhat (Agile practitioners), but the signal is concentrated on throughput, making the relevance to Product Backlog almost entirely tangential. No penalties are applied as there are no outdated practices or contradictory tone. The low confidence score reflects only a faint, indirect connection by virtue of being within Agile contexts where a backlog exists, but not addressing the backlog or its management explicitly or implicitly.",
    "level": "Ignored"
  },
  "Software Development": {
    "resourceId": "Throughput",
    "category": "Software Development",
    "calculated_at": "2025-05-06T20:56:54",
    "ai_confidence": 91.4,
    "ai_mentions": 7.6,
    "ai_alignment": 9.2,
    "ai_depth": 8.9,
    "ai_intent": 9.1,
    "ai_audience": 9.4,
    "ai_signal": 8.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 91.0,
    "reasoning": "The content explicitly discusses 'throughput' as a delivery metric used within software delivery systems, referencing Agile and Lean methodologies—core to software development best practices. 'Throughput' itself is not only named several times but contextualized in a way that directly relates to measuring and improving software delivery performance. The explanation covers conceptual underpinnings (flow, value delivery, continuous improvement), references tooling (cumulative flow diagrams, flow analytics), and methodologies (Agile, Lean), signaling a strong alignment and depth. The intended audience—teams seeking empirical insights for improvement in delivery—matches practitioners and stakeholders in software development rather than a broader or unrelated audience. Minimal tangential information is present, with all content relevant and focused on the value of throughput in a software delivery lifecycle context. No penalties are needed, as the content is current, unbiased, and highly relevant. The final confidence score, weighted by the rubric, appropriately reflects the evidence and integration with key SDLC and Agile principles.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the category, as it thoroughly explores 'throughput' within software delivery, referencing Agile and Lean practices. It’s clearly aimed at software development professionals, focusing on relevant metrics, tools, and methodologies. The discussion is well-aligned, current, and free from unrelated details, making it highly suitable for those interested in improving software delivery performance."
  },
  "Hypothesis Driven Development": {
    "resourceId": "Throughput",
    "category": "Hypothesis Driven Development",
    "calculated_at": "2025-05-06T20:56:54",
    "ai_confidence": 20.2,
    "ai_mentions": 0.0,
    "ai_alignment": 2.5,
    "ai_depth": 2.7,
    "ai_intent": 2.5,
    "ai_audience": 5.6,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 20.0,
    "reasoning": "The content focuses exclusively on throughput as a delivery metric, explaining how it measures system capacity and flow efficiency. There are no explicit mentions of hypothesis-driven development or any direct references to concepts such as experimentation, validated learning, or hypothesis formulation. Conceptual alignment with Hypothesis Driven Development is weak; while the discussion involves empirical observation and data-driven adjustments, it does not discuss forming or testing hypotheses, or using experiment results to drive product decisions. The depth is moderate for the topic of throughput but not for the principles of hypothesis-driven development. The primary intent is informative regarding metrics, not experimentation or learning cycles. The audience is likely practitioners in Agile or Lean environments, which partially overlaps with Hypothesis Driven Development's audience, and the signal-to-noise ratio is high as the content is focused and concise. Overall, the confidence score reflects a very loose and mostly indirect relationship with the category.",
    "level": "Ignored"
  },
  "Working Agreements": {
    "resourceId": "Throughput",
    "category": "Working Agreements",
    "calculated_at": "2025-05-06T20:56:56",
    "ai_confidence": 20.55,
    "ai_mentions": 0.4,
    "ai_alignment": 2.1,
    "ai_depth": 2.3,
    "ai_intent": 2.7,
    "ai_audience": 6.5,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 21.0,
    "reasoning": "The content discusses throughput as a delivery metric, emphasizing its role in process observability, empirical inspection, and system performance in Agile and Lean contexts. While it references concepts relevant to teams (such as continuous improvement, feedback, and workflow adjustment), there are no explicit or implicit mentions of working agreements: no definition, importance, examples, establishment, or adaptation of team norms or principles. The focus is technical (metrics, measurement, process flow), not on collaborative practices, team alignment, or behavioral norms. The intent is to inform about throughput as a metric rather than to establish or refine team working agreements. The content targets practitioners interested in process performance, which partially overlaps with the working agreements audience, but not centrally so. Most of the content is on-topic for process improvement, but off-topic for working agreements, providing a strong signal-to-noise ratio for its main topic while weak for this category. No penalties were applied as the tone and content are up-to-date and neutral. Overall, while tangentially connected through broader themes of continuous improvement, it does not address working agreements as a topic, resulting in a low confidence score.",
    "level": "Ignored"
  },
  "Test First Development": {
    "resourceId": "Throughput",
    "category": "Test First Development",
    "calculated_at": "2025-05-06T20:56:48",
    "ai_confidence": 9.6,
    "ai_mentions": 0.0,
    "ai_alignment": 1.6,
    "ai_depth": 1.4,
    "ai_intent": 1.0,
    "ai_audience": 2.5,
    "ai_signal": 3.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 10.0,
    "reasoning": "The content is exclusively focused on throughput as a metric for measuring delivery, flow efficiency, and system constraints. There are no direct mentions of Test First Development, nor are any of its core concepts—test criteria, TDD, ATDD, success criteria, or feedback driven by testing—referenced or implied. Alignment is minimal because while both topics relate to delivery and feedback, the mechanisms and aims differ: throughput is about flow metrics, not about driving implementation by defining tests first. Depth remains low as all discussion centers on how throughput informs process improvement, not on how testing practices define or impact delivery. The intent is unrelated to Test First Development, and the audience seems oriented toward process managers or Agile practitioners, not necessarily those interested in test-first methodologies. The signal is midrange as the content is clearly presented and focused, yet entirely off-topic for the evaluated category. No penalties were applied as the material is current, neutral, and objective. Confidence is thus extremely low, reflecting a lack of substantive connection to the Test First Development category.",
    "level": "Ignored"
  },
  "Operational Practices": {
    "resourceId": "Throughput",
    "category": "Operational Practices",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 84.34,
    "ai_mentions": 7.9,
    "ai_alignment": 9.3,
    "ai_depth": 8.5,
    "ai_intent": 9.1,
    "ai_audience": 8.2,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 84.0,
    "reasoning": "The content provides a focused discussion on 'throughput' as an operational metric within Agile and Lean frameworks. While the term 'operational practices' is not directly named, the content describes the practical application of throughput, including its role in process improvement, workflow optimization, and empirical inspection—central to operational practices. It also discusses tools and metrics (cumulative flow diagrams, flow analytics) and contextualizes throughput within continuous improvement, decision-making, and workflow adjustments. The depth is substantial, providing more than surface-level definition, though the content stops short of full implementation case studies or advanced comparative discussion. The main intent is clearly to inform those involved in operations and team delivery about best practices for measurement and improvement, aligning well with the category’s core purpose and audience. The signal-to-noise ratio remains high, with all content tightly focused on throughput as an operational lever. No penalties were necessary, as the material is current and supportive, with no sign of outdated information or misleading framing. Overall, the confidence score reflects strong conceptual alignment, intent, and depth, balanced by slightly lower direct mention and moderately broad audience references.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the category, as it thoroughly explores throughput as a key operational metric in Agile and Lean contexts. It explains practical uses, relevant tools, and its role in continuous improvement, offering actionable insights for operations teams. While it doesn’t provide case studies or advanced comparisons, its focus and depth make it highly relevant for those seeking best practices in operational measurement."
  },
  "Azure DevOps": {
    "resourceId": "Throughput",
    "category": "Azure DevOps",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 13.3,
    "ai_mentions": 0.0,
    "ai_alignment": 1.8,
    "ai_depth": 2.1,
    "ai_intent": 3.5,
    "ai_audience": 2.7,
    "ai_signal": 2.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content discusses 'Throughput' as a general delivery metric used for inspecting team and system effectiveness, referencing concepts such as flow efficiency, cumulative flow diagrams, and Agile/Lean delivery. However, there is no direct mention, reference, or implication of Azure DevOps or its specific functionalities, tools, or methodologies. The content broadly aligns to Agile practices and metrics but remains generic, without any Azure DevOps context or application. The intended audience of this content appears to be Agile teams or general practitioners interested in workflow metrics, not specifically Azure DevOps users. There is some relevance if throughput as a concept is measured within Azure DevOps; however, this connection is not made in the content. No penalties were applied because the content is neither obsolete nor contradicts the framing. The overall low confidence score reflects the absence of Azure DevOps-specific context or focus.",
    "level": "Ignored"
  },
  "Pragmatic Thinking": {
    "resourceId": "Throughput",
    "category": "Pragmatic Thinking",
    "calculated_at": "2025-05-06T20:56:47",
    "ai_confidence": 79.1,
    "ai_mentions": 2.7,
    "ai_alignment": 8.5,
    "ai_depth": 7.8,
    "ai_intent": 7.9,
    "ai_audience": 8.4,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 79.0,
    "reasoning": "The content describes throughput in highly practical terms, emphasizing its role in quantifying team and system efficiency, detecting constraints, and informing decision-making—key aspects of pragmatic thinking. The alignment score is high because the discussion directly engages with real-world application in Agile and Lean contexts and focuses on actionable metrics (e.g., cumulative flow diagrams, work-in-progress limits). It doesn't name 'Pragmatic Thinking' but strongly demonstrates its principles. Depth is solid, with examples of how throughput is used and what it enables, but it stops short of specific case studies or deeply complex scenarios, so the score is slightly reduced. The intent is highly supportive of adaptation and evidence-based improvement, which is core to the category, as is the audience (Agile/Lean teams and practitioners). Signal-to-noise is strong, with no tangents, but not 'perfect' as the focus is specifically on throughput, not all of pragmatic thinking. No out-of-date practices or negative tone were observed, so no penalties are applied. The final confidence score reflects a strong, but not exhaustive, fit for the 'Pragmatic Thinking' category.",
    "level": "Secondary",
    "reasoning_summary": "This content is a strong fit for the 'Pragmatic Thinking' category, as it clearly explains throughput in practical, actionable terms relevant to Agile and Lean teams. It focuses on real-world application and evidence-based improvement, though it doesn’t cover every aspect of pragmatic thinking. The discussion is concise and relevant, supporting the category well without unnecessary detail."
  },
  "Asynchronous Development": {
    "resourceId": "Throughput",
    "category": "Asynchronous Development",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 19.1,
    "ai_mentions": 0.3,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 2.5,
    "ai_audience": 5.2,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 19.0,
    "reasoning": "The content focuses exclusively on throughput as a delivery metric, explaining its use in tracking system performance, trend analysis, and process improvement. There are no explicit mentions or references to asynchronous development, its principles, tools, workflows, or team collaboration across time zones. The discussion does not cover asynchronous versus synchronous practices or any challenges distinctive to asynchronous workflows. Instead, it remains entirely centered on throughput in general software or systems delivery contexts. While throughput measurement can be relevant to asynchronous development teams, the main themes, purpose, and details do not align with the described category. No parts of the content contradict or undermine asynchronous development, nor is it outdated, so no penalties are applied. The signal-to-noise ratio is high (content is on-topic regarding throughput), but this does not serve the intended category audience or purpose, explaining the low confidence score.",
    "level": "Ignored"
  },
  "Cell Structure Design": {
    "resourceId": "Throughput",
    "category": "Cell Structure Design",
    "calculated_at": "2025-05-06T20:56:47",
    "ai_confidence": 14.3,
    "ai_mentions": 0.5,
    "ai_alignment": 2.3,
    "ai_depth": 2.8,
    "ai_intent": 1.6,
    "ai_audience": 3.2,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content focuses on throughput as a delivery and observability metric for teams and systems. There are no direct mentions or references to Cell Structure Design, Beta Codex, autonomous cells, decentralisation, or complexity theory. The main ideas align more with generic Agile, Lean, and workflow optimisation, not with networked, cell-based organisational structures. While terms like 'transparency' and 'continuous improvement' appear (which are conceptually adjacent), their treatment is within the scope of delivery performance rather than organisational architecture. No references to audience or design approaches specific to Cell Structure Design are present. The discussion is relatively focused on metrics, offering depth, but that depth does not extend to the core principles of the evaluated category. No penalty is warranted, as the tone is neutral and there is no outdated or critical content.",
    "level": "Ignored"
  },
  "Azure Boards": {
    "resourceId": "Throughput",
    "category": "Azure Boards",
    "calculated_at": "2025-05-06T20:56:59",
    "ai_confidence": 36.6,
    "ai_mentions": 0.5,
    "ai_alignment": 3.7,
    "ai_depth": 3.3,
    "ai_intent": 3.2,
    "ai_audience": 4.9,
    "ai_signal": 4.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 37.0,
    "reasoning": "The content provides a general overview of the throughput metric, its meaning, and its applications in Agile and Lean workflows. However, there are no direct mentions of Azure Boards or its specific features, nor does the discussion center on how throughput is tracked, measured, or optimized within Azure Boards. While the discussion aligns with Agile teams and their interest in flow metrics (such as throughput), the conceptual link to Azure Boards is only implicit and not explored. The content addresses a relevant audience and avoids off-topic discussion, but it's generic and lacks depth regarding Azure Boards implementation or best practices. Confidence is low due to lack of specificity and direct mention, but not zero since throughput is a metric used in Azure Boards for Agile project management and reporting.",
    "level": "Ignored"
  },
  "Scrum Values": {
    "resourceId": "Throughput",
    "category": "Scrum Values",
    "calculated_at": "2025-05-06T20:56:47",
    "ai_confidence": 11.25,
    "ai_mentions": 0.2,
    "ai_alignment": 1.6,
    "ai_depth": 2.9,
    "ai_intent": 2.3,
    "ai_audience": 2.7,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 11.0,
    "reasoning": "The content provides a detailed explanation of 'Throughput' as a metric for measuring completed work and improving flow in Agile or Lean systems. However, it does not mention Scrum Values or the five key principles (Commitment, Courage, Focus, Openness, Respect), nor does it anchor its discussion in the values underpinning Scrum. There is only a tangential connection through generic terms like 'transparency' and 'continuous improvement,' which are not discussed within the context of Scrum Values but rather as properties of empirical process control. The primary audience appears to be practitioners interested in metrics and flow analysis—not specifically those seeking foundational guidance on Scrum Values. No penalties were applied since the content is not outdated or critical in tone, but the confidence rating is low because the material falls outside the intended scope as defined.",
    "level": "Ignored"
  },
  "Troubleshooting": {
    "resourceId": "Throughput",
    "category": "Troubleshooting",
    "calculated_at": "2025-05-06T20:56:51",
    "ai_confidence": 30.45,
    "ai_mentions": 0.9,
    "ai_alignment": 3.4,
    "ai_depth": 3.1,
    "ai_intent": 3.8,
    "ai_audience": 7.2,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 30.0,
    "reasoning": "The content focuses on defining throughput as a metric for how much work a system completes, with emphasis on flow efficiency, system delivery, and performance monitoring. There is an implicit connection to the identification of system constraints (which could be relevant to troubleshooting), but the core content uses throughput in a general observability and process improvement context, rather than directly addressing issue identification or resolution. Direct mentions of troubleshooting are absent. While some concepts like 'detecting constraints' and using data for feedback could tangentially support troubleshooting efforts, the main purpose remains descriptive and informational about throughput as a flow metric, not systematic troubleshooting in a technical sense. The audience is reasonably aligned (technical practitioners), and the content stays focused with minimal extraneous information, but the conceptual alignment and depth with respect to troubleshooting are low.",
    "level": "Ignored"
  },
  "Agile Philosophy": {
    "resourceId": "Throughput",
    "category": "Agile Philosophy",
    "calculated_at": "2025-05-06T20:56:51",
    "ai_confidence": 67.2,
    "ai_mentions": 2.2,
    "ai_alignment": 7.1,
    "ai_depth": 6.5,
    "ai_intent": 6.8,
    "ai_audience": 7.4,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 67.0,
    "reasoning": "The content centers on 'Throughput' as an observability and delivery metric, describing its use in tracking flow, identifying constraints, and enabling empirical improvement. While it acknowledges concepts like transparency, continuous improvement, and feedback, which align with Agile principles, there are few if any direct references to Agile Philosophy (such as the Manifesto, core values, or explicit cultural/organizational shifts). Instead, references to Agile are contextual—mentioning that throughput is used in Agile and Lean contexts—rather than exploring Agile as a mindset. Depth is moderate: the article describes throughput's purpose and relationship to improvement but does not explore philosophical underpinnings or contrast throughput with other Agile Philosophy themes. The audience is practitioners interested in metrics—likely relevant to Agile teams—but the focus is more technical and practical than philosophical. Signal-to-noise is high, as the content is tightly focused, but overall it leans towards applied practice rather than philosophical discussion. This produces a moderate confidence: the concepts align with Agile Philosophy as supporting elements, but the main thrust is on the metric itself and its pragmatic benefits, not on Agile Philosophy as a whole.",
    "level": "Secondary"
  },
  "Lean": {
    "resourceId": "Throughput",
    "category": "Lean",
    "calculated_at": "2025-05-06T20:56:52",
    "ai_confidence": 74.85,
    "ai_mentions": 5.6,
    "ai_alignment": 8.5,
    "ai_depth": 7.8,
    "ai_intent": 8.9,
    "ai_audience": 7.7,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 75.0,
    "reasoning": "The content directly mentions Lean only once, alongside Agile, resulting in a moderate 'Direct Mentions' score. Its conceptual alignment is strong—the description of throughput focuses on flow efficiency, system constraints, and continuous improvement, all central principles in Lean thinking. The mention of tools like cumulative flow diagrams and emphasis on value delivery ties well with Lean, though the discussion could be more explicit about Lean methodologies. Depth is well above average: it explores throughput beyond surface-level definitions, discussing its use for inspecting system performance, continuous improvement, and feedback mechanisms. The intent clearly fits the Lean category by aiming to inform process improvement and support empiricism. The primary audience appears to be practitioners and teams involved in workflow optimization, aligning with the Lean audience. Signal-to-noise is high, with nearly all content relevant and focused, providing practical examples of throughput’s significance in process management. No outdated or contradictory elements are present; thus, no penalties are applied. The final confidence score reflects a strong, but not absolute, match: the main concepts fit Lean, but the content is not exclusively Lean-centric and could enhance explicit Lean terminology and methodology references.",
    "level": "Secondary",
    "reasoning_summary": "This content is a strong fit for the Lean category. While it only briefly mentions Lean by name, its focus on flow efficiency, system constraints, and continuous improvement closely aligns with Lean principles. The discussion is practical and relevant for process improvement, making it valuable for Lean practitioners, though it could be even stronger with more explicit Lean terminology and examples."
  },
  "Azure Pipelines": {
    "resourceId": "Throughput",
    "category": "Azure Pipelines",
    "calculated_at": "2025-05-06T20:56:51",
    "ai_confidence": 8.8,
    "ai_mentions": 0.2,
    "ai_alignment": 1.3,
    "ai_depth": 1.6,
    "ai_intent": 1.5,
    "ai_audience": 2.5,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "The content focuses strictly on the definition, purpose, and value of the throughput metric within general workflow and delivery contexts, referencing Agile, Lean, and observability practices in software teams. There are no direct or indirect mentions of Azure Pipelines or any Azure DevOps-specific tooling, nor is the concept tied to CI/CD or pipeline automation in the Azure ecosystem. The key topics (pipeline configuration, YAML definitions, deployment strategies, CI/CD, etc.) are not covered. The metric is framed broadly to apply to workflow systems or possibly software teams but without reference to any specific platform or technology. The audience could overlap technically, but this would be incidental rather than intentional. Thus, all dimensions receive very low scores, and the confidence score is correspondingly minimal and proportional to the absence of relevant Azure Pipelines content.",
    "level": "Ignored"
  },
  "Technical Mastery": {
    "resourceId": "Throughput",
    "category": "Technical Mastery",
    "calculated_at": "2025-05-06T20:56:51",
    "ai_confidence": 69.6,
    "ai_mentions": 2.1,
    "ai_alignment": 7.8,
    "ai_depth": 7.2,
    "ai_intent": 7.6,
    "ai_audience": 7.0,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 70.0,
    "reasoning": "There is only a weak direct mention of technical mastery concepts—terms like 'software craftsmanship', 'code quality', or 'engineering practices' do not appear. However, the content aligns conceptually with some core technical mastery ideas, particularly with respect to measuring and improving system performance via throughput metrics. It discusses techniques for tracking performance using cumulative flow diagrams and flow analytics, which are relevant tools in technical delivery. The depth covers several practical implications—such as detecting trends, adjusting WIP limits, and utilizing empirical feedback for continuous improvement—though it remains focused on throughput as a delivery metric rather than the broader aspects of software craftsmanship or architectural best practices. The intent is informative and targets an audience familiar with Agile/Lean and technical delivery, reasonably aligned but still a bit general (could be of interest beyond just technical mastery practitioners). Signal-to-noise is high as most content is on-topic, but not wholly focused on architectural or code-level excellence. No penalties were necessary, as content does not contradict or undermine the category and references remain modern.",
    "level": "Secondary"
  },
  "Common Goals": {
    "resourceId": "Throughput",
    "category": "Common Goals",
    "calculated_at": "2025-05-06T20:56:54",
    "ai_confidence": 39.95,
    "ai_mentions": 0.7,
    "ai_alignment": 4.3,
    "ai_depth": 3.6,
    "ai_intent": 2.8,
    "ai_audience": 7.2,
    "ai_signal": 7.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 40.0,
    "reasoning": "The content is focused on throughput as a delivery and flow metric. It provides a substantive overview of what throughput measures, its value for teams, and how it fits within Agile and Lean observability, including its use for empirical inspection and continuous improvement. However, there is virtually no direct mention or discussion of 'Common Goals', alignment with strategic objectives, or examples like OKRs, Product Goals, or Sprint Goals. The main intent is exploratory and informative about a process metric, not the concept of Common Goals. While relevant for Agile practitioners (audience-aligned), the discussion remains tactical, concentrated on metrics and flow efficiency rather than foundational alignment of strategy and execution. Depth is moderate in relation to metrics, not Common Goals. The content is focused without filler, resulting in a high signal-to-noise ratio. No penalties were applied, as the content is current, neutral, and not critical or contradictory; but due to the lack of coverage of Common Goals, confidence is low to moderate.",
    "level": "Ignored"
  },
  "Ability to Innovate": {
    "resourceId": "Throughput",
    "category": "Ability to Innovate",
    "calculated_at": "2025-05-06T20:56:54",
    "ai_confidence": 26.15,
    "ai_mentions": 0.5,
    "ai_alignment": 2.2,
    "ai_depth": 2.3,
    "ai_intent": 3.3,
    "ai_audience": 7.5,
    "ai_signal": 6.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 26.0,
    "reasoning": "The content explicitly discusses throughput as a delivery metric, highlighting its use in tracking system flow, identifying constraints, and supporting continuous improvement. However, it does not directly mention innovation or specifically link throughput to the organization's ability to innovate, nor does it address key innovation-related topics such as learning cycles, experimentation, or innovation capability metrics. There are no explicit references to Evidence-Based Management or established innovation theories in Agile or DevOps contexts. Therefore, while the content is methodologically relevant and may be tangentially useful for innovation discussions, the conceptual alignment and depth regarding 'Ability to Innovate' are quite limited. The intended audience (teams using Agile/Lean methods) aligns moderately with the category, and the content is focused and relevant to delivery metrics, resulting in a higher signal-to-noise ratio score. No penalties are applied due to outdatedness or contradiction.",
    "level": "Ignored"
  },
  "Continuous Learning": {
    "resourceId": "Throughput",
    "category": "Continuous Learning",
    "calculated_at": "2025-05-06T20:56:54",
    "ai_confidence": 57.6,
    "ai_mentions": 2.8,
    "ai_alignment": 6.7,
    "ai_depth": 6.9,
    "ai_intent": 5.7,
    "ai_audience": 7.2,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 58.0,
    "reasoning": "The content discusses throughput primarily as a metric for analyzing flow and performance in Agile and Lean environments. While it touches on concepts tangential to Continuous Learning—such as empirical inspection, transparency, and continuous improvement—the explicit focus is on measurement and system efficiency rather than the practices and mindsets that foster continuous learning. There is no direct mention of 'Continuous Learning,' growth mindset, knowledge sharing, or skill development. The alignment and depth scores reflect partial connection via references to feedback loops and ongoing inspection, but the discussion does not deeply engage with how throughput enables learning at the individual or team level. The audience is well-aligned (Agile, Lean practitioners), and the signal is strong as the content is concise and focused. No penalties were applied, as the content is not outdated nor is the tone negative. The final confidence score represents a moderate but not strong fit with the 'Continuous Learning' category.",
    "level": "Tertiary"
  },
  "Agile Product Operating Model": {
    "resourceId": "Throughput",
    "category": "Agile Product Operating Model",
    "calculated_at": "2025-05-06T20:56:55",
    "ai_confidence": 55.95,
    "ai_mentions": 1.2,
    "ai_alignment": 6.1,
    "ai_depth": 5.8,
    "ai_intent": 6.4,
    "ai_audience": 6.3,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 56.0,
    "reasoning": "The content discusses throughput as a delivery and observability metric in Agile and Lean contexts. It covers how throughput reflects systemic delivery, supports trend analysis, identifies constraints, and aids in empirical inspection and continuous improvement—elements tangentially relevant to the Agile Product Operating Model (APOM). However, it never directly mentions APOM or any of its defining frameworks, practices, or organizational shifts. The discussion is at the metric/process level rather than about the holistic operating model, so alignment and depth are moderate. The intent is somewhat relevant, focusing on operational insights that could support APOM goals, and the audience seems to include practitioners interested in metrics that impact product delivery. However, the content lacks explicit, deep discussion of APOM itself, its principles, or the broader product operating paradigm. The signal is fairly high, as the content maintains focus on throughput without going off-topic, but ultimately, the fit is indirect and mainly through supporting agile concepts rather than direct APOM substance.",
    "level": "Tertiary"
  },
  "Scrum Master": {
    "resourceId": "Throughput",
    "category": "Scrum Master",
    "calculated_at": "2025-05-06T20:56:56",
    "ai_confidence": 32.65,
    "ai_mentions": 0.4,
    "ai_alignment": 3.2,
    "ai_depth": 4.2,
    "ai_intent": 4.1,
    "ai_audience": 4.8,
    "ai_signal": 5.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 33.0,
    "reasoning": "The content describes throughput as a delivery metric and explains how it informs system inspection and process improvement. However, there are no direct mentions or explicit references to the Scrum Master role, nor is there a focus on the accountability, responsibilities, or distinct impact of the Scrum Master within Scrum. The discussion is generalized to Agile and Lean contexts, with no indication that it is tailored toward the Scrum framework or the specific accountabilities of a Scrum Master. Alignment is partially present in the sense that throughput metrics are tools a Scrum Master might use to foster empiricism and continuous improvement, but there is no discussion about how the Scrum Master enables these outcomes or their unique influence. The depth is moderate, focused on describing what throughput is, its utility, and related tools, but not applied to the systemic change led by a Scrum Master. The intent seems to be informative for practitioners or teams who are measuring and acting on throughput, with some indirect value for a Scrum Master, but it's not directly accountable or purpose-built for them. The audience is fairly generic (teams, possibly Scrum Masters or Agile Coaches), and while the signal-to-noise ratio is decent (the content is focused on throughput), it does not orient itself to the audience of Scrum Masters per se. No penalties were applied, as the content is not outdated nor critical, but it only receives low to moderate marks across most dimensions for lack of specificity, direct reference, and role alignment.",
    "level": "Ignored"
  },
  "Continuous Improvement": {
    "resourceId": "Throughput",
    "category": "Continuous Improvement",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 87.6,
    "ai_mentions": 7.3,
    "ai_alignment": 9.5,
    "ai_depth": 8.6,
    "ai_intent": 8.9,
    "ai_audience": 8.1,
    "ai_signal": 8.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 88.0,
    "reasoning": "The content explicitly references how throughput enables 'empirical inspection,' 'feedback that informs decision-making', and 'guides adjustments,' which are essential elements of continuous improvement. The text situates throughput within Agile and Lean contexts—further aligning it with the continuous improvement philosophy. It discusses using throughput to assess workflow changes, visualisation tools, and real-time analysis, all of which are methods used for continuous, iterative enhancement. However, 'continuous improvement' is referenced directly only once and implicitly otherwise, resulting in a slightly lower mentions score. The content assumes a practitioner or agile-focused audience, fitting the category's target group, but is technical enough that some less-experienced audiences may not be fully addressed, leading to an 8.1 in audience alignment. Depth is strong, detailing several mechanisms by which throughput supports ongoing improvement, but does not explore cultural or large-scale strategic implications, so does not receive a perfect score. No penalties applied as there are no outdated practices or tone issues. The confidence score (87.6) reflects a strong but not absolutely comprehensive fit.",
    "level": "Primary",
    "reasoning_summary": "This content is a strong fit for the continuous improvement category, as it clearly explains how throughput supports ongoing enhancement in Agile and Lean settings. It covers practical methods like workflow assessment and real-time analysis, making it relevant for practitioners. While it could address broader strategic aspects, its focus on actionable techniques and feedback loops aligns well with the category’s intent."
  },
  "Forecasting": {
    "resourceId": "Throughput",
    "category": "Forecasting",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 81.6,
    "ai_mentions": 3.2,
    "ai_alignment": 8.1,
    "ai_depth": 8.4,
    "ai_intent": 7.9,
    "ai_audience": 8.0,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 82.0,
    "reasoning": "The content thoroughly explains throughput within Agile and Lean environments, highlighting it as a key metric for inspecting flow and system effectiveness. It mentions empirical inspection, trend detection, and improvement, all of which conceptually align well with forecasting practices, especially when combined with tools like cumulative flow diagrams. However, the term 'forecasting' is not directly mentioned and the primary focus is on observability and measurement of throughput, not purely on forecasting future outcomes. While the discussion details how throughput informs planning and decision-making—essential elements for forecasting—it does not delve deeply into forecasting techniques or best practices specifically. The content’s intent is informative and targets Agile practitioners, matching the category’s intended audience. Signal is strong with minimal filler. The calibrated confidence reflects conceptually strong but not explicit alignment with forecasting, moderately limited by infrequent direct references.",
    "level": "Primary",
    "reasoning_summary": "The content fits the category as it clearly discusses throughput in Agile and Lean contexts, emphasising its role in monitoring and improving workflow—key aspects relevant to forecasting. While it doesn’t explicitly focus on forecasting methods, it provides valuable insights for practitioners interested in using throughput data for planning and prediction, making it a strong conceptual match for the category’s audience."
  },
  "Acceptance Test Driven Development": {
    "resourceId": "Throughput",
    "category": "Acceptance Test Driven Development",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 2.1,
    "ai_mentions": 0.0,
    "ai_alignment": 1.3,
    "ai_depth": 1.6,
    "ai_intent": 2.1,
    "ai_audience": 2.7,
    "ai_signal": 2.6,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content does not directly mention Acceptance Test Driven Development or any related terms, resulting in a zero for the 'mentions' dimension. Conceptually, the entire discussion centers on throughput as a metric for delivery flow and performance—not acceptance criteria, test automation, or collaborative practices associated with ATDD. Alignment and depth are both very low because there is no substantive overlap with ATDD's core principles, practices, or stakeholder interactions. The purpose is to inform about observability and improvement at a process level, not to educate on ATDD specifically, so the intent dimension is also very low. The intended audience is practitioners interested in delivery metrics, which might include some overlap with ATDD audiences, but the content does not target or address ATDD-specific challenges, tools, or methodologies. Signal-to-noise ratio is moderate; the content is focused but completely off-topic for ATDD. No penalties were applied: the content is not outdated nor is it critical of ATDD. The final confidence score is very low, accurately reflecting that there is negligible relevance to the 'Acceptance Test Driven Development' category.",
    "level": "Ignored"
  },
  "Organisational Physics": {
    "resourceId": "Throughput",
    "category": "Organisational Physics",
    "calculated_at": "2025-05-06T20:56:48",
    "ai_confidence": 59.7,
    "ai_mentions": 0.7,
    "ai_alignment": 6.4,
    "ai_depth": 6.7,
    "ai_intent": 7.2,
    "ai_audience": 7.6,
    "ai_signal": 8.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 60.0,
    "reasoning": "The content on 'Throughput' directly discusses the use of throughput as a system-level, flow-based delivery metric, referencing systems performance and analysis of overall workflow rather than individual productivity. This aligns conceptually with organisational physics, particularly in its focus on system constraints, feedback, and value flow. However, 'Organisational Physics' is not directly mentioned (hence a low 'mentions' score), and while systems thinking is implied (via flow, constraints, and feedback), the content does not explicitly discuss systems thinking principles, holistic system dynamics, or emergent behaviour in-depth—thus, depth and alignment are moderate. The intent is practical and informative for practitioners, aiming to improve organisational outcomes, which fits the category audience and purpose. Signal-to-noise is strong, as the content remains focused. No penalties were applied as there is no outdated or contradictory information. Overall, the confidence reflects a solid if moderately indirect fit for Organisational Physics: it applies core concepts but lacks explicit theory and depth.",
    "level": "Tertiary"
  },
  "Entrepreneurship": {
    "resourceId": "Throughput",
    "category": "Entrepreneurship",
    "calculated_at": "2025-05-06T20:56:58",
    "ai_confidence": 15.6,
    "ai_mentions": 0.4,
    "ai_alignment": 1.6,
    "ai_depth": 1.8,
    "ai_intent": 2.5,
    "ai_audience": 4.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "The content focuses exclusively on 'Throughput' as a delivery and flow metric, explaining its use in tracking work completed over time, flow efficiency, and system constraints. There are no direct or implicit references to entrepreneurship, innovation, risk-taking, or entrepreneurial mindset. The explanation is rooted in general team and system observability, particularly within Agile and Lean practices, which may have tangential value in entrepreneurial settings but do not address any core entrepreneurial principles or strategies. No discussion is made regarding business creation, risk management, or value-driven decision-making specific to entrepreneurship. The intent is clearly informational about throughput measurement, oriented more towards process improvement and project management professionals. The content is focused with minimal off-topic noise, but almost none of the signal pertains to entrepreneurship as defined. No penalties applied as the content is current and not critical of the category; the low score reflects lack of category fit, not outdated or negative tone.",
    "level": "Ignored"
  },
  "Strategic Goals": {
    "resourceId": "Throughput",
    "category": "Strategic Goals",
    "calculated_at": "2025-05-06T20:56:48",
    "ai_confidence": 46.42,
    "ai_mentions": 1.2,
    "ai_alignment": 4.3,
    "ai_depth": 4.5,
    "ai_intent": 4.0,
    "ai_audience": 6.0,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 46.0,
    "reasoning": "The content describes throughput as a delivery metric within Agile and Lean contexts, with emphasis on measurement and continuous improvement. There is no direct mention of 'strategic goals' or explicit connection to long-term objectives or business agility at an organizational level. The focus is on operational flow, efficiency, and team-level adaptation rather than establishing, aligning, or refining strategic objectives. While throughput data could technically inform strategic decision-making, this content makes no such connection, instead centering on tactical inspection and workflow management. Audience alignment is moderate, as practitioners and analysts would use the described techniques, but strategists and executives are not clearly targeted. Signal is relatively high, as the explanations are relevant and on topic, but relevance to the 'Strategic Goals' category is limited to indirect relationships with continuous improvement. The depth score reflects a solid exploration of throughput but not of strategic goal setting or measurement. No penalties are applied as the content is current, neutral in tone, and not outdated.",
    "level": "Tertiary"
  },
  "Team Collaboration": {
    "resourceId": "Throughput",
    "category": "Team Collaboration",
    "calculated_at": "2025-05-06T20:57:00",
    "ai_confidence": 53.35,
    "ai_mentions": 1.2,
    "ai_alignment": 5.9,
    "ai_depth": 5.5,
    "ai_intent": 4.2,
    "ai_audience": 8.0,
    "ai_signal": 6.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 53.0,
    "reasoning": "The content primarily discusses 'throughput' as a team-level metric in Agile and Lean systems, focusing on the observability of system flow and value delivery. There is an indirect link to team collaboration, particularly in references to team-level inspection, adjusting team composition, and transparency. However, the discussion does not explicitly address collaboration techniques, shared ownership, communication, or the interpersonal dynamics that define the 'Team Collaboration' category. The intent is more aligned with workflow and system performance rather than enhancing or exploring team collaboration itself. The audience (Agile/DevOps practitioners) matches, and the content maintains high signal-to-noise, with minimal off-topic material. Nonetheless, since team collaboration is neither the main focus nor deeply explored, the confidence score remains moderate, reflecting conceptual adjacency but insufficient direct coverage.",
    "level": "Tertiary"
  },
  "Agnostic Agile": {
    "resourceId": "Throughput",
    "category": "Agnostic Agile",
    "calculated_at": "2025-05-06T20:56:48",
    "ai_confidence": 38.9,
    "ai_mentions": 0.3,
    "ai_alignment": 3.7,
    "ai_depth": 3.2,
    "ai_intent": 3.3,
    "ai_audience": 5.2,
    "ai_signal": 5.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content focuses exclusively on the metric of throughput as a tool for inspecting work progress and system flow in agile or Lean environments. While it references flow efficiency, empirical inspection, and continuous improvement—ideas compatible with Agnostic Agile—it never explicitly mentions Agnostic Agile nor addresses its unique principles, ethical considerations, or context-driven approach. The main purpose is informative but does not go beyond generic agile/Lean best practices, with no clear comparison to rigid frameworks or discussion of tailoring methodology based on context. Audience alignment is moderate, as the topic is broadly relevant to agile practitioners. The signal is reasonably high as the content stays on topic, but it only covers throughput as a concept—not the philosophy or principles behind Agnostic Agile. Therefore, the overall confidence that this content specifically fits under the 'Agnostic Agile' category is modest.",
    "level": "Ignored"
  },
  "Deployment Strategies": {
    "resourceId": "Throughput",
    "category": "Deployment Strategies",
    "calculated_at": "2025-05-06T20:56:48",
    "ai_confidence": 11.7,
    "ai_mentions": 0.4,
    "ai_alignment": 1.3,
    "ai_depth": 1.0,
    "ai_intent": 1.0,
    "ai_audience": 2.4,
    "ai_signal": 1.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 12.0,
    "reasoning": "This content focuses exclusively on 'throughput' as a delivery metric for assessing workflow efficiency and system constraints. It describes throughput's use for analyzing team delivery, identifying bottlenecks, and improving flow, referencing tools such as cumulative flow diagrams and its relevance in Agile and Lean contexts. However, there are no direct or even indirect mentions of deployment methodologies, risk mitigation practices, or techniques such as blue-green deployments, canary releases, rolling updates, feature toggles, infrastructure as code, or continuous deployment. The intent is centered on process and flow metrics, not deployment strategy. The target audience (teams interested in measurement and improvement) might sometimes overlap with those concerned with deployment, but the substance is not relevant for practitioners looking for actionable deployment strategies. The signal is almost entirely on process flow, not deployment. Accordingly, the confidence in this content fitting the 'Deployment Strategies' category is extremely low.",
    "level": "Ignored"
  },
  "Deployment Frequency": {
    "resourceId": "Throughput",
    "category": "Deployment Frequency",
    "calculated_at": "2025-05-06T20:56:48",
    "ai_confidence": 12.8,
    "ai_mentions": 0.2,
    "ai_alignment": 1.2,
    "ai_depth": 1.1,
    "ai_intent": 2.4,
    "ai_audience": 2.2,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 13.0,
    "reasoning": "The content focuses entirely on throughput as a metric for inspecting work completed per unit time, emphasizing flow efficiency, system constraints, and improvement in Agile/Lean settings. There are no direct mentions or discussions of deployment frequency, CI/CD, or rapid software release strategies. While throughput is related to delivery performance, the content does not connect its discussion to software deployment cycles, release intervals, or DevOps practices central to deployment frequency. The intent and target audience (teams interested in delivery metrics and flow) only partially overlap with the deployment frequency category. As such, the piece is tangential, with minimal conceptual alignment and depth regarding deployment frequency. No penalties were necessary since the content neither contradicts nor displays outdated practices.",
    "level": "Ignored"
  },
  "Market Share": {
    "resourceId": "Throughput",
    "category": "Market Share",
    "calculated_at": "2025-05-06T20:56:51",
    "ai_confidence": 7.8,
    "ai_mentions": 0.1,
    "ai_alignment": 1.2,
    "ai_depth": 1.0,
    "ai_intent": 0.9,
    "ai_audience": 2.5,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 8.0,
    "reasoning": "The content focuses entirely on the metric 'Throughput,' which is about measuring work completed over time to assess delivery efficiency, system flow, and process improvement. There is no explicit or implicit mention of market share, competitive positioning, or strategies to expand market presence. None of the key topics for the Market Share category, such as capturing a larger market audience or analyzing market competition, are present. The context is strictly operational and process-oriented for internal delivery teams rather than strategic market positioning. As such, only negligible alignment, mention, or relevance can be drawn. The small positive scores in each dimension reflect a generic business/operational audience but do not indicate substantive applicability to the Market Share category. No penalties were necessary as the content is neither outdated nor contradictory, simply irrelevant.",
    "level": "Ignored"
  },
  "Systems Thinking": {
    "resourceId": "Throughput",
    "category": "Systems Thinking",
    "calculated_at": "2025-05-06T20:56:51",
    "ai_confidence": 54.15,
    "ai_mentions": 1.2,
    "ai_alignment": 5.6,
    "ai_depth": 5.9,
    "ai_intent": 5.8,
    "ai_audience": 8.1,
    "ai_signal": 7.7,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 54.0,
    "reasoning": "The content directly discusses throughput, a system-level metric, but never mentions 'Systems Thinking' by name nor explicitly frames the discussion in terms of systems theory principles. Alignment is fair: throughput as a concept relates to understanding system performance and constraints, aligning indirectly with Systems Thinking notions of flow, feedback, and interdependence. However, there is little to no discussion of foundational systems thinking principles, holistic analysis, feedback loops as such, or the mapping of complex systems. The depth of discussion is modest; the content remains focused on throughput as a metric, tools for measuring it, and its benefits for transparency and improvement—yet it does not go beyond surface treatment or reference to broader systems concepts or methodologies (such as causal loop diagrams, system dynamics, or the Cynefin Framework). The intent is generally aligned with continuous improvement and systemic observation, but does not position itself within the systems thinking paradigm explicitly. The primary audience—teams practicing Agile or Lean—overlaps with those likely to be interested in systems thinking, boosting this dimension. The overall signal is high since the discussion is crisp and focused on throughput in a system context, but lacks wider systemic framing. The final confidence is moderate: throughput is relevant to system dynamics but the piece falls short of exploring or clearly connecting to Systems Thinking as a discipline.",
    "level": "Tertiary"
  },
  "Agile Values and Principles": {
    "resourceId": "Throughput",
    "category": "Agile Values and Principles",
    "calculated_at": "2025-05-06T20:56:48",
    "ai_confidence": 38.65,
    "ai_mentions": 3.1,
    "ai_alignment": 4.1,
    "ai_depth": 3.7,
    "ai_intent": 4.2,
    "ai_audience": 6.5,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 39.0,
    "reasoning": "The content focuses on throughput as a delivery metric and discusses its use in Agile and Lean contexts, particularly for examining flow efficiency and promoting continuous improvement. There is a brief touch on ideas like empirical inspection, transparency, and continuous improvement, which are related to Agile principles. However, the core discussion is centered on the metric, its utility, and relevant tools for measurement rather than on the Agile Values and Principles themselves. There are no direct references to the Agile Manifesto, its specific values, or the twelve principles; nor are there substantial discussions about the underlying philosophy, culture, or mindset shifts that comprise the core of this category. The purpose is informative about the metric, not an exploration of foundational Agile beliefs. Therefore, alignment and depth are moderate, and mentions are low as the category is not directly named or thoroughly examined. Audience fit is fair as practitioners interested in Agile metrics may read this, and the content signal is mostly on-topic without significant distractions. No penalties were applied since there are no signs of outdated practices or contradictory tone.",
    "level": "Ignored"
  },
  "Azure Repos": {
    "resourceId": "Throughput",
    "category": "Azure Repos",
    "calculated_at": "2025-05-06T20:56:52",
    "ai_confidence": 2.3,
    "ai_mentions": 0.0,
    "ai_alignment": 0.9,
    "ai_depth": 0.7,
    "ai_intent": 2.0,
    "ai_audience": 5.1,
    "ai_signal": 2.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 2.0,
    "reasoning": "The content focuses exclusively on throughput as a delivery metric, referencing concepts like flow, work item completion, and continuous improvement within Agile/Lean contexts. There are no direct mentions of Azure Repos, or even general source control practices, nor any discussion of Git/TFVC, branching, code reviews, or integration with CI/CD as specified in the classification definition. The conceptual alignment and depth scores are very low since the content addresses metrics and flow efficiency, not functionalities or best practices relevant to Azure Repos. The intent could serve technical audiences interested in DevOps, but the material does not specifically target those seeking Azure Repos guidance. The overall confidence score is extremely low accordingly, as the content is off-category with no relevant mention or coverage of the required topics.",
    "level": "Ignored"
  },
  "Technical Debt": {
    "resourceId": "Throughput",
    "category": "Technical Debt",
    "calculated_at": "2025-05-06T20:56:47",
    "ai_confidence": 14.23,
    "ai_mentions": 0.4,
    "ai_alignment": 1.6,
    "ai_depth": 1.9,
    "ai_intent": 2.2,
    "ai_audience": 4.3,
    "ai_signal": 4.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 14.0,
    "reasoning": "The content is focused exclusively on the metric of throughput—how much work is completed in a given time frame—as an indicator of flow efficiency in Agile and Lean environments. There are no direct mentions of technical debt or its management, nor is there any exploration of technical debt concepts such as suboptimal code, remediation strategies, or its impact on maintainability. The discussion is purely about delivery metrics and process flow optimization, not about the trade-offs or long-term code health that define technical debt. While the intended audience (software teams, Agile practitioners) might overlap partially with that of technical debt content, the main themes do not substantially align. The signal-to-noise ratio is reasonably high, but the signals are not relevant to the technical debt category. Therefore, the overall confidence that this content fits the 'Technical Debt' category is very low.",
    "level": "Ignored"
  },
  "Test Driven Development": {
    "resourceId": "Throughput",
    "category": "Test Driven Development",
    "calculated_at": "2025-05-06T20:56:52",
    "ai_confidence": 7.25,
    "ai_mentions": 0.0,
    "ai_alignment": 0.75,
    "ai_depth": 0.7,
    "ai_intent": 1.1,
    "ai_audience": 2.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 7.0,
    "reasoning": "The content does not reference Test Driven Development (TDD) directly or indirectly. Its entire focus is on throughput as a flow metric in software delivery, with discussion of metrics like cumulative flow diagrams and WIP limits, all of which pertain to Agile and Lean process management. There are no mentions of writing tests, the TDD cycle, code quality, testing frameworks, or any TDD concepts. The audience is practitioners focused on delivery and process management, not specifically TDD practitioners. No penalty deductions were required. All scores are low and varied to represent total lack of relevance to the Test Driven Development category. The final confidence score is extremely low, appropriately reflecting the complete misalignment with TDD topics.",
    "level": "Ignored"
  },
  "Ethos": {
    "resourceId": "Throughput",
    "category": "Ethos",
    "calculated_at": "2025-05-13T21:57:39",
    "ai_confidence": 22.7,
    "ai_mentions": 0.2,
    "ai_alignment": 2.8,
    "ai_depth": 2.3,
    "ai_intent": 2.4,
    "ai_audience": 7.1,
    "ai_signal": 7.9,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 23.0,
    "reasoning": "The content thoroughly discusses throughput as a metric for flow and delivery analysis, detailing its practical use for feedback and improvement in Agile and Lean settings. However, it does not reference or explore foundational beliefs, convictions, or system-level values underpinning ethos. The focus is on actionable metrics, not the sustaining ethos beneath Agile or Lean. There’s no discussion of ethos-driven leadership or system behaviour, and references are strictly to practices and measurement. Audience fit is strong for practitioners, and the content is focused and clear, but lacks conceptual and depth alignment to the ethos category.",
    "reasoning_summary": "This content discusses throughput as a performance metric, focusing on tools and practical implementation in Agile and Lean but lacks exploration of underlying convictions or system beliefs, making it a weak fit for the 'Ethos' category.",
    "level": "Ignored"
  },
  "Agile Transformation": {
    "resourceId": "Throughput",
    "category": "Agile Transformation",
    "calculated_at": "2025-05-13T21:57:37",
    "ai_confidence": 62.0,
    "ai_mentions": 3.6,
    "ai_alignment": 7.1,
    "ai_depth": 6.8,
    "ai_intent": 7.3,
    "ai_audience": 6.1,
    "ai_signal": 6.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 62.0,
    "reasoning": "The content discusses throughput as a flow metric valuable in Agile and Lean settings, explaining its application, benefits, and tools like cumulative flow diagrams. While it references Agile principles (empirical inspection, continuous improvement), it centers on a specific metric rather than the full scope of Agile transformation (strategies, change management, leadership, etc.). The intent is informative and somewhat aligned, but depth on transformation is moderate. No penalties applied.",
    "reasoning_summary": "This content explains throughput in Agile and Lean contexts and highlights its role in delivering value and continuous improvement. While relevant to Agile practices, its primary focus on a specific metric means only partial alignment with the comprehensive scope of Agile transformation.",
    "level": "Secondary"
  },
  "Customer Focus": {
    "resourceId": "Throughput",
    "category": "Customer Focus",
    "calculated_at": "2025-05-13T21:57:39",
    "ai_confidence": 23.65,
    "ai_mentions": 0.1,
    "ai_alignment": 2.7,
    "ai_depth": 2.3,
    "ai_intent": 2.9,
    "ai_audience": 7.2,
    "ai_signal": 8.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 24.0,
    "reasoning": "The content centers on 'throughput' as a delivery metric for analyzing work completion and system flow but does not link this measurement to customer value, outcomes, or customer-focused decisions. It prioritizes internal process inspection, flow optimization, and empirical planning within teams. Feedback loops and improvement discussions are focused on team effectiveness, not customer impact or validated needs. No substantive mention or actionable practices relating throughput directly to customer outcomes, feedback, or value measurement—distinct exclusions per guidelines.",
    "reasoning_summary": "This content focuses on throughput and internal process metrics, without connecting those metrics to customer value, feedback, or outcomes. Its primary emphasis is on delivery efficiency and system optimization, not Customer Focus as defined by the category.",
    "level": "Ignored"
  },
  "First Principal": {
    "resourceId": "Throughput",
    "category": "First Principal",
    "calculated_at": "2025-05-13T21:57:39",
    "ai_confidence": 34.85,
    "ai_mentions": 0.1,
    "ai_alignment": 4.6,
    "ai_depth": 3.9,
    "ai_intent": 5.2,
    "ai_audience": 8.3,
    "ai_signal": 7.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 35.0,
    "reasoning": "The content thoroughly describes the concept of throughput as a delivery metric in Lean/Agile, focusing on its value for teams and systems. However, it does not directly mention or define first principles, nor does it clearly distinguish between first and derived principles, or frame throughput as an immutable, foundational constraint. The discussion remains at the level of important metrics and practices, rather than the identification, explanation, or application of first principles as required by the strict category definition.",
    "reasoning_summary": "This content details throughput as an important metric in Lean/Agile, but it doesn’t link it to foundational first principles or discuss it as an immutable constraint. It’s informative for practitioners, but falls short of qualifying as a robust first principles discussion.",
    "level": "Ignored"
  },
  "Portfolio Management": {
    "resourceId": "Throughput",
    "category": "Portfolio Management",
    "calculated_at": "2025-05-13T21:57:40",
    "ai_confidence": 42.5,
    "ai_mentions": 1.2,
    "ai_alignment": 3.9,
    "ai_depth": 4.3,
    "ai_intent": 3.7,
    "ai_audience": 6.8,
    "ai_signal": 7.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 42.0,
    "reasoning": "The content focuses on throughput as a team-level and system-wide delivery metric. There is no explicit mention of portfolio management or alignment of investments with strategy. While throughput is relevant to Agile and Lean practices, it is discussed in terms of process health, flow efficiency, and team optimization—not portfolio-level prioritization, value stream management, or organizational strategy alignment. The audience may include strategists but the level is practitioner-focused. Therefore, alignment and depth are modest, and direct mentions are nearly absent, resulting in a moderate-to-low confidence score.",
    "reasoning_summary": "This content explains throughput as a team or system metric, relevant to delivery and flow but not directly to portfolio management. It lacks references to portfolio strategy, investment prioritization, or value stream optimization at the portfolio level, so the category fit is weak.",
    "level": "Tertiary"
  },
  "Install and Configuration": {
    "resourceId": "Throughput",
    "category": "Install and Configuration",
    "calculated_at": "2025-05-13T21:57:38",
    "ai_confidence": 2.7,
    "ai_mentions": 0.0,
    "ai_alignment": 0.8,
    "ai_depth": 0.7,
    "ai_intent": 1.2,
    "ai_audience": 3.8,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 3.0,
    "reasoning": "The content focuses exclusively on throughput as a metric in Agile/Lean contexts, discussing its measurement, purpose, and connection to workflow health. There are no direct or indirect mentions of installation or configuration processes, nor any substantive exploration of tools or practices involved in setting up such measurements. The audience is mixed, with some technical references to diagrams, but lacks install/config guidance. No penalties applied, but scores are extremely low across all critical install-config dimensions.",
    "reasoning_summary": "This content is all about understanding and using the throughput metric in Agile but never discusses installing or configuring tools or systems. It's conceptual, not technical setup–focused, so it doesn't match the Install and Configuration category.",
    "level": "Ignored"
  },
  "Evidence Based Leadership": {
    "resourceId": "Throughput",
    "category": "Evidence Based Leadership",
    "calculated_at": "2025-05-13T21:57:40",
    "ai_confidence": 84.7,
    "ai_mentions": 4.6,
    "ai_alignment": 8.6,
    "ai_depth": 7.8,
    "ai_intent": 8.2,
    "ai_audience": 8.9,
    "ai_signal": 9.4,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 85.0,
    "reasoning": "The content clearly discusses throughput as a metric for system-wide performance, focusing on empirical inspection and data-driven improvement, directly supporting evidence-based decision-making. It references tools and practices (cumulative flow, flow analytics) linked to Agile and Lean, which align with the category's focus. While 'evidence based leadership' is not mentioned directly, the discussion is conceptually tied to leadership practices that rely on objective metrics. The depth is moderate: the text explores implications for workflow, planning, and process adjustment, but does not include explicit leadership case studies or cite best practices by name. Intent and audience are highly aligned, targeting leaders or team facilitators interested in objective, actionable data for driving improvement. Nearly all content is relevant and focused, with minimal filler.",
    "reasoning_summary": "This content closely aligns with evidence-based leadership by emphasizing the use of throughput metrics for informed decision-making and system improvements. While it doesn't directly mention 'evidence-based leadership,' its focus on objective, analytic practices makes it highly relevant for leaders seeking data-driven insights.",
    "level": "Primary"
  },
  "Open Space Agile": {
    "resourceId": "Throughput",
    "category": "Open Space Agile",
    "calculated_at": "2025-05-13T21:57:40",
    "ai_confidence": 18.2,
    "ai_mentions": 0.0,
    "ai_alignment": 2.1,
    "ai_depth": 2.5,
    "ai_intent": 2.0,
    "ai_audience": 7.6,
    "ai_signal": 5.2,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 18.0,
    "reasoning": "The content focuses exclusively on the concept of throughput as a flow metric within Agile and Lean practices. It makes no direct or indirect reference to Open Space Agile or its core tenets, such as collective participation, emergence, psychological safety, or using Open Space Technology. There is no mention or contextual clue tying the content explicitly to the category. While the topic's general audience (Agile practitioners) is tangentially aligned, the depth, alignment, and intent are only weakly connected. The signal-to-noise ratio is moderate, as all discussion remains tightly scoped to throughput with little unrelated content, but the core topic diverges significantly from Open Space Agile.",
    "reasoning_summary": "This content discusses throughput in Agile, but never mentions Open Space Agile or its foundational principles. While the audience may overlap, the main focus is misaligned; it doesn’t explore Open Space practices or values, resulting in a very low confidence for this category.",
    "level": "Ignored"
  },
  "Definition of Workflow": {
    "resourceId": "Throughput",
    "category": "Definition of Workflow",
    "calculated_at": "2025-05-23T22:06:50",
    "ai_confidence": 26.73,
    "ai_mentions": 0.5,
    "ai_alignment": 3.0,
    "ai_depth": 2.2,
    "ai_intent": 2.9,
    "ai_audience": 6.0,
    "ai_signal": 2.0,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 27.0,
    "reasoning": "The content focuses on defining 'Throughput' as a delivery metric related to workflow and system performance, but does not mention or explore the Definition of Workflow itself. While it references concepts like WIP and workflow changes, these are discussed in the context of measuring flow, not explicitly articulating agreements or explicit workflow policies. The intent centers on metric explanation rather than workflow definition. The content aligns with an agile audience, is targeted, but only tangentially relates to the category.",
    "reasoning_summary": "This content gives an overview of throughput as a flow metric, not the Definition of Workflow. It only briefly relates to workflow by mentioning how throughput analysis supports workflow changes and improvements, but does not directly address or define workflow itself in the Kanban or agile sense.",
    "level": "Ignored"
  },
  "Objective Key Results": {
    "resourceId": "Throughput",
    "category": "Objective Key Results",
    "calculated_at": "2025-07-23T12:07:09",
    "ai_confidence": 8.59,
    "ai_mentions": 0.2,
    "ai_alignment": 1.3,
    "ai_depth": 1.7,
    "ai_intent": 1.0,
    "ai_audience": 2.1,
    "ai_signal": 2.3,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 9.0,
    "reasoning": "This content discusses throughput as an Agile/Lean flow metric, but does not mention or discuss Objectives or Key Results (OKRs), nor does it connect throughput to outcome-based measurement per the OKR framework. The focus is entirely on throughput as a delivery metric, not as part of an OKR system. There are some parallels in intent—such as transparency and improvement—but these are not framed within OKR principles, vocabulary, or John Doerr's 'Measure What Matters.' Depth is limited to discussing throughput in the context of process health, flow, and empirical feedback, not strategic outcomes or alignment. There is no indication the audience is focused on strategy/OKR topics.",
    "reasoning_summary": "The content focuses solely on throughput as a delivery and process flow metric, without referencing OKRs or aligning with their framework. Parallels in continuous improvement and transparency exist, but they're not related to Objectives or Key Results.",
    "level": "Ignored"
  },
  "Product Developer": {
    "resourceId": "Throughput",
    "category": "Product Developer",
    "calculated_at": "2025-07-23T12:07:18",
    "ai_confidence": 16.47,
    "ai_mentions": 0.1,
    "ai_alignment": 1.2,
    "ai_depth": 1.5,
    "ai_intent": 1.8,
    "ai_audience": 6.0,
    "ai_signal": 6.5,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 16.0,
    "reasoning": "The content exclusively discusses throughput as a team or system-level delivery metric, focusing on flow, efficiency, and tracking. There are no explicit or implied references to the Product Developer role, its accountabilities, or unique behaviors. The only faint alignment is that Product Developers might use throughput data, but this is generic to most Agile or Lean teams. The primary audience is practitioners interested in flow metrics, not those seeking information about Product Developer roles specifically.",
    "reasoning_summary": "The content is focused on system throughput metrics in Agile and Lean contexts, with no meaningful reference to the Product Developer role’s purpose, accountability, or behaviors. Its relevance to the 'Product Developer' category is minimal and highly incidental.",
    "level": "Ignored"
  },
  "Agentic Engineering": {
    "resourceId": "Throughput",
    "category": "Agentic Engineering",
    "calculated_at": "2025-07-23T12:07:28",
    "ai_confidence": 57.6,
    "ai_mentions": 0.2,
    "ai_alignment": 6.8,
    "ai_depth": 5.6,
    "ai_intent": 7.2,
    "ai_audience": 7.0,
    "ai_signal": 8.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 58.0,
    "reasoning": "The content introduces throughput as a metric for flow and system inspection, emphasizing observability, feedback, and empirical adaptation—concepts related to Agentic Engineering. However, it does not refer to 'agentic engineering' directly and lacks explicit discussion of developer or AI agency, ethical considerations, or autonomy-driven engineering practices. The focus is technical (metrics/flow) rather than philosophical or transformative, which reduces alignment and depth. The target audience (practitioners) and the signal-to-noise ratio are strong.",
    "reasoning_summary": "This piece focuses on throughput as a metric for system observability and continuous improvement, which aligns with some Agentic Engineering concepts. Still, it stops short of addressing autonomy, agency, or agentic decision frameworks, limiting its direct relevance.",
    "level": "Tertiary"
  },
  "Collective Intelligence": {
    "resourceId": "Throughput",
    "category": "Collective Intelligence",
    "calculated_at": "2025-07-23T12:06:51",
    "ai_confidence": 16.9,
    "ai_mentions": 0.2,
    "ai_alignment": 1.0,
    "ai_depth": 1.1,
    "ai_intent": 1.5,
    "ai_audience": 4.0,
    "ai_signal": 3.8,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 17.0,
    "reasoning": "The content focuses on throughput as a process and performance metric in Agile/Lean, emphasizing team/system efficiency, trends, and flow analysis using analytics tools. There are no direct mentions or discussions of human-AI collaboration, collective intelligence, distributed cognition, or the emergent benefits of human-AI teaming. The context is team-level delivery and process improvement, not human-AI partnerships. Minimal conceptual overlap (empirical feedback, team decisions) is tangential and generic.",
    "reasoning_summary": "This content is primarily about measuring flow efficiency in team delivery, not human-AI collaboration or the core tenets of collective intelligence. It lacks references to human-AI partnership or emergent capabilities.",
    "level": "Ignored"
  },
  "Agentic Software Delivery": {
    "resourceId": "Throughput",
    "category": "Agentic Software Delivery",
    "calculated_at": "2025-08-07T06:11:56",
    "ai_confidence": 21.84,
    "ai_mentions": 0.2,
    "ai_alignment": 2.4,
    "ai_depth": 2.1,
    "ai_intent": 4.8,
    "ai_audience": 7.2,
    "ai_signal": 7.1,
    "ai_penalties_applied": false,
    "ai_penalty_points": 0,
    "ai_penalty_details": "none",
    "final_score": 22.0,
    "reasoning": "The content describes throughput as a metric for flow efficiency, relevant to Agile/Lean delivery and observability. However, it does not mention agentic delivery, autonomous AI agents, or human-AI integration. Its focus is on empirical team inspection, not agentic orchestration.",
    "reasoning_summary": "The content relates to delivery metrics and observability but does not discuss agentic software delivery, AI agents, or human-agent collaboration. It only partially aligns with the category.",
    "level": "Ignored"
  }
}